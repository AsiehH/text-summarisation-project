text,summary
"  Consider the blow-up $X$ of $\mathbb{P}^3$ at 6 points in very general position and the 15 lines through the 6 points. We construct an infinite-order pseudo-automorphism $\phi_X$ on $X$, induced by the complete linear system of a divisor of degree 13. The effective cone of $X$ has infinitely many extremal rays and hence, $X$ is not a Mori Dream Space. The threefold $X$ has a unique anticanonical section which is a Jacobian K3 Kummer surface $S$ of Picard number 17. The restriction of $\phi_X$ on $S$ realizes one of Keum's 192 infinite-order automorphisms of Jacobian K3 Kummer surfaces. In general, we show the blow-up of $\mathbb{P}^n$ ($n\geq 3$) at $(n+3)$ very general points and certain 9 lines through them is not Mori Dream, with infinitely many extremal effective divisors. As an application, for $n\geq 7$, the blow-up of $\overline{M}_{0,n}$ at a very general point has infinitely many extremal effective divisors. ",Birational geometry of blow-ups of projective spaces along points and   lines
"  New deformed affine algebras A_{\hbar,\eta}(\hat{g}) are defined for any simply-laced classical Lie algebra g, which are generalizations of the algebra A_{\hbar,\eta}(\hat{sl_2}) recently proposed by Khoroshkin, Lebedev and Pakuliak (KLP). Unlike the work of KLP, we associate to the new algebras the structure of an infinite Hopf family of algebras in contrast to the one containing only finite number of algebras introduced by KLP. Bosonic representation for A_{\hbar,\eta}(\hat{g}) at level 1 is obtained, and it is shown that, by repeated application of Drinfeld-like comultiplications, a realization of A_{\hbar,\eta}(\hat{g}) at any positive integer level can be obtained. For the special case of g=sl_{r+1}, (r+1)-dimensional evaluation representation is given. The corresponding intertwining operators are defined and the intertwining relations are also derived explicitly. ","The algebra A_{\hbar,\eta}(\hat{g}) and Infinite Hopf family of algebras"
"  Currently, Deep Learning (DL) components within a Case-Based Reasoning (CBR) application often lack the comprehensive integration of available domain knowledge. The trend within machine learning towards so-called Informed machine learning can help to overcome this limitation. In this paper, we therefore investigate the potential of integrating domain knowledge into Graph Neural Networks (GNNs) that are used for similarity assessment between semantic graphs within process-oriented CBR applications. We integrate knowledge in two ways: First, a special data representation and processing method is used that encodes structural knowledge about the semantic annotations of each graph node and edge. Second, the message-passing component of the GNNs is constrained by knowledge on legal node mappings. The evaluation examines the quality and training time of the extended GNNs, compared to the stock models. The results show that both extensions are capable of providing better quality, shorter training times, or in some configurations both advantages at once. ",Informed Machine Learning for Improved Similarity Assessment in   Process-Oriented Case-Based Reasoning
"  Highly efficient and widely applicable working mechanisms that allow nanomaterials and devices to respond to external stimuli with controlled mechanical motions could make far-reaching impact to reconfigurable, adaptive, and robotic nanodevices. Here, we report an innovative mechanism that allows multifold reconfiguration of mechanical rotation of semiconductor nanoentities in electric (E) fields by visible light stimulation. When illuminated by light in the visible to infrared range, the rotation speed of semiconductor Si nanowires in electric fields can instantly increase, decrease, and even reverse the orientation depending on the intensity of the applied light and the AC E-field frequency. This multifold rotation configuration is highly efficient, instant, and facile. Switching between different modes can be simply controlled by the light intensity at an AC frequency. An array of experimentations, theoretical analysis, and simulations are carried out to understand the underlying principle, which can be attributed to the optically tunable polarization of Si nanowires in aqueous suspension and an external electric field. Finally, leveraging this newly discovered effect, we successfully differentiate semiconductor and metallic nanoentities in a non-contact and non-destructive manner. This research could inspire a new class of reconfigurable nanoelectromechanical and nanorobotic devices for optical sensing, communication, molecule release, detection, nanoparticle separation, and microfluidic automation. ",Visible -Light-Gated Reconfigurable Rotation of Nanomotors in Electric   Fields
"  Using experiments and theory, we show that light scattering by inhomogeneities in the index of refraction of a fluid can drive a large-scale flow. The experiment uses a near-critical, phase-separated liquid, which experiences large fluctuations in its index of refraction. A laser beam traversing the liquid produces a large-scale deformation of the interface and can cause a liquid jet to form. We demonstrate that the deformation is produced by a scattering-induced flow by obtaining good agreements between the measured deformations and those calculated assuming this mechanism. ",Liquid Transport Due to Light Scattering
"  In December 1911, Max Abraham published a paper on gravitation at the basis of which was Albert Einstein's 1911 June conclusion about a relationship between the velocity of light and the gravitational potential. In February 1912, Einstein published his work on static gravitational fields, which was based on his 1911 June theory. In March 1912, Einstein corrected his paper, but Abraham claimed that Einstein borrowed his equations; however, it was actually Abraham who needed Einstein's ideas and not the other way round. Einstein thought that Abraham converted to his theory of static fields while Abraham presumed exactly the opposite. Einstein then moved to Zurich and switched to new mathematical tools. He examined various candidates for generally covariant field equations, and already considered the field equations of his general theory of relativity about three years before he published them in November 1915. However, he discarded these equations only to return to them more than three years later. Einstein's 1912 theory of static fields finally led him to reject the generally covariant field equations and to develop limited generally covariant field equations. ",Einstein's 1912-1913 struggles with Gravitation Theory: Importance of   Static Gravitational Fields Theory
"  We consider a hyperk\""ahler reduction and describe it via frame bundles. Tracing the connection through the various reductions, we recover the results of Gocho and Nakajima. In addition, we show that the fibers of such a reduction are necessarily totally geodesic. As an independent result, we describe O'Neill's submersion tensors on principal bundles. ","Some Remarks on the Hyperk\""ahler Reduction"
"  Connected vehicles are poised to transform the field of environmental sensing by enabling acquisition of scientific data at unprecedented scales. Drawing on a real-world dataset collected from almost 70 connected vehicles, this study generates improved rainfall estimates by combining weather radar with windshield wiper observations. Existing methods for measuring precipitation are subject to spatial and temporal uncertainties that compromise high-precision applications like flash flood forecasting. Windshield wiper measurements from connected vehicles correct these uncertainties by providing precise information about the timing and location of rainfall. Using co-located vehicle dashboard camera footage, we find that wiper measurements are a stronger predictor of binary rainfall state than traditional stationary gages or radar-based measurements. We introduce a Bayesian filtering framework that generates improved rainfall estimates by updating radar rainfall fields with windshield wiper observations. We find that the resulting rainfall field estimate captures rainfall events that would otherwise be missed by conventional measurements. We discuss how these enhanced rainfall maps can be used to improve flood warnings and facilitate real-time operation of stormwater infrastructure. ",Vehicles as sensors: high-accuracy rainfall maps from windshield wiper   measurements
"  We use properties of doubly-magic nuclei, ab-initio calculations of low-density neutron matter, and of neutron stars to constrain the parameters of the Skyrme energy-density functional. We find all of these properties can be reproduced within a constrained family of Skyrme parameters. The maximum mass of a neutron star is found to be sensitive to the neutron effective mass. A value of [$ m^{*}_{\rm n}/m](\rho_0) = 0.60-0.65 $ is required to obtain a maximum neutron star mass of 2.1 solar masses. Using the constrained Skyrme functional with the aforementioned effective mass, the predicted radius for a neutron star of 1.4 solar masses is 12.4(1) km and $\Lambda$ = 423(40). ","Constraints on Skyrme Equations of State from Doubly Magic Nuclei,   Ab-Initio Calculations of Low-Density Neutron Matter, and Neutron Stars"
"  We review the spectral cover formalism for constructing both U(n) and SU(n) holomorphic vector bundles on elliptically fibered Calabi-Yau three-folds which admit a section. We discuss the allowed bases of these three-folds and show that physical constraints eliminate Enriques surfaces from consideration. Relevant properties of the remaining del Pezzo and Hirzebruch surfaces are presented. Restricting the structure group to SU(n), we derive, in detail, a set of rules for the construction of three-family particle physics theories with phenomenologically relevant gauge groups. We show that anomaly cancellation generically requires the existence of non-perturbative vacua containing five-branes. We illustrate these ideas by constructing four explicit three-family non-perturbative vacua. ",Holomorphic Vector Bundles and Non-Perturbative Vacua in M-Theory
"  In this paper, we introduce a notion of backdoors to Reiter's propositional default logic and study structural properties of it. Also we consider the problems of backdoor detection (parameterised by the solution size) as well as backdoor evaluation (parameterised by the size of the given backdoor), for various kinds of target classes (cnf, horn, krom, monotone, identity). We show that backdoor detection is fixed-parameter tractable for the considered target classes, and backdoor evaluation is either fixed-parameter tractable, in para-DP2 , or in para-NP, depending on the target class. ",Strong Backdoors for Default Logic
"  Suppose that $\mathcal{P}$ is a property that may be satisfied by a random code $C \subset \Sigma^n$. For example, for some $p \in (0,1)$, $\mathcal{P}$ might be the property that there exist three elements of $C$ that lie in some Hamming ball of radius $pn$. We say that $R^*$ is the threshold rate for $\mathcal{P}$ if a random code of rate $R^{*} + \varepsilon$ is very likely to satisfy $\mathcal{P}$, while a random code of rate $R^{*} - \varepsilon$ is very unlikely to satisfy $\mathcal{P}$. While random codes are well-studied in coding theory, even the threshold rates for relatively simple properties like the one above are not well understood.   We characterize threshold rates for a rich class of properties. These properties, like the example above, are defined by the inclusion of specific sets of codewords which are also suitably ""symmetric."" For properties in this class, we show that the threshold rate is in fact equal to the lower bound that a simple first-moment calculation obtains. Our techniques not only pin down the threshold rate for the property $\mathcal{P}$ above, they give sharp bounds on the threshold rate for list-recovery in several parameter regimes, as well as an efficient algorithm for estimating the threshold rates for list-recovery in general. ",Sharp threshold rates for random codes
"  We present a phase-resolved, optical, spectroscopic study of the eclipsing low-mass X-ray binary, EXO 0748-676 = UY Vol. The sensitivity of Gemini combined with our complete phase coverage makes for the most detailed blue spectroscopic study of this source obtained during its extended twenty-four year period of activity. We identify 12 optical emission lines and present trailed spectra, tomograms, and the first modulation maps of this source in outburst. The strongest line emission originates downstream of the stream-impact point, and this component is quite variable from night-to-night. Underlying this is weaker, more stable axisymmetric emission from the accretion disk. We identify weak, sharp emission components moving in phase with the donor star, from which we measure Kem = 329+/-26 km/s. Combining all the available dynamical constraints on the motion of the donor star with our observed accretion disk velocities we favor a neutron star mass close to canonical (M1~1.5Msun) and a very low mass donor (M2~0.1$Msun). We note that there is no evidence for CNO processing that is often associated with undermassive donor stars, however. A main sequence donor would require both a neutron star more massive than 2Msun and substantially sub-Keplerian disk emission. ",Gemini/GMOS Spectroscopy of EXO 0748-676 (=UY Vol) in Outburst
"  We consider a phenomenological model of inflation where the inflaton is the phase of a complex scalar field $\Phi$. Planck-suppressed operators of $\mathcal O(f^5/M_\mathrm{pl})$ modify the geometry of the vev $\langle \Phi \rangle$ at first order in the decay constant $f$, which adds a first order periodic term to the definition of the canonically normalized inflaton $\phi$. This correction to the inflaton induces a fixed number of extra oscillatory terms in the potential $V \sim \theta^p$. We derive the same result in a toy scenario where the vacuum $\langle \Phi \rangle$ is an ellipse with an arbitrarily large eccentricity. These extra oscillations change the form of the power spectrum as a function of scale $k$ and provide a possible mechanism for differentiating EFT-motivated inflation from models where the angular shift symmetry is a gauge symmetry. ",Power spectrum oscillations from Planck-suppressed operators in   effective field theory motivated monodromy inflation
"  We present WISEA J114724.10$-$204021.3, a young, low-mass, high probability member of the TW Hya association. WISEA J114724.10$-$204021.3 was discovered based on its red AllWISE color (W1$-$W2 = 0.63 mag) and extremely red 2MASS $J-K_{\rm S}$ color ($>$ 2.64 mag), the latter of which is confirmed with near-infrared photometry from the VISTA Hemisphere Survey ($J-K_{\rm S}$ = 2.57$\pm$0.03). Follow-up near-infrared spectroscopy shows a spectral type of L7 $\pm$ 1 as well as several spectroscopic indicators of youth. These include a peaked $H$-band shape and a steeper $K$-band slope, traits typically attributed to low surface gravity. The sky position, proper motion, and distance estimates of WISEA J114724.10$-$204021.3 are all consistent with membership in the $\sim$10 Myr old TW Hya association. Using the age of the TW Hya association and evolutionary models, we estimate the mass of WISEA J114724.10$-$204021.3 to be 5$-$13 $M_{\rm Jup}$, making it one of the youngest and lowest mass free-floating objects yet discovered in the Solar neighborhood. ",WISEA J114724.10-204021.3: A Free-Floating Planetary Mass Member of the   TW Hya Association
"  I review a number of the open questions about neutrino properties, critique recent hints of neutrino mass, and discuss one recently proposed neutrino mass matrix to illustrate the direction in which we may be headed. I also present one example of the implications of these new developments for astrophysics. ",Theoretical Issues in Neutrino Physics
"  Noises, artifacts, and loss of information caused by the magnetic resonance (MR) reconstruction may compromise the final performance of the downstream applications. In this paper, we develop a re-weighted multi-task deep learning method to learn prior knowledge from the existing big dataset and then utilize them to assist simultaneous MR reconstruction and segmentation from the under-sampled k-space data. The multi-task deep learning framework is equipped with two network sub-modules, which are integrated and trained by our designed iterative teacher forcing scheme (ITFS) under the dynamic re-weighted loss constraint (DRLC). The ITFS is designed to avoid error accumulation by injecting the fully-sampled data into the training process. The DRLC is proposed to dynamically balance the contributions from the reconstruction and segmentation sub-modules so as to co-prompt the multi-task accuracy. The proposed method has been evaluated on two open datasets and one in vivo in-house dataset and compared to six state-of-the-art methods. Results show that the proposed method possesses encouraging capabilities for simultaneous and accurate MR reconstruction and segmentation. ",Multi-task MR Imaging with Iterative Teacher Forcing and Re-weighted   Deep Learning
"  We show that the classical Pollard rho algorithm for discrete logarithms produces a collision in expected time O(sqrt(n)(log n)^3). This is the first nontrivial rigorous estimate for the collision probability for the unaltered Pollard rho graph, and is close to the conjectured optimal bound of O(sqrt(n)). The result is derived by showing that the mixing time for the random walk on this graph is O((log n)^3); without the squaring step in the Pollard rho algorithm, the mixing time would be exponential in log n. The technique involves a spectral analysis of directed graphs, which captures the effect of the squaring step. ",Spectral Analysis of Pollard Rho Collisions
"  We study quantized beamforming in wireless amplify-and-forward relay-interference networks with any number of transmitters, relays, and receivers. We design the quantizer of the channel state information to minimize the probability that at least one receiver incorrectly decodes its desired symbol(s). Correspondingly, we introduce a generalized diversity measure that encapsulates the conventional one as the first-order diversity. Additionally, it incorporates the second-order diversity, which is concerned with the transmitter power dependent logarithmic terms that appear in the error rate expression. First, we show that, regardless of the quantizer and the amount of feedback that is used, the relay-interference network suffers a second-order diversity loss compared to interference-free networks. Then, two different quantization schemes are studied: First, using a global quantizer, we show that a simple relay selection scheme can achieve maximal diversity. Then, using the localization method, we construct both fixed-length and variable-length local (distributed) quantizers (fLQs and vLQs). Our fLQs achieve maximal first-order diversity, whereas our vLQs achieve maximal diversity. Moreover, we show that all the promised diversity and array gains can be obtained with arbitrarily low feedback rates when the transmitter powers are sufficiently large. Finally, we confirm our analytical findings through simulations. ",Distributed Beamforming in Wireless Multiuser Relay-Interference   Networks with Quantized Feedback
  We present a simultaneous analysis of elastic and transition form factors of the nucleon. The calculations are performed in the framework of an algebraic model of baryons. Effects of meson cloud couplings are considered. ,Electromagnetic form factors of baryons in an algebraic approach
"  When people choose routes minimizing their individual delay, the aggregate congestion can be much higher compared to that experienced by a centrally-imposed routing. Yet centralized routing is incompatible with the presence of self-interested agents. How can we reconcile the two? In this paper we address this question within a repeated game framework and propose a fair incentive mechanism based on artificial currencies that routes selfish agents in a system-optimal fashion, while accounting for their temporal preferences. We instantiate the framework in a parallel-network whereby agents commute repeatedly (e.g., daily) from a common start node to the end node. Thereafter, we focus on the specific two-arcs case whereby, based on an artificial currency, the agents are charged when traveling on the first, fast arc, whilst they are rewarded when traveling on the second, slower arc. We assume the agents to be rational and model their choices through a game where each agent aims at minimizing a combination of today's discomfort, weighted by their urgency, and the average discomfort encountered for the rest of the period (e.g., a week). We show that, if prices of artificial currencies are judiciously chosen, the routing pattern converges to a system-optimal solution, while accommodating the agents' urgency. We complement our study through numerical simulations. Our results show that it is possible to achieve a system-optimal solution whilst reducing the agents' perceived discomfort by 14-20% when compared to a centralized optimal but urgency-unaware policy. ",Urgency-aware Optimal Routing in Repeated Games through Artificial   Currencies
"  We compute the electronic structure, spin and charge state of Fe ions, and structural phase stability of paramagnetic CaFeO$_3$ under pressure using a fully self-consistent in charge density DFT+dynamical mean-field theory method. We show that at ambient pressure CaFeO$_3$ is a negative charge-transfer insulator characterized by strong localization of the Fe $3d$ electrons. It crystallizes in the monoclinic $P2_1/n$ crystal structure with a cooperative breathing mode distortion of the lattice. While the Fe $3d$ Wannier occupations and local moments are consistent with robust charge disproportionation of Fe ions in the insulating $P2_1/n$ phase, the physical charge density difference around the structurally distinct Fe A and Fe B ions with the ``contracted'' and ``expanded'' oxygen octahedra, respectively, is rather weak, $\sim$0.04. This implies the importance of the Fe $3d$ and O $2p$ negative charge transfer and supports the formation of a bond-disproportionated state characterized by the Fe A $3d^{5-\delta}\underline{L}^{2-\delta}$ and Fe B $3d^5$ valence configurations with $\delta \ll 1$, in agreement with strong hybridization between the Fe $3d$ and O $2p$ states. Upon compression above $\sim$41 GPa CaFeO$_3$ undergoes the insulator-to-metal phase transition (IMT) which is accompanied by a structural transformation into the orthorhombic $Pbnm$ phase. The phase transition is accompanied by suppression of the cooperative breathing mode distortion of the lattice and, hence, results in the melting of bond disproportionation of the Fe ions. Our analysis suggests that the IMT transition is associated with orbital-dependent delocalization of the Fe $3d$ electrons and leads to a remarkable collapse of the local magnetic moments. Our results imply the crucial importance of the interplay of electronic correlations and structural effects to explain the properties of CaFeO$_3$. ",Metal-insulator transition and local-moment collapse in negative   charge-transfer CaFeO$_3$ under pressure
"  We show that the identification problem for a class of dynamic panel logit models with fixed effects has a connection to the truncated moment problem in mathematics. We use this connection to show that the sharp identified set of the structural parameters is characterized by a set of moment equality and inequality conditions. This result provides sharp bounds in models where moment equality conditions do not exist or do not point identify the parameters. We also show that the sharp identifying content of the non-parametric latent distribution of the fixed effects is characterized by a vector of its generalized moments, and that the number of moments grows linearly in T. This final result lets us point identify, or sharply bound, specific classes of functionals, without solving an optimization problem with respect to the latent distribution. ",Identification of Dynamic Panel Logit Models with Fixed Effects
  A comprehensive study of the problem of laminar film condensation with both a gravitational type body force and a moving vapour concurrent and parallel to the surface has been presented here. It demonstrates where both the body force and vapour velocity are significant through a comprehensive numerical solution obtained by a modified Keller box method. Important parameters governing condensation and heat transfer of pure vapour are determined. A perturbation analysis is applied in the leading edge and downstream regimes. The thin film approximations for the both regimes are obtained and compared with exact numerical solutions. ,Mixed-convection laminar film condensation on a semi-infinite vertical   plate
"  We report on systematic study of electronic transport in low-biased, disordered graphene nanowires. We reveal the emergence of unipolar transport as the defect concentration increases beyond 0.3\% where an almost insulating behaviour is observed on n-type channels whilst a metallic behaviour is observed in p-type channels. The conductance shows a plateau that extends through the entire side above the Dirac point (n-type) and the conductivity coincides with the minimum conductivity at the Dirac point. The minimum conductivity decreases with increasing defect concentration pointing out towards the absence of zero energy modes in the disordered samples. Raman spectroscopy and X-ray photoemission spectroscopy were used to probe the nature of the defects created by helium ion irradiation and revealed the presence of oxygen-carbon bonds as well as the presence of $sp^3$ configuration uncovered from the C KLL Auger spectrum. The observed behaviour is attributed to the dangling bonds created by sputtering of carbon atoms in graphene lattice by bombarding helium ions. The dangling bonds act as charge traps, pinning the Fermi level to the Dirac point. ",Defect-induced Fermi level pinning and suppression of ambipolar   behaviour in graphene
"  The growth of dust grains in protoplanetary disks is a necessary first step towards planet formation. This growth has been inferred via observations of thermal dust emission towards mature protoplanetary systems (age >2 million years) with masses that are, on average, similar to Neptune3. In contrast, the majority of confirmed exoplanets are heavier than Neptune. Given that young protoplanetary disks are more massive than their mature counterparts, this suggests that planet formation starts early, but evidence for grain growth that is spatially and temporally coincident with a massive reservoir in young disks remains scarce. Here, we report observations on a lack of emission of carbon monoxide isotopologues within the inner ~15 au of a very young (age ~100,000 years) disk around the Solar-type protostar TMC1A. By using the absence of spatially resolved molecular line emission to infer the gas and dust content of the disk, we conclude that shielding by millimeter-size grains is responsible for the lack of emission. This suggests that grain growth and millimeter-size dust grains can be spatially and temporally coincident with a mass reservoir sufficient for giant planet formation. Hence, planet formation starts during the earliest, embedded phases in the life of young stars. ",Evidence for the start of planet formation in a young circumstellar disk
"  It is discussed the problem on construction of optimal quadrature formulas in the sense of Sard in the space $L_2^{(m)}(0,1)$, when the nodes of quadrature formulas are equally spaced. Here the representations of optimal coefficients for any natural numbers $m$ and $N$ are found. ","Optimal quadrature formulas of closed type in the space $L_2^{(m)}(0,1)$"
"  Chaotic mixing in a closed vessel is studied experimentally and numerically in different 2-D flow configurations. For a purely hyperbolic phase space, it is well-known that concentration fluctuations converge to an eigenmode of the advection-diffusion operator and decay exponentially with time. We illustrate how the unstable manifold of hyperbolic periodic points dominates the resulting persistent pattern. We show for different physical viscous flows that, in the case of a fully chaotic Poincare section, parabolic periodic points at the walls lead to slower (algebraic) decay. A persistent pattern, the backbone of which is the unstable manifold of parabolic points, can be observed. However, slow stretching at the wall forbids the rapid propagation of stretched filaments throughout the whole domain, and hence delays the formation of an eigenmode until it is no longer experimentally observable. Inspired by the baker's map, we introduce a 1-D model with a parabolic point that gives a good account of the slow decay observed in experiments. We derive a universal decay law for such systems parametrized by the rate at which a particle approaches the no-slip wall. ",Slow decay of concentration variance due to no-slip walls in chaotic   mixing
"  The quark-level linear sigma model is employed to compute a variety of electromagnetic and weak observables of light mesons, including pion and kaon form factors and charge radii, charged-pion polarizabilities, semileptonic weak $K_{\ell3}$ decay, semileptonic weak radiative pion and kaon form factors, radiative decays of vector mesons, and nonleptonic weak $K_{2\pi}$ decay. The agreement of all these predicted observables with experiment is striking. In passing, the tight link between the linear sigma model and vector-meson dominance is shown. Some conclusions are drawn on the linear sigma model in connection with lattice and renormalization-group approaches to QCD. ",Meson Form Factors and the Quark-Level Linear Sigma Model
"  We report on the temperature dependence of the intrinsic resistance of long individual disordered single-wall carbon nanotubes. The resistance grows dramatically as the temperature is reduced, and the functional form is consistent with an activated behavior. These results are described by Coulomb blockade along a series of quantum dots. We occasionally observe a kink in the activated behavior that reflects the change of the activation energy as the temperature range is changed. This is attributed to charge hopping events between non-adjacent quantum dots, which is possible through cotunneling processes. ",Cotunneling and one-dimensional localization in individual single-wall   carbon nanotubes
"  The blue phases are observed in highly chiral liquid crystalline compositions that nascently organize into a three-dimensional, crystalline nanostructure. The periodicity of the unit cell lattice parameters is on the order of the wavelength of visible light and accordingly, the blue phases exhibit a selective reflection as a photonic crystal. Here, we detail the synthesis of liquid crystalline elastomers (LCEs) that retain blue phase I, blue phase II, and blue phase III. The mechanical properties and deformation of LCEs retaining the blue phases are contrasted to the cholesteric phase in fully solid elastomers with glass transition temperatures below room temperature. Mechanical deformation and chemical swelling of the lightly crosslinked polymer networks induces lattice asymmetry in the blue phase LCE evident in the tuning of the selective reflection. The lattice periodicity of the blue phase LCE is minimally affected by temperature. The oblique lattice planes of the blue phase LCEs tilt and red-shift in response to mechanical deformation. The retention of the blue phases in fully solid, elastomeric films could enable new functional implementations in photonics, sensing, and energy applications. ",Retention and Deformation of the Blue Phases in Liquid Crystalline   Elastomers
"  The one-loop induced Z --> g g gamma and Z-prime --> g g gamma decays are studied within the context of the minimal 331 model, which predicts the existence of new gauge bosons and three exotic quarks. It is found that the Z --> g g gamma decay is insensitive to the presence of the exotic quarks, as it is essentially governed by the first two families of known quarks. As to the Z-prime --> g g gamma decay, it is found that the exotic quark contribution dominates and that for a heavy Z-prime boson it leads to a Gamma(Z-prime --> g g gamma) that is more than one order of magnitude larger than that associated with Gamma(Z-prime --> g g g). ",Decays Z --> g g gamma and Z-prime --> g g gamma in the minimal 331   model
"  We consider the mass-subcritical Hartree equation with a homogeneous kernel, in the space of square integrable functions whose Fourier transform is integrable. We prove a global well-posedness result in this space. On the other hand, we show that the Cauchy problem is not even locally well-posed if we simply work in the space of functions whose Fourier transform is integrable. Similar results are proven when the kernel is not homogeneous, and is such that its Fourier transform belongs to some Lebesgue space. ",On the Cauchy problem for Hartree equation in the Wiener algebra
"  After an introduction to event generators we give an overview of developments in the field of joining matrix elements with parton showers. Starting with matrix element corrections, we also discuss implementations that match LO and NLO matrix elements with parton shower results correctly. Finally, the new Monte Carlo program Herwig++ is described. We report on its status of development and some major physics improvements. ",Event Generators - New Developments
"  We formulate a six dimensional $U(1)$ gauge theory compactified on a (two dimensional) sphere $S^2$ with flux and localized brane sources. Profiles of the lowest Kaluza-Klein (KK) wavefunctions and their masses are derived analytically. In contrast to ordinary sphere compactifications, the above setup can lead to the degeneracy of and the sharp localizations of the linearly independent lowest KK modes, depending on the number of branes and their tensions. Moreover, it can naturally accommodate CP violation in Yukawa interactions. ",Wavefunctions on $S^2$ with flux and branes
"  Flooding results in 8 billion dollars of damage annually in the US and causes the most deaths of any weather related event. Due to climate change scientists expect more heavy precipitation events in the future. However, no current datasets exist that contain both hourly precipitation and river flow data. We introduce a novel hourly river flow and precipitation dataset and a second subset of flash flood events with damage estimates and injury counts. Using these datasets we create two challenges (1) general stream flow forecasting and (2) flash flood damage estimation. We have created several publicly available benchmarks and an easy to use package. Additionally, in the future we aim to augment our dataset with snow pack data and soil index moisture data to improve predictions. ","FlowDB a large scale precipitation, river, and flash flood dataset"
"  This study investigates the deployment of a medium-scale neutrino detector near Turkey's first nuclear power plant, the Akkuyu Nuclear Power Plant. The aim of this detector is to become a modular testbed for new technologies in the fields of new detection media and innovative photosensors. Such technologies include Water-based Liquid Scintillator (WbLS), Large Area Picosecond Photo-Detectors (LAPPDs), dichroic Winston cones, and large area silicon photomultiplier modules. The detector could be used for instantaneous monitoring of the Akkuyu Nuclear Power Plant via its antineutrino flux. In addition to its physics and technological goals, it would be an invaluable opportunity for the nuclear and particle physics community in Turkey to play a role in the development of next generation of particle detectors in the field of neutrino physics. ",Water-based Liquid Scintillator Detector as a New Technology Testbed for   Neutrino Studies in Turkey
"  Several years ago we demonstrated that the Casimir energy for perfectly reflecting and imperfectly reflecting parallel plates gravitated normally, that is, obeyed the equivalence principle. At that time the divergences in the theory were treated only formally, without proper regularization, and the coupling to gravity was limited to the canonical energy-momentum-stress tensor. Here we strengthen the result by removing both of those limitations. We consider, as a toy model, massless scalar fields interacting with semitransparent ($\delta$-function) potentials defining parallel plates, which become Dirichlet plates for strong coupling. We insert space and time point-split regulation parameters, and obtain well-defined contributions to the self- energy of each plate, and the interaction energy between the plates. (This self-energy does not vanish even in the conformally-coupled, strong-coupled limit.) We also compute the local energy density, which requires regularization near the plates. In general, the energy density includes a surface energy that resides precisely on the boundaries. This energy is also regulated. The gravitational interaction of this well-defined system is then investigated, and it is verified that the equivalence principle is satisfied. ",How does Casimir energy fall? IV. Gravitational interaction of   regularized quantum vacuum energy
"  We give upper and lower bounds of perturbation series for transition densities, corresponding to additive gradient perturbations satisfying certain space-time integrability conditions. ",Estimates of gradient perturbation series
"  By quenched-randomly mixing local units of different spatial dimensionalities, we have studied Ising spin-glass systems on hierarchical lattices continuously in dimensionalities 1 =< d =< 3. The global phase diagram in temperature, antiferromagnetic bond concentration, and spatial dimensionality is calculated. We find that, as dimension is lowered, the spin-glass phase disappears to zero temperature at the lower-critical dimension d_c=2.431. Our system being a physically realizable system, this sets an upper limit to the lower-critical dimension in general for the Ising spin-glass phase. As dimension is lowered towards d_c, the spin-glass critical temperature continuously goes to zero, but the spin-glass chaos fully sustains to the brink of the disappearance of the spin-glass phase. The Lyapunov exponent, measuring the strength of chaos, is thus largely unaffected by the approach to d_c and shows a discontinuity to zero at d_c. ",A Lower Lower-Critical Spin-Glass Dimension from Quenched   Mixed-Spatial-Dimensional Spin Glasses
"  Holographic principle states that the maximum entropy of a system is its boundary area in Planck units. However, such a holographic entropy cannot be realized by the conventional quantum field theory. We need a new microscopic theory which naturally possesses all the holographic degrees of freedom. In this paper, we provide some preliminary thoughts on how to construct a theory with holographic degrees of freedom. It may shed light on the understanding of quantum properties of gravity and the early stage of the universe. ",Some thoughts on constructing a microscopic theory with holographic   degrees of freedom
"  Many modern theories which try to unify gravity with the Standard Model of particle physics, as e.g. string theory, propose two key modifications to the commonly known physical theories: i) the existence of additional space dimensions; ii) the existence of a minimal length distance or maximal resolution. While extra dimensions have received a wide coverage in publications over the last ten years (especially due to the prediction of micro black hole production at the LHC), the phenomenology of models with a minimal length is still less investigated. In a summer study project for bachelor students in 2010 we have explored some phenomenological implications of the potential existence of a minimal length. In this paper we review the idea and formalism of a quantum gravity induced minimal length in the generalised uncertainty principle framework as well as in the coherent state approach to non-commutative geometry. These approaches are effective models which can make model-independent predictions for experiments and are ideally suited for phenomenological studies. Pedagogical examples are provided to grasp the effects of a quantum gravity induced minimal length. This article is intended for graduate students and non-specialists interested in quantum gravity. ",Physics on Smallest Scales - An Introduction to Minimal Length   Phenomenology
"  It has been established that local lattice spin Hamiltonians can be used for universal adiabatic quantum computation. However, the 2-local model Hamiltonians used in these proofs are general and hence do not limit the types of interactions required between spins. To address this concern, the present paper provides two simple model Hamiltonians that are of practical interest to experimentalists working towards the realization of a universal adiabatic quantum computer. The model Hamiltonians presented are the simplest known QMA-complete 2-local Hamiltonians. The 2-local Ising model with 1-local transverse field which has been realized using an array of technologies, is perhaps the simplest quantum spin model but is unlikely to be universal for adiabatic quantum computation. We demonstrate that this model can be rendered universal and QMA-complete by adding a tunable 2-local transverse XX coupling. We also show the universality and QMA-completeness of spin models with only 1-local Z and X fields and 2-local ZX interactions. ",Realizable Hamiltonians for Universal Adiabatic Quantum Computers
"  The coupling of translational modes to the reorientational motion is an essential property of systems with internal orientational degrees of freedom. Due to their high complexity most of those systems (molecular crystals, glasses...) present a major puzzle for scientists. In this paper we analyze the Raman scattering of a relatively simple ferroelectric system, KTa(1-x)Nb(x)O(3), which may serve as a model for more complicated cases. We are showing that there is a strong coupling between translational and reorientational motion in the crystal. Our data suggest that this coupling is the main reason for the depolarized component of the second order Raman spectra and that it is also responsible for lowering of the frequency (softening) of the transverse acoustic mode down to the third of three transitions, below which reorientational motion is no longer allowed. ",Translational and rotational mode coupling in disordered ferroelectric   KTa(1-x)Nb(x)O(3) studied by Raman spectroscopy
"  The occurrence of a critical period of plasticity in the visual cortex has long been established, yet its function in normal development is not fully understood. Here we show that as the late phase of the critical period unfolds, different areas of cat visual cortex develop in a coordinated manner. Orientation columns in areas V1 and V2 become matched in size in regions that are mutually connected. The same age trend is found for such regions in the left and right brain hemisphere. Our results indicate that a function of critical period plasticity is to progressively coordinate the functional architectures of different cortical areas - even across hemispheres. ",Inter-areal coordination of columnar architectures during visual   cortical development
"  We modify Wythoff's game by allowing an additional move, which we call a ""split"", and show how the $P$-positions are coded by the Tribonacci word. We analyze the table of letter positions of arbitrary $k$-bonacci words and find a $\mathrm{mex}$-rule that generates the Quadribonacci table. ",A modification of Wythoff's Nim
"  Fibrewise T-duality (Fourier-Mukai transform) for D-branes on an elliptic Calabi-Yau three-fold $X$ is seen to have an expected adiabatic form for its induced cohomology operation only when an appropriately twisted operation resp. twisted charge is defined. Some differences with the case of $K3$ as well as connections with the spectral cover construction for bundles on $X$ are pointed out. In the context of mirror symmetry Kontsevich's association of line bundle twists (resp. a certain 'diagonal' operation) with monodromies (esp. the conifold monodromy) is made explicit and checked for two example models. Interpreting this association as a relation between FM transforms and monodromies, we express the fibrewise FM transform through known monodromies. The operation of fibrewise duality as well as the notion of a certain index relevant to the computation of the moduli space of the bundle is transported to the sLag side. Finally the moduli space for D4-branes and its behaviour under the FM transform is considered with an application to the spectral cover. ",Fourier-Mukai Transform and Mirror Symmetry for D-Branes on Elliptic   Calabi-Yau
"  Congestion is an important issue which researchers focus on in the Transmission Control Protocol (TCP) network environment. To keep the stability of the whole network, congestion control algorithms have been extensively studied. Queue management method employed by the routers is one of the important issues in the congestion control study. Active queue management (AQM) has been proposed as a router-based mechanism for early detection of congestion inside the network. In this paper we analyzed several active queue management algorithms with respect to their abilities of maintaining high resource utilization, identifying and restricting disproportionate bandwidth usage, and their deployment complexity. We compare the performance of FRED, BLUE, SFB, and CHOKe based on simulation results, using RED and Drop Tail as the evaluation baseline. The characteristics of different algorithms are also discussed and compared. Simulation is done by using Network Simulator(NS2) and the graphs are drawn using X- graph. ",Anakyzing the performance of Active Queue Management Algorithms
"  Atomic defect centers in diamond have been widely exploited in numerous quantum applications like quantum information, sensing, quantum photonics and so on. In this context, there is always a requirement to improve and optimize the preparation procedure to generate the defect centers in controlled fashion, and to explore new defect centers which can have the potential to overcome the current technological challenges. Through this letter we report enhancing the concentration of Ge and Xe vacancy centers in nanocrystalline diamond (NCD) by means of He+ irradiation. We have demonstrated controlled growth of NCD by chemical vapor deposition (CVD) and implantation of Ge and Xe ions into the CVD-grown samples. NCDs were irradiated with He+ ions and characterized through optical spectroscopy measurements. Recorded photoluminescence results revealed a clear signature of enhancement of the Xe-related and Ge vacancies in NCDs. ",Enhancement of concentration of XeV and GeV centers in nanocrystalline   diamond through He+ irradiation
"  We study spectral and thermodynamic properties of the Sachdev-Ye-Kitaev model, a variant of the $k$-body embedded random ensembles studied for several decades in the context of nuclear physics and quantum chaos. We show analytically that the fourth and sixth order energy cumulants vanish in the limit of large number of particles $N \to \infty$ which is consistent with a Gaussian spectral density. However, for finite $N$, the tail of the average spectral density is well approximated by a semi-circle law. The specific heat coefficient, determined numerically from the low temperature behavior of the partition function, is consistent with the value obtained by previous analytical calculations. For energy scales of the order of the mean level spacing we show that level statistics are well described by random matrix theory. Due to the underlying Clifford algebra of the model, the universality class of the spectral correlations depends on $N$. For larger energy separations we identify an energy scale that grows with $N$, reminiscent of the Thouless energy in mesoscopic physics, where deviations from random matrix theory are observed. Our results are a further confirmation that the Sachdev-Ye-Kitaev model is quantum chaotic for all time scales. According to recent claims in the literature, this is an expected feature in field theories with a gravity-dual. ",Spectral and thermodynamic properties of the Sachdev-Ye-Kitaev model
"  We consider a nanosystem connected to measurement probes via leads. When a magnetic flux is varied through a ring attached to one lead at a distance Lc from the nanosystem, the effective nanosystem transmission |ts|^2 exhibits Aharonov-Bohm oscillations if the electrons interact inside the nanosystem. These oscillations can be very large if Lc is small and if the nanosystem has almost degenerate levels which are put near the Fermi energy by a local gate. ",Effect of measurement probes upon the conductance of an interacting   nanosystem: Detection of an attached ring by non local many body effects
"  We study anharmonic effects in MgB2 by comparing Inelastic X-ray and Ramanscattering together with ab-initio calculations. Using high statistics and high q resolution measurements we show that the E2g mode linewidth is independent of temperature along Gamma-A. We show, contrary to previous claims, that the Raman-peak energy decreases as a function of increasing temperature, a behaviour inconsistent with all the anharmonic ab-initio calculations of the E2g mode at Gamma available in literature. These findings and the excellent agreement between the X-ray measured and ab-initio calculated phonon spectra suggest that anharmonicity is not the main mechanism determining the temperature behaviour of the Raman-peak energy. The Raman E2g peak position and linewidth can be explained by large dynamical effects in the phonon self-energy. In light of the present findings, the commonly accepted explanation of the reduced isotope effect in terms of anharmonic effects needs to be reconsidered. ",Anharmonic effects in MgB2? A comparative inelastic X-ray scattering and   Raman study
"  The amplification of a surface electromagnetic wave by means of ultrarelativistic monoenergetic electron bunch running over the flat plasma surface in absence of a magnetic field is studied theoretically. It is shown that when the ratio of electron bunch number density to plasma electron number density multiplied by a powered to 5 relativity factor is much higher than 1, i.e $\gamma^5 n_b/n_p>> 1$, the saturation field of the surface electromagnetic wave induced by trapping of bunch electrons gains the magnitude: $E_x=B_y\approx 0.16 \frac{\omega_p m c}{e} (\frac{2n_b}{\gamma^2 n_p})^{1/7}$ and does not approache the surface electromagnetic wave front breakdown threshold in plasma. The surface electromagnetic wave saturation energy density in plasma can exceed the electron bunch energy density. Here, we discuss the possibility of generation of superpower Teraherz radiation on a basis of such scheme. ",Amplification of a surface electromagnetic wave by running over plasma   surface ultrarelativistic electron bunch as a new scheme for generation of   Teraherz radiation
"  An efficient and compact approach to the inclusion of dissipative effects in Non-Equilibrium Green's Function (NEGF) simulations of electronic systems is introduced. The algorithm is based on two well known methods in the literature, firstly that of the so-called Recursive Green's Function (RGF) and secondly that of B\""uttiker probes. Numerical methods for exact evaluation of the Jacobian are presented by a direct extension to RGF which can be modularly included in any codebase that uses it presently. Then using both physical observations and numerical methods, the computation time of the B\""uttiker probe Jacobian is improved significantly. An improvement to existing phonon models within B\""uttiker probes is then demonstrated in the simulation of fully atomistic graphene nanoribbon based field effect transistors in n-i-n and p-i-n operation. ","B\""uttiker probes and the Recursive Green's Function; an efficient   approach to include dissipation in general configurations"
"  Recent multi-messenger detection of the binary neutron star merger (GW170817) energized the astrophysical community and encouraged further research for determination of nuclear physics observables. Comprehensive studies of atomic nuclei in the cosmos provide an opportunity for investigating these astrophysical phenomena and acquiring complementary information on stellar nucleosynthesis processes that can be verified using the latest nuclear data.   Evaluated Nuclear Data File (ENDF) libraries contain complete collections of reaction cross sections over the energy range relevant to astrophysics, fission yields and decay data. These data collections have been used worldwide in nuclear science, industry and national security applications. There is great interest in exploring the ENDF/B-VIII.0 and TALYS Evaluated Nuclear Data Library (TENDL-2015) for nuclear astrophysics purposes and comparing findings with the Karlsruhe Astrophysical Database of Nucleosynthesis in Stars (KADoNiS).   The Maxwellian-averaged cross sections (MACS) and astrophysical reaction rates have been calculated using the ENDF/B-VIII.0 and TENDL-2015 evaluated data sets. The calculated cross sections were combined with the solar system abundances and fitted using the classical model of stellar nucleosynthesis. Astrophysical rapid- and slow-neutron capture, $r$- and $s$-process, respectively, abundances were obtained from present data and compared with available values. Further analysis of MACS reveals potential evaluated libraries data deficiencies and a strong need for new measurements. The current results demonstrate a large nuclear astrophysics potential of evaluated libraries and mutually beneficial relations between nuclear industry and research efforts. ",Determination of Solar System R-Process Abundances using ENDF/B-VIII.0   and TENDL-2015 libraries
"  We have used the CFHT REDEYE infrared camera to obtain deep J and K' images of four fields in the globular cluster M13. The composite K, J-K color-magnitude diagram (CMD) extends from the upper red giant branch (RGB) to 2 magnitudes below the main sequence turn-off (MSTO). Selected [Fe/H]~ -1.6 isochrones from Bergbusch & VandenBerg (1992, ApJS, 81, 163) and Straniero & Chieffi (1991, ApJS, 76, 525) are transformed onto the near-infrared observational plane, and these suggest an age for M13 in the range 14-16 Gyr. We emphasize that any effort to estimate ages should be considered as tentative given uncertainties in the input physics; however, these uncertainties notwithstanding, comparisons between the near-infrared isochrones indicate that age differences of order +/-2 Gyr should be detectable among metal-poor clusters on the K, J-K plane. Building on this result, we find that the difference in J-K color between the MSTO and the base of the RGB in M13 is the same as in M4, and conclude that these clusters have similar ages. This conclusion is verified by comparing (1) the K brightnesses of the MSTO, and (2) the morphologies of optical CMDs. Finally, we investigate the mass function of main sequence stars in M13 with distances between 3 and 6 core radii from the cluster center. The mass functions in the interval 0.55 and 0.8 solar masses are relatively flat, independent of radius. Optical studies at larger radii have found non-zero mass function indices in this same mass interval, and we attribute this radial variation in mass function morphology to dynamical evolution. ",DEEP IR IMAGING OF GLOBULAR CLUSTERS. III. M13
"  The capacitated arc routing problem is a very important problem with many practical applications. This paper focuses on the large scale capacitated arc routing problem. Traditional solution optimization approaches usually fail because of their poor scalability. The divide-and-conquer strategy has achieved great success in solving large scale optimization problems by decomposing the original large problem into smaller sub-problems and solving them separately. For arc routing, a commonly used divide-and-conquer strategy is to divide the tasks into subsets, and then solve the sub-problems induced by the task subsets separately. However, the success of a divide-and-conquer strategy relies on a proper task division, which is non-trivial due to the complex interactions between the tasks. This paper proposes a novel problem decomposition operator, named the route cutting off operator, which considers the interactions between the tasks in a sophisticated way. To examine the effectiveness of the route cutting off operator, we integrate it with two state-of-the-art divide-and-conquer algorithms, and compared with the original counterparts on a wide range of benchmark instances. The results show that the route cutting off operator can improve the effectiveness of the decomposition, and lead to significantly better results especially when the problem size is very large and the time budget is very tight. ",Divide-and-Conquer Large Scale Capacitated Arc Routing Problems with   Route Cutting Off Decomposition
"  The Virtual Telescope for X-ray Observations (VTXO) will use lightweight Phase Fresnel Lenses (PFLs) in a virtual X-ray telescope with $\sim$1 km focal length and with $\sim$50 milli-arcsecond angular resolution. VTXO is formed by using precision formation flying of two SmallSats: a smaller OpticsSat that houses the PFLs and navigation beacons while a larger DetectorSat contains an X-ray camera, a precision start tracker, and the propulsion for the formation flying. The baseline flight dynamics uses a highly elliptical supersynchronous orbit allow the formation to hold in an inertial frame around the 90,000 km apogee for 10 hours of the 32.5 hour orbit with nearly a year mission lifetime. VTXO's fine angular resolution enables measuring the environments close to the central engines of bright compact X-ray sources. This X-ray imaging capability allows for the study of the effects of dust scattering near to the central objects such as Cyg X-3 and GX 5-1, for the search for jet structure near to the compact object in X-ray novae such as Cyg X-1 and GRS 1915+105, and for the search for structure in the termination shock of in the Crab pulsar wind nebula. The VTXO SmallSat and instrument designs, mission parameters, and science performance are described. VTXO development was supported as one of the selected 2018 NASA Astrophysics SmallSat Study (AS$^3$) missions. ",VTXO: The Virtual Telescope for X-ray Observations
  We study the spectrum and eigenstates of the quantum discrete Bose-Hubbard Hamiltonian in a finite one-dimensional lattice containing two bosons. The interaction between the bosons leads to an algebraic localization of the modified extended states in the normal mode space of the noninteracting system. Weight functions of the eigenstates in the space of normal modes are computed by using numerical diagonalization and perturbation theory. We find that staggered states do not compactify in the dilute limit for large chains. ,Quantum q-breathers in a finite Bose-Hubbard chain: The case of two   interacting bosons
"  Power loss in the electronic system is a very crucial limiting factor that can be reduced or minimized with the help of using the reversible logics ""a concept came from Thermodynamics"". In this paper the authors shows the concept of reversible logics for the Electronics system. The logical and physical designing approach is given in the paper in detail. The contradiction of logical and physical reversibility with the conventional CMOS designing is also shows and the solution of that contradiction is also proposed by the authors using adiabatic logic. This Paper gives a complete and clear idea if the thermodynamical concept for the electronics industries for power reduction. ",Towards the Solution of Power Dissipation in Electronics Systems through   Thermodynamics
"  Synchronisation algorithms are central to collaborative editing software. As collaboration is increasingly mediated by mobile devices, the energy efficiency for such algorithms is interest to a wide community of application developers. In this paper we explore the differential synchronisation (diffsync) algorithm with respect to energy consumption on mobile devices. Discussions within this paper are based on real usage data of PDF annotations via the Mendeley iOS app, which requires realtime synchronisation.   We identify three areas for optimising diffsync: a.) Empty cycles in which no changes need to be processed b.) tail energy by adapting cycle intervals and c.) computational complexity. Following these considerations, we propose a push-based diffsync strategy in which synchronisation cycles are triggered when a device connects to the network or when a device is notified of changes. ",Analysis of Differential Synchronisation's Energy Consumption on Mobile   Devices
"  We study theoretically the capillary-gravity waves created at the water-air interface by an external surface pressure distribution symmetrical about a point and moving at constant velocity along a linear trajectory. Within the framework of linear wave theory and assuming the fluid to be inviscid, we calculate the wave resistance experienced by the perturbation as a function of its size (compared to the capillary length). In particular, we analyze how the amplitude of the jump occurring at the minimum phase speed $c_{{\rm min}}=(4 g \gamma /\rho)^{1/4}$ depends on the size of the pressure distribution ($\rho$ is the liquid density, $\gamma$ is the water-air surface tension, and $g$ is the acceleration due to gravity). We also show how for pressure distributions broader than a few capillary lengths, the result obtained by Havelock for the wave resistance in the particular case of pure gravity waves (i.e., $\gamma = 0$) is progressively recovered. ",Wave Resistance for Capillary Gravity Waves: Finite Size Effects
"  We consider the multi-marginal optimal transport of aligning several compactly supported marginals on the Heisenberg group to minimize the total cost, which we take to be the sum of the squared Carnot-Carath\'eodory distances from the marginal points to their barycenter. Under certain technical hypotheses, we prove existence and uniqueness of optimal maps. We also point out several related open questions. ",Multi-marginal optimal transport on the Heisenberg group
"  Electroencephalogram (EEG) signals are frequently used in brain-computer interfaces (BCIs), but they are easily contaminated by artifacts and noises, so preprocessing must be done before they are fed into a machine learning algorithm for classification or regression. Spatial filters have been widely used to increase the signal-to-noise ratio of EEG for BCI classification problems, but their applications in BCI regression problems have been very limited. This paper proposes two common spatial pattern (CSP) filters for EEG-based regression problems in BCI, which are extended from the CSP filter for classification, by making use of fuzzy sets. Experimental results on EEG-based response speed estimation from a large-scale study, which collected 143 sessions of sustained-attention psychomotor vigilance task data from 17 subjects during a 5-month period, demonstrate that the two proposed spatial filters can significantly increase the EEG signal quality. When used in LASSO and k-nearest neighbors regression for user response speed estimation, the spatial filters can reduce the root mean square estimation error by 10.02-19.77%, and at the same time increase the correlation to the true response speed by 19.39-86.47%. ",Spatial Filtering for EEG-Based Regression Problems in Brain-Computer   Interface (BCI)
"  In this chapter we will highlight our experimental studies on natural human walking analysis and introduce a biologically inspired design for simple bipedal locomotion system of humanoid robots. Inspiration comes directly from human walking analysis and human muscles mechanism and control. A hybrid algorithm for walking gaits generation is then proposed as an innovative alternative to classically used kinematics and dynamic equations solving, the gaits include knee, ankle and hip trajectories. The proposed algorithm is an intelligent evolutionary based on particle swarm optimization paradigm. This proposal can be used for small size humanoid robots, with a knee an ankle and a hip and at least six Degrees of Freedom (DOF). ",Toward Intelligent Biped-Humanoids Gaits Generation
"  We consider the three CP-conserving dimension-6 operators that encode the leading new-physics effects in the triple gauge couplings. The contributions to the standard-model electromagnetic dipole and semi-leptonic vector and axial-vector interactions that arise from the insertions of these operators are calculated. We show that radiative and rare $B$-meson decays provide, under certain assumptions, constraints on two out of the three anomalous couplings that are competitive with the restrictions obtained from LEP II, Tevatron and LHC data. The constraints arising from the $Z \to b \bar b$ electroweak pseudo observables, $K \to \pi \nu \bar \nu$ and $\epsilon^\prime/\epsilon$ are also studied. ",Anomalous triple gauge couplings from $B$-meson and kaon observables
"  Earth-based observations are complicated by the opacity of Earth's ionosphere at very low frequencies and strong man-made radio frequency interference. This explains long standing interest in building a low frequency radio telescope on the farside of the Moon. Experience from ground-based observations near the ionospheric cutoff in dealing with the interference, ionosphere, and wide-field imaging/dynamic range problems provides crucial information for future radioastronomic experiments on the Moon. In this purpose we observed non-intensive solar bursts on the example of solar drift pairs (DP) at decameter-meter wavelengths with large and small arrays as well as by a single crossed active dipole. We used the large Ukrainian radio telescope UTR-2, the URAN-2 array, a subarray of the Giant Ukrainian radio telescope (GURT) and a single crossed active dipole to get the spectral properties of radio bursts at the frequency range of 8-80 MHz during solar observations on July 12, 2017. Statistical analysis of upper and lower frequencies, at which DPs are recorded, shows that the occurrence of forward DPs is more preferable at lower frequencies of the decameter range of observations in comparison with reverse DPs generated more likely at meter wavelengths. We conclude that DPs can be detected not only by antenna arrays, but even by a single crossed active dipole. Thus the latter antenna has a good potential for future low-frequency radio telescopes on the Moon. ",Solar bursts as can be observed from the lunar farside with a single   antenna at very low frequencies
"  Let $\mathbb{K}$ be a field, $R$ be an associative and commutative $\mathbb{K}$-algebra and $L$ be a Lie algebra over $\mathbb{K}$. We give some descriptions of injections from $L$ to Lie algebra of $\mathbb{K}$-derivations of $R$ in the terms of $L$. ",On finite-dimensional subalgebras of derivation Lie algebras
"  In this paper, we prove the existence of a common end point for a pair of multivalued mappings satisfying a new generalized weakly contractive condition in a complete metric space. Our result generalizes and extends many known results. ",End point of some generalized weakly contractive multivalued mappings
"  In order to better understand the hydroplaning phenomenon, local velocity measurements of water flow are performed inside the tire grooves of a real car rolling through a water puddle. Velocity fields are obtained by combining refraction Particle Image Velocimetry (r-PIV) illumination, seeding fluorescent particles and either the classical 2D2C or a 2D3C stereoscopic recording arrangements. The presence of some bubble columns inside the grooves is highlighted by separate visualisation using fluorescent contrast technique evidencing two phase flow characteristics. A simple predictive model is proposed supporting the r-PIV analysis. It provides useful information to adjust the focusing distance and to understand the effect of the bubble column presence on the recorded r-PIV images, especially for the seeding particles located in the upper part of the grooves, as fluorescent light is attenuated by the bubbles. Also, the predictions provided by the model are compatible with the measurements. The velocity fields inside the grooves are analysed using ensemble averaging performed over a set of independent snapshots, recorded with the same operating parameters. The variability of the longitudinal velocity distribution measured in a groove for several independent runs is explained by different mechanisms, like the random position of fluorescent seeding particles at various height of the groove, the hydrodynamic interactions between longitudinal and transverse grooves, and the random location of the transverse grooves from one run to an other. Three velocity components in cross-sections of the longitudinal grooves are obtained using the stereoscopic arrangement. They are compatible with the presence of some longitudinal vortices also assumed in the litterature. ",Analysis of the water flow inside tire grooves of a rolling car using   r-PIV
"  This paper contributes new insights into discretizing Coulomb collisions in kinetic plasma models. Building on the previous works [Carrillo et al. J. Comp. Phys. X 7:100066 (2020), Hirvijoki and Burby Phys. Plasmas 27(8):082307 (2020)], I propose deterministic discrete-time energy- and positivity-preserving, entropy-dissipating marker-particle schemes for the standard Landau collision operator and the electrostatic gyrokinetic Landau operator. In case of the standard Landau operator, the scheme preserves also the discrete-time kinetic momentum. The improvements, the extensions of the structure-preserving discretizations in [Carrillo et al. J. Comp. Phys. X 7:100066 (2020), Hirvijoki and Burby Phys. Plasmas 27(8):082307 (2020)] to discrete time, are made possible by exploiting the underlying metriplectic structure of the collision operators involved and the so-called discrete-gradient integrators. ",Structure-preserving marker-particle discretizations of Coulomb   collisions for particle-in-cell codes
"  We investigate 'activity' and 'quiescence' in galaxies at relatively high redshifts by modelling the line(and continuum) spectra of each object. The models account consistently for photoionization and shocks. We claim that the starburst effective temperature, the flux from an AGN, and the shock velocity are critical to activity. The results confirm that two sample galaxies show intense starburst activity with temperatures reaching Ts=2x10^5K and shock velocities Vs> 250 km/s, while for the remaining galaxies of our sample the models show quiescent star formation with Ts< 7x10^4K. A Seyfert 2 like AGN is proposed in one galaxy. The O/H relative abundances derived by the detailed modelling of the spectra are nearly solar for all the sample galaxies, in contrast to those obtained by direct methods. ",Activity and quiescence in galaxies at redshifts 1.4<z<3.5. The role of   the starburst temperature
"  Dengue fever impacts populations across the tropics. Dengue is caused by a mosquito transmitted flavivirus and its burden is projected to increase under future climate and development scenarios. The transmission process of dengue virus is strongly moderated by hydro-climatic conditions that impact the vector's life cycle and behavior. Here, we study the impact of rainfall seasonality and moisture availability on the monthly distribution of reported dengue cases in Sri Lanka. Through cluster analysis, we find an association between seasonal peaks of rainfall and dengue incidence with a two-month lag. We show that a hydrologically driven epidemiological model (HYSIR), which takes into account hydrologic memory in addition to the nonlinear dynamics of the transmission process, captures the two-month lag between rainfall and dengue cases seasonal peaks. Our analysis reveals a non-monotonic dependence of dengue cases on moisture, whereby an increase of cases with increasing moisture is followed by a reduction for very high levels of water availability. Improvement in prediction of the seasonal peaks in dengue incidence results from a seasonally varying dependence of transmission rate on water availability. ",Dengue Seasonality and Non-Monotonic Response to Moisture: A Model-Data   Analysis of Sri Lanka Incidence from 2011 to 2016
"  This is the sequel of the first part math.DG/0611281.   Here, the procedure of transgressing the families index theorem (the so-called $\eta$-form) is adapted to take in account the case of Dirac type operators with kernels of varying dimension.   The constructed form is then used to define the direct image under proper submersions of the ``free multiplicative'' $K$-theory which was defined in the first part, the behaviour of the characteristic classes on free multiplicative $K$-theory under submersion is studied.   Some universal caracterisation of the forms is provided.   Finally, combining our result with Bismut and Lott's results on direct images of flat vector bundles yields a ``Grothendieck-Riemann-Roch'' theorem for Nadel-Chern-Simons classes on relative $K$-theory for flat vector bundles which was defined in the first part. ","Direct image for multiplicative and relative $K$-theories from   transgression of the families index theorem, part 2"
"  The goal of this article is twofold: in a first part, we prove Gaussian estimates for the heat kernel of Schr{\""o}dinger operators delta + V whose potential V is ""small at infinity"" in an integral sense. In a second part, we prove sharp boundedness result for the associated Riesz transform with potential d(delta+V) --1/2. A characterization of p-hyperbolicity, which is of independent interest, is also proved. ",Heat Kernel And Riesz Transform Of Schrodinger Operators
"  Because noisy, intermediate-scale quantum (NISQ) machines accumulate errors quickly, we need new approaches to designing NISQ-aware algorithms and assessing their performance. Algorithms with characteristics that appear less desirable under ideal circumstances, such as lower success probability, may in fact outperform their ideal counterparts on existing hardware. We propose an adaptation of Grover's algorithm, subdividing the phase flip into segments to replace a digital counter and complex phase flip decision logic. We applied this approach to obtaining the best solution of the MAX-CUT problem in sparse graphs, utilizing multi-control, Toffoli-like gates with residual phase shifts. We implemented this algorithm on IBM Q processors and succeeded in solving a 5-node MAX-CUT problem, demonstrating amplitude amplification on four qubits. This approach will be useful for a range of problems, and may shorten the time to reaching quantum advantage. ",Subdivided Phase Oracle for NISQ Search Algorithms
"  We are given a stack of pancakes of different sizes and the only allowed operation is to take several pancakes from top and flip them. The unburnt version requires the pancakes to be sorted by their sizes at the end, while in the burnt version they additionally need to be oriented burnt-side down. We present an algorithm with the average number of flips, needed to sort a stack of n burnt pancakes, equal to 7n/4+O(1) and a randomized algorithm for the unburnt version with at most 17n/12+O(1) flips on average.   In addition, we show that in the burnt version, the average number of flips of any algorithm is at least n+\Omega(n/log n) and conjecture that some algorithm can reach n+\Theta(n/log n).   We also slightly increase the lower bound on g(n), the minimum number of flips needed to sort the worst stack of n burnt pancakes. This bound, together with the upper bound found by Heydari and Sudborough in 1997, gives the exact number of flips to sort the previously conjectured worst stack -I_n for n=3 mod 4 and n>=15. Finally we present exact values of f(n) up to n=19 and of g(n) up to n=17 and disprove a conjecture of Cohen and Blum by showing that the burnt stack -I_{15} is not the worst one for n=15. ",Average number of flips in pancake sorting
"  We prove uniqueness for continuity equations in Hilbert spaces $H$. The corresponding drift $F$ is assumed to be in a first order Sobolev space with respect to some Gaussian measure. As in previous work on the subject, the proof is based on commutator estimates which are infinite dimensional analogues to the classical ones due to DiPerna-Lions. Our general approach is, however, quite different since, instead of considering renormalized solutions, we prove a dense range condition implying uniqueness. In addition, compared to known results by Ambrosio-Figalli and Fang-Luo, we use a different approximation procedure, based on a more regularizing Ornstein-Uhlenbeck semigroup and consider Sobolev spaces of vector fields taking values in $H$ rather than the Cameron-Martin space of the Gaussian measure. This leads to different conditions on the derivative of $F$, which are incompatible with previous work on the subject. Furthermore, we can drop the usual exponential integrability conditions on the Gaussian divergence of $F$, thus improving known uniqueness results in this respect. ",Uniqueness for continuity equations in Hilbert spaces with weakly   differentiable drift
"  Low-rank matrices play a fundamental role in modeling and computational methods for signal processing and machine learning. In many applications where low-rank matrices arise, these matrices cannot be fully sampled or directly observed, and one encounters the problem of recovering the matrix given only incomplete and indirect observations. This paper provides an overview of modern techniques for exploiting low-rank structure to perform matrix recovery in these settings, providing a survey of recent advances in this rapidly-developing field. Specific attention is paid to the algorithms most commonly used in practice, the existing theoretical guarantees for these algorithms, and representative practical applications of these techniques. ",An overview of low-rank matrix recovery from incomplete observations
"  Unsupervised image-to-image translation aims to learn the mapping between two visual domains with unpaired samples. Existing works focus on disentangling domain-invariant content code and domain-specific style code individually for multimodal purposes. However, less attention has been paid to interpreting and manipulating the translated image. In this paper, we propose to separate the content code and style code simultaneously in a unified framework. Based on the correlation between the latent features and the high-level domain-invariant tasks, the proposed framework demonstrates superior performance in multimodal translation, interpretability and manipulation of the translated image. Experimental results show that the proposed approach outperforms the existing unsupervised image translation methods in terms of visual quality and diversity. ",Separating Content and Style for Unsupervised Image-to-Image Translation
"  We present Early Science observations with the Large Millimeter Telescope, AzTEC 1.1 mm continuum images and wide bandwidth spectra (73-111 GHz) acquired with the Redshift Search Receiver, towards four bright lensed submillimetre galaxies identified through the Herschel Lensing Survey-snapshot and the SCUBA-2 Cluster Snapshot Survey. This pilot project studies the star formation history and the physical properties of the molecular gas and dust content of the highest redshift galaxies identified through the benefits of gravitational magnification. We robustly detect dust continuum emission for the full sample and CO emission lines for three of the targets. We find that one source shows spectroscopic multiplicity and is a blend of three galaxies at different redshifts (z=2.040, 3.252 and 4.680), reminiscent of previous high-resolution imaging follow-up of unlensed submillimetre galaxies, but with a completely different search method, that confirm recent theoretical predictions of physically unassociated blended galaxies. Identifying the detected lines as 12CO (J_up=2-5) we derive spectroscopic redshifts, molecular gas masses, and dust masses from the continuum emission. The mean H_2 gas mass of the full sample is (2.0 +- 0.2) x 10^11 M_sun/\mu, and the mean dust mass is (2.0+-0.2) x 10^9 M_sun/\mu, where \mu=2-5 is the expected lens amplification. Using these independent estimations we infer a gas-to-dust ratio of \delta_GDR=55-75, in agreement with other measurements of submillimetre galaxies. Our magnified high-luminosity galaxies fall on the same locus as other high-redshift submillimetre galaxies, extending the L'_CO - L_FIR correlation observed for local luminous and ultraluminous infrared galaxies to higher FIR and CO luminosities. ",Early Science with the Large Millimeter Telescope: Observations of dust   continuum and CO emission lines of cluster-lensed submillimetre galaxies at   z=2.0-4.7
"  We study the K-theory of actions of diagonalizable group schemes on noetherian regular separated algebraic spaces: our main result shows how to reconstruct the K-theory ring of such an action from the K-theory rings of the loci where the stabilizers have constant dimension. We apply this to the calculation of the equivariant K-theory of toric varieties, and give conditions under which the Merkurjev spectral sequence degenerates, so that the equivariant K-theory ring determines the ordinary K-theory ring. We also prove a very refined localization theorem for actions of this type. ",Higher algebraic K-theory for actions of diagonalizable groups
"  We propose that the energetic major outburst of the supernova (SN) impostor SN 2009ip in September 2012 (outburst 2012b) was a mergerburst event, where two massive stars merged. The previous outbursts of 2009 and 2011 might have occurred near periastron passages of the binary system prior to the merger, in a similar manner to the luminosity peaks in the nineteenth century Great Eruption of the massive binary system Eta Carinae. The major 2012b outburst and the 2012a pre-outburst, resemble the light curve of the mergerburst event V838 Mon. A merger of an evolved star with a mass of M1~60-100Mo and a secondary main sequence star of M2~0.2-0.5M1 can account for the energy of SN 2009ip and for the high velocities of the ejected gas. The ejected nebula is expected to have a non-spherical structure, e.g. bipolar or even a more complicated morphology. ",Explaining the supernova impostor sn 2009ip as mergerburst
"  The use of a running coupling constant in renormalizable theories is well known, but the implementation of this idea for effective field theories with a dimensional coupling constant is in general less useful. Nevertheless there are multiple attempts to define running couplings including the effects of gravity, with varying conclusions. We sort through many of the issues involved, most particularly the idea of operator mixing and also the kinematics of crossing, using calculations in Yukawa and lambda phi^4 theory as illustrative examples. We remain in the perturbative regime. In some theories with a high permutation symmetry, such as lambda phi^4, a reasonable running coupling can be defined. However in most cases, such as Yukawa and gauge theories, a running coupling fails to correctly account for the energy dependence of the interaction strength. As a byproduct we also contrast on-shell and off-shell renormalizaton schemes and show that operators which are normally discarded, such as those that vanish by the equations of motion, are required for off-shell renormalization of effective field theories. Our results suggest that the inclusion of gravity in the running of couplings is not useful or universal in the description of physical processes. ",Running couplings and operator mixing in the gravitational corrections   to coupling constants
"  Motivated by the recent measurement of the primeval abundance of deuterium, we re-examine the nuclear inputs to big-bang nucleosynthesis (BBN). Using Monte-Carlo realization of the nuclear cross-section data to directly estimate the theoretical uncertainties for the yields of D, 3-He and 7-Li, we show that previous estimates were a factor of 2 too large. We sharpen the BBN determination of the baryon density based upon deuterium, rho_B = (3.6 +/- 0.4) * 10^{-31} g/cm^3 (Omega_B h^2 = 0.019 +/- 0.0024), which leads to a predicted 4-He abundance, Y_P = 0.246 +/- 0.0014 and a stringent limit to the equivalent number of light neutrino species: N_nu < 3.20 (all at 95% cl). The predicted 7-Li abundance, 7-Li/H = (3.5 + 1.1 - 0.9) * 10^{-10}, is higher than that observed in pop II stars, (1.7 +/- 0.3) * 10^{-10} (both, 95% cl). We identify key reactions and the energies where further work is needed. ",Sharpening the predictions of big-bang nucleosynthesis
"  We study several sources of theoretical uncertainty in the determination of parton distributions (PDFs) which may affect current PDF sets used for precision physics at the Large Hadron Collider, and explain discrepancies between them. We consider in particular the use of fixed-flavor versus variable-flavor number renormalization schemes, higher twist corrections, and nuclear corrections. We perform our study in the framework of the NNPDF2.3 global PDF determination, by quantifying in each case the impact of different theoretical assumptions on the output PDFs. We also study in each case the implications for benchmark cross sections at the LHC. We find that the impact in a global fit of a fixed-flavor number scheme is substantial, the impact of higher twists is negligible, and the impact of nuclear corrections is moderate and circumscribed. ",Theoretical issues in PDF determination and associated uncertainties
"  The Precision Time Protocol (PTP) aims to provide highly accurate and synchronised clocks. Its defining standard, IEEE 1588, has a security section (""Annex K"") which relies on symmetric-key secrecy. In this paper we present a detailed threat analysis of the PTP standard, in which we highlight the security properties that should be addressed by any security extension. During this analysis we identify a sequence of new attacks and non-cryptographic network-based defenses that mitigate them. We then suggest to replace Annex K's symmetric cryptography by an efficient elliptic-curve Public-Key signatures. We implemented all our attacks to demonstrate their effectiveness, and also implemented and evaluated both the network and cryptographic defenses. Our results show that the proposed schemes are extremely practical, and much more secure than previous suggestions. ",A Security Analysis and Revised Security Extension for the Precision   Time Protocol
"  In this article, we give a proof for that the cardinality of a function basis of the invariants for a finite dimensional real vector space by a compact group is lower bounded by the intuitive difference of the dimensions of the vector space and the group. An application is given to the space of third order three dimensional symmetric and traceless tensors, showing that each minimal integrity basis is an irreducible function basis, which solves a problem in applied mechanics. ",A Lower Bound for the Cardinality of Function Basis of Tensor Invariants
  In arXiv:0810.2076 we presented a conjecture generalizing the Cauchy formula for Macdonald polynomials. This conjecture encodes the mixed Hodge polynomials of the representation varieties of Riemann surfaces with semi-simple conjugacy classes at the punctures. We proved several results which support this conjecture. Here we announce new results which are consequences of those of arXiv:0810.2076. ,Topology of character varieties and representations of quivers
"  An interesting inference drawn by some Covid-19 epidemiological models is that there exists a proportion of the population who are not susceptible to infection -- even at the start of the current pandemic. This paper introduces a model of the immune response to a virus. This is based upon the same sort of mean-field dynamics as used in epidemiology. However, in place of the location, clinical status, and other attributes of people in an epidemiological model, we consider the state of a virus, B and T-lymphocytes, and the antibodies they generate. Our aim is to formalise some key hypotheses as to the mechanism of resistance. We present a series of simple simulations illustrating changes to the dynamics of the immune response under these hypotheses. These include attenuated viral cell entry, pre-existing cross-reactive humoral (antibody-mediated) immunity, and enhanced T-cell dependent immunity. Finally, we illustrate the potential application of this sort of model by illustrating variational inversion (using simulated data) of this model to illustrate its use in testing hypotheses. In principle, this furnishes a fast and efficient immunological assay--based on sequential serology--that provides a (i) quantitative measure of latent immunological responses and (ii) a Bayes optimal classification of the different kinds of immunological response (c.f., glucose tolerance tests used to test for insulin resistance). This may be especially useful in assessing SARS-CoV-2 vaccines. ",Dynamic causal modelling of immune heterogeneity
"  For theories of relativistic matter fields there exist two possible definitions of the stress-energy tensor, one defined by a variation of the action with the coframes at fixed connection, and the other at fixed torsion. These two stress-energy tensors do not necessarily coincide and it is the latter that corresponds to the Cauchy stress measured in the lab. In this note we discuss the corresponding issue for non-relativistic matter theories. We point out that while the physical non-relativistic stress, momentum, and mass currents are defined by a variation of the action at fixed torsion, the energy current does not admit such a description and is naturally defined at fixed connection. Any attempt to define an energy current at fixed torsion results in an ambiguity which cannot be resolved from the background spacetime data or conservation laws. We also provide computations of these quantities for some simple non-relativistic actions. ","Physical stress, mass, and energy for non-relativistic matter"
"  We report the magnetoresistance of ScSb, which is a semimetal with a simple rocksalt-type structure. We found that the magnetoresistance reaches $\sim$28000 % at 2 K and 14 T in our best sample, and it exhibits a resistivity plateau at low temperatures. The Shubnikov-de Haas oscillations extracted from the magnetoresistance data allow the full construction of the Fermi surface, including the so-called $\alpha_3$ pocket which has been missing in other closely related monoantimonides, and an additional hole pocket centered at $\Gamma$. The electron concentration ($n$) and the hole concentration ($p$) are extracted from our analysis, which indicate that ScSb is a nearly compensated semimetal with $n/p\approx0.93$. The calculated band structure indicates the absence of a band inversion, and the large magnetoresistance in ScSb can be attributed to the nearly perfect compensation of electrons and holes, despite the existence of the additional hole pocket. ",Extremely large magnetoresistance and the complete determination of the   Fermi surface topology in the semimetal ScSb
"  Analytic proof calculi are introduced for box and diamond fragments of basic modal fuzzy logics that combine the Kripke semantics of modal logic K with the many-valued semantics of G\""odel logic. The calculi are used to establish completeness and complexity results for these fragments. ","Towards a Proof Theory of G\""odel Modal Logics"
"  Increasing number of cyber-attacks demotivate people to use Information and Communication Technology (ICT) for industrial as well as day to day work. A main reason for the increasing number of cyber-attacks is mistakes that programmers make while developing software applications that are caused by usability issues exist in security Application Programming Interfaces (APIs). These mistakes make software vulnerable to cyber-attacks. In this paper, we attempt to take a step closer to solve this problem by proposing a methodology to evaluate the usability and identify usability issues exist in security APIs. By conducting a review of previous research, we identified 5 usability evaluation methodologies that have been proposed to evaluate the usability of general APIs and characteristics of those methodologies that would affect when using these methodologies to evaluate security APIs. Based on the findings, we propose a methodology to evaluate the usability of security APIs. ",A methodology to Evaluate the Usability of Security APIs
"  We show that every finite-dimensional quantum system with Markovian time evolution has an autonomous unitary dilation which can be dynamically decoupled. Since there is also always an autonomous unitary dilation which cannot be dynamically decoupled, this highlights the role of dilations in the control of quantum noise. We construct our dilation via a time-dependent version of Stinespring in combination with Howland's clock Hamiltonian and certain point-localised states, which may be regarded as a C*-algebraic analogue of improper bra-ket position eigenstates and which are hence of independent mathematical and physical interest. ",Control of quantum noise: on the role of dilations
"  In isotropic strain gradient elasticity, we decompose the strain gradient tensor into its irreducible pieces under the n-dimensional orthogonal group O(n). Using the Young tableau method for traceless tensors, four irreducible pieces (n>2), which are canonical, are obtained. In three dimensions, the strain gradient tensor can be decomposed into four irreducible pieces with 7+5+3+3 independent components whereas in two dimensions, the strain gradient tensor can be decomposed into three irreducible pieces with 2+2+2 independent components. The knowledge of these irreducible pieces is extremely useful when setting up constitutive relations and strain energy. ",Irreducible decomposition of strain gradient tensor in isotropic strain   gradient elasticity
"  Humans comprehend a natural scene at a single glance; painters and other visual artists, through their abstract representations, stressed this capacity to the limit. The performance of computer vision solutions matched that of humans in many problems of visual recognition. In this paper we address the problem of recognizing the genre (subject) in digitized paintings using Convolutional Neural Networks (CNN) as part of the more general dealing with abstract and/or artistic representation of scenes. Initially we establish the state of the art performance by training a CNN from scratch. In the next level of evaluation, we identify aspects that hinder the CNNs' recognition, such as artistic abstraction. Further, we test various domain adaptation methods that could enhance the subject recognition capabilities of the CNNs. The evaluation is performed on a database of 80,000 annotated digitized paintings, which is tentatively extended with artistic photographs, either original or stylized, in order to emulate artistic representations. Surprisingly, the most efficient domain adaptation is not the neural style transfer. Finally, the paper provides an experiment-based assessment of the abstraction level that CNNs are able to achieve. ",Can We Teach Computers to Understand Art? Domain Adaptation for   Enhancing Deep Networks Capacity to De-Abstract Art
"  For predictive maintenance, we examine one of the largest public datasets for machine failures derived along with their corresponding precursors as error rates, historical part replacements, and sensor inputs. To simplify the time and accuracy comparison between 27 different algorithms, we treat the imbalance between normal and failing states with nominal under-sampling. We identify 3 promising regression and discriminant algorithms with both higher accuracy (96%) and twenty-fold faster execution times than previous work. Because predictive maintenance success hinges on input features prior to prediction, we provide a methodology to rank-order feature importance and show that for this dataset, error counts prove more predictive than scheduled maintenance might imply solely based on more traditional factors such as machine age or last replacement times. ",Data Strategies for Fleetwide Predictive Maintenance
"  The concept of $\e$-randomizing quantum channels has been introduced by Hayden, Leung, Shor and Winter in connection with approximately encrypting quantum states. They proved using a discretization argument that sets of roughly $d \log d$ random unitary operators provide examples of such channels on $\C^d$. We show that a simple trick improves the efficiency of the argument and reduces the number of unitary operators to roughly $d$. ",A remark on the paper ``Randomizing quantum states: Constructions and   applications''
"  We consider a certain class of Schubert varieties of the affine Grassmannian of type A. By embedding a Schubert variety into a finite-dimensional Grassmannian, we construct an explicit basis of sections of the basic line bundle by restricting certain Pl\""ucker co-ordinates.   As a consequence, we write an explicit set of generators for the degree-one part of the ideal of the finite-dimensional embedding. This in turn gives a set of generators for the degree-one part of the ideal defining the affine Grassmannian inside the infinite Grassmannian which we conjecture to be a complete set of ideal generators.   We apply our results to the orbit closures of nilpotent matrices. We describe (in a characteristic-free way) a filtration for the coordinate ring of a nilpotent orbit closure and state a conjecture on the SL(n)-module structures of the constituents of this filtration. ",On Ideal Generators for Affine Schubert Varieties
"  A hom-associative algebra is an algebra whose associativity is twisted by an algebra homomorphism. It was previously shown by the author that the Hochschild cohomology of a hom-associative algebra $A$ carries a Gerstenhaber structure. In this short paper, we show that this Gerstenhaber structure together with certain operations on the Hochschild homology of $A$ makes a noncommutative differential calculus. As an application, we obtain a Batalin-Vilkovisky algebra structure on the Hochschild cohomology of a regular unital symmetric hom-associative algebra. ",Noncommutative differential calculus on (co)homology of hom-associative   algebras
"  Carr and Hawking showed that the proper size of a spherical overdense region surrounded by a flat FRW universe cannot be arbitrarily large as otherwise the region would close up on itself and become a separate universe. From this result they derived a condition connecting size and density of the overdense region ensuring that it is part of our universe. Carr used this condition to obtain an upper bound for the density fluctuation amplitude with the property that for smaller amplitudes the formation of a primordial black hole is possible, while larger ones indicate a separate universe. In contrast, we find that the appearance of a maximum is not a consequence of avoiding separate universes but arises naturally from the geometry of the chosen slicing. Using instead of density a volume fluctuation variable reveals that a fluctuation is a separate universe iff this variable diverges on superhorizon scales. Hence Carr's and Hawking's condition does not pose a physical constraint on density fluctuations. The dynamics of primordial black hole formation with an initial curvature fluctuation amplitude larger than the one corresponding to the maximum density fluctuation amplitude was previously not considered in detail and so we compare it to the well-known case where the amplitude is smaller by presenting embedding and conformal diagrams of both types in dust spacetimes. ",Separate Universes Do Not Constrain Primordial Black Hole Formation
"  We present the first quantum anonymous notification (QAN) protocol that introduces anonymity and paves the way for anonymous secure quantum communication in quantum networks. QAN protocol has applications ranging from multiparty quantum computation to quantum internet. We utilize the QAN protocol to propose an anonymous quantum private comparison protocol in an $n$-node quantum network. This protocol can compare private information of any $2 \leq k \leq n$ parties with the help of the remaining $n-k$ parties and a semi-honest third party. These protocols feature a traceless property, i.e., encoding operations cannot be traced back to their originating sources. Security analysis shows that this protocol is robust against external adversaries and malicious participants. ",Quantum Anonymity for Quantum Networks
"  Light-matter coupling in van der Waal's materials holds significant promise in realizing Bosonic condensation and superfluidity. The underlying semiconductor's crystal asymmetry, if any, can be utilized to form anisotropic half-light half-matter quasiparticles. We demonstrate generation of such highly anisotropic exciton-polaritons at the interface of a biaxial layered semiconductor, stacked on top of a distributed Bragg reflector. The spatially confined photonic mode in this geometry couples with polarized excitons and their Rydberg states, creating a system of highly anisotropic polariton manifolds, displaying Rabi splitting of up to 68 meV. Rotation of the incident beam polarization is used to tune coupling strength and smoothly switch regimes from weak to strong coupling, while also enabling transition from one three-body coupled oscillator system to another. Light-matter coupling is further tunable by varying the number of weakly coupled optically active layers. Our work provides a versatile method of engineering devices for applications in polarization-controlled polaritonics and optoelectronics. ",Interfacial anisotropic exciton-polariton manifolds in ReS$_2$
"  This article proposes a transfer reinforcement learning (RL) based adaptive energy managing approach for a hybrid electric vehicle (HEV) with parallel topology. This approach is bi-level. The up-level characterizes how to transform the Q-value tables in the RL framework via driving cycle transformation (DCT). Especially, transition probability matrices (TPMs) of power request are computed for different cycles, and induced matrix norm (IMN) is employed as a critical criterion to identify the transformation differences and to determine the alteration of the control strategy. The lower-level determines how to set the corresponding control strategies with the transformed Q-value tables and TPMs by using model-free reinforcement learning (RL) algorithm. Numerical tests illustrate that the transferred performance can be tuned by IMN value and the transfer RL controller could receive a higher fuel economy. The comparison demonstrates that the proposed strategy exceeds the conventional RL approach in both calculation speed and control performance. ",Adaptive Energy Management for Real Driving Conditions via Transfer   Reinforcement Learning
"  We develop a forcing poset with finite conditions which adds a partial square sequence on a given stationary set, with adequate sets of models as side conditions. We then develop a kind of side condition product forcing for simultaneously adding partial square sequences on multiple stationary sets. We show that certain quotients of such forcings have the $\omega_1$-approximation property. We apply these ideas to prove, assuming the consistency of a greatly Mahlo cardinal, that it is consistent that the approachability ideal $I[\omega_2]$ does not have a maximal set modulo clubs. ",The Approachability Ideal Without a Maximal Set
"  We use the SYK family of models with $N$ Majorana fermions to study the complexity of time evolution, formulated as the shortest geodesic length on the unitary group manifold between the identity and the time evolution operator, in free, integrable, and chaotic systems. Initially, the shortest geodesic follows the time evolution trajectory, and hence complexity grows linearly in time. We study how this linear growth is eventually truncated by the appearance and accumulation of conjugate points, which signal the presence of shorter geodesics intersecting the time evolution trajectory. By explicitly locating such ""shortcuts"" through analytical and numerical methods, we demonstrate that: (a) in the free theory, time evolution encounters conjugate points at a polynomial time; consequently complexity growth truncates at $O(\sqrt{N})$, and we find an explicit operator which ""fast-forwards"" the free $N$-fermion time evolution with this complexity, (b) in a class of interacting integrable theories, the complexity is upper bounded by $O({\rm poly}(N))$, and (c) in chaotic theories, we argue that conjugate points do not occur until exponential times $O(e^N)$, after which it becomes possible to find infinitesimally nearby geodesics which approximate the time evolution operator. Finally, we explore the notion of eigenstate complexity in free, integrable, and chaotic models. ",Complexity Growth in Integrable and Chaotic Models
"  Sunspots are the most spectacular manifestation of solar magnetism, yet, 99% of the solar surface remains 'quiet' at any time of the solar cycle. The quiet sun is not void of magnetic fields, though; they are organized at smaller spatial scales and evolve relatively fast, which makes them difficult to detect. Thus, although extensive quiet Sun magnetism would be a natural driver to a uniform, steady heating of the outer solar atmosphere, it is not clear what the physical processes involved would be due to lack of observational evidence. We report the topology and dynamics of the magnetic field in very quiet regions of the Sun from spectropolarimetric observations of the Hinode satellite, showing a continuous injection of magnetic flux with a well organized topology of Omega-loop from below the solar surface into the upper layers. At first stages, when the loop travels across the photosphere, it has a flattened (staple-like) geometry and a mean velocity ascent of $\sim3$ km/s. When the loop crosses the minimum temperature region, the magnetic fields at the footpoints become almost vertical and the loop topology ressembles a potential field. The mean ascent velocity at chromospheric height is $\sim12$ km/s. The energy input rate of these small-scale loops in the lower boundary of the chromosphere is (at least) of 1.4x10^6-2.2x10^7 erg cm-2 s-1. Our findings provide empirical evidence for solar magnetism as a multi-scale system, in which small-scale low-flux magnetism plays a crucial role, at least as important as active regions, coupling different layers of the solar atmosphere and being an important ingredient for chromospheric and coronal heating models. ",Small magnetic loops connecting the quiet surface and the hot outer   atmosphere of the Sun
  We study the quenched and unquenched lattice Schwinger model with Wilson fermions. The lowest non-trivial order of the systematic expansion recently proposed by Sexton and Weingarten is shown to allow good estimates of long distance physics from quenched configurations. Results for the static potential and the lowest bound state mass are presented. ,Unquenching the Schwinger Model (revised)
"  We investigate the formation of discs within binary systems where at least one component has left the main sequence. In particular we calculate the occurrence rates of systems which can host long-lived, massive discs that may be able to support the formation of planets. We synthesize a population based on Milky Way properties, using both theoretical and observational inputs to constrain key properties such as the shape of the initial mass function, binary fraction, and mass transfer physics. We predict 0.26\% of binary systems will host Second generation discs (where the primary has evolved), and 0.13\% of systems will host Third generation discs (where the secondary also evolves). For the Milky Way, this translates into 130 million and 90 million Second and Third generation systems respectively from an estimated total of 50 billion binary systems. Of these systems that form discs, we estimate approximately 20\% of Second and 3.8\% of Third generation discs have enough mass to form a planetary system. We speculate on how the process of planet formation differs in these systems from conventional planet formation in protostellar discs. ",The galactic rate of second and third generation disc and planet   formation
  We use an off-lattice discretization of fractional Brownian motion and a Metropolis Algorithm to determine the asymptotic scaling of this discretized fractional Brownian motion under the influence of an excluded volume as in the Edwards and Domb-Joyce models. We find a good agreement between the Flory index describing the scaling of end-to-end length with a mean field formula proposed earlier for this class of models. ,Scaling Properties of Weakly Self-Avoiding Fractional Brownian Motion in   One Dimension
"  Expression for the Witten-Nester 4-spinor 3-form of the Hamiltonian density of gravitational field in the asymptotically flat space-time in terms of the Sommers-Sen spinors, direct with a certain orthonormal three-frame connect, is obtained. A direct connection between the one and the ADM Hamiltonian density in the Sen-Witten frame is established on this basis. ",Sen-Witten orthonormal three-frame and gravitational energy   quasilocalization
"  Digitally unwrapping images of paper sheets is crucial for accurate document scanning and text recognition. This paper presents a method for automatically rectifying curved or folded paper sheets from a few images captured from multiple viewpoints. Prior methods either need expensive 3D scanners or model deformable surfaces using over-simplified parametric representations. In contrast, our method uses regular images and is based on general developable surface models that can represent a wide variety of paper deformations. Our main contribution is a new robust rectification method based on ridge-aware 3D reconstruction of a paper sheet and unwrapping the reconstructed surface using properties of developable surfaces via $\ell_1$ conformal mapping. We present results on several examples including book pages, folded letters and shopping receipts. ",Multiview Rectification of Folded Documents
  Let $f:T\longrightarrow T$ be a mapping and $\Omega$ be a subset of $T$ which intersects every (positive) orbit of $f$. Assume that there are given a second dynamical system $\lambda:Y\longrightarrow Y$ and a mapping $\alpha:\Omega\longrightarrow Y$. For $t\in T$ let $\delta(t)$ be the smallest $k$ such that $f^k(t)\in\Omega$ and let $t_\Omega:=f^{\delta(t)}(t)$ be the first element in the orbit of $t$ which belongs to $\Omega$. Then we define a mapping $F:T\longrightarrow Y$ by $F(t):=\lambda^{\delta(t)}(t_\Omega)$. ,Random functions from coupled dynamical systems
"  We give necessary and sufficient conditions for a big and nef line bundle L of any degree on a K3 surface or Enriques surface to be k-very ample and k-spanned. Furthermore, we give necessary and sufficient conditions for a spanned and big line bundle on a K3 surface to be birationally k-very ample and birationally k-spanned, and relate these concepts to the Clifford index and gonality of smooth curves in |L|. ",On kth-order embeddings of K3 surfaces and Enriques surfaces
"  We solved with a numerical procedure the HTL improved ladder DS equation for the retarded fermion self-energy function $\Sigma_R$ to study the spontaneous generation of fermion mass in thermal QCD/QED, and studied the gauge-dependence of the solution within a general covariant gauge where the gauge parameter $\xi$ is any constant number.   With the numerical solutions thus obtained, we found the followings; i) The fermion wave function renormalization function $A(P)$ always deviates largely from unity even at the momentum where the mass is defined, thus the corresponding solutions explicitly contradict with the Ward-Takahashi identity. ii) As a result, the obtained solutions strongly depend on the choice of gauge parameters: the critical temperatures and the critical coupling constants significantly change gauge by gauge. In all gauges we studied in the present analysis, we could not find any solution, having a possibility to be consistent with the Ward-Takahashi identity. Thus we are forced to investigate the procedure to find a gauge which enables us to get a solution being consistent with the Ward-Takahashi identity, otherwise we can not obtain any physically sensible conclusions through the analysis of the point-vertex ladder DS equation no matter how the gauge propagator gets improved. ",Analysis of the Phase Structure of Thermal QED/QCD through the HTL   Improved Ladder Dyson-Schwinger Equation --On the Gauge Dependence of the   Solution--
"  The conventional oblique parameters analyses of precision electroweak data can be consistently cast in the modern framework of the Standard Model effective field theory (SMEFT) when restrictions are imposed on the SMEFT parameter space so that it describes universal theories. However, the usefulness of such analyses is challenged by the fact that universal theories at the scale of new physics, where they are matched onto the SMEFT, can flow to nonuniversal theories with renormalization group (RG) evolution down to the electroweak scale, where precision observables are measured. The departure from universal theories at the electroweak scale is not arbitrary, but dictated by the universal parameters at the matching scale. But to define oblique parameters, and more generally universal parameters at the electroweak scale that directly map onto observables, additional prescriptions are needed for the treatment of RG-induced nonuniversal effects. We perform a RG analysis of the SMEFT description of universal theories, and discuss the impact of RG on simplified, universal-theories-motivated approaches to fitting precision electroweak and Higgs data. ",Renormalization group evolution of the universal theories EFT
"  In this work, we generalize the numerical approach to Gaudin models developed earlier by us to degenerate systems showing that their treatment is surprisingly convenient from a numerical point of view. In fact, high degeneracies not only reduce the number of relevant states in the Hilbert space by a non negligible fraction, they also allow to write the relevant equations in the form of sparse matrix equations. Moreover, we introduce a new inversion method based on a basis of barycentric polynomials which leads to a more stable and efficient root extraction which most importantly avoids the necessity of working with arbitrary precision. As an example we show the results of our procedure applied to the Richardson model on a square lattice. ",Bethe Ansatz and Ordinary Differential Equation Correspondence for   Degenerate Gaudin Models
  We show experimentally that workload-based AP-STA associations can improve system throughput significantly. We present a predictive model that guides optimal resource allocations in dense Wi-Fi networks and achieves 72-77% of the optimal throughput with varying training data set sizes using a 3-day trace of real cable modem traffic. ,A Learning Approach to Wi-Fi Access
"  Modern machine learning focuses on highly expressive models that are able to fit or interpolate the data completely, resulting in zero training loss. For such models, we show that the stochastic gradients of common loss functions satisfy a strong growth condition. Under this condition, we prove that constant step-size stochastic gradient descent (SGD) with Nesterov acceleration matches the convergence rate of the deterministic accelerated method for both convex and strongly-convex functions. We also show that this condition implies that SGD can find a first-order stationary point as efficiently as full gradient descent in non-convex settings. Under interpolation, we further show that all smooth loss functions with a finite-sum structure satisfy a weaker growth condition. Given this weaker condition, we prove that SGD with a constant step-size attains the deterministic convergence rate in both the strongly-convex and convex settings. Under additional assumptions, the above results enable us to prove an O(1/k^2) mistake bound for k iterations of a stochastic perceptron algorithm using the squared-hinge loss. Finally, we validate our theoretical findings with experiments on synthetic and real datasets. ",Fast and Faster Convergence of SGD for Over-Parameterized Models and an   Accelerated Perceptron
"  In this paper, we study a class of nonlocal dispersion equation with monostable nonlinearity in $n$-dimensional space u_t - J\ast u +u+d(u(t,x))= \int_{\mathbb{R}^n} f_\beta (y) b(u(t-\tau,x-y)) dy, u(s,x)=u_0(s,x), s\in[-\tau,0], \ x\in \mathbb{R}^n} \] where the nonlinear functions $d(u)$ and $b(u)$ possess the monostable characters like Fisher-KPP type, $f_\beta(x)$ is the heat kernel, and the kernel $J(x)$ satisfies ${\hat J}(\xi)=1-\mathcal{K}|\xi|^\alpha+o(|\xi|^\alpha)$ for $0<\alpha\le 2$. After establishing the existence for both the planar traveling waves $\phi(x\cdot{\bf e}+ct)$ for $c\ge c_*$ ($c_*$ is the critical wave speed) and the solution $u(t,x)$ for the Cauchy problem, as well as the comparison principles, we prove that, all noncritical planar wavefronts $\phi(x\cdot{\bf e}+ct)$ are globally stable with the exponential convergence rate $t^{-n/\alpha}e^{-\mu_\tau}$ for $\mu_\tau>0$, and the critical wavefronts $\phi(x\cdot{\bf e}+c_*t)$ are globally stable in the algebraic form $t^{-n/\alpha}$. The adopted approach is Fourier transform and the weighted energy method with a suitably selected weight function. These rates are optimal and the stability results significantly develop the existing studies for nonlocal dispersion equations. ",Planar Traveling Waves For Nonlocal Dispersion Equation With Monostable   Nonlinearity
"  This is a survey paper on algorithms for solving problems in 3-dimensional topology. In particular, it discusses Haken's approach to the recognition of the unknot, and recent variations. ",Algorithms for recognizing knots and 3-manifolds
"  We study bifurcations of a three-dimensional diffeomorphism, $g_0$, that has a quadratic homoclinic tangency to a saddle-focus fixed point with multipliers $(\lambda e^{i\vphi}, \lambda e^{-i\vphi}, \gamma)$, where $0<\lambda<1<|\gamma|$ and $|\lambda^2\gamma|=1$. We show that in a three-parameter family, $g_{\eps}$, of diffeomorphisms close to $g_0$, there exist infinitely many open regions near $\eps =0$ where the corresponding normal form of the first return map to a neighborhood of a homoclinic point is a three-dimensional H\'enon-like map. This map possesses, in some parameter regions, a ""wild-hyperbolic"" Lorenz-type strange attractor. Thus, we show that this homoclinic bifurcation leads to a strange attractor. We also discuss the place that these three-dimensional H\'enon maps occupy in the class of quadratic volume-preserving diffeomorphisms. ",Chaotic dynamics of three-dimensional H\'enon maps that originate from a   homoclinic bifurcation
"  Research on success factors involved in the agile transformation process is not conclusive and there is still need for guidelines to help in the transformation process considering the organizational context (culture, values, needs, reality and goals). The usage of success factors as a tool to help agile adoption raises the following research question: What are the success factors for an organization and their teams in preparation for the agile transformation process? This research presents an assessment of the organizational environment including the company's goals and the perception of the team members to provide awareness of how the organization should prepare for the next steps in the agile transformation. The findings show that a company based in Chicago, USA, succeeded implementing customer involvement and self-organized teams but faces challenges with measurement models and training. The main contribution of the research is understand which success factors exist in their environment and how they can be used during agile adoption. ",Assessing Agile Transformation Success Factors
"  Projected Hartree-Fock theory provides an accurate description of many kinds of strong correlation but does not properly describe weakly correlated systems. Coupled cluster theory, in contrast, does the opposite. It therefore seems natural to combine the two so as to describe both strong and weak correlations with high accuracy in a relatively black-box manner. Combining the two approaches, however, is made more difficult by the fact that the two techniques are formulated very differently. In earlier work, we showed how to write spin-projected Hartree-Fock in a coupled-cluster-like language. Here, we fill in the gaps in that earlier work. Further, we combine projected Hartree-Fock and coupled cluster theory in a variational formulation and show how the combination performs for the description of the Hubbard Hamiltonian and for several small molecular systems. ",Projected Hartree-Fock as a Polynomial of Particle-Hole Excitations and   Its Combination With Variational Coupled Cluster Theory
"  A cosmological model with a gravitational Lagrangian $L_g(R)\propto R+A R^n$ is set up to account for the presently observed re-acceleration of the universe. The evolution equation for the scale factor $a$ of the universe is analyzed in detail for the two parameters $n=2$ and $n=4/3$, which were preferred by previous studies of the early universe. The initial conditions are specified at a red-shift parameter $z\approx 0$. The fit to the observable data fixes the free parameter $A$. The analysis shows that the model with $n=2$ agrees better with present data. Then, if we set $w(q)=-1$ at $z=0$, corresponding to the deceleration parameter $q\approx -1/2$, we find that at $z\approx 0.5$, $w(q)$ has evolved to $w\approx -0.72$, corresponding to $q\approx 0$. At $z\approx 1$ we find $w\approx 0$ corresponding to $q\approx 1/2$. These results are compared with the flat Friedmann model with cold matter and Lambda-term (LCDM model) for the same initial conditions at $z\approx 0$. The other choice of the model with $n=4/3$ allows for big crunch. However this possibility is eliminated by the fit of $A$ to the present data. ",Geometric model of dark energy
"  Although it is usually thought that a class of weakly interacting massive particle (WIMP) dark matters (DMs), which have the vector coupling with the $Z$ boson, is denied by null results of the direct DM searches, such WIMP DMs are still viable if they are superheavy with the mass of $m_{DM} \gtrsim 10^9$ GeV. In the future, the superheavy WIMP DMs can be searched up to $m_{DM} \simeq 10^{12}$ GeV, which corresponds to the so-called neutrino floor limit. We show that the observed abundance of $\Omega_\mathrm{DM}h^2 \simeq 0.1$ for a superheavy WIMP DM can be reproduced by a suitable reheating temperature of $T_R \simeq m_{DM}/29$ after inflation, if the direct inflaton decay into DM is negligible or kinematically forbidden. ",Superheavy WIMP dark matter from incomplete thermalization
"  Smart power grids are one of the most complex cyber-physical systems, delivering electricity from power generation stations to consumers. It is critically important to know exactly the current state of the system as well as its state variation tendency; consequently, state estimation and state forecasting are widely used in smart power grids. Given that state forecasting predicts the system state ahead of time, it can enhance state estimation because state estimation is highly sensitive to measurement corruption due to the bad data or communication failures. In this paper, a hybrid deep learningbased method is proposed for power system state forecasting. The proposed method leverages Convolutional Neural Network (CNN) for predicting voltage magnitudes and a Deep Recurrent Neural Network (RNN) for predicting phase angels. The proposed CNN-RNN model is evaluated on the IEEE 118-bus benchmark. The results demonstrate that the proposed CNNRNN model achieves better results than the existing techniques in the literature by reducing the normalized Root Mean Squared Error (RMSE) of predicted voltages by 10%. The results also show a 65% and 35% decrease in the average and maximum absolute error of voltage magnitude forecasting. ",A Hybrid Deep Learning-Based State Forecasting Method for Smart Power   Grids
"  We give an expansion of the solution of the evolution equation for the massless Dirac fields in the outer region of de Sitter-Reissner-Nordstr\""om black hole in terms of resonances. By means of this method we describe the decay of local energy for compactly supported data. The proof uses the cut-off resolvent estimates for the semi-classical Schr\""odinger operators from Bony and H\""afner, 2008. The method extends to the Dirac operators on spherically symmetric asymptotically hyperbolic manifolds. ","Resonance expansions of massless Dirac fields propagating in the   exterior of a de Sitter-Reissner-Nordstr\""om black hole"
"  Extra-galactic planetary nebulae (PNe) permit the study of dust and molecules in metallicity environments other than the Galaxy. Their known distances lower the number of free parameters in the observations vs. models comparison, providing strong constraints on the gas-phase and solid-state astrochemistry models. Observations of PNe in the Galaxy and other Local Group galaxies such as the Magellanic Clouds (MC) provide evidence that metallicity affects the production of dust as well as the formation of complex organic molecules and inorganic solid-state compounds in their circumstellar envelopes. In particular, the lower metallicity MC environments seem to be less favorable to dust production and the frequency of carbonaceous dust features and complex fullerene molecules is generally higher with decreasing metallicity. Here, I present an observational review of the dust and molecular content in extra-galactic PNe as compared to their higher metallicity Galactic counterparts. A special attention is given to the level of dust processing and the formation of complex organic molecules (e.g., polycyclic aromatic hydrocarbons, fullerenes, and graphene precursors) depending on metallicity. ",Dust and molecules in extra-galactic planetary nebulae
"  The question addressed in this paper is: What originates pure spin superradiance in a polarized spin system placed inside a resonator? The term ""pure"" means that no initial coherence is imposed on spins, and its appearance manifests a purely self-organized collective effect. The consideration is based on a microscopic model with dipole spin interactions. An accurate solution of evolution equations is given. The results show that the resonator Nyquist noise does not play, contrary to the common belief, any role in starting spin superradiance, but the emergence of the latter is initiated by local spin fluctuations. The decisive role of nonsecular dipole interactions is stressed. ",Origin of Pure Spin Superradiance
  Finite temperature phase boundary between superfluid phase and normal state is analytically derived by studying the stability of normal state in rotating bosonic optical lattice. We also prove that the oscillation behavior of critical hopping matrix directly follows the upper boundary of Hofstadter butterfly as the function of effective magnetic field. ,Finite Temperature Phase Diagram in Rotating Bosonic Optical Lattice
"  We study minority games in efficient regime. By incorporating the utility function and aggregating agents with similar strategies we develop an effective mesoscale notion of state of the game. Using this approach, the game can be represented as a Markov process with substantially reduced number of states with explicitly computable probabilities. For any payoff, the finiteness of the number of states is proved. Interesting features of an extensive random variable, called aggregated demand, viz. its strong inhomogeneity and presence of patterns in time, can be easily interpreted. Using Markov theory and quenched disorder approach, we can explain important macroscopic characteristics of the game: behavior of variance per capita and predictability of the aggregated demand. We prove that in case of linear payoff many attractors in the state space are possible. ",Mesoscopic approach to minority games in herd regime
"  Minimization of the number of numerically calculated coefficients for new analytical forms as a product of exponential function r1 by the sum of the exponential terms Ai*exp(-ai*r2) have been done. The optimum is N=10. Calculations have been done for realistic phenomenological Reid93 potential. Spherical S0 and quadrupole S2 form factors is parameterized by the coefficients for deuteron wave function in coordinate representation. The result t20(p) in wide area of momentas for Reid93 potential agreed well with the literature results for other potential nucleon-nucleon models, and with experimental datas of world collaborations and reviews. The obtained results will allow studying the deuteron electromagnetic structure, its form-factors, differential cross section of double scattering in more detail in future, and also for calculations the theoretical values of spin observables in dp- scattering. ",Parameterization of the deuteron wave functions and form factors
"  The cosmic microwave background (CMB) temperature bispectrum is currently the most precise tool for constraining primordial non-Gaussianity (NG). The Planck temperature data tightly constrain the amplitude of local-type NG: $f_{\rm NL}^{\rm loc} = 2.5 \pm 5.7$. Here, we compute previously-neglected foreground biases in temperature-based $f_{\rm NL}^{\rm loc}$ measurements, due to the integrated Sachs-Wolfe (ISW) effect, gravitational lensing, the thermal and kinematic Sunyaev-Zel'dovich effects, and the cosmic infrared background. While standard analyses already subtract a significant bias on $f_{\rm NL}^{\rm loc}$ due to the ISW-lensing bispectrum, many other secondary anisotropy terms are present in the temperature bispectrum. We compute the dominant biases on $f_{\rm NL}^{\rm loc}$ arising from these signals. Most of the biases are non-blackbody, and are thus reduced by multifrequency component separation methods; however, recent analyses have found that extragalactic foregrounds are present at non-negligible levels in the Planck component-separated maps. Moreover, the Planck FFP8 simulations do not include the foreground correlations that generate these biases. We compute the biases for individual frequencies; some are comparable to the statistical error bar on $f_{\rm NL}^{\rm loc}$, even for the main CMB channels (100, 143, and 217 GHz). For future experiments, they greatly exceed the statistical error (considering temperature only). Alternatively, the foreground contributions can be marginalized over, but this leads to a non-negligible increase in the error bar on $f_{\rm NL}^{\rm loc}$. A full assessment will require calculations in tandem with component separation, ideally using simulations. We also compute these biases for equilateral and orthogonal NG, finding large effects for the latter. We conclude that the search for primordial NG using Planck data may not yet be over. ",Foreground Biases on Primordial Non-Gaussianity Measurements from the   CMB Temperature Bispectrum: Implications for Planck and Beyond
"  End-to-end neural machine translation has overtaken statistical machine translation in terms of translation quality for some language pairs, specially those with large amounts of parallel data. Besides this palpable improvement, neural networks provide several new properties. A single system can be trained to translate between many languages at almost no additional cost other than training time. Furthermore, internal representations learned by the network serve as a new semantic representation of words -or sentences- which, unlike standard word embeddings, are learned in an essentially bilingual or even multilingual context. In view of these properties, the contribution of the present work is two-fold. First, we systematically study the NMT context vectors, i.e. output of the encoder, and their power as an interlingua representation of a sentence. We assess their quality and effectiveness by measuring similarities across translations, as well as semantically related and semantically unrelated sentence pairs. Second, as extrinsic evaluation of the first point, we identify parallel sentences in comparable corpora, obtaining an F1=98.2% on data from a shared task when using only NMT context vectors. Using context vectors jointly with similarity measures F1 reaches 98.9%. ",An Empirical Analysis of NMT-Derived Interlingual Embeddings and their   Use in Parallel Sentence Identification
"  Electron acceleration to non-thermal energies is known to occur in low Mach number (M<5) shocks in galaxy clusters and solar flares, but the electron acceleration mechanism remains poorly understood. Using two-dimensional (2D) particle-in-cell (PIC) plasma simulations, we showed in Paper I that electrons are efficiently accelerated in low Mach number (M=3) quasi-perpendicular shocks via a Fermi-like process. The electrons bounce between the upstream region and the shock front, with each reflection at the shock resulting in energy gain via shock drift acceleration. The upstream scattering is provided by oblique magnetic waves, that are self-generated by the electrons escaping ahead of the shock. In the present work, we employ additional 2D PIC simulations to address the nature of the upstream oblique waves. We find that the waves are generated by the shock-reflected electrons via the firehose instability, which is driven by an anisotropy in the electron velocity distribution. We systematically explore how the efficiency of wave generation and of electron acceleration depend on the magnetic field obliquity, the flow magnetization (or equivalently, the plasma beta), and the upstream electron temperature. We find that the mechanism works for shocks with high plasma beta (>20) at nearly all magnetic field obliquities, and for electron temperatures in the range relevant for galaxy clusters. Our findings offer a natural solution to the conflict between the bright radio synchrotron emission observed from the outskirts of galaxy clusters and the low electron acceleration efficiency usually expected in low Mach number shocks. ",Non-Thermal Electron Acceleration in Low Mach Number Collisionless   Shocks. II. Firehose-Mediated Fermi Acceleration and its Dependence on   Pre-Shock Conditions
"  We give a systematic account of the various pictures of KK-theory for real C*-algebras, proving natural isomorphisms between the groups that arise from each picture. As part of this project, we develop the universal properties of KK-theory, and we use CRT-structures to prove that a natural transformation from F(A) to G(A) between homotopy equivalent, stable, half-exact functors defined on real C*-algebras is an isomorphism provided it is an isomorphism on the smaller class of C*-algebras. Finally, we develop E-theory for real C*-algebras and use that to obtain new negative results regarding the problem of approximating almost commuting real matrices by exactly commuting real matrices. ",Pictures of KK-theory for real C*-algebras and almost commuting matrices
"  We model the solar horizontal velocity power spectrum at scales larger than granulation using a two-component approximation to the mass continuity equation. The model takes four times the density scale height as the integral (driving) scale of the vertical motions at each depth. Scales larger than this decay with height from the deeper layers. Those smaller are assumed to follow a Kolomogorov turbulent cascade, with the total power in the vertical convective motions matching that required to transport the solar luminosity in a mixing length formulation. These model components are validated using large scale radiative hydrodynamic simulations. We reach two primary conclusions: 1. The model predicts significantly more power at low wavenumbers than is observed in the solar photospheric horizontal velocity spectrum. 2. Ionization plays a minor role in shaping the observed solar velocity spectrum by reducing convective amplitudes in the regions of partial helium ionization. The excess low wavenumber power is also seen in the fully nonlinear three-dimensional radiative hydrodynamic simulations employing a realistic equation of state. This adds to other recent evidence suggesting that the amplitudes of large scale convective motions in the Sun are significantly lower than expected. Employing the same feature tracking algorithm used with observational data on the simulation output, we show that the observed low wavenumber power can be reproduced in hydrodynamic models if the amplitudes of large scale modes in the deep layers are artificially reduced. Since the large scale modes have reduced amplitudes, modes on the scale of supergranulation and smaller remain important to convective heat flux even in the deep layers, suggesting that small scale convective correlations are maintained through the bulk of the solar convection zone. ",The Role of Subsurface Flows in Solar Surface Convection: Modeling the   Spectrum of Supergranular and Larger Scale Flows
"  A characterization of a class of optimal three-weight cyclic codes of dimension 3 over any finite field was recently presented in [10]. Shortly after this, a generalization for the sufficient numerical conditions of such characterization was given in [3]. The main purpose of this work is to show that the numerical conditions found in [3], are also necessary. As we will see later, an interesting feature of the present work, in clear contrast with these two preceding works, is that we use some new and non-conventional methods in order to achieve our goals. In fact, through these non-conventional methods, we not only were able to extend the characterization in [10], but also present a less complex proof of such extended characterization, which avoids the use of some of the sophisticated --but at the same time complex-- theorems, that are the key arguments of the proofs given in [10] and [3]. Furthermore, we also find the parameters for the dual code of any cyclic code in our extended characterization class. In fact, after the analysis of some examples, it seems that such dual codes always have the same parameters as the best known linear codes. ",An extended characterization of a class of optimal three-weight cyclic   codes over any finite field
"  We present the discovery of a huge (19$\arcmin$ $\times$ 16$\arcmin$) dust ring surrounding a bright (V = 10.60) red star. The dust ring has, at D = 700 pc, a diameter of 4 pc, and a central hole of ~1.5 pc across. Part of the shell is also seen as an absorption nebulosity. The star is classified as a M3III AGB star. Among AGB stars its detached shell is of unrivalled size. Detached shells around AGB stars are normally interpreted in terms of thermal pulses. However, in this case a significant fraction of the shell may consist of swept-up ISM; the detached appearance can be explained with wind--ISM interaction. We present a model where the AGB wind has been stopped by the surrounding ISM, and the swept-up shell is now expanding at the sound speed. The model predicts that the ring will disperse over a few times 10^5 yr, and eventually will leave a large hole in the ISM surrounding the AGB star or its future planetary nebula. ",A wall of dust around a proto-Mira
"  In this work we extend a recent result by Dyda et. al. [B. Dyda, A. Kuznetsov, M. Kwasnicki, Eigenvalues of the fractional Laplace equation in the unit ball, J. Lond. Math. Soc. (2) 95 (2017), 500-518.] to dimension 3. ",Anti-symmetry of the second eigenfunction of the fractional Laplace   operator in a 3-D ball
"  Finding the ground state energy of the Heisenberg Hamiltonian is an important problem in the field of condensed matter physics. In some configurations, such as the antiferromagnetic translationally-invariant case on the 2D square lattice, its exact ground state energy is still unknown. We show that finding the ground state energy of the Heisenberg model cannot be an NP-Hard problem unless P=NP. We prove this result using a reduction to a sparse set and certain theorems from computational complexity theory. The result hints at the potential tractability of the problem and encourages further research towards a positive complexity result. In addition, we prove similar results for many similarly structured Hamiltonian problems, including certain forms of the Ising, t-J, and Fermi-Hubbard models. ",Non-NP-Hardness of Translationally-Invariant Spin-Model Problems
"  We investigate the extent to which leptonic CP-violation in (3+2) sterile neutrino models leads to different oscillation probabilities for $\bar{\nu}_{\mu}\to\bar{\nu}_e$ and $\nu_{\mu}\to\nu_e$ oscillations at MiniBooNE. We are using a combined analysis of short-baseline (SBL) oscillation results, including the LSND and null SBL results, to which we impose additional constraints from atmospheric oscillation data. We obtain the favored regions in MiniBooNE oscillation probability space for both (3+2) CP-conserving and (3+2) CP-violating models. We further investigate the allowed CP-violation phase values and the MiniBooNE reach for such a CP violation measurement. The analysis shows that the oscillation probabilities in MiniBooNE neutrino and antineutrino running modes can differ significantly, with the latter possibly being as much as three times larger than the first. In addition, we also show that all possible values of the single CP-violation phase measurable at short baselines in (3+2) models are allowed within 99% CL by existing data. ",Leptonic CP violation studies at MiniBooNE in the (3+2) sterile neutrino   oscillation hypothesis
"  Premier cloud service providers (CSPs) offer two types of purchase options, namely on-demand and spot instances, with time-varying features in availability and price. Users like startups have to operate on a limited budget and similarly others hope to reduce their costs. While interacting with a CSP, central to their concerns is the process of cost-effectively utilizing different purchase options possibly in addition to self-owned instances. A job in data-intensive applications is typically represented by a directed acyclic graph which can further be transformed into a chain of tasks. The key to achieving cost efficiency is determining the allocation of a specific deadline to each task, as well as the allocation of different types of instances to the task. In this paper, we propose a framework that determines the optimal allocation of deadlines to tasks. The framework also features an optimal policy to determine the allocation of spot and on-demand instances in a predefined time window, and a near-optimal policy for allocating self-owned instances. The policies are designed to be parametric to support the usage of online learning to infer the optimal values against the dynamics of cloud markets. Finally, several intuitive heuristics are used as baselines to validate the cost improvement brought by the proposed solutions. We show that the cost improvement over the state-of-the-art is up to 24.87% when spot and on-demand instances are considered and up to 59.05% when self-owned instances are considered. ",Towards Cost-Optimal Policies for DAGs to Utilize IaaS Clouds with   Online Learning
"  In this paper we have proposed a dynamic buffer allocation algorithm for the prefix, based on the popularity of the videos. More cache blocks are allocated for most popular videos and a few cache blocks are allocated for less popular videos. Buffer utilization is also maximized irrespective of the load on the Video-on-Demand system. Overload can lead the server getting slowed down. By storing the first few seconds of popular video clips, a multimedia local server can shield the users from the delay, throughput, and loss properties of the path between the local server and the central server. The key idea of controlled multicast is used to allow clients to share a segment of a video stream even when the requests arrive at different times. This dynamic buffer allocation algorithm is simulated and its performance is evaluated based on the buffer utilization by multimedia servers and average buffer allocation for the most popular videos. Our simulation results shows efficient utilization of network bandwidth and reduced hard disk utilization hence resulting in increase in the number of requests being served. ",A Strategy to enable Prefix of Multicast VoD through dynamic buffer   allocation
"  Network analysis provides a powerful framework for the interpretation of genome-wide data. While static network approaches have proved fruitful, there is increasing interest in the insights gained from the analysis of cellular networks under different conditions. In this work, we study the effect of stress on cellular networks in fission yeast. Stress elicits a sophisticated and large scale cellular response, involving a shift of resources from cell growth and metabolism towards protection and maintenance. Previous work has suggested that these changes can be appreciated at the network level.   In this paper, we study two types of cellular networks: gene co-regulation networks and weighted protein interaction networks. We show that in response to oxidative stress, the co-regulation networks re-organize towards a more modularised structure: while sets of genes become more tightly co-regulated, co-regulation between these modules is decreased. This shift translates into longer average shortest path length, increased transitivity, and decreased modular overlap in these networks. We also find a similar change in structure in the weighted protein interaction network in response to both oxidative stress and nitrogen starvation, confirming and extending previous findings.   These changes in network structure could represent an increase in network robustness and/or the emergence of more specialised functional modules. Additionally, we find stress induces tighter co-regulation of non-coding RNAs, decreased functional importance of splicing factors, as well as changes in the centrality of genes involved in chromatin organization, cytoskeleton organization, cell division, and protein turnover. ",Stress induces remodelling of yeast interaction and co-expression   networks
"  There is a need to better understand the intrinsic limit of radiofrequency (RF) surface impedance that determines the performance of superconducting RF cavities in particle accelerators. Here we present a field-dependent derivation of Mattis-Bardeen (M-B) theory of the RF surface impedance of BCS superconductors based on the shifted Density of States (DoS) resulting from coherently moving Cooper pairs [1].The surprising reduction in resistance with increasing field is explained to be an intrinsic effect. Using this analysis coded in MathematicaTM, survey calculations have been completed which examine the sensitivities of this surface impedance to variation of the BCS material parameters and temperature.Our theoretical prediction of the effective BCS RF surface resistance (Rs) of niobium as a function of peak surface magnetic field amplitude agrees well with recently reported record low loss resonant cavity measurements from Jefferson Lab (JLab) and Fermi National Accelerator Lab (FNAL) with carefully, yet differently, prepared niobium material. The results present a refined description of the ""best theoretical"" performance available to potential applications with corresponding materials. [1]Xiao, B.P., C.E. Reece, and M.J. Kelley, Superconducting surface impedance under radiofrequency field. Physica C: Superconductivity, 2013. 490(0): p. 26-31. ",A new first-principles calculation of field-dependent RF surface   impedance of BCS superconductor and application to SRF cavities
"  At this point in time, two major areas of physics, statistical mechanics and quantum mechanics, rest on the foundations of probability and entropy. The last century saw several significant fundamental advances in our understanding of the process of inference, which make it clear that these are inferential theories. That is, rather than being a description of the behavior of the universe, these theories describe how observers can make optimal predictions about the universe. In such a picture, information plays a critical role. What is more is that little clues, such as the fact that black holes have entropy, continue to suggest that information is fundamental to physics in general.   In the last decade, our fundamental understanding of probability theory has led to a Bayesian revolution. In addition, we have come to recognize that the foundations go far deeper and that Cox's approach of generalizing a Boolean algebra to a probability calculus is the first specific example of the more fundamental idea of assigning valuations to partially-ordered sets. By considering this as a natural way to introduce quantification to the more fundamental notion of ordering, one obtains an entirely new way of deriving physical laws. I will introduce this new way of thinking by demonstrating how one can quantify partially-ordered sets and, in the process, derive physical laws. The implication is that physical law does not reflect the order in the universe, instead it is derived from the order imposed by our description of the universe. Information physics, which is based on understanding the ways in which we both quantify and process information about the world around us, is a fundamentally new approach to science. ",Information Physics: The New Frontier
  Magneto-Raman scattering experiments from the surface of graphite reveal novel features associated to purely electronic excitations which are observed in addition to phonon-mediated resonances. Graphene-like and graphite domains are identified through experiments with $\sim 1\mu m$ spatial resolution performed in magnetic fields up to 32T. Polarization resolved measurements emphasize the characteristic selection rules for electronic transitions in graphene. Graphene on graphite displays the unexpected hybridization between optical phonon and symmetric across the Dirac point inter Landau level transitions. The results open new experimental possibilities - to use light scattering methods in studies of graphene under quantum Hall effect conditions. ,Magneto-Raman scattering of graphene on graphite: Electronic and phonon   excitations
"  In this paper, we prove the irreducibility of the monodromy action on the anti-invariant part of the vanishing cohomology on a double cover of a very general element in an ample hypersurface of a complex smooth projective variety branched at an ample divisor. As an application, we study dominant rational maps from a double cover of a very general surface $S$ of degree$\geq 7$ in ${\mathbb P}^3$ branched at a very general quadric surface to smooth projective surfaces $Z$. Our method combines the classification theory of algebraic surfaces, deformation theory, and Hodge theory. ",Vanishing cohomology on a double cover
"  We explore the internal structure of red sequence galaxies in the Coma cluster across a wide range of luminosities ($-17>M_g>-22$) and cluster-centric radii ($0<r_{\rm{cluster}}<1.3 r_{200}$). We present the 2D bulge-disc decomposition of galaxies in deep Canada-France-Hawaii Telescope $u,g,i$ imaging using GALFIT. Rigorous filtering is applied to identify an analysis sample of 200 galaxies which are well described by an `archetypal' S0 structure (central bulge + outer disc). We consider internal bulge and/or disc colour gradients by allowing component sizes to vary between bands. Gradients are required for $30\%$ of analysis sample galaxies. Bulge half-light radii are found to be uncorrelated with galaxy luminosity ($R_e \sim 1$ kpc, $n\sim2$) for all but the brightest galaxies ($M_g<-20.5$). The S0 discs are brighter (at fixed size, or smaller at fixed luminosity) than those of star-forming spirals. A similar colour-magnitude relation is found for both bulges and discs. The global red sequence for S0s in Coma hence results from a combination of both component trends. We measure an average bulge $-$ disc colour difference of $0.09\pm0.01$ mag in $g-i$, and $0.16\pm0.01$ mag in $u-g$. Using simple stellar population models, bulges are either $\sim2$-$3\times$ older, or $\sim2\times$ more metal-rich than discs. The trend towards bluer global S0 colours observed further from Coma's core is driven by a significant correlation in disc colour with cluster-centric radius. An equivalent trend is detected in bulge colours at a marginal significance level. Our results therefore favour environment-mediated mechanisms of disc fading as the dominant factor in S0 formation. ",Dissecting the Red Sequence: The Bulge and Disc Colours of Early-Type   Galaxies in the Coma Cluster
"  These are lectures presented at the summer course on ``Low Dimensional Quantum Field Theories for Condensed Matter Physicists'', 24 Aug. to 4 Sep. 1992, Trieste, Italy. I review recent work, performed in collaboration primarily with N. Read and Jinwu Ye, on the properties of quantum antiferromagnets in two dimensions. The emphasis is on the properties of the antiferromagnet in states which do not have any long-range magnetic order. The universal spin dynamics in the quantum critical region of number of frustrated and random antiferromagnets is studied; implications for neutron scattering experiments in the lightly-doped cuprates are noted. The nature of the quantum-disordered phase of non-random frustrated antiferromagnets is examined in some detail: the states found have ({\em i\/}) collinear spin correlations, spin-Peierls or valence-bond-solid order, and confined spinons, order and confined spinons or ({\em ii\/}) coplanar spin correlations, no spin-Peierls order and deconfined bosonic spinons. ",Quantum Antiferromagnets in Two Dimensions
"  Many automated operations in agriculture, such as weeding and plant counting, require robust and accurate object detectors. Robotic fruit harvesting is one of these, and is an important technology to address the increasing labour shortages and uncertainty suffered by tree crop growers. An eye-in-hand sensing setup is commonly used in harvesting systems and provides benefits to sensing accuracy and flexibility. However, as the hand and camera move from viewing the entire trellis to picking a specific fruit, large changes in lighting, colour, obscuration and exposure occur. Object detection algorithms used in harvesting should be robust to these challenges, but few datasets for assessing this currently exist. In this work, two new datasets are gathered during day and night operation of an actual robotic plum harvesting system. A range of current generation deep learning object detectors are benchmarked against these. Additionally, two methods for fusing depth and image information are tested for their impact on detector performance. Significant differences between day and night accuracy of different detectors is found, transfer learning is identified as essential in all cases, and depth information fusion is assessed as only marginally effective. The dataset and benchmark models are made available online. ",Dataset and Performance Comparison of Deep Learning Architectures for   Plum Detection and Robotic Harvesting
"  This paper presents enhancement strategies for the Hermitian and skew-Hermitian splitting method based on gradient iterations. The spectral properties are exploited for the parameter estimation, often resulting in a better convergence. In particular, steepest descent with early stopping can generate a rough estimate of the optimal parameter. This is better than an arbitrary choice since the latter often causes stability problems or slow convergence. Additionally, lagged gradient methods are considered as inner solvers for the splitting method. Experiments show that they are competitive with conjugate gradient in low precision. ",Parameter Estimation in the Hermitian and Skew-Hermitian Splitting   Method Using Gradient Iterations
"  Companies are fundamental units of contemporary economies and markets and are important mechanisms through which humans interact with their environments. Understanding general properties that underlie the processes of growth in companies have long been of interest, yet fundamental debates about the effects of firm size on growth have persisted. Here we develop a scaling framework that focuses on company size as the critical feature determining a variety of tradeoffs, and use this to reveal novel systematic behavior across the diversity of publicly-traded companies. Using a large database of 31,553 companies over more than 70 years, we show how the dynamics of companies expressed as scaling relationships leads to a quantitative, predictive theory for their growth. We find that companies exhibit size-dependent changes in their financial composition. Most notably net income scales sublinearly with the assets of a company (i.e., size), while liabilities scale linearly. From these scaling relationships we derive an equation for the size-dependent growth of companies where, surprisingly and nontrivially, assets grow as a power law in time. These results illustrate that while companies are part of a larger class of growth phenomena driven by incomes and costs that scale with size, they are unique in that they grow without bound following a temporal power-law. This temporal growth sets companies apart from the scaling of organisms, and from other institutions, such as cities, nations, and markets, where growth over time is often exponential. The perspective we develop here highlights novel dynamics in the scaling of human economies. ",Scaling laws and a general theory for the growth of companies
"  Carbon-based molecular semiconductors are explored for application in spintronics because their small spin-orbit coupling promises long spin life times. We calculate the electronic transport from first principles through spin valves comprising bi- and tri-layers of the fullerene molecules C60 and C70, sandwiched between two Fe electrodes. The spin polarization of the current, and the magnetoresistance depend sensitively on the interactions at the interfaces between the molecules and the metal surfaces. They are much less affected by the thickness of the molecular layers. A high current polarization (CP > 90%) and magnetoresistance (MR > 100%) at small bias can be attained using C70 layers. In contrast, the current polarization and the magnetoresistance at small bias are vanishingly small for C60 layers. Exploiting a generalized Julli`ere model we can trace the differences in spin-dependent transport between C60 and C70 layers to differences between the molecule-metal interface states. These states also allow one to interpret the current polarization and the magnetoresistance as a function of the applied bias voltage. ",Magnetoresistance in multilayer fullerene spin valves: a   first-principles study
  Winds from accretion disks have been proposed as the driving source for precessing jets and extreme bipolar morphologies in Planetary Nebulae (PNe) and proto-PNe (pPNe). Here we apply MHD disk wind models to PNe and pPNe by estimating separately the asymptotic MHD wind velocities and mass loss rates. We show that the resulting winds can recover the observed momentum and energy input rates for PNe and pPNe. ,MHD Disk Winds in PNe and pPNe
"  Desert dust aerosols affect Earth's global energy balance through direct interactions with radiation, and through indirect interactions with clouds and ecosystems. But the magnitudes of these effects are so uncertain that it remains unclear whether atmospheric dust has a net warming or cooling effect on global climate. Consequently, it is still uncertain whether large changes in atmospheric dust loading over the past century have slowed or accelerated anthropogenic climate change, or what the effects of potential future changes in dust loading will be. Here we present an analysis of the size and abundance of dust aerosols to constrain the direct radiative effect of dust. Using observational data on dust abundance, in situ measurements of dust optical properties and size distribution, and climate and atmospheric chemical transport model simulations of dust lifetime, we find that the dust found in the atmosphere is substantially coarser than represented in current global climate models. Since coarse dust warms climate, the global dust direct radiative effect is likely to be less cooling than the ~-0.4 W/m2 estimated by models in a current global aerosol model ensemble. Instead, we constrain the dust direct radiative effect to a range between -0.48 and +0.20 W/m2, which includes the possibility that dust causes a net warming of the planet. ",Smaller desert dust cooling effect estimated from analysis of dust size   and abundance
  A compressed sensing scheme for near-field imaging of corrugations of relative sparse Fourier components is proposed. The scheme employs random sparse measurement of near field to recover the angular spectrum of the scattered field. It is shown heuristically and numerically that under the Rayleigh hypothesis the angular spectrum is compressible and amenable to compressed sensing techniques.   Iteration schemes are developed for recovering the surface profile from the angular spectrum.   The proposed nonlinear least squares in the Fourier basis produces accurate reconstructions even when the Rayleigh hypothesis is known to be false. ,Compressive Imaging of Subwavelength Structures II. Periodic Rough   Surfaces
"  This paper develops a set of simplified dynamical models with which to explore the conditions under which temporal differentiation leads to optimized system output. By temporal differentiation, we mean a division of labor whereby different subtasks associated with performing a given task are done at different times. The idea is that, by focusing on one particular set of subtasks at a time, it is possible to increase the efficiency with which each subtask is performed, thereby allowing for faster completion of the overall task. For this paper, we consider a process whereby some resource is converted into some final product in a series of three agent-mediated steps. Temporal differentiation is incorporated by allowing the agents to oscillate between performing the first two steps and performing the last step. We find that temporal differentiation is favored when the number of agents is small, and when the process intermediates have a much longer lifetime than the original resource. Within the framework of biological systems, we argue that these results provide a possible evolutionary basis for the emergence of sleep, and also of distinct REM and non-REM sleep states. We also discuss our use of a three-step model. Briefly, in order for temporal differentiation to increase product output in a mean-field description of resource metabolism, it is necessary for temporal differentiation to have a nonlinear effect on individual process rates. For stochastic models, we argue that temporal differentiation can increase product output even in fundamentally linear systems. ",Temporal differentiation and the optimization of system output
"  We present the results of the analysis of LR optical-NIR spectra (0.6-2.4 um) of a sample 47 YSOs in the ChaI and II star-forming clouds. These data are part of the POISSON project (Protostellar Optical-Infrared Spectral Survey on NTT). The aim is to determine the accretion luminosity (Lacc) and mass accretion rate (Macc) of the sources through the analysis of the detected emission features. We also aim at verifying the reliability and consistency of the existing empirical relationships connecting emission line luminosity and Lacc. We employ five tracers (OI-6300A, Ha, CaII-8542A, Pab, and Brg) to derive the accretion luminosity. The tracers provide Lacc values showing different scatters when plotted as a function of L*. The Brg seems to be the most reliable, because it gives the minimum Lacc dispersion over the entire range of L*, whereas the other tracers provide much more scattered Lacc values, which are not expected for our homogeneous sample. The comparison between Lacc(Brg) and Lacc obtained from the other tracers also shows systematic differences among the empirical relationships. These may probably be ascribed to different excitation mechanisms contributing to the line emission, which may vary between our sample and those where the relationships were calibrated. Adopting the Lacc derived from Brg, we find Lacc=0.1L*-1L* for all sources, and Macc of the order of 10^-7-10^-9 Msun/yr. The Macc derived in ChaI are proportional to M*^2, as found in other low-mass star-forming regions. The discrepancies observed in the case of Lacc(Brg) and Lacc(Pab) can be related to different intrinsic Pab/Brg, ratios. The derived ratios show the existence of two different emission modalities, one that agrees with predictions of both wind and accretion models, the other suggesting optically thick emission from relatively small regions (10^21-10^22 cm^-3) with gas at low temperatures (<4000K). ",POISSON project - I - Emission lines as accretion tracers in young   stellar objects: results from observations of Chamaeleon I and II sources
  Let $G$ be a finite group with derived subgroup of rank $r$. We prove that $\gzz\leq |G'|^{2r}$. Motivated by the results of I. M. Isaacs in \cite{isa} we show that if $G$ is capable then $\gz\leq |G'|^{4r}$. This answers a question of L. Pyber. We prove that if $G$ is a capable $p$-group then the rank of $G/\mathbf{Z}(G)$ is bounded above in terms of the rank of $G'$. ,On finite groups whose derived subgroup has bounded rank
"  This Letter presents the observation and measurement of electroweak production of a same-sign $W$ boson pair in association with two jets using 36.1 fb$^{-1}$ of proton-proton collision data recorded at a center-of-mass energy of $\sqrt{s}=13$ TeV by the ATLAS detector at the Large Hadron Collider. The analysis is performed in the detector fiducial phase-space region, defined by the presence of two same-sign leptons, electron or muon, and at least two jets with a large invariant mass and rapidity difference. A total of 122 candidate events are observed for a background expectation of $69 \pm 7$ events, corresponding to an observed signal significance of 6.5 standard deviations. The measured fiducial signal cross section is $\sigma^{\mathrm {fid.}}=2.89^{+0.51}_{-0.48} \mathrm{(stat.)} ^{+0.29}_{-0.28} \mathrm{(syst.)}$ fb. ",Observation of electroweak production of a same-sign $W$ boson pair in   association with two jets in $pp$ collisions at $\sqrt{s}=13$ TeV with the   ATLAS detector
"  The notion of a subtractive category, recently introduced by the author, is a ``categorical version'' of the notion of a (pointed) subtractive variety of universal algebras, due to A. Ursini. We show that a subtractive variety $\C$, whose theory contains a unique constant, is abelian (i.e. $\C$ is the variety of modules over a fixed ring), if and only if the dual category $\C^\mathrm{op}$ of $\C$, is subtractive. More generally, we show that $\C$ is additive if and only if both $\C$ and $\C^\mathrm{op}$ are subtractive, where $\C$ is an arbitrary finitely complete pointed category, with binary sums, and such that each morphism $f$ in $\C$ can be presented as a composite $f=me$, where $m$ is a monomorphism and $e$ is an epimorphism. ",Closedness properties of internal relations IV: Expressing additivity of   a category via subtractivity
"  Syndromic surveillance systems continuously monitor multiple pre-diagnostic daily streams of indicators from different regions with the aim of early detection of disease outbreaks. The main objective of these systems is to detect outbreaks hours or days before the clinical and laboratory confirmation. The type of data that is being generated via these systems is usually multivariate and seasonal with spatial and temporal dimensions. The algorithm What's Strange About Recent Events (WSARE) is the state-of-the-art method for such problems. It exhaustively searches for contrast sets in the multivariate data and signals an alarm when find statistically significant rules. This bottom-up approach presents a much lower detection delay comparing the existing top-down approaches. However, WSARE is very sensitive to the small-scale changes and subsequently comes with a relatively high rate of false alarms. We propose a new approach called EigenEvent that is neither fully top-down nor bottom-up. In this method, we instead of top-down or bottom-up search, track changes in data correlation structure via eigenspace techniques. This new methodology enables us to detect both overall changes (via eigenvalue) and dimension-level changes (via eigenvectors). Experimental results on hundred sets of benchmark data reveals that EigenEvent presents a better overall performance comparing state-of-the-art, in particular in terms of the false alarm rate. ",EigenEvent: An Algorithm for Event Detection from Complex Data Streams   in Syndromic Surveillance
"  A typical mission profile of submarine-launched cruise missiles begins with the launch phase which covers the motion of the missile from the launch to the water-exit and continues with the boost phase which lasts from the water-exit to the beginning of the cruise phase. In order to achieve the desired range of the launch and boost phases, efficient utilization of available energy which carries the missile to the beginning of the cruise phase is necessary. For this purpose, this study presents a new approach for energy-optimal control of the underwater and air motion of a submarine-launched cruise missile. In this approach, the aforementioned problem is modeled and solved as a minimum-effort optimal control problem. Then, the effects of initial and final conditions on energy need are investigated, and the optimal conditions that result with the minimum energy need are determined. Prior to the guidance and control design steps, six degrees of freedom (6 DOF) motion equations are derived and the hydrodynamic and aerodynamic parameters are retrieved. The nonlinear 6 DOF motion model is simplified and linearized before minimum-effort optimal control design part. Results of the designed guidance and control strategies are presented through the nonlinear 6 DOF simulations. Finally, some comments are made and future studies are mentioned based on theoretical and simulation studies. ",Energy-Optimal Control of a Submarine-Launched Cruise Missile
"  In our previous work (Assier \& Shanin, QJMAM, 2019), we gave a new spectral formulation in two complex variables associated with the problem of plane-wave diffraction by a quarter-plane. In particular, we showed that the unknown spectral function satisfies a condition of additive crossing about its branch set. In this paper, we study a very similar class of spectral problem, and show how the additive crossing can be exploited in order to express its solution in terms of Lam\'e functions. The solutions obtained can be thought of as tailored vertex Green's functions whose behaviours in the near-field are directly related to the eigenvalues of the Laplace-Beltrami operator. This is important since the correct near-field behaviour at the tip of the quarter-plane had so far never been obtained via a multivariable complex analysis approach. ","Vertex Green's functions of a quarter-plane. Links between the   functional equation, additive crossing and Lam\'e functions"
"  We briefly review some current theoretical and experimental aspects of the problem of a single spinless impurity in a 3D polarised atomic Fermi gas at zero temperature where the interactions can be tuned using a wide Feshbach resonance. We show that various few-body states in vacuum composed of the impurity and background gas atoms (single impurity, dimer, trimer, tetramer) give rise to corresponding dressed states ({\em polaron}, {\em dimeron}, {\em trimeron}, {\em tetrameron}) in the gas and inherit many of their characteristics. We study the ground state focussing on the choice of wave function and its properties. We raise a few unsolved problems: whether the polaron and dimeron are really separate branches, what other few-body states might exist, the nature of the groundstate for large numbers of particle-hole pairs and why is the polaron ansatz so good. We then turn to the excited states, and to the calculation of the effective mass. We examine the bounds on the effective mass and raise a conjecture about that of composite quasiparticle states. ",A single impurity in an ideal atomic Fermi gas: current understanding   and some open problems
"  The PAX project at GSI Darmstadt plans to polarize an antiproton beam by repeated interaction with a hydrogen target in a storage ring. Many of the beam particles are required to remain within the ring after interaction with the target, so small scattering angles are important. Hence we concentrate on low momentum transfer (small t), a region where electromagnetic effects dominate the hadronic effects. A colliding beam of polarized electrons with energy sufficient to provide scattering of antiprotons beyond ring acceptance may polarize an antiproton beam by spin filtering. Expressions for spin observables are provided and are used to estimate the rate of buildup of polarization of an antiproton beam. ",Spin Observables for Polarizing Antiprotons
"  We have studied experimentally the phenomena of jump-to-contact (JC) and jump-out-of-contact (JOC) in gold electrodes. JC can be observed at the first contact when the two metals approach each other while JOC occurs in the last contact before breaking. When the indentation depth between the electrodes is limited to a certain value of conductance, a highly reproducible behaviour in the evolution of the conductance can be obtained for hundreds of cycles of formation and rupture. Molecular dynamics simulations of this process show how the two metallic electrodes are shaped into tips of a well-defined crystallographic structure formed through a mechanical annealing mechanism. We report a detailed analysis of the atomic configurations obtained before contact and rupture of these stable structures and obtained their conductance using first-principlesquantum transport calculations. These results help us understand the values of conductance obtained experimentally in the JC and JOC phenomena and improve our understanding of atomic-sized contacts and the evolution of their structural characteristics. ",Understanding the structure of the first atomic contact in Gold
"  This paper presents the constraints on the time variation of the fine structure constant at recombination relative to its present value, Delta_alpha = (alpha_rec-alpha_0) / alpha_0, obtained from the analysis of the WMAP-3yr Cosmic Microwave Background (CMB) data, with an additional prior on the Hubble expansion rate from HST Hubble Key Project. I found out that -0.039 < Delta_alpha < 0.010 at 95% C.L., which brings a 30% improvement to the previous limits from WMAP-1yr data. The corresponding recombination redshift, 1012 < z_rec < 1115, shows a delayed recombination epoch compared with the results from WMAP-1yr data. ",Constraints on time variation of fine structure constant from WMAP-3yr   data
"  Motivated by applications in cancer genomics and following the work of Hajirasouliha and Raphael (WABI 2014), Hujdurovi\'c et al. (IEEE TCBB, to appear) introduced the minimum conflict-free row split (MCRS) problem: split each row of a given binary matrix into a bitwise OR of a set of rows so that the resulting matrix corresponds to a perfect phylogeny and has the minimum possible number of rows among all matrices with this property. Hajirasouliha and Raphael also proposed the study of a similar problem, in which the task is to minimize the number of distinct rows of the resulting matrix. Hujdurovi\'c et al. proved that both problems are NP-hard, gave a related characterization of transitively orientable graphs, and proposed a polynomial-time heuristic algorithm for the MCRS problem based on coloring cocomparability graphs.   We give new, more transparent formulations of the two problems, showing that the problems are equivalent to two optimization problems on branchings in a derived directed acyclic graph. Building on these formulations, we obtain new results on the two problems, including: (i) a strengthening of the heuristic by Hujdurovi\'c et al. via a new min-max result in digraphs generalizing Dilworth's theorem, which may be of independent interest, (ii) APX-hardness results for both problems, (iii) approximation algorithms, and (iv) exponential-time algorithms solving the two problems to optimality faster than the na\""ive brute-force approach. Our work relates to several well studied notions in combinatorial optimization: chain partitions in partially ordered sets, laminar hypergraphs, and (classical and weighted) colorings of graphs. ",Perfect phylogenies via branchings in acyclic digraphs and a   generalization of Dilworth's theorem
"  We study two-dimensional non-abelian BF theory in Lorenz gauge and prove that it is a topological conformal field theory. This opens the possibility to compute topological string amplitudes (Gromov-Witten invariants). We found that the theory is exactly solvable in the sense that all correlators are given by finite-dimensional convergent integrals. Surprisingly, this theory turns out to be logarithmic in the sense that there are correlators given by polylogarithms and powers of logarithms. Furthermore, we found fields with ""logarithmic conformal dimension"" (elements of a Jordan cell for $L_0$). We also found certain vertex operators with anomalous dimensions that depend on the non-abelian coupling constant. The shift of dimension of composite fields may be understood as arising from the dependence of subtracted singular terms on local coordinates. This generalizes the well-known explanation of anomalous dimensions of vertex operators in the free scalar field theory. ",Two-dimensional non-abelian BF theory in Lorenz gauge as a solvable   logarithmic TCFT
"  Using the width of emission lines in XMM-Newton Reflection Grating Spectrometer spectra, we place direct constraints on the turbulent velocities of the X-ray emitting medium in the cores of 62 galaxy clusters, groups and elliptical galaxies. We find five objects where we can place an upper limit on the line-of-sight broadening of 500 km/s (90 per cent confidence level), using a single thermal component model. Two other objects are lower than this limit when two thermal components are used. Half of the objects examined have an upper limit on the velocity broadening of less than 700 km/s. To look for objects which have significant turbulent broadening, we use Chandra spectral maps to compute the expected broadening caused by the spatial extent of the source. Comparing these with our observed results, we find that Klemola 44 has extra broadening at the level of 1500 km/s. RX J1347.5-1145 shows weak evidence for turbulent velocities at 800 km/s. In addition we obtain limits on turbulence for Zw3146, Abell 496, Abell 1795, Abell 2204 and HCG 62 of less than 200 km/s. After subtraction of the spatial contribution and including a 50 km/s systematic uncertainty, we find at least 15 sources with less than 20 per cent of the thermal energy density in turbulence. ","Constraints on turbulent velocity broadening for a sample of clusters,   groups and elliptical galaxies using XMM-Newton"
"  Spin current generators are critical components for spintronics-based information processing. In this work, we theoretically and computationally investigate the bulk spin photovoltaic (BSPV) effect for creating DC spin current under light illumination. The only requirement for BPSV is inversion symmetry breaking, thus it applies to a broad range of materials and can be readily integrated with existing semiconductor technologies. The BSPV effect is a cousin of the bulk photovoltaic (BPV) effect, whereby a DC charge current is generated under light. Thanks to the different selection rules on spin and charge currents, a pure spin current can be realized if the system possesses mirror symmetry or inversion-mirror symmetry. The mechanism of BPSV and the role of the electronic relaxation time $\tau$ are also elucidated. We apply our theory to several distinct material systems, including transition metal dichalcogenides, anti-ferromagnetic $\rm MnBi_2Te_4$, and the surface of topological crystalline insulator cubic $\rm SnTe$. ",Pure Spin Photocurrent in Non-centrosymmetric Crystals: Bulk Spin   Photovoltaic Effect
"  Landau level gaps are important parameters for understanding electronic interactions and symmetry-broken processes in bilayer graphene (BLG). Here we present transport spectroscopy measurements of LL gaps in double-gated suspended BLG with high mobilities in the quantum Hall regime. By using bias as a spectroscopic tool, we measure the gap {\Delta} for the quantum Hall (QH) state at filling factor {\nu}={\pm}4 and -2. The single-particle gap for {\nu}=4 scales linearly with magnetic field B and is independent of the out-of-plane electric field E. For the symmetry-broken {\nu}=-2 state, the measured values of gap are 1.1 meV/T and 0.17 meV/T for singly-gated geometry and dual-gated geometry at E=0, respectively. The difference between the two values arises from the E-dependence of the gap, suggesting that the {\nu}=-2 state is layer polarized. Our studies provide the first measurements of the gaps of the broken symmetry QH states in BLG with well-controlled E, and establish a robust method that can be implemented for studying similar states in other layered materials. ",Transport Measurement of Landau level Gaps in Bilayer Graphene
"  Scanning diamond magnetometers based on the optically detected magnetic resonance of the nitrogen-vacancy centre offer very high sensitivity and non-invasive imaging capabilities when the stray fields emanating from ultrathin magnetic materials are sufficiently low (< 10 mT). Beyond this low-field regime, the optical signal quenches and a quantitative measurement is challenging. While the field-dependent NV photoluminescence can still provide qualitative information on magnetic morphology, this operation regime remains unexplored particularly for surface magnetisation larger than $\sim$ 3 mA. Here, we introduce a multi-angle reconstruction technique (MARe) that captures the full nanoscale domain morphology in all magnetic-field regimes leading to NV photoluminescence quench. To demonstrate this, we use [Ir/Co/Pt]$_{14}$ multilayer films with surface magnetisation an order of magnitude larger than previous reports. Our approach brings non-invasive nanoscale magnetic field imaging capability to the study of a wider pool of magnetic materials and phenomena. ",Multi-Angle Reconstruction of Domain Morphology with All-Optical Diamond   Magnetometry
"  The need for training data can impede the adoption of novel imaging modalities for learning-based medical image analysis. Domain adaptation methods partially mitigate this problem by translating training data from a related source domain to a novel target domain, but typically assume that a one-to-one translation is possible. Our work addresses the challenge of adapting to a more informative target domain where multiple target samples can emerge from a single source sample. In particular we consider translating from mp-MRI to VERDICT, a richer MRI modality involving an optimized acquisition protocol for cancer characterization. We explicitly account for the inherent uncertainty of this mapping and exploit it to generate multiple outputs conditioned on a single input. Our results show that this allows us to extract systematically better image representations for the target domain, when used in tandem with both simple, CycleGAN-based baselines, as well as more powerful approaches that integrate discriminative segmentation losses and/or residual adapters. When compared to its deterministic counterparts, our approach yields substantial improvements across a broad range of dataset sizes, increasingly strong baselines, and evaluation measures. ",Harnessing Uncertainty in Domain Adaptation for MRI Prostate Lesion   Segmentation
"  We consider a smooth one-parameter family $t \to f_t$ of diffeomorphisms with compact transitive Axiom A attractors. Our first result (corrected) is that for any function $G$ in the Sobolev space $H^r_p$, with $p>1$ and $0<r<1/p$, the map $R(t)$ sending $t$ to the average of $G$ with respect to the SRB measure of $f_t$ is $\alpha$-H\""older continuous for all $\alpha <r- |log \mathcal J|/(p|log \nu_s|$) where $\mathcal J\le 1$ is the strongest volume contraction and $\nu_s<1$ is the weakest contraction. This applies to $\theta(x)=h(x)\Theta(g(x)-a)$ (for all $\alpha <1- |log \mathcal J|/|log \nu_s|$) for $h$ and $g$ smooth and $\Theta$ the Heaviside function, if $a$ is not a critical value of $g$. Our second result says that for any such function so that, in addition, the intersection of the set of points $x$ so that $g(x)=a$ with the support of $h$ is foliated by ""admissible stable leaves"" of $f_t$, the map $R(t)$ is differentiable. (We provide distributional linear response and fluctuation-dissipation formulas for the derivative.) Obtaining linear response or fractional response for such observables is motivated by extreme-value theory. --- Second version, following the referee's comments: We explain better the cone choices around (2.4). Appendix A contains information on the Banach spaces. We added the paragraph containing (2.6) in the proof of Theorem 2.1. In the proof of Theorem 3.3, we do not need to introduce mollifiers. However, the new argument around (2.6) is not available here, so we must replace the pair $(u-1, |s-1|)$ by $(u-2, |s-2|)$. This is why we now assume that $h$ is $C^3$ and that $g$ and the foliations are $C^4$. --- Third version: We have added a corrigendum modifying the first result (Theorem 2.1). ",Linear and fractional response for the SRB measure of smooth hyperbolic   attractors and discontinuous observables
"  Within an improved transport model, we examine effects of the high momentum tail of the nucleon momentum distribution induced by short-range correlations on the proton-proton momentum correlation function in $^{197}$Au+$^{197}$Au collisions at 400 MeV/nucleon. It is found that the proton-proton momentum correlation function from preequilibrium emissions responds sensitively to the presence as well as fraction of nucleons in the high momentum tail of the nucleon momentum distribution, but is almost robustly insensitive to other factors including the symmetry energy and the uncertainty of cutoff value of nucleon effective high momentum. In terms of the sensitivity and clearness, we propose that the proton-proton momentum correlation function from preequilibrium emissions can be as an effective probe of the high momentum tail of the nucleon momentum distribution. ",Proton-proton momentum correlation function as a probe of the high   momentum tail of the nucleon momentum distribution
"  In this paper the existence and unicity of a stable periodic orbit is proven, for a class of piecewise affine differential equations in dimension 3 or more, provided their interaction structure is a negative feedback loop. It is also shown that the same systems converge toward a unique stable equilibrium point in dimension 2. This extends a theorem of Snoussi, which showed the existence of these orbits only. The considered class of equations is usually studied as a model of gene regulatory networks. It is not assumed that all decay rates are identical, which is biologically irrelevant, but has been done in the vast majority of previous studies. Our work relies on classical results about fixed points of monotone, concave operators acting on positive variables. Moreover, the used techniques are very likely to apply in more general contexts, opening directions for future work. ",Periodic solutions of piecewise affine gene network models: the case of   a negative feedback loop
"  We describe a new technique of quantum astrometry, which potentially can improve the resolution of optical interferometers by orders of magnitude. The approach requires fast imaging of single photons with sub-nanosecond resolution, greatly benefiting from recent advances in photodetection technologies. We also describe results of first proof of principle measurements and lay out future plans. ",Fast imaging of single photons in quantum assisted optical   interferometers
"  A supersymmetric quantum mechanical model is constructed for BPS states bound to surface operators in five dimensional SU(r) gauge theories using D-brane engineering. This model represents the effective action of a certain D2-brane configuration, and is naturally obtained by dimensional reduction of a quiver $(0,2)$ gauged linear sigma model. In a special stability chamber, the resulting moduli space of quiver representations is shown to be virtually smooth and isomorphic to a moduli space of framed quotients on the projective plane. A precise conjecture relating a K-theoretic partition function of this moduli space to refined open string invariants of toric lagrangian branes is formulated for conifold and local P^1 x P^1 geometries. ","D-branes, surface operators, and ADHM quiver representations"
"  It is known that modeling uncertainties and astrophysical foregrounds can potentially introduce appreciable bias in the deduced values of cosmological parameters. While it is commonly assumed that these uncertainties will be accounted for to a sufficient level of precision, the level of bias has not been properly quantified in most cases of interest. We show that the requirement that the bias in derived values of cosmological parameters does not surpass nominal statistical error, translates into a maximal level of overall error $O(N^{-1/2})$ on $|\Delta P(k)|/P(k)$ and $|\Delta C_{l}|/C_{l}$, where $P(k)$, $C_{l}$, and $N$ are the matter power spectrum, angular power spectrum, and number of (independent Fourier) modes at a given scale $l$ or $k$ probed by the cosmological survey, respectively. This required level has important consequences on the precision with which cosmological parameters are hoped to be determined by future surveys: In virtually all ongoing and near future surveys $N$ typically falls in the range $10^{6}-10^{9}$, implying that the required overall theoretical modeling and numerical precision is already very high. Future redshifted-21-cm observations, projected to sample $\sim 10^{14}$ modes, will require knowledge of the matter power spectrum to a fantastic $10^{-7}$ precision level. We conclude that realizing the expected potential of future cosmological surveys, which aim at detecting $10^{6}-10^{14}$ modes, sets the formidable challenge of reducing the overall level of uncertainty to $10^{-3}-10^{-7}$. ",Bias-Limited Extraction of Cosmological Parameters
"  We investigate traffic routing both from the perspective of real world data as well as theory. First, we reveal through data analytics a natural but previously uncaptured regularity of real world routing behavior. Agents only consider, in their strategy sets, paths whose free-flow costs (informally their lengths) are within a small multiplicative $(1+\theta)$ constant of the optimal free-flow cost path connecting their source and destination where $\theta\geq0$. In the case of Singapore, $\theta=1$ is a good estimate of agents' route (pre)selection mechanism. In contrast, in Pigou networks the ratio of the free-flow costs of the routes and thus $\theta$ is infinite, so although such worst case networks are mathematically simple they correspond to artificial routing scenarios with little resemblance to real world conditions, opening the possibility of proving much stronger Price of Anarchy guarantees by explicitly studying their dependency on $\theta$. We provide an exhaustive analysis of this question by providing provably tight bounds on PoA($\theta$) for arbitrary classes of cost functions both in the case of general congestion/routing games as well as in the special case of path-disjoint networks. For example, in the case of the standard Bureau of Public Roads (BPR) cost model, $c_e(x)= a_e x^4+b_e$ and more generally quartic cost functions, the standard PoA bound for $\theta=\infty$ is $2.1505$ (Roughgarden, 2003) and it is tight both for general networks as well as path-disjoint and even parallel-edge networks. In comparison, in the case of $\theta=1$, the PoA in the case of general networks is only $1.6994$, whereas for path-disjoint/parallel-edge networks is even smaller ($1.3652$), showing that both the route geometries as captured by the parameter $\theta$ as well as the network topology have significant effects on PoA (Figure 1). ",Data-Driven Models of Selfish Routing: Why Price of Anarchy Does Depend   on Network Topology
"  We prove Stanley's plethysm conjecture for the $2 \times n$ case, which composed with the work of Black and List provides another proof of Foulkes conjecture for the $2 \times n$ case. We also show that the way Stanley formulated his conjecture, it is false in general, and suggest an alternative formulation. ",On plethysm conjectures of Stanley and Foulkes: the $2 \times n$ case
  Developing Text Normalization (TN) systems for Text-to-Speech (TTS) on new languages is hard. We propose a novel architecture to facilitate it for multiple languages while using data less than 3% of the size of the data used by the state of the art results on English. We treat TN as a sequence classification problem and propose a granular tokenization mechanism that enables the system to learn majority of the classes and their normalizations from the training data itself. This is further combined with minimal precoded linguistic knowledge for other classes. We publish the first results on TN for TTS in Spanish and Tamil and also demonstrate that the performance of the approach is comparable with the previous work done on English. All annotated datasets used for experimentation will be released at https://github.com/amazon-research/proteno. ,Proteno: Text Normalization with Limited Data for Fast Deployment in   Text to Speech Systems
"  The Hong-Ou-Mandel (HOM) effect ranks among the most notable quantum interference phenomena, and is central to many applications in quantum technologies. The fundamental effect appears when two independent and indistinguishable photons are superimposed on a beam splitter, which achieves a complete suppression of coincidences between the two output ports. Much less studied, however, is when the fields share coherence (continuous-wave lasers) or mode envelope properties (pulsed lasers). In this case, we expect the existence of two distinct and concurrent HOM interference regimes: the traditional HOM dip on the coherence length time scale, and a structured HOM interference pattern on the pulse length scale. We develop a theoretical framework that describes HOM interference for laser fields having arbitrary temporal waveforms and only partial overlap in time. We observe structured HOM interference from a continuous-wave laser via fast polarization modulation and time-resolved single photon detection fast enough to resolve these structured HOM dips. ",Hong-Ou-Mandel interference of unconventional temporal laser modes
"  Python Library for simulating unManNed vehiclEs(PLANE) is an open source software module, written in Python, that focuses on Unmanned Aerial Vehicles (UAVs), on their movements and on the mechanics of flight, thus devoting particular attention to the equations that describe drones' movement. In the context of the Internet of Drones (IoD), the module can be widely used for the study of the mutual control of position/coordination in scenarios in which drones may find obstacles, as it happens in densely populated urban scenarios. Emphasis is put on ease of use, performance evaluation, documentation, and Application Programming Interface (API) consistency. The software tool has minimal dependencies and is distributed under MIT License. Source code, binaries, and documentation can be downloaded from GitHub. ",PLANE: An Extensible Open Source Framework for modeling the Internet of   Drones
"  We report an integrated all-optical radio frequency spectrum analyzer based on a ~ 4cm long doped silica glass waveguide, with a bandwidth greater than 2.5 THz. We use this device to characterize the intensity power spectrum of ultrahigh repetition rate mode-locked lasers at repetition rates up to 400 GHz, and observe dynamic noise related behavior not observable with other techniques. ",Terahertz bandwidth integrated radio frequency spectrum analyzer via   nonlinear optics
"  We calculate the next-to-next-to-next-to-leading order (N$^3$LO) QCD corrections to vector-boson fusion (VBF) Higgs pair production in the limit in which there is no partonic exchange between the two protons. We show that the inclusive cross section receives negligible corrections at this order, while the scale variation uncertainties are reduced by a factor four. We present differential distributions for the transverse momentum and rapidity of the final state Higgs bosons, and show that there is almost no kinematic dependence to the third order corrections. Finally we study the impact of deviations from the Standard Model in the trilinear Higgs coupling, and show that the structure of the higher order corrections does not depend on the self-coupling. These results are implemented in the latest release of the proVBFH-incl program. ",Vector-Boson Fusion Higgs Pair Production at N$^3$LO
"  We consider a variant of regression problem, where the correspondence between input and output data is not available. Such shuffled data is commonly observed in many real world problems. Taking flow cytometry as an example, the measuring instruments may not be able to maintain the correspondence between the samples and the measurements. Due to the combinatorial nature of the problem, most existing methods are only applicable when the sample size is small, and limited to linear regression models. To overcome such bottlenecks, we propose a new computational framework -- ROBOT -- for the shuffled regression problem, which is applicable to large data and complex nonlinear models. Specifically, we reformulate the regression without correspondence as a continuous optimization problem. Then by exploiting the interaction between the regression model and the data correspondence, we develop a hypergradient approach based on differentiable programming techniques. Such a hypergradient approach essentially views the data correspondence as an operator of the regression, and therefore allows us to find a better descent direction for the model parameter by differentiating through the data correspondence. ROBOT can be further extended to the inexact correspondence setting, where there may not be an exact alignment between the input and output data. Thorough numerical experiments show that ROBOT achieves better performance than existing methods in both linear and nonlinear regression tasks, including real-world applications such as flow cytometry and multi-object tracking. ",A Hypergradient Approach to Robust Regression without Correspondence
"  The theory of pattern formation in reaction-diffusion systems is extended to the case of a directed network. Due to the structure of the network Laplacian of the scrutinised system, the dispersion relation has both real and imaginary parts, at variance with the conventional case for a symmetric network. It is found that the homogeneous fixed point can become unstable due to the topology of the network, resulting in a new class of instabilities which cannot be induced on undirected graphs. Results from a linear stability analysis allow the instability region to be analytically traced. Numerical simulations show that the instability can lead to travelling waves, or quasi-stationary patterns, depending on the characteristics of the underlying graph. The results presented here could impact on the diverse range of disciplines where directed networks are found, such as neuroscience, computer networks and traffic systems. ",Topology-driven instabilities: the theory of pattern formation on   directed networks
"  Consider a polynomial optimisation problem, whose instances vary continuously over time. We propose to use a coordinate-descent algorithm for solving such time-varying optimisation problems. In particular, we focus on relaxations of transmission-constrained problems in power systems.   On the example of the alternating-current optimal power flows (ACOPF), we bound the difference between the current approximate optimal cost generated by our algorithm and the optimal cost for a relaxation using the most recent data from above by a function of the properties of the instance and the rate of change to the instance over time. We also bound the number of floating-point operations that need to be performed between two updates in order to guarantee the error is bounded from above by a given constant. ",A Coordinate-Descent Algorithm for Tracking Solutions in Time-Varying   Optimal Power Flows
"  Let N be an irreducible, compact 3-manifold with empty or toroidal boundary which is not a closed graph manifold. Using recent work of Agol, Kahn-Markovic and Przytycki-Wise we will show that pi_1(N) admits a cofinal filtration with `fast' growth of Betti numbers as well as a cofinal filtration of pi_1(N) with `slow' growth of ranks. ",A note on the growth of Betti numbers and ranks of 3-manifold groups
"  We propose and study a method called FLOT that estimates scene flow on point clouds. We start the design of FLOT by noticing that scene flow estimation on point clouds reduces to estimating a permutation matrix in a perfect world. Inspired by recent works on graph matching, we build a method to find these correspondences by borrowing tools from optimal transport. Then, we relax the transport constraints to take into account real-world imperfections. The transport cost between two points is given by the pairwise similarity between deep features extracted by a neural network trained under full supervision using synthetic datasets. Our main finding is that FLOT can perform as well as the best existing methods on synthetic and real-world datasets while requiring much less parameters and without using multiscale analysis. Our second finding is that, on the training datasets considered, most of the performance can be explained by the learned transport cost. This yields a simpler method, FLOT$_0$, which is obtained using a particular choice of optimal transport parameters and performs nearly as well as FLOT. ",FLOT: Scene Flow on Point Clouds Guided by Optimal Transport
"  A new isomorphism invariant of matroids is introduced, in the form of a quasisymmetric function. This invariant (1) defines a Hopf morphism from the Hopf algebra of matroids to the quasisymmetric functions, which is surjective if one uses rational coefficients, (2) is a multivariate generating function for integer weight vectors that give minimum total weight to a unique base of the matroid, (3) is equivalent, via the Hopf antipode, to a generating function for integer weight vectors which keeps track of how many bases minimize the total weight, (4) behaves simply under matroid duality, (5) has a simple expansion in terms of P-partition enumerators, and (6) is a valuation on decompositions of matroid base polytopes.   This last property leads to an interesting application: it can sometimes be used to prove that a matroid base polytope has no decompositions into smaller matroid base polytopes. Existence of such decompositions is a subtle issue arising in work of Lafforgue, where lack of such a decomposition implies the matroid has only a finite number of realizations up to projective equivalence. ",A quasisymmetric function for matroids
"  We consider the nonlinear Schr\""{o}dinger equation $(-\Delta +V(x))u = \Gamma(x) |u|^{p-1}u$, $x\in \R^n$ with $V(x) = V_1(x) \chi_{\{x_1>0\}}(x)+V_2(x) \chi_{\{x_1<0\}}(x)$ and $\Gamma(x) = \Gamma_1(x) \chi_{\{x_1>0\}}(x)+\Gamma_2(x) \chi_{\{x_1<0\}}(x)$ and with $V_1, V_2, \Gamma_1, \Gamma_2$ periodic in each coordinate direction. This problem describes the interface of two periodic media, e.g. photonic crystals. We study the existence of ground state $H^1$ solutions (surface gap soliton ground states) for $0<\min \sigma(-\Delta +V)$. Using a concentration compactness argument, we provide an abstract criterion for the existence based on ground state energies of each periodic problem (with $V\equiv V_1, \Gamma\equiv \Gamma_1$ and $V\equiv V_2, \Gamma\equiv \Gamma_2$) as well as a more practical criterion based on ground states themselves. Examples of interfaces satisfying these criteria are provided. In 1D it is shown that, surprisingly, the criteria can be reduced to conditions on the linear Bloch waves of the operators $-\tfrac{d^2}{dx^2} +V_1(x)$ and $-\tfrac{d^2}{dx^2} +V_2(x)$. ","Surface Gap Soliton Ground States for the Nonlinear Schr\""{o}dinger   Equation"
  We study quantum corrections to conductivity in a 2D system with a smooth random potential and strong spin-orbit splitting of the spectrum. We show that the interference correction is positive and down to the very low temperature can exceed the negative correction related to electron-electron interactions. We discuss this result in the context of the problem of the metal-insulator transition in Si-MOSFET structures. ,Quantum conductivity corrections in two dimensional long-range   disordered systems with strong spin-orbit splitting of electron spectrum
"  In this paper, we study the asymptotic behavior of the following function $$M_k(n):=(-1)^{k-1} \sum_{j=0}^{k-1}\big(p(n-j(3j+1)/2)-p(n-j(3j+5)/2-1)\big),$$ which arises from Andrews and Merca's truncated pentagonal number theorem. ",A further look at the truncated pentagonal number theorem
"  It is demonstrated that sonic crystals (periodic structures of sound scatterers) can be used to design acoustic barriers that attenuate efficiently broadband noise. Traffic noise is chosen here as an example in which our design procedure is applied. The structures consist of cylindrical units containing rubber crumb, a sound absorbing material. An optimization algorithm is developed to obtain the material distribution and the dimensions of the sonic crystal giving the best attenuation properties for this noise. The good agreement found between predictions and measurements for a barrier (3m height) characterized in a transmission room gives strong support to our proposal. ",Optimum control of broadband noise by barriers based on sonic crystals
"  We present two counterexamples to the paper by Carot et al. in Gen. Rel. Grav. 1997, 29, 1223 and show that the results obtained are correct but not general. ",Comment on Ricci Collineations for type B warped space-times
"  Some elements of the theory and algorithmics corresponding to the computation of semilinear sparse models for discrete-time signals are presented. In this study, we will focus on approximately eventually periodic discrete-time signals, that is, signals that can exhibit an aperiodic behavior for an initial amount of time, and then become approximately periodic afterwards. The semilinear models considered in this study are obtained by combining sparse representation methods, linear autoregressive models and GRU neural network models, initially fitting each block model independently using some reference data corresponding to some signal under consideration, and then fitting some mixing parameters that are used to obtain a signal model consisting of a linear combination of the previously fitted blocks using the aforementioned reference data, computing sparse representations of some of the matrix parameters of the resulting model along the process. Some prototypical computational implementations are presented as well. ",Computing Semilinear Sparse Models for Approximately Eventually Periodic   Signals
"  A generalized description of entanglement and quantum correlation properties constraining internal degrees of freedom of Dirac(-like) structures driven by arbitrary Poincar\'e classes of external field potentials is proposed. The role of (pseudo)scalar, (pseudo)vector and tensor interactions in producing/destroying intrinsic quantum correlations for $\mbox{SU}(2) \otimes \mbox{SU}(2)$ bi-spinor structures is discussed in terms of generic coupling constants. By using a suitable ansatz to obtain the Dirac Hamiltonian eigenspinor structure of time-independent solutions of the associated Liouville equation, the quantum entanglement, via concurrence, and quantum correlations, via geometric discord, are computed for several combinations of well-defined Poincar\'e classes of Dirac potentials. Besides its inherent formal structure, our results setup a framework which can be enlarged as to include localization effects and to map quantum correlation effects into Dirac-like systems which describe low-energy excitations of graphene and trapped ions. ",Entanglement of Dirac bi-spinor states driven by Poincar\'e classes of   $\mbox{SU}(2) \otimes \mbox{SU}(2)$ coupling potentials
  Objective: to establish an algorithmic framework and a benchmark dataset for comparing methods of pulse rate estimation using imaging photoplethysmography (iPPG). Approach: first we reveal essential steps of pulse rate estimation from facial video and review methods applied at each of the steps. Then we investigate performance of these methods for DEAP dataset www.eecs.qmul.ac.uk/mmv/datasets/deap/ containing facial videos and reference contact photoplethysmograms. Main results: best assessment precision is achieved when pulse rate is estimated using continuous wavelet transform from iPPG extracted by the POS method (overall mean absolute error below 2 heart beats per minute). Significance: we provide a generic framework for theoretical comparison of methods for pulse rate estimation from iPPG and report results for the most popular methods on a publicly available dataset that can be used as a benchmark. ,Pulse rate estimation using imaging photoplethysmography: generic   framework and comparison of methods on a publicly available dataset
"  We numerically investigate the stationary and non-equilibrium critical dynamics in three-dimensional isotropic Heisenberg antiferromagnets. Since the non-conserved staggered magnetization couples dynamically to the conserved magnetization density, we employ a hybrid simulation algorithm that combines reversible spin precession with relaxational Kawasaki spin exchange processes. We measure the dynamic critical exponent and identify a suitable intermediate time window to obtain the aging scaling exponents. Our results support an earlier renormalization group prediction: While the critical aging collapse exponent assumes a universal value, the associated temporal decay exponent in the two-time spin autocorrelation function depends on the initial distribution of the conserved fields; here, specifically on the width of the initial spin orientation distribution. ",Non-universal critical aging scaling in three-dimensional Heisenberg   antiferromagnets
"  Magnetic fields without a direction of continuous symmetry have the generic feature that neighboring field lines exponentiate away from each other and become stochastic, hence the ideal constraint of preserving magnetic field line connectivity becomes exponentially sensitive to small deviations from ideal Ohm's law. The idea of breaking field line connectivity by stochasticity as a mechanism for fast reconnection is tested with numerical simulations based on reduced magnetohydrodynamics equations with a strong guide field line-tied to two perfectly conducting end plates. Starting from an ideally stable force-free equilibrium, the system is allowed to undergo resistive relaxation. Two distinct phases are found in the process of resistive relaxation. During the quasi-static phase, rapid change of field line connectivity and strong induced flow are found in regions of high field line exponentiation. However, although the field line connectivity of individual field lines can change rapidly, the overall pattern of field line mapping appears to deform gradually. From this perspective, field line exponentiation appears to cause enhanced diffusion rather than reconnection. In some cases, resistive quasi-static evolution can cause the ideally stable initial equilibrium to cross a stability threshold, leading to formation of intense current filaments and rapid change of field line mapping into a qualitatively different pattern. It is in this onset phase that the change of field line connectivity is more appropriately designated as magnetic reconnection. Our results show that rapid change of field line connectivity appears to be a necessary, but not a sufficient condition for fast reconnection. ",Rapid Change of Field Line Connectivity and Reconnection in Stochastic   Magnetic Fields
"  We study quantum discord between two free modes of a massive scalar field in a maximally entangled state in de Sitter space. We introduce two observers, one in a global chart and the other in an open chart of de Sitter space, and the observers determine the quantum discord created by each detecting one of the modes. This situation is analogous to the relationship between an observer in a Minkowski chart and another in one of the two Rindler charts in flat space. We find that the state becomes less entangled as the curvature of the open chart gets larger. In particular, for the cases of a massless, and a conformally coupled scalar field, the entanglement vanishes in the limit of infinite curvature. However, we find that the quantum discord never disappears even in the limit that entanglement disappears. ",Quantum discord in de Sitter space
"  We introduce an improved semiclassical dynamics approach to quantum vibrational spectroscopy. In this method, a harmonic-based phase space sampling is preliminarily driven toward non-harmonic quantization by slowly switching on the actual potential. The new coordinates and momenta serve as initial conditions for the semiclassical dynamics calculation, leading to a substantial decrease in the number of chaotic trajectories to deal with. Applications are presented for model and molecular systems of increasing dimensionality characterized by moderate or high chaoticity. They include a bidimensional Henon-Heiles potential, water, formaldehyde, and methane.The method improves accuracy and precision of semiclassical results and it can be easily interfaced with all pre-existing semiclassical theories. ",Improved semiclassical dynamics through adiabatic switching trajectory   sampling
"  The interfacial structures and interactions of two-dimensional (2D) materials on solid substrates are of fundamental importance for the fabrication and application of 2D materials. However, selection of a suitable solid substrate to grow 2D material, determination and control of the 2D material-substrate interface remain a big challenge due to the large diversity of possible configurations. Here, we propose a computational framework to select an appropriate substrate for epitaxial growth of 2D material and to predict possible 2D material-substrate interface structures and orientations using density functional theory calculations performed for all non-equivalent atomic structures satisfying the symmetry constraints. The approach was validated by the correct prediction of three experimentally reported 2D material-substrate interface systems with only the given information of two parent materials. Several possible interface configurations are also proposed based on this approach. We therefore construct a database that contains these interface systems and has been continuously expanding. This database serves as preliminary guidance for epitaxial growth and stabilization of new materials in experiments. ",Database Construction for Two-Dimensional Material-Substrate Interfaces
"  This paper establishs the large deviation principle (LDP) for multiple averages on $\mathbb{N}^d$. We extend the previous work of [Carinci et al., Indag. Math. 2012] to multidimensional lattice $\mathbb{N}^d$ for $d\geq 2$. The same technique is also applicable to the weighted multiple average launched by Fan [Fan, Adv. Math. 2021]. Finally, the boundary conditions are imposed to the multiple sum and explicit formulae of the energy functions with respect to the boundary conditions are obtained. ",Large Deviation Principle of Multidimensional Multiple Averages on   $\mathbb{N}^d$
"  Rotation curves for four spiral galaxies with recently determined Cepheid-based distances are reconsidered in terms of modified Newtonian dynamics (MOND). For two of the objects, NGC 2403 and NGC 7331, the rotation curves predicted by MOND are compatible with the observed curves when these galaxies are taken to be at the Cepheid distance. For NGC 3198, the largest distance for which reasonable agreement is obtained is 10% smaller than the Cepheid-based distance; i.e., MOND clearly prefers a smaller distance. This conclusion is unaltered when new near-infrared photometry of NGC 3198 is taken as the tracer of the stellar mass distribution. For the large Sc spiral, NGC 2841, MOND requires a distance which is at least 20% larger than the Cepheid-based distance. However, the discrepancy of the Tully-Fisher and SNIa distances with the Cepheid determination casts some doubt upon the Cepheid method in this case. ",MOND rotation curves for spiral galaxies with Cepheid-based distances
"  These days, vast amounts of knowledge are available online, most of it in written form. Search engines help us access this knowledge, but aggregating, relating and reasoning with it is still a predominantly human effort. One of the key challenges for automated reasoning based on natural-language texts is the need to extract meaning (semantics) from texts. Natural language understanding (NLU) systems describe the conversion from a set of natural language utterances to terms in a particular logic. Tools for the co-development of grammar and target logic are currently largely missing.   We will describe the Grammatical Logical Framework (GLF), a combination of two existing frameworks, in which large parts of a symbolic, rule-based NLU system can be developed and implemented: the Grammatical Framework (GF) and MMT. GF is a tool for syntactic analysis, generation, and translation with complex natural language grammars and MMT can be used to specify logical systems and to represent knowledge in them. Combining these tools is possible, because they are based on compatible logical frameworks: Martin-L\""of type theory and LF. The flexibility of logical frameworks is needed, as NLU research has not settled on a particular target logic for meaning representation. Instead, new logics are developed all the time to handle various language phenomena. GLF allows users to develop the logic and the language parsing components in parallel, and to connect them for experimentation with the entire pipeline. ",GF + MMT = GLF -- From Language to Semantics through LF
"  Many interesting shapes appearing in the biological world are formed by the onset of mechanical instability. In this work we consider how the build-up of residual stress can cause a solid to buckle. In all past studies a fictitious (virtual) stress-free state was required to calculate the residual stress. In contrast, we use a model which is simple and allows the prescription of any residual stress field.   We specialize the analysis to an elastic tube subject to a two-dimensional residual stress, and find that incremental wrinkles can appear on its inner or its outer face, depending on the location of the highest value of the residual hoop stress. We further validate the predictions of the incremental theory with finite element simulations, which allow us to go beyond this threshold and predict the shape, number and amplitude of the resulting creases. ",Morphology of residually-stressed tubular tissues: Beyond the elastic   multiplicative decomposition
"  We explore the tunneling transport properties of a quantum dot embedded in an optical microcavity and coupled to a semiconductor-superconductor one-dimensional nanowire (Majorana nanowire) hosting Majorana zero modes (MZMs) at their edges. Conductance profiles reveal that strong light-matter coupling can be employed to distinguish between the cases of highly nonlocal MZMs, overlapped MZMs and quasi-MZMs. Moreover, we show that it is possible to access the degree of Majorana nonlocality (topological quality factor) by changing the dot spectrum through photon-induced transitions tuned by an external pump applied to the microcavity. ",Accessing the degree of Majorana nonlocality with photons
"  Given a pair of real functions $(k,f)$, we study the conditions they must satisfy for $k+\lambda f$ to be the curvature in the arc-length of a closed planar curve for all real $\lambda$. Several equivalent conditions are pointed out, certain periodic behaviours are shown as essential and a family of such pairs is explicitely constructed. The discrete counterpart of the problem is also studied. Finally, the characterization obtained is used to show that a sufficient analogue of the 4-vertex theorem cannot be developed. ",Affine subspaces of curvature functions from closed planar curves
"  Model independent verification of the quark combinatorics rules, which govern the ratios of the yields of secondaries, is presented for jet processes. Because of a large number of produced resonances in the hadron jets, a test of the quark combinatorics rules is hardly possible in the central region, x_{hadron} < 0.2. However, a model-independent verification is plausible at x_{hadron} \sim 1. It is shown that for the large x_{hadron} kinematical region the quark combinatorial relations are in a reasonable agreement with data for \rho^0/\pi^0 and p/\pi^+ ratios. ",Quark combinatorics for production ratios in hadronic Z^0 decays
"  We study the effects of varying the pre-implant film thickness and implant temperature on the electrical and superconducting properties of metal-mixed ion-implanted polymers. We show that it is possible to drive a superconductor-insulator transition in these materials via control of the fabrication parameters. We observe peaks in the magnetoresistance and demonstrate that these are caused by the interplay between superconductivity and weak localization in these films, which occurs due to their granular structure. We compare these magnetoresistance peaks with those seen in unimplanted films and other organic superconductors, and show that they are distinctly different. ",Competition between Superconductivity and Weak Localization in   Metal-Mixed Ion-Implanted Polymers
"  This note is a survey of results on the function $F_{\mathbf{k}}(z)$ introduced by G. Kawashima, and its applications to the study of multiple zeta values. We stress the viewpoint that the Kawashima function is a generalization of the digamma function $\psi(z)$, and explain how various formulas for $\psi(z)$ are generalized. We also discuss briefly the relationship of the results on the Kawashima functions with a recent work on Kawashima's MZV relation by M. Kaneko and the author. ",A Note on Kawashima Functions
"  End-to-end (E2E) models have made rapid progress in automatic speech recognition (ASR) and perform competitively relative to conventional models. To further improve the quality, a two-pass model has been proposed to rescore streamed hypotheses using the non-streaming Listen, Attend and Spell (LAS) model while maintaining a reasonable latency. The model attends to acoustics to rescore hypotheses, as opposed to a class of neural correction models that use only first-pass text hypotheses. In this work, we propose to attend to both acoustics and first-pass hypotheses using a deliberation network. A bidirectional encoder is used to extract context information from first-pass hypotheses. The proposed deliberation model achieves 12% relative WER reduction compared to LAS rescoring in Google Voice Search (VS) tasks, and 23% reduction on a proper noun test set. Compared to a large conventional model, our best model performs 21% relatively better for VS. In terms of computational complexity, the deliberation decoder has a larger size than the LAS decoder, and hence requires more computations in second-pass decoding. ",Deliberation Model Based Two-Pass End-to-End Speech Recognition
  This paper contains results relating currents and voltages in resistive networks to appropriate random trees or forests in those networks. ,Random Trees in Electrical Networks
"  We provide insights into the influence of surface termination on the oxygen vacancy incorporation for the perovskite model material SrTiO3 during annealing in reducing gas environments. We present a novel approach to control to tailor the oxygen vacancy formation by controlling the termination. We prove that a SrO-termination can inhibit the incorporation of oxygen vacancies across the (100)-surface and apply this to control their incorporation during thin film growth. Utilizing the conducting interface between LaAlO3 and SrTiO3, we could tailor the oxygen-vacancy based conductivity contribution by the level of SrO termination at the interface. ",SrTiO$_3$ termination control: A method to tailor the oxygen exchange   kinetics
"  Kasteleyn counted the number of domino tilings of a rectangle by considering a mutation of the adjacency matrix: a Kasteleyn matrix K. In this paper we present a generalization of Kasteleyn matrices and a combinatorial interpretation for the coefficients of the characteristic polynomial of KK^\ast (which we call the singular polynomial), where K is a generalized Kasteleyn matrix for a planar bipartite graph. We also present a q-version of these ideas and a few results concerning tilings of special regions such as rectangles. ",Singular polynomials of generalized Kasteleyn matrices
"  We argue that the observed large-scale cosmic microwave anomalies, discovered by WMAP and confirmed by the Planck satellite, are most naturally explained in the context of a marginally-open universe. Particular focus is placed on the dipole power asymmetry, via an open universe implementation of the large-scale gradient mechanism of Erickcek et al. Open inflation models, which are motivated by the string landscape and which can excite `super-curvature' perturbation modes, can explain the presence of a very-large-scale perturbation that leads to a dipole modulation of the power spectrum measured by a typical observer. We provide a specific implementation of the scenario which appears compatible with all existing constraints. ",Cosmic microwave background anomalies in an open universe
"  In this paper, we consider the final state problem for the nonlinear Klein-Gordon equation (NLKG) with a critical nonlinearity in three space dimensions. We prove that for a given asymptotic profile, there exists a solution to (NLKG) which converges to given asymptotic profile as t to infinity. Here the asymptotic profile is given by the leading term of the solution to the linear Klein-Gordon equation with a logarithmic phase correction. Construction of a suitable approximate solution is based on the combination of Fourier series expansion for the nonlinearity used in our previous paper and smooth modification of phase correction by Ginibre-Ozawa. ",Modified scattering for the Klein-Gordon equation with the critical   nonlinearity in three dimensions
"  We studied the adsorption of a charged protein onto an oppositely charged membrane, composed of mobile phospholipids of differing valence, using a statistical-thermodynamical approach. A two-block model was employed, one block corresponding to the protein-affected region on the membrane, referred to as the adsorption domain, and the other to the unaffected remainder of the membrane. We calculated the protein-induced lipid rearrangement in the adsorption domain as arising from the interplay between the electrostatic interactions in the system and the mixing entropy of the lipids. Equating the electrochemical potentials of the lipids in the two blocks yields an expression for the relations among the various lipid fractions in the adsorption domain, indicating a sensitive dependence of lipid fraction on valence. This expression is a result of the two-block picture but does not depend on further details of the protein-membrane interaction. We subsequently calculated the lipid fractions themselves using the Poisson-Boltzmann theory. We examined the dependence of lipid enrichment, i.e., the ratio between the lipid fractions inside and outside the adsorption domain, on various parameters such as ionic strength and lipid valence. Maximum enrichment was found for lipid valence of about (-3) to (-4) in physiological conditions. Our results are in qualitative agreement with recent experimental studies on the interactions between peptides having a domain of basic residues and membranes containing a small fraction of the polyvalent phosphatidylinositol 4,5-bisphosphate (PIP2). This study provides theoretical support for the suggestion that proteins adsorbed onto membranes through a cluster of basic residues may sequester PIP2 and other polyvalent lipids. ",Increased Concentration of Polyvalent Phospholipids in the Adsorption   Domain of a Charged Protein
"  Occurring in protoplanetary discs composed of dust and gas, streaming instabilities are a favoured mechanism to drive the formation of planetesimals. The Polydispserse Streaming Instability is a generalisation of the Streaming Instability to a continuum of dust sizes. This second paper in the series provides a more in-depth derivation of the governing equations and presents novel numerical methods for solving the associated linear stability problem. In addition to the direct discretisation of the eigenproblem at second order introduced in the previous paper, a new technique based on numerically reducing the system of integral equations to a complex polynomial combined with root finding is found to yield accurate results at much lower computational cost. A related method for counting roots of the dispersion relation inside a contour without locating those roots is also demonstrated. Applications of these methods show they can reproduce and exceed the accuracy of previous results in the literature, and new benchmark results are provided. Implementations of the methods described are made available in an accompanying Python package psitools. ",Polydisperse Streaming Instability II. Methods for solving the linear   stability problem
"  Searching sounds by text labels is often difficult, as text descriptions cannot describe the audio content in detail. Query by vocal imitation bridges such gap and provides a novel way to sound search. Several algorithms for sound search by vocal imitation have been proposed and evaluated in a simulation environment, however, they have not been deployed into a real search engine nor evaluated by real users. This pilot work conducts a subjective study to compare these two approaches to sound search, and tries to answer the question of which approach works better for what kinds of sounds. To do so, we developed two web-based search engines for sound, one by vocal imitation (Vroom!) and the other by text description (TextSearch). We also developed an experimental framework to host these engines to collect statistics of user behaviors and ratings. Results showed that Vroom! received significantly higher search satisfaction ratings than TextSearch did for sound categories that were difficult for subjects to describe by text. Results also showed a better overall ease-of-use rating for Vroom! than TextSearch on the limited sound library in our experiments. These findings suggest advantages of vocal-imitation-based search for sound in practice. ",Sound Search by Text Description or Vocal Imitation?
"  We study the homotopy derivations of the framed little discs operads, which correspond to the homotopy derivations of the BV2n operads. By extending a result by Willwacher about the homotopy derivations of the en operads we show that the homotopy derivations of the BV2n operads may be described through the cohomology of a suitable graph complex. We will present an explicit quasi-isomorphic map. ",Homotopy derivations of the framed little discs operads
"  J\""urgen Ehlers developed \emph{frame theory} to better understand the relationship between general relativity and Newtonian gravity. Frame theory contains a parameter $\lambda$, which can be thought of as $1/c^2$, where $c$ is the speed of light. By construction, frame theory is equivalent to general relativity for $\lambda >0$, and reduces to Newtonian gravity for $\lambda =0$. Moreover, by setting $\ep=\sqrt{\lambda}$, frame theory provides a framework to study the Newtonian limit $\ep \searrow 0$ (i.e. $c\to \infty$). A number of ideas relating to frame theory that were introduced by J\""urgen have subsequently found important applications to the rigorous study of both the Newtonian limit and post-Newtonian expansions. In this article, we review frame theory and discuss, in a non-technical fashion, some of the rigorous results on the Newtonian limit and post-Newtonian expansions that have followed from J\""urgen's work. ",Existence of families of spacetimes with a Newtonian limit
"  Sliced inverse regression (SIR) is the most widely-used sufficient dimension reduction method due to its simplicity, generality and computational efficiency. However, when the distribution of the covariates deviates from the multivariate normal distribution, the estimation efficiency of SIR is rather low. In this paper, we propose a robust alternative to SIR - called elliptical sliced inverse regression (ESIR) for analysing high dimensional, elliptically distributed data. There are wide range of applications of the elliptically distributed data, especially in finance and economics where the distribution of the data is often heavy-tailed. To tackle the heavy-tailed elliptically distributed covariates, we novelly utilize the multivariate Kendall's tau matrix in a framework of so-called generalized eigenvector problem for sufficient dimension reduction. Methodologically, we present a practical algorithm for our method. Theoretically, we investigate the asymptotic behavior of the ESIR estimator and obtain the corresponding convergence rate under high dimensional setting. Quantities of simulation results show that ESIR significantly improves the estimation efficiency in heavy-tailed scenarios. A stock exchange data analysis also demonstrates the effectiveness of our method. Moreover, ESIR can be easily extended to most other sufficient dimension reduction methods. ",High Dimensional Elliptical Sliced Inverse Regression in non-Gaussian   Distributions
"  We investigate classical anomalous electrical transport in a driven, resistively and capacitively shunted Josephson junction device. Novel transport phenomena are identified in chaotic regimes when the junction is subjected to both, a time periodic (ac) and a constant, biasing (dc) current. The dependence of the voltage across the junction on the dc-current exhibits a rich diversity of anomalous transport characteristics: In particular, depending on the chosen parameter regime we can identify so termed absolute negative conductance around zero dc-bias, the occurrence of negative differential conductance and, after crossing a zero conductance, the emergence of a negative nonlinear conductance in the non-equilibrium response regime remote from zero dc-bias. ",Anomalous transport in biased ac-driven Josephson junctions: Negative   conductances
"  The nonadiabatic regime of the electron-phonon interaction leads to behaviors of some physical measurable quantities qualitatively different from those expected from the Migdal-Eliashberg theory. Here we identify in the Pauli paramagnetic susceptibility $\chi$ one of such quantities and show that the nonadiabatic corrections reduce $\chi$ with respect to its adiabatic limit. We show also that the nonadiabatic regime induces an isotope dependence of $\chi$, which in principle could be measured. ",Pauli susceptibility of nonadiabatic Fermi liquids
"  This paper aims at demonstrating that: 1/ Assuming the equality of the two-way transit time of light in vacuo, along the two perpendicular arms of Michelson's interferometers (modern versions of Michelson's experiment), and the anisotropy of the one-way speed of light in the Earth frame, two facts supported today by strong experimental arguments, length contraction (in Lorentz and FitzGerald's approach) should no longer be regarded as an ad hoc hypothesis, it appears necessary and can be easily deduced. 2/ Builder and Prokhovnik had the great merit of having shown that, as a result of to length contraction, the two-way transit time of light along a rod is the same in all directions in space (and not only in two privileged directions). We agree with these authors up to this point, but, contrary to what is often believed, their approach failed to reconcile aether theory with the invariance of the apparent (measured) two-way speed of light. Yet, as we shall show, due to the systematic measurement distortions entailed by length contraction and clock retardation assumed by aether theory, the two-way speed of light, although anisotropic and dependent on the absolute speed of the frame where it is measured, is always found equal to C. The reasons of this paradoxical but important result will be developed here. They confirm Lorentz-Fitzgerald's contraction and lend support of the existence of a preferred aether frame. ",Two-way speed of light and Lorentz-FitzGerald's contraction in aether   theory
"  A Stein covering of a complex manifold may be used to realise its analytic cohomology in accordance with the Cech theory. If, however, the Stein covering is parameterised by a smooth manifold rather than just a discrete set, then we construct a cohomology theory in which an exterior derivative replaces the usual combinatorial Cech differential. Our construction is motivated by integral geometry and the representation theory of Lie groups. ",Smoothly Parameterised Cech Cohomology of Complex Manifolds
"  To which degree are shape indices of individual cells of a tessellation characteristic for the stochastic process that generates them? Within the context of stochastic geometry and the physics of disordered materials, this corresponds to the question of relationships between different stochastic models. In the context of image analysis of synthetic and biological materials, this question is central to the problem of inferring information about formation processes from spatial measurements of resulting random structures. We address this question by a theory-based simulation study of shape indices derived from Minkowski tensors for a variety of tessellation models. We focus on the relationship between two indices: an isoperimetric ratio of the empirical averages of cell volume and area and the cell elongation quantified by eigenvalue ratios of interfacial Minkowski tensors. Simulation data for these quantities, as well as for distributions thereof and for correlations of cell shape and volume, are presented for Voronoi mosaics of the Poisson point process, determinantal and permanental point processes, and Gibbs hard-core and random sequential absorption processes as well as for Laguerre tessellations of polydisperse spheres and STIT- and Poisson hyperplane tessellations. These data are complemented by mechanically stable crystalline sphere and disordered ellipsoid packings and area-minimising foam models. We find that shape indices of individual cells are not sufficient to unambiguously identify the generating process even amongst this limited set of processes. However, we identify significant differences of the shape indices between many of these tessellation models. Given a realization of a tessellation, these shape indices can narrow the choice of possible generating processes, providing a powerful tool which can be further strengthened by density-resolved volume-shape correlations. ",Cell shape analysis of random tessellations based on Minkowski tensors
"  We present high angular resolution observations of the HCN(1-0) emission (at ~1"" or ~34 pc), together with CO J = 1-0, 2-1, and 3-2 observations, toward the Seyfert 2 nucleus of M51 (NGC 5194). The overall HCN(1-0) distribution and kinematics are very similar to that of the CO lines, which have been indicated as the jet-entrained molecular gas in our past observations. In addition, high HCN(1-0)/CO(1-0) brightness temperature ratio of about unity is observed along the jets, similar to that observed at the shocked molecular gas in our Galaxy. These results strongly indicate that both diffuse and dense gases are entrained by the jets and outflowing from the AGN. The channel map of HCN(1-0) at the systemic velocity shows a strong emission right at the nucleus, where no obvious emission has been detected in the CO lines. The HCN(1-0)/CO(1-0) brightness temperature ratio at this region reaches >2, a value that cannot be explained considering standard physical/chemical conditions. Based on our calculations, we suggest infrared pumping and possibly weak HCN masing, but still requiring an enhanced HCN abundance for the cause of this high ratio. This suggests the presence of a compact dense obscuring molecular gas in front of the nucleus of M51, which remains unresolved at our ~1"" (~34 pc) resolution, and consistent with the Seyfert 2 classification picture. ",Resolving the Bright HCN(1-0) Emission toward the Seyfert 2 Nucleus of   M51: Shock Enhancement by Radio Jets and Weak Masing by Infrared Pumping?
  Intensive numerical studies of exact ground states of the 2-d ferromagnetic random field Ising model at T=0 with gaussian distribution of fields are presented. Standard finite size scaling analysis of the data suggests the existence of a transition at sigma_c= 0.64 +/- 0.08. Results are compared with existing theories and with the study of metastable avalanches in the same model. ,Numerical signs for a transition in the 2d Random Field Ising Model at   T=0
"  Decision-making is a process of choosing among alternative courses of action for solving complicated problems where multi-criteria objectives are involved. The past few years have witnessed a growing recognition of Soft Computing (SC) technologies that underlie the conception, design and utilization of intelligent systems. In this paper, we present different SC paradigms involving an artificial neural network trained using the scaled conjugate gradient algorithm, two different fuzzy inference methods optimised using neural network learning/evolutionary algorithms and regression trees for developing intelligent decision support systems. We demonstrate the efficiency of the different algorithms by developing a decision support system for a Tactical Air Combat Environment (TACE). Some empirical comparisons between the different algorithms are also provided. ",Decision Support Systems Using Intelligent Paradigms
"  It is shown that quantum mechanics is a plausible statistical description of an ontology described by classical electrodynamics. The reason that no contradiction arises with various no-go theorems regarding the compatibility of QM with a classical ontology, can be traced to the fact that classical electrodynamics of interacting particles has never been given a consistent definition. Once this is done, our conjecture follows rather naturally, including a purely classical explanation of photon related phenomena. Our analysis entirely rests on the block-universe view entailed by relativity theory. ",Quantum mechanics as a statistical description of classical   electrodynamics
"  Herbig-Haro jets often show some degree of curvature along their path, in many cases produced by the ram pressure of a side-wind. We present simulations of both laboratory and astrophysical curved jets and experimental results from laboratory experiments. We discuss the properties and similarities of the laboratory and astrophysical flow, which show the formation of internal shocks and working surfaces. In particular the results illustrate how the break-up of the bow-shock and clumps in the flow are produced without invoking jet variability; we also discuss how jet rotation reduces the growth of the Rayleigh-Taylor instability in curved jets. ",Curved Herbig-Haro Jets: Simulations and Experiments
"  We study the production of photons from a quark gluon plasma in local thermal equilibrium by introducing a non-perturbative formulation of the real time evolution of the density matrix. The main ingredient is the real time effective action for the electromagnetic field to $\mathcal{O}(\alpha_{em})$ and to all orders in $\alpha_s$. The real time evolution is completely determined by the solution of a \emph{classical stochastic} non-local Langevin equation which provides a Dyson-like resummation of the perturbative expansion. The Langevin equation is solved in closed form by Laplace transform in terms of the thermal photon polarization. A quantum kinetic description emerges directly from this formulation. We find that photons with $k \lesssim 200 ~{Mev}$ \emph{thermalize} as plasmon quasiparticles in the plasma on time scales $t \sim 10-20 ~{fm}/c$ which is of the order of the lifetime of the QGP expected at RHIC and LHC. We then obtain the direct photon yield to lowest order in $\alpha_{em}$ and to leading logarithmic order in $\alpha_s$ in a \emph{uniform} expansion valid at all time. The yield during a QGP lifetime $t \sim 10 ~{fm}/c$ is systematically larger than that obtained with the equilibrium formulation and the spectrum features a distinct flattening for $k \gtrsim 2.5 ~{Gev}$. We discuss the window of reliability of our results, the theoretical uncertainties in \emph{any} treatment of photon emission from a QGP in LTE and the shortcomings of the customary S-matrix approach. ",Photon production from a thermalized quark gluon plasma: quantum   kinetics and nonperturbative aspects
"  The capture or scattering of an initially straight infinite test cosmic string by a Kerr-Newman black hole, or by any other small source of an electrovac gravitational field, is analyzed analytically when the string moves with initial velocity v and large impact parameter b >> M so that the string stays very nearly straight (except during the final capture process, if that occurs, or except far behind the gravitating object, if b is not much greater than the energy of the object in the frame of the string). The critical impact parameter for capture at low velocities is shown to be [(pi/2)(M^2-Q^2)/v]^{1/2}. For all larger b, the displacement of the string from the plane of the gravitating object after the scattering approaches the final value [b^2 - (pi/2)(M^2-Q^2)/v]^{1/2} - 2 pi M v/(1-v^2)^{1/2}, for any v, so long as b >> M. ",Gravitational Capture and Scattering of Straight Test Strings with Large   Impact Parameters
"  We combine semi-analytical methods with a ultra-high resolution simulation of a galaxy cluster (of mass 2.3 10^14h-1Msolar, and 4 10^6 particles within its virial radius) formed in a standard CDM universe to study the spatial distribution and orbital properties of the present-day descendents of Lyman Break Galaxies (LBGs). At the present time only five (out of 12) of halos containing LBGs survive as separate entities inside the cluster virial radius. Their circular velocities are in the range 200 - 550 km/sec. Seven halos merged together to form the central object at the very center of the cluster. Using semi-analytical modeling of galaxy evolution we show that descendents of halos containing LBGs now host giant elliptical galaxies. Galaxy orbits are radial, with a pericenter to apocenter ratio of about 1:5. The orbital eccentricities of LBGs descendents are statistically indistinguishable from those of the average galaxy population inside the cluster, suggesting that the orbits of these galaxies are not significantly affected by dynamical friction decay after the formation of the cluster's main body. In this cluster, possibly due to its early formation time, the descendents of LBGs are contained within the central 60% of the cluster virial radius and have an orbital velocity dispersion lower than the global galaxy population, originating a mild luminosity segregation for the brightest cluster members. Mass estimates based only on LBGs descendents (especially including the central cD) reflect this bias in space and velocity and underestimate the total mass of this well virialized cluster by up to a factor of two compared to estimates using at least 20 cluster members. ",The descendents of Lyman Break Galaxies in galaxy clusters: spatial   distribution and orbital properties
"  Steganography, as one of the three basic information security systems, has long played an important role in safeguarding the privacy and confidentiality of data in cyberspace. The text is the most widely used information carrier in people's daily life, using text as a carrier for information hiding has broad research prospects. However, due to the high coding degree and less information redundancy in the text, it has been an extremely challenging problem to hide information in it for a long time. In this paper, we propose a steganography method which can automatically generate steganographic text based on the Markov chain model and Huffman coding. It can automatically generate fluent text carrier in terms of secret information which need to be embedded. The proposed model can learn from a large number of samples written by people and obtain a good estimate of the statistical language model. We evaluated the proposed model from several perspectives. Experimental results show that the performance of the proposed model is superior to all the previous related methods in terms of information imperceptibility and information hidden capacity. ",Automatically Generate Steganographic Text Based on Markov Model and   Huffman Coding
"  Materials can be classified by the topological character of their electronic structure and, in this perspective, global attributes immune to local deformations have been discussed in terms of Berry curvature and Chern numbers. Except for instructional simple models, linear response theories have been ubiquitously employed in calculations of topological properties of real materials. Here we propose a completely different and versatile approach to get the topological characteristics of materials by calculating physical observables from the real-time evolving Bloch states: the cell-averaged current density reveals the anomalous velocities whose integration leads to the conductivity quantum. Results for prototypical cases are shown, including a spin-frozen valley-Hall and a quantum anomalous Hall insulator. The advantage of this method is best illustrated by the example of a quantum spin Hall insulator: the quantized spin Hall conductivity is straightforwardly obtained irrespective of the non-Abelian nature in its Berry curvature. Moreover, the method can be extended to the description of real observables in non-equilibrium states of topological materials. ",Unraveling materials Berry curvature and Chern-Simons numbers from   real-time evolution of Bloch states
"  We consider the following constrained Rayleigh quotient optimization problem (CRQopt) $$ \min_{x\in \mathbb{R}^n} x^{T}Ax\,\,\mbox{subject to}\,\, x^{T}x=1\,\mbox{and}\,C^{T}x=b, $$ where $A$ is an $n\times n$ real symmetric matrix and $C$ is an $n\times m$ real matrix.   Usually, $m\ll n$. The problem is also known as the constrained eigenvalue problem in the literature because it becomes an eigenvalue problem if the linear constraint $C^{T}x=b$ is removed. We start by equivalently transforming CRQopt into an optimization problem, called LGopt, of minimizing the Lagrangian multiplier of CRQopt, and then an problem, called QEPmin, of finding the smallest eigenvalue of a quadratic eigenvalue problem. Although such equivalences has been discussed in the literature, it appears to be the first time that these equivalences are rigorously justified. Then we propose to numerically solve LGopt and QEPmin by the Krylov subspace projection method via the Lanczos process. The basic idea, as the Lanczos method for the symmetric eigenvalue problem, is to first reduce LGopt and QEPmin by projecting them onto Krylov subspaces to yield problems of the same types but of much smaller sizes, and then solve the reduced problems by some direct methods, which is either a secular equation solver (in the case of LGopt) or an eigensolver (in the case of QEPmin). The resulting algorithm is called the Lanczos algorithm. We perform convergence analysis for the proposed method and obtain error bounds. The sharpness of the error bound is demonstrated by artificial examples, although in applications the method often converges much faster than the bounds suggest. Finally, we apply the Lanczos algorithm to semi-supervised learning in the context of constrained clustering. ",Linear Constrained Rayleigh Quotient Optimization: Theory and Algorithms
"  The $a_0^0(980)-f_0(980)$ mixing is one of the most potential tools to learn about the nature of $a_0^0(980)$ and $f_0(980)$. Using the $f_0(980)$-$a_0^0(980)$ mixing intensity $\xi_{af}$ measured recently at BESIII, we calculate the the branching ratio of the the isospin violation decay $J/\psi \rightarrow\gamma\eta_c \rightarrow \gamma \pi^0 a_0^0(1450)\rightarrow \gamma \pi^0 a_0^0(980)f_0(500)\rightarrow \gamma \pi^0 f_0(980) f_0(500) \rightarrow \gamma \pi^0 \pi^+\pi^- \pi^+\pi^-$. The value of the branching ratio is found to be $O(10^{-6})$, which can be observed with $10^{10}$ $J/\psi$ events collected at BESIII. The narrow peak from the $f_0(980)$-$a_0^0(980)$ mixing in the $\pi^+\pi^-$ mass square spectrum can also be observed. In addition, we study the non-resonant decay $a_0^0(1450)\rightarrow f_0(980) \pi^+\pi^-(\text{non-resonant})$, which is dominated by the $a_0^0(980)$-$f_{0}(980)$ mixing. We find that the non-resonant decay $a_0^0(1450)\rightarrow f_0(980) \pi^+\pi^-$ and the decay $a_0^0(1450)\rightarrow f_0(980) f_0(500)$ can be combined to measure the mixing intensity $\xi_{af}$ in experiment. These decays are the perfect complement to the decay $\chi_{c1}\rightarrow f_{0}(980)\pi^{0}\to\pi^{+}\pi^{-}\pi^{0}$ which had been observed at BESIII, the observations of them will make the measurement of the mixing intensity $\xi_{af}$ more precisely. ",Study of $a_0^0(980)$-$f_0(980)$ mixing from $a_0(1450) \to a_0^0(980)   f_0(500) \to \pi^+ \pi^- f_0(500)$
  The gravity-driven flow along an annular topological defect (string) with transversely corrugations is investigated by using the verified transition-rate model and boundary perturbation method. We found that for certain activation volume and energy there exists possible frictionless states which might be associated with the missing momentum of inertia or dark matter. ,Gravity-driven Transport along Cylindrical Topological Defects :   Possible Dark Matter and Nearly Frictionless States
"  It is frequently suggested that predictions made by game theory could be improved by considering computational restrictions when modeling agents. Under the supposition that players in a game may desire to balance maximization of payoff with minimization of strategy complexity, Rubinstein and co-authors studied forms of Nash equilibrium where strategies are maximally simplified in that no strategy can be further simplified without sacrificing payoff. Inspired by this line of work, we introduce a notion of equilibrium whereby strategies are also maximally simplified, but with respect to a simplification procedure that is more careful in that a player will not simplify if the simplification incents other players to deviate. We study such equilibria in two-player machine games in which players choose finite automata that succinctly represent strategies for repeated games; in this context, we present techniques for establishing that an outcome is at equilibrium and present results on the structure of equilibria. ","Bounded Rationality, Strategy Simplification, and Equilibrium"
"  A class of problems in quantum information theory, having an elementary formulation but still resisting solution, concerns the additivity properties of various quantities characterizing quantum channels, notably the ""classical capacity"", and the ""maximal output purity"". All known results, including extensive numerical work, are consistent with the conjecture that these quantities are indeed additive (resp. multiplicative) with respect to tensor products of channels. A proof of this conjecture would have important consequences in quantum information theory. In particular, according to this conjecture, the classical capacity or the maximal purity of outputs cannot be increased by using entangled inputs of the channel. In this paper we state the additivity/multiplicativity problems, give some relations between them, and prove some new partial results, which also support the conjecture. ",On some additivity problems in quantum information theory
"  We obtain several lower bounds on the $\textsf{Max-Cut}$ of $d$-degenerate $H$-free graphs. Let $f(m,d,H)$ denote the smallest $\textsf{Max-Cut}$ of an $H$-free $d$-degenerate graph on $m$ edges. We show that $f(m,d,K_r)\ge \left(\frac{1}{2} + d^{-1+\Omega(r^{-1})}\right)m$, generalizing a recent work of Carlson, Kolla, and Trevisan. We also give bounds on $f(m,d,H)$ when $H$ is a cycle, odd wheel, or a complete bipartite graph with at most 4 vertices on one side. We also show stronger bounds on $f(m,d,K_r)$ assuming a conjecture of Alon, Bollabas, Krivelevich, and Sudakov (2003). We conjecture that $f(m,d,K_r)= \left( \frac{1}{2} + \Theta_r(d^{-1/2}) \right)m$ for every $r\ge 3$, and show that this conjecture implies the ABKS conjecture. ",Max-Cut in Degenerate $H$-Free Graphs
"  Unsupervised learning in a generalized Hopfield associative-memory network is investigated in this work. First, we prove that the (generalized) Hopfield model is equivalent to a semi-restricted Boltzmann machine with a layer of visible neurons and another layer of hidden binary neurons, so it could serve as the building block for a multilayered deep-learning system. We then demonstrate that the Hopfield network can learn to form a faithful internal representation of the observed samples, with the learned memory patterns being prototypes of the input data. Furthermore, we propose a spectral method to extract a small set of concepts (idealized prototypes) as the most concise summary or abstraction of the empirical data. ",Unsupervised prototype learning in an associative-memory network
"  We develop, analyze and experiment with a new tool, called MADMX, which extracts frequent motifs, possibly including don't care characters, from biological sequences. We introduce density, a simple and flexible measure for bounding the number of don't cares in a motif, defined as the ratio of solid (i.e., different from don't care) characters to the total length of the motif. By extracting only maximal dense motifs, MADMX reduces the output size and improves performance, while enhancing the quality of the discoveries. The efficiency of our approach relies on a newly defined combining operation, dubbed fusion, which allows for the construction of maximal dense motifs in a bottom-up fashion, while avoiding the generation of nonmaximal ones. We provide experimental evidence of the efficiency and the quality of the motifs returned by MADMX ",MADMX: A Novel Strategy for Maximal Dense Motif Extraction
"  The International Gamma-Ray Astrophysics Laboratory (INTEGRAL) satellite has detected in excess of 1000 sources in the ~20-100 keV band during its surveys of the sky over the past 17 years. We obtained 5 ks observations of 15 unclassified IGR sources with the Chandra X-ray Observatory in order to localize them, to identify optical/IR counterparts, to measure their soft X-ray spectra, and to classify them. For 10 of the IGR sources, we detect Chandra sources that are likely (or in some cases certain) to be the counterparts. IGR J18007-4146 and IGR J15038-6021 both have Gaia parallax distances, placing them at 2.5+0.5-0.4 and 1.1+1.5-0.4 kpc, respectively. We tentatively classify both of them as intermediate polar-type Cataclysmic Variables. Also, IGR J17508-3219 is likely to be a Galactic source, but it is unclear if it is a Dwarf Nova or another type of transient. For IGR J17118-3155, we provide a Chandra localization, but it is unclear if the source is Galactic or extragalactic. Based on either near-IR/IR colors or the presence of extended near-IR emission, we classify four sources as Active Galactic Nuclei (IGR J16181-5407, IGR J16246-4556, IGR J17096-2527, and IGR J19294+1327), and IGR J20310+3835 and IGR J15541-5613 are AGN candidates. In addition, we identified an AGN in the INTEGRAL error circle of IGR J16120-3543 that is a possible counterpart. ",Chandra Observations of High Energy X-ray Sources Discovered by INTEGRAL
"  We propose a novel approach for class-agnostic object proposal generation, which is efficient and especially well-suited to detect small objects. Efficiency is achieved by scale-specific objectness attention maps which focus the processing on promising parts of the image and reduce the amount of sampled windows strongly. This leads to a system, which is $33\%$ faster than the state-of-the-art and clearly outperforming state-of-the-art in terms of average recall. Secondly, we add a module for detecting small objects, which are often missed by recent models. We show that this module improves the average recall for small objects by about $53\%$. ","AttentionMask: Attentive, Efficient Object Proposal Generation Focusing   on Small Objects"
"  We study the partial transposition ${W}^\Gamma=(\mathrm{id}\otimes \mathrm{t})W\in M_{dn}(\mathbb C)$ of a Wishart matrix $W\in M_{dn}(\mathbb C)$ of parameters $(dn,dm)$. Our main result is that, with $d\to\infty$, the law of $m{W}^\Gamma$ is a free difference of free Poisson laws of parameters $m(n\pm 1)/2$. Motivated by questions in quantum information theory, we also derive necessary and sufficient conditions for these measures to be supported on the positive half line. ",Asymptotic eigenvalue distributions of block-transposed Wishart matrices
"  Tycho Brahe, the most prominent and accomplished astronomer of his era, made measurements of the apparent sizes of the Sun, Moon, stars, and planets. From these he showed that within a geocentric cosmos these bodies were of comparable sizes, with the Sun being the largest body and the Moon the smallest. He further showed that within a heliocentric cosmos, the stars had to be absurdly large - with the smallest star dwarfing even the Sun. (The results of Tycho's calculations are illustrated in this paper.) Various Copernicans responded to this issue of observation and geometry by appealing to the power of God: They argued that giant stars were not absurd because even such giant objects were nothing compared to an infinite God, and that in fact the Copernican stars pointed out the power of God to humankind. Tycho rejected this argument. ","Regarding how Tycho Brahe noted the absurdity of the Copernican Theory   regarding the Bigness of Stars, while the Copernicans appealed to God to   answer that absurdity"
"  We study the redshift evolution of the luminosity function (LF) and redshift selection effect of long gamma-ray bursts (LGRBs). The method is to fit the observed peak flux and redshift distributions, simultaneously. To account for the complex triggering algorithm of Swift, we use a flux triggering efficiency function. We find evidence supporting an evolving LF, where the break luminosity scales as $L_b\propto (1+z)^{\tau}$, with $\tau =3.5^{+0.4}_{-0.2}$ and $\tau =0.8^{+0.1}_{-0.08}$ for two kind of LGRB rate models. The corresponding local GRB rates are $\dot{R}(0)=0.86^{+0.11}_{-0.08} \yr^{-1}\Gpc^{-3}$ and $\dot{R}(0)= 0.54^{+0.25}_{-0.07} \yr^{-1}\Gpc^{-3}$, respectively. Furthermore, by comparing the redshift distribution between the observed one and our mocked one, we find that the redshift detection efficiency of the flux triggered GRBs decreases with redshift. Especially, a great number of GRBs miss their redshifts in the redshift range of $1<z<2.5$, where ""redshift desert"" effect may be dominated. More interestingly, our results show that the ""redshift desert"" effect is mainly introduced by the dimmer GRBs, e.g., $P<10^{-7}\ergs /\s/\cm^2$, but has no effect on the brighter GRBs. ",Research on the redshift evolution of luminosity function and selection   effect of GRBs
"  Based on the results of the earlier spectroscopic observations with the 6-m BTA telescope of the SAO RAS we refine the metallicity estimates of the complexes of ionized gas in the VII Zw 403 galaxy. Infrared observations from the Spitzer Space Telescope are used to search for a possible correlation of the mass fraction distribution of the polycyclic aromatic hydrocarbons (PAH) with the distribution of ionized and neutral hydrogen, and with the metallicity of gas in the HII regions of the galaxy. ",Gas and dust in the BCD galaxy VII Zw 403 (UGC 6456)
"  Recent experiments on the bacterial flagellar motor have shown that the structure of this nanomachine, which drives locomotion in a wide range of bacterial species, is more dynamic than previously believed. Specifically, the number of active torque-generating units (stators) was shown to vary across applied loads. This finding invalidates the experimental evidence reporting that limiting (zero-torque) speed is independent of the number of active stators. Here, we propose that, contrary to previous assumptions, the maximum speed of the motor is not universal, but rather increases as additional torque-generators are recruited. This result arises from our assumption that stators disengage from the motor for a significant portion of their mechanochemical cycles at low loads. We show that this assumption is consistent with current experimental evidence and consolidate our predictions with arguments that a processive motor must have a high duty ratio at high loads. ",The Limiting Speed of the Bacterial Flagellar Motor
"  In the presence of a chemical potential, the effect of a magnetic field on chiral symmetry breaking goes beyond the well-known magnetic catalysis. Due to a subtle interplay with the chemical potential, the magnetic field may work not only in favor but also against the chirally broken phase. At sufficiently large coupling, the magnetic field favors the broken phase only for field strengths beyond any conceivable value in nature. Therefore, in the interior of magnetars, a possible transition from chirally broken hadronic matter to chirally symmetric quark matter might occur at smaller densities than previously thought. ","Chiral transition in dense, magnetized matter"
"  In this article, we take into account the one-pion exchange force besides the one-gluon exchange force to study the mass difference of the $\pi$ and $\rho$ mesons with the Bethe-Salpeter equation. After projecting the Bethe-Salpeter equation into an simple form, we can see explicitly that the bound energy $|E_\pi|\gg |E_\rho|$. ",Analysis of mass difference of the $\pi$ and $\rho$ with Bethe-Salpeter   equation
"  We present a simple experiment that allows us to demonstrate graphically that the intensity of sound waves is proportional to the square of their amplitude, a result that is theoretically analysed in any introductory wave course but rarely demonstrated empirically. To achieve our goal, we use an audio signal generator that, when connected to a loudspeaker, produces sine waves that can be easily observed and measured using an oscilloscope. The measurements made with these instruments allow us to create a plot of amplitude versus sound intensity level, which verifies the mathematical relationship between amplitude and intensity mentioned above. Among the experimental errors, the plot obtained is in excellent agreement with what is theoretically expected. ",Graphic relation between amplitude and sound intensity level
"  A study of the performance of the ATLAS tau and missing energy triggers with data collected in spring 2010 at {\surd}s = 7 TeV proton-proton collisions at the Large Hadron Collider (LHC) is presented. A comparison was performed between data and Monte Carlo simulations for the tau and missing transverse energy triggers. As well as a comparison between missing transverse energy trigger quantities and their offline reconstructed counterparts. Tau trigger results compare well with predictions from Monte Carlo simulations. Slight deviations are observed for tau shower shape quantities. Possible sources contributing to the discrepancy such as the simulation of the underlying event are currently being studied. The missing transverse energy reconstructed by the Event Filter is well correlated with the offline result. In addition, there is good agreement between the results obtained with collision data and Monte Carlo simulations. ",Performance of the ATLAS Tau and Missing Energy triggers with 7 TeV   proton proton collisions at the LHC
"  We review theoretical aspects of unitary Fermi gas (UFG), which has been realized in ultracold atom experiments. We first introduce the epsilon expansion technique based on a systematic expansion in terms of the dimensionality of space. We apply this technique to compute the thermodynamic quantities, the quasiparticle spectrum, and the critical temperature of UFG. We then discuss consequences of the scale and conformal invariance of UFG. We prove a correspondence between primary operators in nonrelativistic conformal field theories and energy eigenstates in a harmonic potential. We use this correspondence to compute energies of fermions at unitarity in a harmonic potential. The scale and conformal invariance together with the general coordinate invariance constrains the properties of UFG. We show the vanishing bulk viscosities of UFG and derive the low-energy effective Lagrangian for the superfluid UFG. Finally we propose other systems exhibiting the nonrelativistic scaling and conformal symmetries that can be in principle realized in ultracold atom experiments. ","Unitary Fermi gas, epsilon expansion, and nonrelativistic conformal   field theories"
  We review some peculiar features of Sudakov expansions in the calculation of electroweak radiative corrections in the MSSM at high energy. We give specific examples and consider in particular the process b g -> t W of single top quark production relevant for the top quark physics programme at LHC. ,Sudakov Expansions and Top Quark Physics at LHC
"  We determine the magnetic phase diagram for the YBa$_2$Cu$_3$O$_{6+x}$ and La$_{2-x}$Sr$_x$CuO$_4$ systems from various NMR experiments. We discuss the possible interpretation of NMR and neutron scattering experiments in these systems in terms of both the non-linear $\sigma$-model of nearly localized spins and a nearly antiferromagnetic Fermi liquid description of magnetically coupled quasiparticles. We show for both the 2:1:4 and 1:2:3 systems that bulk properties, such as the spin susceptibiltiy, and probes at the antiferromagnetic wavevector $(\pi, \pi)$, such as $^{63}T_1$, the $ ^{63}Cu$ spin relaxation time, both display a crossover at a temperature $T_{cr}$, which increases linearly with decreasing hole concentration, from a non-universal regime to a $z=1$ scaling regime characterized by spin pseudogap behavior. We pursue the consequences of the ansatz that $T_{cr}$ corresponds to a fixed value of the antiferromagnetic correlation length, $\xi$, and show how this enables one to extract the magnitude and temperature dependence of $\xi$ from measurements of $T_1$ alone. We show that like $T_{cr}$, the temperature $T_*$ which marks a crossover at low temperatures from the $z=1$ scaling regime to a quantum disordered regime, exhibits the same dependence on doping for the 2:1:4 and 1:2:3 systems, and so arrive at a unified description of magnetic behavior in the cuprates, in which the determining factor is the planar hole concentration. We apply our quantitative results for YBa$_2$Cu$_3$O$_7$ to the recent neutron scattering experiments of Fong {\em et al}, and show that the spin excitation near $40 meV$ measured by them corresponds to a spin gap excitation, which is overdamped in the normal state, but becomes visible in the superconducting state. ",Magnetic scaling in cuprate superconductors
"  We study electromagnetic properties of the nucleon and Roper resonance in a chiral quark-diquark model including two kinds of diquarks needed to describe the nucleon: scalar and axial-vector diquarks. The nucleon and Roper resonance are described as superpositions of two quark-diquark bound states of a quark and a scalar diquark and of a quark and an axial-vector diquark. Electromagnetic form factors of the nucleon and Roper resonance are obtained from one-loop diagrams where the quark and diquarks are coupled by a photon. We include the effects of intrinsic properties of the diquarks: the intrinsic form factors both of the diquarks and the anomalous magnetic moment of the axial-vector diquark. The electric form factors of the proton and neutron reasonably agree with the experiments due to the inclusions of the diquark sizes, while the magnetic moments become smaller than the experimental values because of the scalar dominance in the nucleon. The charge radii of the Roper resonance are almost comparable with those of the nucleon. ",Structure of the Roper Resonance with Diquark Correlations
"  We connect the configurational entropy of a liquid to the geometrical properties of its local energy landscape, using a high-temperature expansion. It is proposed that correlations between local structures arises from their overlap and, being geometrical in nature, can be usefully determined using the inherent structures of high temperature liquids. We show quantitatively how the high-temperature covariance of these local structural fluctuations arising from their geometrical overlap, combined with their energetic stability, control the decrease of entropy with decreasing energy. We apply this formalism to a family of Favoured Local Structure (FLS) lattice models with two low symmetry FLS's which are found to either crystallize or form a glass on cooling. The covariance, crystal energy and estimated freezing temperature are tested as possible predictors of glass-forming ability in the model system. ",From Liquid Structure to Configurational Entropy: Introducing Structural   Covariance
  I provide analytical or semi-analytical expressions for the small-angle scattering of colloidal objects that can be described as curved plates. These models could help characterize a variety of inorganic or biological systems. ,"Solution scattering from colloidal curved plates: barrel tiles, scrolls   and spherical patches"
"  We investigated multilayer plates made by exfoliation from a high-quality MoS$_2$ crystal and reveal that they represent a new object - van der Waals homostructure consisting of a bulk core and a few detached monolayers on its surface. This architecture comprising elements with different electron band structure leads to specific luminescence, when the broad emission band from the core is cut by the absorption peaks of strong exciton resonances in the surface monolayers. The exfoliated flakes exhibit strong optical anisotropy. We have observed a conversion of normally incident light polarization to $15\%$ in transmission geometry. This background effect is due to fluctuations of the c axis relative to the normal, whereas the pronounced resonance contribution is explained by the polarization anisotropy of excitons localized in the stripes of dissected surface monolayers. ",MoS$_2$ flake as a van der Waals homostructure: luminescence properties   and optical anisotropy
"  By neglecting the relative quark momenta in the propagator term, the two-photon and two-gluon decay amplitude of heavy quarkonia states can be written as a local heavy quark field operator matrix element which could be obtained from other processes or computed with QCD sum rules technique or lattice simulation, as shown in a recent work on $\eta_{c,b}$ two-photon decays. In this talk, I would like to discuss a similar calculation on $P$-wave $\chi_{c0,2}$ and $\chi_{b0,2}$ two-photon decays. We show that the effective Lagrangian for the two-photon decays of the $P$-wave $\chi_{c0,2}$ and $\chi_{b0,2}$ is given by the heavy quark energy-momentum tensor local operator and its trace, the $\bar{Q}Q$ scalar density. A simple expression for $\chi_{c0}$ two-photon and two-gluon decay rate in terms of the $f_{\chi_{c0}}$ decay constant, similar to that of $\eta_{c}$ is obtained. From the existing   QCD sum rules value for $f_{\chi_{c0}}$, we get $5\rm\,keV$ for the $\chi_{c0}$ two-photon width, somewhat larger than measurement. ",Two-Photon and Two-gluon Decays of $0^{++}$ and $2^{++}$ P-wave Heavy   Quarkonium States
  In the framework of I3HP there are two Transnational Access Activities related to Computational Hadron Physics. One of these activities is access to the mass storage system at Konrad-Zuse-Zentrum fuer Informationstechnik Berlin (ZIB). European lattice physics collaborations can apply for mass storage capacity in order to store and share their configurations or other data (see http://www.zib.de/i3hp/). In this paper formal and technical aspects of usage as well as the conformance to the International Lattice DataGrid (ILDG) are explained. ,Using the Mass Storage System at ZIB within I3HP
"  Extensive measurements of the X-ray background (XRB) yield a reasonably reliable characterisation of its basic properties. Having resolved most of the cosmic XRB into discrete sources, the levels and spectral shapes of its main components can be used to probe both the source populations and also alternative cosmological and large-scale structure models. Recent observations of clusters seem to provide evidence that clusters formed earlier and are more abundant than predicted in the standard $\Lambda$CDM model. This motivates interest in alternative models that predict enhanced power on cluster scales. We calculate predicted levels and spectra of the superposed emission from groups and clusters of galaxies in $\Lambda$CDM and in two viable alternative non-Gaussian ($\chi^2$) and early dark energy models. The predicted levels of the contribution of clusters to the XRB in the non-Gaussian models exceed the measured level at low energies and levels of the residual XRB in the 2-8 keV band; these particular models are essentially ruled out. Our work demonstrates the diagnostic value of the integrated X-ray emission from clusters, by considering also its dependences on different metallicities, gas and temperature profiles, Galactic absorption, merger scenarios, and on a non-thermal pressure component. We also show that the XRB can be used for a upper limit for the concentration parameter value. ",Cluster contribution to the X-ray background as a cosmological probe
"  For future configurations, we study the relation between the abatement of the noise sources and the Signal to Noise Ratio (SNR) for coalescing binaries. Our aim is not the proposition of a new design, but an indication of where in the bandwidth or for which noise source, a noise reduction would be most efficient. We take VIRGO as the reference for our considerations, solely applicable to the inspiralling phase of a coalescing binary. Thus, only neutron stars and small black holes of few solar masses are encompassed by our analysis. The contributions to the SNR given by final merge and quasi-normal ringing are neglected. It is identified that i) the reduction in the mirror thermal noise band provides the highest gain for the SNR, when the VIRGO bandwidth is divided according to the dominant noises; ii) it exists a specific frequency at which lies the potential largest increment in the SNR, and that the enlargement of the bandwidth, where the noise is reduced, produces a shift of such optimal frequency to higher values; iii) the abatement of the pendulum thermal noise provides the largest, but modest, gain, when noise sources are considered separately. Our recent astrophysical analysis on event rates for neutron stars leads to a detection rate of one every 148 or 125 years for VIRGO and LIGO, respectively, while a recently proposed and improved, but still conservative, VIRGO configuration would provide an increase to 1.5 events per year. Instead, a bi-monthly event rate, similar to advanced LIGO, requires a 16 times gain. We analyse the 3D (pendulum, mirror, shot noises) parameter space showing how such gain could be achieved. ",Advanced VIRGO: detector optimization for gravitational waves by   inspiralling binaries
"  We study how the singular behaviour of classical systems at bifurcations is reflected by their quantum counterpart. The semiclassical contributions of individual periodic orbits to trace formulae of Gutzwiller type are known to diverge when orbits bifurcate, a situation characteristic for systems with a mixed phase space. This singular behaviour is reflected by the quantum system in the semiclassical limit, in which the individual contributions remain valid closer to a bifurcation, while the true collective amplitude at the bifurcation increases with some inverse power of Planck's constant (with an exponent depending on the type of bifurcation). We illustrate the interplay between the two competing limits (closeness to a bifurcation and smallness of $\hbar$) numerically for a generic dynamical system, the kicked top. ",Semiclassical singularities from bifurcating orbits
"  ML4Chem is an open-source machine learning library for chemistry and materials science. It provides an extendable platform to develop and deploy machine learning models and pipelines and is targeted to the non-expert and expert users. ML4Chem follows user-experience design and offers the needed tools to go from data preparation to inference. Here we introduce its atomistic module for the implementation, deployment, and reproducibility of atom-centered models. This module is composed of six core building blocks: data, featurization, models, model optimization, inference, and visualization. We present their functionality and easiness of use with demonstrations utilizing neural networks and kernel ridge regression algorithms. ",ML4Chem: A Machine Learning Package for Chemistry and Materials Science
"  We study the Luttinger-liquid parameter $K_{\rho}$ of the Hubbard chain and the Hubbard ladder models by the ordinary perturbation method combined with the Luttinger-liquid relation. According to the Luttinger-liquid relation, the critical exponent $K_{\rho}$ is related to the charge susceptibility $\chi_c$ and the Drude weight D by $ K\sb{\rho}={1/2}(\pi \chi_c D)^{1/2}$. By calculating these quantities with the perturbation method, we obtain $K_{\rho}$ at the first-order analytically and up to the second-order numerically. We compare these results with results of the Bethe ansatz for the Hubbard chain and that of the numerical diagonalization for the Hubbard ladder. It shows that the perturbation calculation of $K_{\rho}$ is reliable in the weak coupling regime. ",Luttinger-liquid Parameter of Hubbard Chain and Hubbard Ladder
"  We present a new type of ultracompact objects, featuring lightrings and echoes in the gravitational-wave spectrum. These particle-like solutions arise in Einstein-scalar-Gauss-Bonnet theories in four spacetime dimensions, representing globally regular spacetime manifolds. The scalar field diverges at the center, but the effective stress-energy tensor is free from pathologies. We determine their domain of existence and compare with wormhole solutions, black holes and the Fisher solution. ",Particle-like ultracompact objects in Einstein-scalar-Gauss-Bonnet   theories
"  Graph data management (also called NoSQL) has revealed beneficial characteristics in terms of flexibility and scalability by differently balancing between query expressivity and schema flexibility. This peculiar advantage has resulted into an unforeseen race of developing new task-specific graph systems, query languages and data models, such as property graphs, key-value, wide column, resource description framework (RDF), etc. Present-day graph query languages are focused towards flexible graph pattern matching (aka sub-graph matching), whereas graph computing frameworks aim towards providing fast parallel (distributed) execution of instructions. The consequence of this rapid growth in the variety of graph-based data management systems has resulted in a lack of standardization. Gremlin, a graph traversal language, and machine provides a common platform for supporting any graph computing system (such as an OLTP graph database or OLAP graph processors). We present a formalization of graph pattern matching for Gremlin queries. We also study, discuss and consolidate various existing graph algebra operators into an integrated graph algebra. ",Towards an Integrated Graph Algebra for Graph Pattern Matching with   Gremlin (Extended Version)
"  We examine fluctuation-induced (pseudo-Casimir) interactions in nematic liquid-crystalline films confined between two surfaces, where one of the surfaces imposes a strong homeotropic anchoring (ensuring a uniform mean director profile), while the other one is assumed to be a chemically disordered substrate exhibiting an annealed, random distribution of anchoring energies. We employ a saddle-point approximation to evaluate the free energy of interaction mediated between the two surfaces and investigate how the interaction force is influenced by the presence of disordered surface anchoring energy. It is shown that the disorder results in a renormalization of the effective surface anchoring parameter in a way that it leads to quantitative and qualitative changes (including a change of sign at intermediate inter-surface separations) in the pseudo-Casimir interaction force when compared with the interaction force in the absence of disorder. ",Fluctuation-induced interactions in nematics with disordered anchoring   energy
"  Object referring has important applications, especially for human-machine interaction. While having received great attention, the task is mainly attacked with written language (text) as input rather than spoken language (speech), which is more natural. This paper investigates Object Referring with Spoken Language (ORSpoken) by presenting two datasets and one novel approach. Objects are annotated with their locations in images, text descriptions and speech descriptions. This makes the datasets ideal for multi-modality learning. The approach is developed by carefully taking down ORSpoken problem into three sub-problems and introducing task-specific vision-language interactions at the corresponding levels. Experiments show that our method outperforms competing methods consistently and significantly. The approach is also evaluated in the presence of audio noise, showing the efficacy of the proposed vision-language interaction methods in counteracting background noise. ",Object Referring in Visual Scene with Spoken Language
"  We present the discovery of a long-period, rapidly oscillating Ap star, HD177765. Using high-resolution time-series observations obtained with UVES at the ESO VLT telescope, we found radial velocity variations with amplitudes 7-150 m/s and a period of 23.6 min, exceeding that of any previously known roAp star. The largest pulsation amplitudes are observed for Eu III, Ce III and for the narrow core of Halpha. We derived the atmospheric parameters and chemical composition of HD177765, showing this star to be similar to other long-period roAp stars. Comparison with theoretical pulsational models indicates an advanced evolutionary state for HD177765. Abundance analyses of this and other roAp stars suggest a systematic variation with age of the rare-earth line anomalies seen in cool Ap stars. ",Discovery of the longest-period rapidly oscillating Ap star HD177765
"  An antiferromagnetic insulating state has been found in the zigzag phosphorene nanoribbons (ZPNRs) from a comprehensive density functional theory calculations. Comparing with other one-dimensional systems, the magnetism in ZPNRs display several surprising characteristics: (i) the magnetic moments are antiparallel arranged at each zigzag edge; (ii) the magnetism is quite stable in energy (about 29 meV/magnetic-ion) and the band gap is big (about 0.7 eV); (iii) a moderate compressive strain will induce a magnetic to nonmagnetic as well as semiconductor to metal transition. All of these phenomena arise naturally due to one unique mechanism, namely the electronic instability induced by the half-filled one dimensional bands which cross the Fermi level at around {\pi}/2a. The unusual electronic and magnetic properties in ZPNRs endow them great potential for the applications in nanoelectronic devices. ",Tunable Magnetic Semiconductor Behavior Driven by Half-Filled One   Dimensional Band in Zigzag Phosphorene Nanoribbons
  We review the special theory of relativity kinematics and dynamics as well as the general theory of relativity under the aspect of logic. ,Logical Analysis of Relativity Theory
"  Research in the field of low-temperature electronics is limited by the small number of electrical contacts available on cryogenic set ups. This not only restricts the number of devices that can be fabricated, but also the device and circuit complexity. We present an on-chip multiplexing technique which significantly increases the number of devices locally measurable on a single chip, without the modification of existing fabrication or experimental set-ups. We demonstrate the operation of the multiplexer by performing electrical measurements of 256 quantum wires formed by split-gate devices using only 19 electrical contacts on a cryogenic set-up. The multiplexer allows the measurement of many devices and enables us to perform statistical analyses of various electrical features which exist in quantum wires. We use this architecture to investigate spatial variations of electrical characteristics, and reproducibility on two separate cooldowns. These statistical analyses are necessary to study device yield and manufacturability, in order for such devices to form the building blocks for the realisation of quantum integrated circuits. The multiplexer provides a scalable architecture which makes a whole series of further investigations into more complex devices possible. ",A low-temperature device architecture for the statistical study of   electrical characteristics of 256 quantum devices
"  The unique capabilities of Swift that make it ideal for discovery and follow-up of Gamma-Ray bursts also makes it the idea mission for discovery and monitoring of X-ray Transients in the Milky Way and the Large and Small Magellanic Clouds. The Burst Alert Telescope allows for detection of new transient outbursts, the automated follow-up capabilities of Swift allow for rapid observation and localization of the new transient in X-rays and optical/UV bands, and Swift's rapid slewing capabilities allows for low-overhead short observations to be obtained, opening up the possibility of regular, sensitive, long term monitoring of transient outbursts that are not possible with other currently operational X-ray missions. In this paper I describe the methods of discovery of X-ray transients utilizing Swift's BAT and also collaboration with the MAXI telescope. I also detail two examples of X-ray transient science enabled by Swift: Swift discovery and monitoring observations of MAXI J1659-152, a Black Hole candidate Low Mass X-ray Binary in the Galactic Halo, which has the shortest known orbital period of any such system; and Swift monitoring of IGR J00569-7226, an edge on Be/X-ray binary that displayed a outburst in 2013 and 2014, and which monitoring by Swift allowed for detection of dips, eclipses and the determination of the orbital parameters, utilizing a measurement of doppler shifts in the pulsar period. ",The Galactic Transient Sky with Swift
"  We present the response time measurements of a Cs2Te photocathode illuminated with two 100 fs duration, variable time separation laser pulses at 266 nm wavelength. The response time was confirmed in dispersive region downstream of a 12-cell standing wave S-band acceleration structure using a well-known RF zero-crossing technique. At the same time it was also measured by changing mechanical path-length difference between two micro-bunches. Both methods agree that Cs2Te photocathode time response is of the order of 250 fs and thereby it is possible to generate and control a THz sequence of relativistic electron bunches by a conventional S-band RF gun. This result further opens a possibility to construct wide-range tunable THz FEL. ",Femtosecond response time measurements of a Cs2Te photocathode
  We derive the exact solution of the Boltzmann kinetic equation for the three-dimensional Lorentz model in the presence of a constant and uniform magnetic field. The velocity distribution of the electrons reduces exponentially fast to its spherically symmetric component. In the long time hydrodynamic limit there remains only the diffusion process governed by an anisotropic diffusion tensor. The systematic way of building the Chapman-Enskog solutions is described. ,Three-dimensional Lorentz model in a magnetic field : exact and   Chapman-Enskog solutions
"  The magnetic properties of GdBaMn_{2}O_{5.0}, which exhibits charge ordering, are studied from 2 to 400 K using single crystals. In a small magnetic field applied along the easy axis, the magnetization M shows a temperature-induced reversal which is sometimes found in ferrimagnets. In a large magnetic field, on the other hand, a sharp change in the slope of M(T) coming from an unusual turnabout of the magnetization of the Mn sublattices is observed. Those observations are essentially explained by a molecular field theory which highlights the role of delicate magnetic interactions between Gd^{3+} ions and the antiferromagnetically coupled Mn^{2+}/Mn^{3+} sublattices. ",Peculiar Ferrimagnetism Associated with Charge Order in Layered   Perovskite GdBaMn2O5
"  AdS/CFT correspondence is now widely used for study of strongly coupled plasmas, such as produced in ultrarelativistic heavy ion collisions at RHIC. While properties of equilibrated plasma and small deviations from equilibrium are by now reasonably well understood, its initial formation and thermal equilibration is much more challenging issue which remains to be studied. In the dual gravity language, these problems are related to formation of bulk black holes, and trapped surfaces we study in this work is a way to estimate the properties (temperature and entropy) of such black hole. Extending the work by Gubser et al, we find numerically trapped surfaces for non-central collision of shock waves with different energies. We observe a critical impact parameter, beyond which the trapped surface does not exist: and we argue that there are experimental indications for similar critical impact parameter in real collisions. We also present a simple solvable example of shock wave collision: wall-on-wall collision. The applicability of this approach to heavy ion collision is critically discussed. ",Grazing Collisions of Gravitational Shock Waves and Entropy Production   in Heavy Ion Collision
"  Given an iterated function system (IFS) of contractive similitudes, the theory of Gromov hyperbolic graph on the IFS has been established recently. In the paper, we introduce a notion of simple augmented tree which is a Gromov hyperbolic graph. By generalizing a combinatorial device of rearrangeable matrix, we show that there exists a near-isometry between the simple augmented tree and the symbolic space of the IFS, so that their hyperbolic boundaries are Lipschitz equivalent. We then apply this to consider the Lipschitz equivalence of self-similar sets with or without assuming the open set condition. Moreover, we also provide a criterion for a self-similar set to be a Cantor-type set which completely answers an open question raised in \cite{LaLu13}. Our study extends the previous works. ","Self-similar sets, simple augmented trees, and their Lipschitz   equivalence"
"  We approach the study of totally real immersions of smooth manifolds into holomorphic Riemannian space forms of constant sectional curvature -1. We introduce a notion of first and second fundamental form, we prove that they satisfy a similar version of the classic Gauss-Codazzi equations, and conversely that solutions of Gauss-Codazzi equations are immersion data of some equivariant map. This study has some interesting geometric consequences:   1) it provides a formalism to study immersions of surfaces into SL(2,C) and into the space of geodesics of H^3;   2) it generalizes the classical theory of immersions into non-zero curvature space forms, leading to a model for the transitioning of hypersurfaces among H^n, AdS^n, dS^n and S^n;   3) we prove that a holomorphic family of immersion data corresponds to a holomorphic family of immersions, providing an effective way to construct holomorphic maps into the SO(n,C)-character variety. In particular we will point out a simpler proof of the holomorphicity of the complex landslide;   4) we see how, under certain hypothesis, complex metrics on a surface (i.e. complex bilinear forms of its complexified tangent bundle) of constant curvature -1 correspond to pairs of projective surfaces with the same holonomy. Applying Bers Double Uniformization Theorem to this construction we prove a Uniformization Theorem for complex metrics on a surface. ","On immersions of surfaces into SL(2,C) and geometric consequences"
"  Using the Dissipation Theorem and a corollary of the Fluctuation Theorem, namely the Second Law Inequality, we give a first-principles derivation of Boltzmann's postulate of equal a priori probability in phase space for the microcanonical ensemble. We show that if the initial distribution differs from the uniform distribution over the energy hypersurface, then under very wide and commonly satisfied conditions, the initial distribution will relax to that uniform distribution. This result is somewhat analogous to the Boltzmann H-theorem but unlike that theorem, applies to dense fluids as well as dilute gases and also permits a nonmonotonic relaxation to equilibrium. We also prove that in ergodic systems the uniform (microcanonical) distribution is the only stationary, dissipationless distribution for the constant energy ensemble. ",A simple mathematical proof of Boltzmann's equal a priori probability   hypothesis
"  We identify a population of morphologically defined E/S0 galaxies lying on the blue sequence at the present epoch. Using three samples, we analyze blue-sequence E/S0s with stellar masses >10^8 Msun, arguing that individual objects may be evolving either up toward the red sequence or down into the blue sequence. Blue-sequence E/S0 galaxies become more common with decreasing stellar mass, comprising <2% of E/S0s near the ""shutdown mass"" M_s ~ 1-2 x 10^11 Msun, increasing to >5% near the ""bimodality mass"" M_b ~ 3 x 10^10 Msun, and sharply rising to >20-30% below the ""threshold mass"" M_t ~ 4-6 x 10^9 Msun. The strong emergence of blue-sequence E/S0s below M_t coincides with a previously reported global increase in mean atomic gas fractions below M_t for galaxies of all types on both sequences, suggesting that the availability of cold gas may be basic to blue-sequence E/S0s' existence. Environmental analysis reveals that many sub-M_b blue-sequence E/S0s reside in low to intermediate density environments. In mass-radius and mass-sigma scaling relations, blue-sequence E/S0s are more similar to red-sequence E/S0s than to late-type galaxies, but they represent a transitional class. While some of them, especially in the high-mass range from M_b to M_s, resemble major-merger remnants that will likely fade onto the red sequence, most blue-sequence E/S0s below M_b show signs of disk and/or pseudobulge building, which may be enhanced by companion interactions. We argue that sub-M_b blue-sequence E/S0s occupy a ""sweet spot"" in stellar mass and concentration, with both abundant gas and optimally efficient star formation, which may enable the formation of large spiral disks. [abridged] ",E/S0 Galaxies on the Blue Color-Stellar Mass Sequence at z=0: Fading   Mergers or Future Spirals?
  A higher order theory of gravitation is considered which is obtained by modifying Einstein field equations. The Lagrange used to modify this in the form a polynomial in (scalar curvature) R. In this equation we have studied spherical symmetric metric. ,Spherically Symmetric Considerations for a Higher Order Theory of   Gravitation
"  We perform a large-scale statistical analysis (> 2000 independent simulations) of the elongation and rupture of gold nanowires, probing the validity and scope of the recently proposed ductile-to-brittle transition that occurs with increasing nanowire length [Wu et. al., Nano Lett., 12, 910-914 (2012)]. To facilitate a high-throughput simulation approach, we implement the second-moment approximation to the tight-binding (TB-SMA) potential within HOOMD-Blue, a molecular dynamics package which runs on massively parallel graphics processing units (GPUs). In a statistical sense, we find that the nanowires obey the ductile-to-brittle model quite well; however, we observe several unexpected features from the simulations that build on our understanding of the ductile-to-brittle transition. First, occasional failure behavior is observed that qualitatively differs from that predicted by the model prediction; this is attributed to stochastic thermal motion of the Au atoms and occurs at temperatures as low as 10 K. In addition, we also find that the ductile-to-brittle model, which was developed using classical dislocation theory, holds for nanowires as small as 3 nm in diameter. Finally, we demonstrate that the nanowire critical length is higher at 298 K relative to 10 K, a result that is not predicted by the ductile-to-brittle model. These results offer practical design strategies for adjusting nanowire failure and structure, and also demonstrate that GPU computing is an excellent tool for studies requiring a large number independent trajectories in order to fully characterize a system's behavior. ",Probing the Statistical Validity of the Ductile-to-Brittle Transition in   Metallic Nanowires Using GPU Computing
"  We use supersymmetry to address the little hierarchy problem in Randall-Sundrum models by naturally generating a hierarchy between the IR scale and the electroweak scale. Supersymmetry is broken on the UV brane which triggers the stabilization of the warped extra dimension at an IR scale of order 10 TeV. The Higgs and top quark live near the IR brane whereas light fermion generations are localized towards the UV brane. Supersymmetry breaking causes the first two sparticle generations to decouple, thereby avoiding the supersymmetric flavour and CP problems, while an accidental R-symmetry protects the gaugino mass. The resulting low-energy sparticle spectrum consists of stops, gauginos and Higgsinos which are sufficient to stabilize the little hierarchy between the IR scale and the electroweak scale. Finally, the supersymmetric little hierarchy problem is ameliorated by introducing a singlet Higgs field on the IR brane. ",A natural little hierarchy for RS from accidental SUSY
"  Prior work inspired by compression algorithms has described how the Burrows Wheeler Transform can be used to create a distance measure for bioinformatics problems. We describe issues with this approach that were not widely known, and introduce our new Burrows Wheeler Markov Distance (BWMD) as an alternative. The BWMD avoids the shortcomings of earlier efforts, and allows us to tackle problems in variable length DNA sequence clustering. BWMD is also more adaptable to other domains, which we demonstrate on malware classification tasks. Unlike other compression-based distance metrics known to us, BWMD works by embedding sequences into a fixed-length feature vector. This allows us to provide significantly improved clustering performance on larger malware corpora, a weakness of prior methods. ",A New Burrows Wheeler Transform Markov Distance
"  The application of PhotoEmission Electron Microscopy (PEEM) and Low Energy Electron Microscopy (LEEM) techniques to the study of the electronic and chemical structure of ferroelectric materials is reviewed. Electron optics in both techniques gives spatial resolution of a few tens of nanometres. PEEM images photoelectrons whereas LEEM images reflected and elastically backscattered electrons. Both PEEM and LEEM can be used in direct and reciprocal space imaging. Together, they provide access to surface charge, work function, topography, chemical mapping, surface crystallinity and band structure. Examples of applications for the study of ferroelectric thin films and single crystals are presented. ",Full field electron spectromicroscopy applied to ferroelectric materials
"  In the paper, the authors find two closed forms involving the Stirling numbers of the second kind and in terms of a determinant of combinatorial numbers for the Bernoulli polynomials and numbers. ",Two closed forms for the Bernoulli polynomials
"  The strictly classical propagation of an initial Wigner function, referred to as TWA or LSC-IVR, is considered to provide approximate averages, despite not being a true Wigner function: it does not represent a positive operator. We here show that its symplectic Fourier transform, the truncated chord approximation (TCA), coincides with the full semiclassical approximation to the evolved quantum characteristic function (or chord function) in a narrow neighbourhood of the origin of the dual chord phase space. Surprisingly, this small region accounts for purely quantum features, such as blind spots and local wave function correlations, as well as the expectation of observables with a close classical correspondence. Direct numerical comparison of the TCA with exact quantum results verifies the semiclassical predictions for an initial coherent state evolving under the Kerr Hamiltonian. The resulting clear criterion for any further features, which may be estimated by classical propagation, is that, within the chord representation, they are concentrated near the origin. ",Distinguishing quantum features in classical propagation
"  In the present paper a newer application of Artificial Neural Network (ANN) has been developed i.e., predicting response-function results of electrical-mechanical system through ANN. This method is specially useful to complex systems for which it is not possible to find the response-function because of complexity of the system. The proposed approach suggests that how even without knowing the response-function, the response-function results can be predicted with the use of ANN to the system. The steps used are: (i) Depending on the system, the ANN-architecture and the input & output parameters are decided, (ii) Training & test data are generated from simplified circuits and through tactic-superposition of it for complex circuits, (iii) Training the ANN with training data through many cycles and (iv) Test-data are used for predicting the response-function results. It is found that the proposed novel method for response prediction works satisfactorily. Thus this method could be used specially for complex systems where other methods are unable to tackle it. In this paper the application of ANN is particularly demonstrated to electrical-circuit system but can be applied to other systems too. ",Predicting Response-Function Results of Electrical/Mechanical Systems   Through Artificial Neural Network
"  Topological insulators represent a novel state of matter with surface charge carriers having a massless Dirac dispersion and locked helical spin polarization. Many exciting experiments have been proposed by theory, yet, their execution have been hampered by the extrinsic conductivity associated with the unavoidable presence of defects in Bi$_2$Te$_3$ and Bi$_2$Se$_3$ bulk single crystals as well as impurities on their surfaces. Here we present the preparation of Bi$_2$Te$_3$ thin films that are insulating in the bulk and the four-point probe measurement of the conductivity of the Dirac states on surfaces that are intrinsically clean. The total amount of charge carriers in the experiment is of order 10$^{12}$ cm$^{-2}$ only and mobilities up to 4,600 cm$^2$/Vs have been observed. These values are achieved by carrying out the preparation, structural characterization, angle-resolved and x-ray photoemission analysis, and the temperature dependent four-point probe conductivity measurement all in-situ under ultra-high-vacuum conditions. This experimental approach opens the way to prepare devices that can exploit the intrinsic topological properties of the Dirac surface states. ",Intrinsic conduction through topological surface states of insulating   Bi$_2$Te$_3$ epitaxial thin films
"  We present the results from an ultra-high-resolution 7mm Very Long Baseline Array (VLBA) study of the relativistic jet in the BL Lacertae object OJ287 from 1995 to 2011 containing 136 total intensity images. Analysis of the image sequence reveals a sharp jet-position-angle swing by >100 deg. during [2004,2006], as viewed in the plane of the sky, that we interpret as the crossing of the jet from one side of the line of sight to the other during a softer and longer term swing of the inner jet. Modulating such long term swing, our images also show for the first time a prominent erratic wobbling behavior of the innermost ~0.4mas of the jet with fluctuations in position angle of up to ~40 deg. over time scales ~2yr. This is accompanied by highly superluminal motions along non-radial trajectories, which reflect the remarkable non-ballistic nature of the jet plasma on these scales. The erratic nature and short time scales of the observed behavior rules out scenarios such as binary black hole systems, accretion disk precession, and interaction with the ambient medium as possible origins of the phenomenon on the scales probed by our observations, although such processes may cause longer-term modulation of the jet direction. We propose that variable asymmetric injection of the jet flow; perhaps related to turbulence in the accretion disk; coupled with hydrodynamic instabilities, leads to the non-ballistic dynamics that cause the observed non-periodic changes in the direction of the inner jet. ",Erratic Jet Wobbling in the BL Lacertae Object OJ287 Revealed by Sixteen   Years of 7mm VLBA Observations
"  The second law of ordinary thermodynamics and the second law of steady state thermodynamics, as proposed by Oono and Paniconi, are investigated from the microscopic point of view for the open quantum system. Based on the H-theorem of Lindblad, we show that both second laws are consistent with the quantum dynamics generated by the completely positive map. In addition, microscopic expressions of entropy production and ``housekeeping heat'' are obtained for some classes of dynamical quantum systems. ",The Second Law of Steady State Thermodynamics for Nonequilibrium Quantum   Dynamics
"  Let $f$ be a polynomial $f$ of degree $d\ge 2$ with integer coefficients which is irreducible over the rationals. Cilleruelo conjectured that the least common multiple of the values of the polynomial at the first $N$ integers satisfies $\log lcm(f(1),\dots, f(N)) \sim (d-1) N\log N$ as $N\to \infty$. This is only known for degree $d=2$. In this note we give a simple lower bound for all degrees $d\geq 2$ which is consistent with the conjecture: $\log lcm (f(1),\dots, f(N)) \gg N\log N$. ",A lower bound on the LCM of polynomial sequences
"  Multivariate time-series data are used in many classification and regression predictive tasks, and recurrent models have been widely used for such tasks. Most common recurrent models assume that time-series data elements are of equal length and the ordered observations are recorded at regular intervals. However, real-world time-series data have neither a similar length nor a same number of observations. They also have missing entries, which hinders the performance of predictive tasks. In this paper, we approach these issues by presenting a model for the combined task of imputing and predicting values for the irregularly observed and varying length time-series data with missing entries. Our proposed model (Bi-GAN) uses a bidirectional recurrent network in a generative adversarial setting. The generator is a bidirectional recurrent network that receives actual incomplete data and imputes the missing values. The discriminator attempts to discriminate between the actual and the imputed values in the output of the generator. Our model learns how to impute missing elements in-between (imputation) or outside of the input time steps (prediction), hence working as an effective any-time prediction tool for time-series data. Our method has three advantages to the state-of-the-art methods in the field: (a) single model can be used for both imputation and prediction tasks; (b) it can perform prediction task for time-series of varying length with missing data; (c) it does not require to know the observation and prediction time window during training which provides a flexible length of prediction window for both long-term and short-term predictions. We evaluate our model on two public datasets and on another large real-world electronic health records dataset to impute and predict body mass index (BMI) values in children and show its superior performance in both settings. ",Time-series Imputation and Prediction with Bi-Directional Generative   Adversarial Networks
"  We present a large deviation principle at speed N for the largest eigenvalue of some additively deformed Wigner matrices. In particular this includes Gaussian ensembles with full-rank general deformation. For the non-Gaussian ensembles, the deformation should be diagonal, and we assume that the laws of the entries have sharp sub-Gaussian Laplace transforms and satisfy certain concentration properties. For these latter ensembles we establish the large deviation principle in a restricted range $(-\infty, x_c)$, where $x_c$ depends on the deformation only and can be infinite. ",Large deviations for extreme eigenvalues of deformed Wigner random   matrices
  We compute the two-loop QCD corrections to $q g \to H q$ and $q \bar{q} \to H g$ amplitudes mediated by loops of nearly massless quarks. These amplitudes provide the last missing ingredient required to compute the NLO QCD corrections to the top-bottom interference contribution to the Higgs boson transverse momentum distribution at hadron colliders. ,Two-loop amplitudes for $q g \to H q$ and $q \bar{q} \to H g$ mediated   by a nearly massless quark
"  A poset can be regarded as a category in which there is at most one morphism between objects, and such that at most one of Hom(c,c') and Hom(c',c) is nonempty for distinct objects c,c'. If we keep in place the latter axiom but allow for more than one morphism between objects, we have a sort of generalized poset in which there are multiplicities attached to covering relations, and possibly nontrivial automorphism groups. We call such a category an ""updown category"". In this paper we give a precise definition of such categories and develop a theory for them. We also give a detailed account of ten examples, including updown categories of integer partitions, integer compositions, planar rooted trees, and rooted trees. ",Updown categories: Generating functions and universal covers
"  In this paper, it is first discovered that EcN has natural magnetically controlled properties, that is, E coli Nissle 1917 cells move in a gradient magnetic field of permanent magnets without artificial magnetic labeling. It is also shown in the paper that the cultivation of EcN in a medium enriched with iron chelates and under the influence of an external magnetic field increases several times the magnetophoretic mobility of E coli Nissle 1917 cells compared to cultivation under standard conditions. Thus, the speed of movement of E coli Nissle 1917 cells in a gradient magnetic field of laboratory magnets is achieved of the order of several mm/s. It has also been shown for the first time that the cultivation of E coli Nissle 1917 biomass is accelerated by cultivation in an external magnetic field, while the change in the concentration of iron chelates in the medium has no effect on the cultivation dynamics of the E coli Nissle 1917 culture. ",Magnetically controlled vector based on E coli Nissle 1917
  We consider the global dynamics below the ground state energy for the Klein-Gordon-Zakharov system in the 3D radial case; and obtain the dichotomy between scattering and finite time blow up. ,Global dynamics below the ground state energy for the   Klein-Gordon-Zakharov system in the 3D radial case
"  We found theoretically that competition between ~Kq^4 and ~Qq^2 terms in the Fourier transformed conformational energy of a single lipid chain, in combination with inter-chain entropic repulsion in the hydrophobic part of the lipid (bi)layer, may cause a crossover on the bilayer pressure-area isotherm P(A)~(A-A_0)^{-n}. The crossover manifests itself in the transition from n=5/3 to n=3. Our microscopic model represents a single lipid molecule as a worm-like chain with finite irreducible cross-section area A_0, flexural rigidity K and stretching modulus Q in a parabolic potential with self-consistent curvature B(A) formed by entropic interactions between hydrocarbon chains in the lipid layer. The crossover area per lipid A* obeys relation Q^2/(KB(A*))~1 . We predict a peculiar possibility to deduce effective elastic moduli K and Q of the individual hydrocarbon chain from the analysis of the isotherm possessing such crossover. Also calculated is crossover-related behavior of the area compressibility modulus K_a, equilibrium area per lipid A_t, and chain order parameter S. ",Flexible-to-semiflexible chain crossover on the pressure-area isotherm   of lipid bilayer
"  We analyze a 37 pb$^{-1}$ data sample collected with the SND detector at the VEPP-2000 $e^+e^-$ collider in the center-of-mass energy range 1.05--2.00 GeV and present an updated measurement of the $e^+e^- \to \omega \pi^0 \to \pi^0\pi^0\gamma$ cross section. In particular, we correct the mistake in radiative correction calculation made in our previous measurement based on a part of the data. The measured cross section is fitted with the vector meson dominance model with three $\rho$-like states and used to test the conserved vector current hypothesis in the $\tau^-\to\omega\pi^-\nu_{\tau}$ decay. ",Updated measurement of the $e^+e^- \to \omega \pi^0 \to   \pi^0\pi^0\gamma$ cross section with the SND detector
"  The use of social media data, like Twitter, for biomedical research has been gradually increasing over the years. With the COVID-19 pandemic, researchers have turned to more nontraditional sources of clinical data to characterize the disease in near real-time, study the societal implications of interventions, as well as the sequelae that recovered COVID-19 cases present (Long-COVID). However, manually curated social media datasets are difficult to come by due to the expensive costs of manual annotation and the efforts needed to identify the correct texts. When datasets are available, they are usually very small and their annotations do not generalize well over time or to larger sets of documents. As part of the 2021 Biomedical Linked Annotation Hackathon, we release our dataset of over 120 million automatically annotated tweets for biomedical research purposes. Incorporating best practices, we identify tweets with potentially high clinical relevance. We evaluated our work by comparing several SpaCy-based annotation frameworks against a manually annotated gold-standard dataset. Selecting the best method to use for automatic annotation, we then annotated 120 million tweets and released them publicly for future downstream usage within the biomedical domain. ",A Biomedically oriented automatically annotated Twitter COVID-19 Dataset
"  As an eclipsing polar with 3.39 hrs orbital period, MN Hya was going through state change when we observed it during 2009-2016. 10 new mid-eclipse times, along with others obtained from literature, allow us to give a new ephemeris. The residuals of linear fit show that period decreased during the phase of state change. It means angular momentum was lost during this phase. The X-ray observation indicates the mass accretion rate as about $3.6\times10^{-9}M_{\odot}yr^{-1}$. The period decrease gives that at least 60 percent of mass being transfered from secondary was lost, maybe in form of the spherically symmetric stellar wind. In high state, the data shows the intensity of the flickering reduced when system had higher accretion rate, and that flickering sticks out with primary timescale about 2 minutes, which implies the position of the threading point as about 30 radius of the white dwarf above the surface of it. The trend of light curves of the system in high state follows that of low state for a large fraction of phase interval from phase 0 to phase 0.4 since which the cyclotron feature is visible, and the primary intensity hump of light curves near phase 0.7 when the system is in high state did not appear on the curve when it is in low state. Those facts contradict the predictions of the two-pole model. ",Photometric Analysis of the eclipsing Polar MN Hya
  The paper deals with the problem of describing fundamental particles. The Einstein-Rosen approach was revisited to explain que charge-mass ratio quantization. Such a result is obtained once a quantization prescription is applied to the expression of gravitational energy defined in the realm of teleparallel gravity. ,On the Quantization of the Charge-Mass Ratio
"  Rapid improvements in machine learning over the past decade are beginning to have far-reaching effects. For communications, engineers with limited domain expertise can now use off-the-shelf learning packages to design high-performance systems based on simulations. Prior to the current revolution in machine learning, the majority of communication engineers were quite aware that system parameters (such as filter coefficients) could be learned using stochastic gradient descent. It was not at all clear, however, that more complicated parts of the system architecture could be learned as well. In this paper, we discuss the application of machine-learning techniques to two communications problems and focus on what can be learned from the resulting systems. We were pleasantly surprised that the observed gains in one example have a simple explanation that only became clear in hindsight. In essence, deep learning discovered a simple and effective strategy that had not been considered earlier. ",What Can Machine Learning Teach Us about Communications?
"  We motivate the study of chiral cosmic strings through a scenario of structure formation which mixes D-term inflation and strings. We then discuss some properties of chiral cosmic strings, and results regarding their evolution and possible cosmological consequences are presented. ",Strings after D-term inflation: evolution and properties of chiral   cosmic strings
"  We report on density functional total energy calculations of the step formation and interaction energies for vicinal TaC(001) surfaces. Our calculations show that double and triple-height steps are favored over single-height steps for a given vicinal orientation, which is in agreement with recent experimental observations. We provide a description of steps in terms of atomic displacements and charge localization and predict an experimentally observable rumpled structure of the step-edges, where the Ta atoms undergo larger displacements compared to the C atoms. ",Ab-initio density functional studies of stepped TaC surfaces
"  We consider decentralized consensus optimization when workers sample data from non-identical distributions and perform variable amounts of work due to slow nodes known as stragglers. The problem of non-identical distributions and the problem of variable amount of work have been previously studied separately. In our work we analyze them together under a unified system model. We study the convergence of the optimization algorithm when combining worker outputs under two heuristic methods: (1) weighting equally, and (2) weighting by the amount of work completed by each. We prove convergence of the two methods under perfect consensus, assuming straggler statistics are independent and identical across all workers for all iterations. Our numerical results show that under approximate consensus the second method outperforms the first method for both convex and non-convex objective functions. We make use of the theory on minimum variance unbiased estimator (MVUE) to evaluate the existence of an optimal method for combining worker outputs. While we conclude that neither of the two heuristic methods are optimal, we also show that an optimal method does not exist. ",Decentralized optimization with non-identical sampling in presence of   stragglers
"  We present near infrared photometry of the Type Ia supernova 1999ee; also, optical and infrared photometry of the Type Ia SNe 2000bh, 2000ca, and 2001ba. For SNe 1999ee and 2000bh we present the first-ever SN photometry at 1.035 microns (the Y-band). We present K-corrections which transform the infrared photometry in the observer's frame to the supernova rest frame. Using our infrared K-corrections and stretch factors derived from optical photometry, we construct JHK templates which can be used to determine the apparent magnitudes at maximum if one has some data in the window -12 to +10 d with respect to T(B_max). Following up previous work on the uniformity of V minus IR loci of Type Ia supernovae of mid-range decline rates, we present unreddened loci for slow decliners. We also discuss evidence for a continuous change of color at a given epoch as a function of decline rate. ","Optical and Infrared Photometry of the Nearby Type Ia Supernovae 1999ee,   2000bh, 2000ca, and 2001ba"
"  We propose a new method for multivariate response regressions where the elements of the response vector can be of mixed types, for example some continuous and some discrete. Our method is based on a model which assumes the observable mixed-type response vector is connected to a latent multivariate normal response linear regression through a link function. We explore the properties of this model and show its parameters are identifiable under reasonable conditions. We impose no parametric restrictions on the covariance of the latent normal other than positive definiteness, thereby avoiding assumptions about unobservable variables which can be difficult to verify. To accommodate this generality, we propose a novel algorithm for approximate maximum likelihood estimation that works ""off-the-shelf"" with many different combinations of response types, and which scales well in the dimension of the response vector. Our method typically gives better predictions and parameter estimates than fitting separate models for the different response types and allows for approximate likelihood ratio testing of relevant hypotheses such as independence of responses. The usefulness of the proposed method is illustrated in simulations; and one biomedical and one genomic data example. ",Mixed-type multivariate response regression with covariance estimation
"  This paper considers asymptotically hyperbolic manifolds with a finite boundary intersecting the usual infinite boundary -- cornered asymptotically hyperbolic manifolds -- and proves a theorem of Cartan-Hadamard type near infinity for the normal exponential map on the finite boundary. As a main application, a normal form for such manifolds at the corner is then constructed, analogous to the normal form for usual asymptotically hyperbolic manifolds and suited to studying geometry at the corner. The normal form is at the same time a submanifold normal form near the finite boundary and an asymptotically hyperbolic normal form near the infinite boundary. ",Exponential map and normal form for cornered asymptotically hyperbolic   metrics
"  In the present article we provide existence, uniqueness and stability results under an exponential moments condition for quadratic semimartingale backward stochastic differential equations (BSDEs) having convex generators. We show that the martingale part of the BSDE solution defines a true change of measure and provide an example which demonstrates that pointwise convergence of the drivers is not sufficient to guarantee a stability result within our framework. ",Quadratic Semimartingale BSDEs under an Exponential Moments Condition
"  We use the Sloan Digital Sky Survey (SDSS) database to explore the effect of the disk inclination angle on the derived star formation rate (SFR), hence on the slope and width of the Main Sequence (MS) relation for star-forming galaxies. We find that SFRs for nearly edge-on disks are underestimated by factors ranging from $\sim$ 0.2 dex for low mass galaxies up to $\sim$ 0.4 dex for high mass galaxies. This results in a substantially flatter MS relation for high-inclination disks compared to that for less inclined ones, though the global effect over the whole sample of star-forming galaxies is relatively minor, given the small fraction of high-inclination disks. However, we also find that galaxies with high-inclination disks represent a non negligible fraction of galaxies populating the so-called green valley, with derived SFRs intermediate between the MS and those of quenched, passively evolving galaxies. ",The effect of disk inclination on the Main Sequence of star forming   galaxies
"  One of the main tasks in the investigation of 2-dimensional transition metal dichalcogenides is the determination of valley lifetimes. In this work, we combine time-resolved Kerr rotation with electrical transport measurements to explore the gate-dependent valley lifetimes of free conduction band electrons of monolayer WSe$_2$. When tuning the Fermi energy into the conduction band we observe a strong decrease of the respective valley lifetimes which is consistent with both spin-orbit and electron-phonon scattering. We explain the formation of a valley polarization by the scattering of optically excited valley polarized bright trions into dark states by intervalley scattering. Furthermore, we show that the conventional time-resolved Kerr rotation measurement scheme has to be modified to account for photo-induced gate screening effects. Disregarding this adaptation can lead to erroneous conclusions drawn from gate-dependent optical measurements and can completely mask the true gate-dependent valley dynamics. ",Valley lifetimes of conduction band electrons in monolayer WSe$_2$
"  Vanishing long-term gradients are a major issue in training standard recurrent neural networks (RNNs), which can be alleviated by long short-term memory (LSTM) models with memory cells. However, the extra parameters associated with the memory cells mean an LSTM layer has four times as many parameters as an RNN with the same hidden vector size. This paper addresses the vanishing gradient problem using a high order RNN (HORNN) which has additional connections from multiple previous time steps. Speech recognition experiments using British English multi-genre broadcast (MGB3) data showed that the proposed HORNN architectures for rectified linear unit and sigmoid activation functions reduced word error rates (WER) by 4.2% and 6.3% over the corresponding RNNs, and gave similar WERs to a (projected) LSTM while using only 20%--50% of the recurrent layer parameters and computation. ",High Order Recurrent Neural Networks for Acoustic Modelling
"  Massive stars can significantly modify the surrounding medium during their lifetime. When the stars explode as supernovae, the resulting shock wave expands within this modified medium and not within the interstellar medium. We explore the evolution of the medium around massive stars, and the expansion of the shock wave within this medium. We then apply these results to understanding the expansion of the shock wave in the ambient medium surrounding SN 1987A, and the evolution of the radio and X-ray emission in this case. ","Supernova Explosions in Winds and Bubbles, with Applications to SN 1987A"
"  The production of jets is studied in collisions of virtual photons, gamma*-p and gamma*-gamma*, specifically for applications at HERA and LEP2. Photon flux factors are convoluted with matrix elements involving either direct or resolved photons and, for the latter, with parton distributions of the photon. Special emphasis is put on the range of uncertainty in the modeling of the resolved component. The resulting model is compared with existing data. ",Jet Production by Virtual Photons
"  This paper is concerned with the multiplicity results to a class of $p$-Kirchhoff type elliptic equation with the homogeneous Neumann boundary conditions by an abstract linking lemma due to Br\'{e}zis and Nirenberg. We obtain the twofold results in subcritical and critical cases, which is a meaningful addition and completeness to the known results about Kirchhoff equation. ",$p$-Kirchhoff type equation with Neumann boundary conditions
"  Seasonal weather forecasts are crucial for long-term planning in many practical situations and skillful forecasts may have substantial economic and humanitarian implications. Current seasonal forecasting models require statistical postprocessing of the output to correct systematic biases and unrealistic uncertainty assessments. We propose a multivariate postprocessing approach utilizing covariance tapering, combined with a dimension reduction step based on principal component analysis for efficient computation. Our proposed technique can correctly and efficiently handle non-stationary, non-isotropic and negatively correlated spatial error patterns, and is applicable on a global scale. Further, a moving average approach to marginal postprocessing is shown to flexibly handle trends in biases caused by global warming, and short training periods. In an application to global sea surface temperature forecasts issued by the Norwegian Climate Prediction Model (NorCPM), our proposed methodology is shown to outperform known reference methods. ",Multivariate postprocessing methods for high-dimensional seasonal   weather forecasts
"  Deep neural networks are prone to overconfident predictions on outliers. Bayesian neural networks and deep ensembles have both been shown to mitigate this problem to some extent. In this work, we aim to combine the benefits of the two approaches by proposing to predict with a Gaussian mixture model posterior that consists of a weighted sum of Laplace approximations of independently trained deep neural networks. The method can be used post hoc with any set of pre-trained networks and only requires a small computational and memory overhead compared to regular ensembles. We theoretically validate that our approach mitigates overconfidence ""far away"" from the training data and empirically compare against state-of-the-art baselines on standard uncertainty quantification benchmarks. ",Mixtures of Laplace Approximations for Improved Post-Hoc Uncertainty in   Deep Learning
"  For a three dimensional magnetohydrodynamic (MHD) plasma the dynamo action with ABC flow as initial condition has been studied. The study delineates crucial parameter that gives a transition from coherent nonlinear oscillation to dynamo. Further, for both kinematic and dynamic models at magnetic Prandtl number equal to unity the dynamo action is studied for driven ABC flows. The magnetic resistivity has been chosen at a value where the fast dynamo occurs and the growth rate shows no further variation with the change of magnetic Reynold's number. The exponent of growth of magnetic energy increases, indicating a faster dynamo, if a higher wave number is excited compared to the one with a lower wave number. The result has been found to hold good for both kinematic and externally forced dynamic dynamos where the backreaction of magnetic field on the velocity field is no more negligible. In case of an externally forced dynamic dynamo, the super Alfvenic flows have been found to excite strong dynamos giving rise to the growth of magnetic energy of seven orders of magnitude. The back-reaction of magnetic field on the velocity field through Lorentz force term has been found to affect the dynamics of the velocity field and in turn the dynamics of magnetic field, leading to a saturation, when the dynamo action is very prominent. ",Study of Dynamo Action in Three Dimensional Magnetohydrodynamic Plasma   with Arnold-Beltrami-Childress Flow
"  We study the nature of the generating series of some models of walks with small steps in the three quarter plane. More precisely, we restrict ourselves to the situation where the group is infinite, the kernel has genus one, and the step set is diagonally symmetric (i.e., with no steps in anti-diagonal directions). In that situation, after a transformation of the plane, we derive a quadrant-like functional equation. Among the four models of walks, we obtain, using difference Galois theory, that three of them have a differentially transcendental generating series, and one has a differentially algebraic generating series. ",On the nature of four models of symmetric walks avoiding a quadrant
"  A compact neutron spectrometer based on the liquid scintillator is presented for neutron energy spectrum measurements at the HL-2A tokamak. The spectrometer was well characterized and a fast digital pulse shape discrimination software was developed using the charge comparison method. A digitizer data acquisition system with a maximum frequency of 1 MHz can work under an environment with a high count rate at HL-2A tokamak. Specific radiation and magnetic shielding for the spectrometer were designed for the neutron spectrum measurement at the HL-2A tokamak. For pulse height spectrum analysis, dedicated numerical simulation utilizing NUBEAM combined with GENESIS was performed to obtain the neutron energy spectrum. Subsequently, the transportation process from the plasma to the detector was evaluated with Monte Carlo calculations. The distorted neutron energy spectrum was folded with the response matrix of the liquid scintillation spectrometer, and good consistency was found between the simulated and measured pulse height spectra. This neutron spectrometer based on a digital acquisition system could be well adopted for the investigation of the auxiliary heating behavior and the fast-ion related phenomenon on different tokamak devices. ",First Neutron Spectrometry Measurement at the HL-2A Tokamak
"  We consider a subclass of bipartite CHSH-type Bell inequalities. We investigate operations, which leave their Tsirelson bound invariant, but change their classical bound. The optimal observables are unaffected except for a relative rotation of the two laboratories. We illustrate the utility of these operations by giving explicit examples: We prove that for a fixed quantum state and fixed measurement setup except for a relative rotation of the two laboratories, there is a Bell inequality that is maximally violated for this rotation, and we optimise some Bell inequalities with respect to the maximal violation. Finally we optimise the qutrit to qubit ratio of some dimension witnessing Bell inequalities. ",Optimisation of Bell inequalities with invariant Tsirelson bound
"  Here we report a modelling study of the spring ozone maximum and its interhemispheric asymmetry in the remote marine boundary layer (MBL). The modelled results are examined at the surface and on a series of time-height cross sections at several locations spread over the Atlantic, the Indian, and the Pacific Oceans. Comparison of model with surface measurements at remote MBL stations indicate a close agreement. The most striking feature of the hemispheric spring ozone maximum in the MBL can be most easily identified at the NH sites of Westman Island, Bermuda, and Mauna Loa, and at the SH site of Samoa. Modelled ozone vertical distributions in the troposphere are compared with ozone profiles. For the Atlantic and the Indian sites, the model generally produces a hemispheric spring ozone maximum close to those of the measurements. The model also produces a spring ozone maximum in the northeastern and tropical north Pacific close to those measurements, and at sites in the NH high latitudes. The good agreement between model and measurements indicate that the model can reproduce the proposed mechanisms responsible for producing the spring ozone maximum in these regions of the MBL, lending confidence in the use of the model to investigate MBL ozone chemistry (see part 2 and part 3). The spring ozone maximum in the tropical central south Pacific and eastern equatorial Pacific are less well reproduced by the model, indicating that both the transport of $O_3$ precursors from biomass burning emissions taking place in southeastern Asia, Australia, Oceania, southern Africa, and South America are not well represented in the model in these regions. Overall, the model produces a better simulation at sites where the stratosphere and biomass burning emissions are the major contributors. ",Modelling the spring ozone maximum and the interhemispheric asymmetry in   the remote marine boundary layer 1. Comparison with surface and ozonesonde   measurements
"  A three-dimensional (3D) correlation function obtained from mid-rapidity, low pT pion pairs in central Au+Au collisions at sqrt(s_NN)=200 GeV is studied. The extracted model-independent source function indicates a long range tail in the directions of the pion pair transverse momentum (out) and the beam (long). Model comparisons to these distensions indicate a proper breakup time \tau_0 ~ 9 fm/c and a mean proper emission duration \Delta\tau ~ 2 fm/c, leading to sizable emission time differences   (<|\Delta \tau_LCM |> ~ 12 fm/c), partly due to resonance decays.   They also suggest an outside-in ""burning"" of the emission source reminiscent of many hydrodynamical models. ",Source breakup dynamics in Au+Au Collisions at sqrt(s_NN)=200 GeV via   three-dimensional two-pion source imaging
"  On the basis of a nine-parameter expanding source model that includes special relativity, quantum statistics, resonance decays, and freeze-out on a realistic hypersurface in spacetime, we analyze in detail invariant pi+, pi-, K+, and K- one-particle multiplicity distributions and pi+ and K+ two-particle correlations in nearly central collisions of Si + Au at a laboratory bombarding energy per nucleon of 14.6 GeV/c. By considering separately the one-particle data and the correlation data, we find that the central baryon density, nuclear temperature, transverse collective velocity, longitudinal collective velocity, and source velocity are determined primarily by one-particle multiplicity distributions and that the transverse radius, longitudinal proper time, width in proper time, and pion incoherence fraction are determined primarily by two-particle correlations. By considering separately the pion data and the kaon data, we find that although the pion freeze-out occurs somewhat later than the kaon freeze-out, the 99% confidence-level error bars associated with the two freeze-outs overlap. These and other detailed studies confirm our earlier conclusion based on the simultaneous consideration of the pion and kaon one-particle and correlation data that the freeze-out temperature is less than 100 MeV and that both the longitudinal and transverse collective velocities--which are anti-correlated with the temperature--are substantial. We also discuss the flaws in several previous analyses that yielded a much higher freeze-out temperature of approximately 140 MeV for both this reaction and other reactions involving heavier projectiles and/or higher bombarding energies. ",Low Freeze-out Temperature and High Collective Velocities in   Relativistic Heavy-Ion Collisions
"  This study aims to enhance spatial reuse by using the new features of IEEE 802.11ax WLANs. Since the wireless medium is a shared medium and there may be multiple basic service sets (BSS) in the same vicinity, BSSs may overlap, and interference occurs. In this situation, BSSs cannot transmit simultaneously due to the exposed node problem. The IEEE 802.11ax standard has a couple of mechanisms to resolve these spectral efficiency problems. One of the most effective mechanisms that address these problems is the overlapping BSS preamble detection (OBSS/PD) mechanism. OBSS/PD mechanism uses the color mechanism to distinguish OBSS signals. By using a signal threshold, the mechanism can ignore some of the signals, which cause interference. In this paper, we propose a rate-adaptive dynamic OBSS/PD threshold algorithm that tracks the changes in transmission rate and dynamically adjusts the threshold step by step considering the changes. ",More WiFi for Everyone: Increasing Spectral Efficiency in WiFi6 Networks   using OBSS/PD Mechanism
"  Recent results of Trudinger on Isoperimetric Inequalities for non-convex bodies are applied to the gravitational collapse of a lightlike shell of matter to form a black hole. Using some integral identities for co-dimension two surfaces in Minkowski spacetime, the area $A$ of the apparent horizon is shown to be bounded above in terms of the mass $M$ by the $16 \pi G^2 M^2$, which is consistent with the Cosmic Censorship Hypothesis. The results hold in four spacetime dimensions and above. ",Collapsing Shells and the Isoperimetric Inequality for Black Holes
"  Following the seminal approach by Talagrand, the concept of Rademacher complexity for independent sequences of random variables is extended to Markov chains. The proposed notion of ""block Rademacher complexity"" (of a class of functions) follows from renewal theory and allows to control the expected values of suprema (over the class of functions) of empirical processes based on Harris Markov chains as well as the excess probability. For classes of Vapnik-Chervonenkis type, bounds on the ""block Rademacher complexity"" are established. These bounds depend essentially on the sample size and the probability tails of the regeneration times. The proposed approach is employed to obtain convergence rates for the kernel density estimator of the stationary measure and to derive concentration inequalities for the Metropolis-Hasting algorithm. ",Rademacher complexity for Markov chains : Applications to kernel   smoothing and Metropolis-Hasting
"  In this paper, we look at the asymmetric simple exclusion process with open boundaries with a current-counting deformation. We construct a two-parameter family of transfer matrices which commute with the deformed Markov matrix of the system. We show that these transfer matrices can be factorised into two commuting matrices with one parameter each, which can be identified with Baxter's Q-operator, and that for certain values of the product of those parameters, they decompose into a sum of two commuting matrices, one of which is the Bethe transfer matrix for a given dimension of the auxiliary space. Using this, we find the T-Q equation for the open ASEP, and, through functional Bethe Ansatz techniques, we obtain an exact expression for the dominant eigenvalue of the deformed Markov matrix. ",Bethe Ansatz and Q-operator for the open ASEP
"  Quantum Teleportation, the transfer of the state of one quantum system to another without direct interaction between both systems, is an important way to transmit information encoded in quantum states and to generate quantum correlations (entanglement) between remote quantum systems. So far, for photons, only superpositions of two distinguishable states (one ``qubit'') could be teleported. Here we show how to teleport a ``qudit'', i.e. a superposition of an arbitrary number $d$ of distinguishable states present in the orbital angular momentum of a single photon using $d$ beam splitters and $d$ additional entangled photons. The same entanglement resource might also be employed to collectively teleport the state of $d/2$ photons at the cost of one additional entangled photon per qubit. This is superior to existing schemes for photonic qubits, which require an additional pair of entangled photons per qubit. ",Qudit-Teleportation for photons with linear optics
"  Spoken dialogue systems typically use a list of top-N ASR hypotheses for inferring the semantic meaning and tracking the state of the dialogue. However ASR graphs, such as confusion networks (confnets), provide a compact representation of a richer hypothesis space than a top-N ASR list. In this paper, we study the benefits of using confusion networks with a state-of-the-art neural dialogue state tracker (DST). We encode the 2-dimensional confnet into a 1-dimensional sequence of embeddings using an attentional confusion network encoder which can be used with any DST system. Our confnet encoder is plugged into the state-of-the-art 'Global-locally Self-Attentive Dialogue State Tacker' (GLAD) model for DST and obtains significant improvements in both accuracy and inference time compared to using top-N ASR hypotheses. ",Modeling ASR Ambiguity for Dialogue State Tracking Using Word Confusion   Networks
  Noise has been measured in two types of coductor-insulator mixtures as a function of bias and composition. It was marked by a huge increase in magnitude as the resistance increased only slightly due to Joule heating. The noise (resistance) current scale $I_s$($I_r$) for nonlinearity were found to scale with the linear resistance $R_o$ as $I_s(I_r) \sim {{R_o}^ {-x_s(x_r)}}$ where the exponent $x_s$ is equal to 0.80 and 0.68 in carbon-wax and carbon-polyethylene respectively and $x_r \approx 0.5$. It is shown that the large increase of noise in nonohmic regime as well as the differences between the noise and resistance exponents are due to the finite-sized inequilibrium thermal fluctuations whose coherence length is same as the correlation length of the underlying percolating systems. A expression for $x_s$ is derived. ,Finite Coherence Length of Thermal Noise in Percolating Systems
"  In supersymmetric theories with R-parity breaking, sleptons can be produced in quark-antiquark annihilation at the Tevatron through interactions in which two quark fields are coupled to a slepton field. If at the same time trilinear slepton-lepton-lepton couplings are present, the sleptons can be searched for as resonances in $p\bar{p}\to \tilde{\nu} \to l^+l^-$ and $\tilde{\tau}\to l\nu $ final states. Existing Tevatron data can be exploited to derive bounds on the Yukawa couplings of sleptons to quark and lepton pairs. Similar bounds can also be obtained from $e^+e^-$ annihilation to hadrons at LEP2. ",R-Parity Violating SUSY Signals in Lepton-Pair Production at the   Tevatron
"  We find nice representatives for the 0-dimensional cusps of the degree $n$ Siegel upper half-space under the action of $\Gamma_0(\stufe)$. To each of these we attach a Siegel Eisenstein series, and then we make explicit a result of Siegel, realizing any integral weight average Siegel theta series of arbitrary level $\stufe$ and Dirichlet character $\chi_L$ modulo $\stufe$ as a linear combination of Siegel Eisenstein series. ",Explicitly realizing average Siegel theta series as linear combinations   of Eisenstein series
"  To study materials phenomena simultaneously at various length scales, descriptions in which matter can be coarse grained to arbitrary levels, are necessary. Attempts to do this in the static regime (i.e. zero temperature) have already been developed. In this letter, we present an approach that leads to a dynamics for such coarse-grained models. This allows us to obtain temperature-dependent and transport properties. Renormalization group theory is used to create new local potentials model between nodes, within the approximation of local thermodynamical equilibrium. Assuming that these potentials give an averaged description of node dynamics, we calculate thermal and mechanical properties. If this method can be sufficiently generalized it may form the basis of a Molecular Dynamics method with time and spatial coarse-graining. ",Dynamic of a non homogeneously coarse grained system
"  Exact solutions of the string equations of motion in a specific Lorentzian wormhole background are obtained. These include both closed and open string configurations. Perturbations about some of these configurations are investigated using the manifestly covariant formalism of Larsen and Frolov. Finally, the generalized Raychaudhuri equations for the corresponding string worldsheet deformations are written down and analysed briefly. ",STRINGS IN A WORMHOLE BACKGROUND
"  We study privacy-preserving query answering in Description Logics (DLs). Specifically, we consider the approach of controlled query evaluation (CQE) based on the notion of instance indistinguishability. We derive data complexity results for query answering over DL-Lite$_{\mathcal{R}}$ ontologies, through a comparison with an alternative, existing confidentiality-preserving approach to CQE. Finally, we identify a semantically well-founded notion of approximated query answering for CQE, and prove that, for DL-Lite$_{\mathcal{R}}$ ontologies, this form of CQE is tractable with respect to data complexity and is first-order rewritable, i.e., it is always reducible to the evaluation of a first-order query over the data instance. ",CQE in Description Logics Through Instance Indistinguishability   (extended version)
"  Solvothermal intercalation of ethylenediamine molecules into FeSe separates the layers by 1078 pm and creates a different stacking. FeSe(en)0.3 is not superconducting although each layer exhibits the stripe-type crystal structure and the Fermi surface topology of superconducting FeSe. FeSe(en)0.3 requires electron-doping for high-Tc similar to monolayers of FeSe@SrTiO3, whose much higher Tc may arise from the proximity of the oxide surface. ",FeSe(en)0.3 - Separated FeSe layers with stripe-type crystal structure   by intercalation of neutral spacer molecules
"  We examine the possibility of localized propagating tachyonic fields within a properly extended relativity. A possible extension is to include superluminal transformations and reference frames. This leads to complex 4D spacetime, or real 8D spacetime M_{4,4}. The mass shell constraint in M_{4,4} becomes, after first quantization, the ultrahyperbolic Klein-Gordon equation. The Cauchy problem for such equation is not well posed, because it is not possible to freely specify initial data on a 7D hypersurface of M_{4,4}. We explicitly demonstrate that it is possible to do it on a space-like 4-surface for bradyons, and on a time-like 4-surface for tachyons. But then the evolution of a bradyonic field into the four time-like directions, or the ""evolution"" of a tachyonic field into the four space-like directions, is not uniquely determined. We argue that this is perhaps no so bad, because in quantum field theory (after second quantization) the classical trajectories of fields are not determined anyway, and so it does not matter, if they are not completely determined already in the first quantized theory. A next possible extension of relativity is to consider 16D Clifford space, C, a space whose elements are oriented r-volumes, r=0,1,2,3,4 of real 4D spacetime. Then the evolution parameter can be associated with an extra light-cone coordinate, e.g., with the sum of the scalar and the pseudoscalar coordinate, and initial data can be given on a light-like hypersurface, in which case the Cauchy problem is well posed. This procedure brings us to the Stueckelberg theory which contains localized propagating tachyons in 4D spacetime. ",Localized Propagating Tachyons in Extended Relativity Theories
"  In this work we study a model of tax evasion. We considered a fixed population divided in three compartments, namely honest tax payers, tax evaders and a third class between the mentioned two, which we call \textit{susceptibles} to become evaders. The transitions among those compartments are ruled by probabilities, similarly to a model of epidemic spreading. These probabilities model social interactions among the individuals, as well as the government's fiscalization. We simulate the model on fully-connected graphs, as well as on scale-free and random complex networks. For the fully-connected and random graph cases we observe that the emergence of tax evaders in the population is associated with an active-absorbing nonequilibrium phase transition, that is absent in scale-free networks. ",Dynamics of tax evasion through an epidemic-like model
"  Trivalent plane graphs are used in various areas of mathematics which relate for instance to the colored Jones polynomial, invariants of 3-manifolds and quantum computation. Their evaluation is based on computations in the Temperley-Lieb algebra and more specifically the Jones-Wenzl projectors. We use the work by Kauffman-Lins to present a quantum combinatorial approach for evaluating a tetrahedral net. On the way we recover two equivalent definitions for the unsigned Stirling numbers of the first kind and we provide an equality for the quantized factorial using these numbers. ",A quantum combinatorial approach for computing a tetrahedral network of   Jones-Wenzl projectors
"  We describe a physical situation where the time integral of the electric field of an electromagnetic wave packet is not zero. More specifically, the non-oscillating component of the Fourier spectrum, i.e. the component resulting from the Fourier transform of the electric field evaluated at $\omega=0$, can be associated with the area under a locally unipolar electromagnetic pulse that travels in free space at the speed of light. ",Unipolar components travelling at the speed of light in vacuo
"  By restricting the variables running over various (possibly different) subfields, we introduce the notion of a partial zeta function. We prove that the partial zeta function is rational in an interesting case, generalizing Dwork's well known rationality theorem. In general, the partial zeta function is probably not rational. But a theorem of Faltings says that the partial zeta function is always nearly rational. ",Partial zeta functions of algebraic varieties over finite fields
"  We perform a detailed numerical study of diffusion in the $\varepsilon$ stadium of Bunimovich, and propose an empirical model of the local and global diffusion for various values of $\varepsilon$ with the following conclusions: (i) the diffusion is normal for all values of $\varepsilon \leq(0.3)$ and all initial conditions, (ii) the diffusion constant is a parabolic function of the momentum (i.e., we have inhomogeneous diffusion), (iii) the model describes the diffusion very well including the boundary effects, (iv) the approach to the asymptotic equilibrium steady state is exponential, (v) the so-called random model (Robnik et al., 1997) is confirmed to apply very well, (vi) the diffusion constant extracted from the distribution function in momentum space and the one derived from the second moment agree very well. The classical transport time, an important parameter in quantum chaos, is thus determined. ",Aspects of diffusion in the stadium billiard
"  We present constructions of countable two-dimensional subshifts of finite type (SFTs) with interesting properties. Our main focus is on properties of the topological derivatives and subpattern posets of these objects. We present a countable SFT whose iterated derivatives are maximally complex from the computational point of view, constructions of countable SFTs with high Cantor-Bendixson ranks, a countable SFT whose subpattern poset contains an infinite descending chain and a countable SFT whose subpattern poset contains all finite posets. When possible, we make these constructions deterministic, and ensure the sets of rows are very simple as one-dimensional subshifts. ",Constructions with Countable Subshifts of Finite Type
"  Spontaneous collapse models and Bohmian mechanics are two different solutions to the measurement problem plaguing orthodox quantum mechanics. They have, a priori nothing in common. At a formal level, collapse models add a non-linear noise term to the Schr\""odinger equation, and extract definite measurement outcomes either from the wave function (e.g. mass density ontology) or the noise itself (flash ontology). Bohmian mechanics keeps the Schr\""odinger equation intact but uses the wave function to guide particles (or fields), which comprise the primitive ontology. Collapse models modify the predictions of orthodox quantum mechanics, whilst Bohmian mechanics can be argued to reproduce them. However, it turns out that collapse models and their primitive ontology can be exactly recast as Bohmian theories. More precisely, considering (i) a system described by a non-Markovian collapse model, and (ii) an extended system where a carefully tailored bath is added and described by Bohmian mechanics, the stochastic wave-function of the collapse model is exactly the wave-function of the original system conditioned on the Bohmian hidden variables of the bath. Further, the noise driving the collapse model is a linear functional of the Bohmian variables. The randomness that seems progressively revealed in the collapse models lies entirely in the initial conditions in the Bohmian-like theory. Our construction of the appropriate bath is not trivial and exploits an old result from the theory of open quantum systems. This reformulation of collapse models as Bohmian theories brings to the fore the question of whether there exists `unromantic' realist interpretations of quantum theory that cannot ultimately be rewritten this way, with some guiding law. It also points to important foundational differences between `true' (Markovian) collapse models and non-Markovian models. ",Non-Markovian wave-function collapse models are Bohmian-like theories in   disguise
"  We study how the nature of a hybrid system (perfect fluid, solid or a mixture of them) could be related to the induction of general relativistic surface degrees of freedom on phase-splitting surfaces upon perturbation of its phases. We work in the scope of phase conversions in the vicinity of sharp phase transition surfaces whose timescales are either much smaller (rapid conversions) or larger (slow conversions) than the ones of the perturbations ($\omega^{-1}$, where $\omega$ is a characteristic frequency of oscillation of the star). In this first approach, perturbations are assumed to be purely radial. We show that surface degrees of freedom could emerge when either the core or the crust of a hybrid star is solid and phase conversions close to a phase-splitting surface are rapid. We also show how this would change the usual stability rule for solid hybrid stars, namely $\partial M_0/\partial \rho_c\geq 0$, where $M_0$ is the total mass to the background hybrid star and $\rho_c$ its central density. Further consequences of our analysis for asteroseismology are also briefly discussed. ",General relativistic surface degrees of freedom in perturbed hybrid   stars
"  The chemotactic network of Escherichia coli has been studied extensively both biophysically and information-theoretically. Nevertheless, the connection between these two aspects is still elusive. In this work, we report such a connection by showing that a standard biochemical model of the chemotactic network is mathematically equivalent to an information-theoretically optimal filtering dynamics. Moreover, we demonstrate that an experimentally observed nonlinear response relation can be reproduced from the optimal dynamics. These results suggest that the biochemical network of E. coli chemotaxis is designed to optimally extract gradient information in a noisy condition. ",A connection between bacterial chemotactic network and optimal filtering
"  Designing software systems for Geometric Computing applications can be a challenging task. Software engineers typically use software abstractions to hide and manage the high complexity of such systems. Without the presence of a unifying algebraic system to describe geometric models, the use of software abstractions alone can result in many design and maintenance problems. Geometric Algebra (GA) can be a universal abstract algebraic language for software engineering geometric computing applications. Few sources, however, provide enough information about GA-based software implementations targeting the software engineering community. In particular, successfully introducing GA to software engineers requires quite different approaches from introducing GA to mathematicians or physicists. This article provides a high-level introduction to the abstract concepts and algebraic representations behind the elegant GA mathematical structure. The article focuses on the conceptual and representational abstraction levels behind GA mathematics with sufficient references for more details. In addition, the article strongly recommends applying the methods of Computational Thinking in both introducing GA to software engineers, and in using GA as a mathematical language for developing Geometric Computing software systems. ",Introducing Geometric Algebra to Geometric Computing Software   Developers: A Computational Thinking Approach
"  We theoretically investigate excitation properties in the pseudogap regime of a trapped Fermi gas. Using a combined $T$-matrix theory with the local density approximation, we calculate strong-coupling corrections to single-particle local density of states (LDOS), as well as the single-particle local spectral weight (LSW). Starting from the superfluid phase transition temperature $T_{\rm c}$, we clarify how the pseudogap structures in these quantities disappear with increasing the temperature. As in the case of a uniform Fermi gas, LDOS and LSW give different pseudogap temperatures $T^*$ and $T^{**}$ at which the pseudogap structures in these quantities completely disappear. Determining $T^*$ and $T^{**}$ over the entire BCS (Bardeen-Cooper-Schrieffer)-BEC (Bose-Einstein condensate) crossover region, we identify the pseudogap regime in the phase diagram with respect to the temperature and the interaction strength. We also show that the so-called back-bending peak recently observed in the photoemission spectra by JILA group may be explained as an effect of pseudogap phenomenon in the trap center. Since strong pairing fluctuations, spatial inhomogeneity, and finite temperatures, are important keys in considering real cold Fermi gases, our results would be useful for clarifying normal state properties of this strongly interacting Fermi system. ",Pseudogap temperature and effects of a harmonic trap in the BCS-BEC   crossover regime of an ultracold Fermi gas
"  Loop Tree Duality (LTD) offers a promising avenue to numerically integrate multi-loop integrals directly in momentum space. It is well-established at one loop, but there have been only sparse numerical results at two loops. We provide a formal derivation for a novel multi-loop LTD expression and study its threshold singularity structure. We apply our findings numerically to a diverse set of up to four-loop finite topologies with kinematics for which no contour deformation is needed. We also lay down the ground work for constructing such a deformation. Our results serve as an important stepping stone towards a generalised and efficient numerical implementation of LTD, applicable to the computation of virtual corrections. ",Loop Tree Duality for multi-loop numerical integration
"  Via the application of parallel magnetic field, we induce a single-layer to bilayer transition in two-dimensional electron systems confined to wide GaAs quantum wells, and study the geometric resonance of composite fermions (CFs) with a periodic density modulation in our samples. The measurements reveal that CFs exist close to bilayer quantum Hall states, formed at Landau level filling factors $\nu=1$ and 1/2. Near $\nu=1$, the geometric resonance features are consistent with half the total electron density in the bilayer system, implying that CFs prefer to stay in separate layers and exhibit a two-component behavior. In contrast, close to $\nu=1/2$, CFs appear single-layer-like (single-component) as their resonance features correspond to the total density. ",Geometric Resonance of Composite Fermions near Bilayer Quantum Hall   States
"  We propose an unsupervised approach for learning end-to-end reconstruction operators for ill-posed inverse problems. The proposed method combines the classical variational framework with iterative unrolling, which essentially seeks to minimize a weighted combination of the expected distortion in the measurement space and the Wasserstein-1 distance between the distributions of the reconstruction and ground-truth. More specifically, the regularizer in the variational setting is parametrized by a deep neural network and learned simultaneously with the unrolled reconstruction operator. The variational problem is then initialized with the reconstruction of the unrolled operator and solved iteratively till convergence. Notably, it takes significantly fewer iterations to converge, thanks to the excellent initialization obtained via the unrolled operator. The resulting approach combines the computational efficiency of end-to-end unrolled reconstruction with the well-posedness and noise-stability guarantees of the variational setting. Moreover, we demonstrate with the example of X-ray computed tomography (CT) that our approach outperforms state-of-the-art unsupervised methods, and that it outperforms or is on par with state-of-the-art supervised learned reconstruction approaches. ",End-to-end reconstruction meets data-driven regularization for inverse   problems
"  The Muon Accelerator Program (MAP) has completed a four-year study on the feasibility of muon colliders and on using stored muon beams for neutrinos. That study was broadly successful in its goals, establishing the feasibility of heavy lepton colliders (HLCs) from the 125 GeV Higgs Factory to more than 10 TeV, as well as exploring using a {\mu} storage ring (MSR) for neutrinos, and establishing that MSRs could provide factory-level intensities of $\nu_e (\bar{\nu}_e)$ and $\bar{\nu}_\mu$ $({\nu}_\mu)$ beams. The key components of the collider and neutrino factory systems were identified. Feasible designs and detailed simulations of all of these components have been obtained, including some initial hardware component tests, setting the stage for future implementation where resources are available and the precise physics goals become apparent. ",Accomplishments of the Heavy Electron Particle Accelerator Program
"  We describe $\delta$ shock wave arising from continuous initial data in the case of triangular conservation law system arising from ""generalized pressureless gas dynamics model"". We use the weak asymptotic method. ",Delta shock wave formation in the case of triangular hyperbolic system   of conservation laws
"  Multi-way Theta-join queries are powerful in describing complex relations and therefore widely employed in real practices. However, existing solutions from traditional distributed and parallel databases for multi-way Theta-join queries cannot be easily extended to fit a shared-nothing distributed computing paradigm, which is proven to be able to support OLAP applications over immense data volumes. In this work, we study the problem of efficient processing of multi-way Theta-join queries using MapReduce from a cost-effective perspective. Although there have been some works using the (key,value) pair-based programming model to support join operations, efficient processing of multi-way Theta-join queries has never been fully explored. The substantial challenge lies in, given a number of processing units (that can run Map or Reduce tasks), mapping a multi-way Theta-join query to a number of MapReduce jobs and having them executed in a well scheduled sequence, such that the total processing time span is minimized. Our solution mainly includes two parts: 1) cost metrics for both single MapReduce job and a number of MapReduce jobs executed in a certain order; 2) the efficient execution of a chain-typed Theta-join with only one MapReduce job. Comparing with the query evaluation strategy proposed in [23] and the widely adopted Pig Latin and Hive SQL solutions, our method achieves significant improvement of the join processing efficiency. ",Efficient Multi-way Theta-Join Processing Using MapReduce
"  Recent data protection regulations (such as GDPR and CCPA) grant consumers various rights, including the right to access, modify or delete any personal information collected about them (and retained) by a service provider. To exercise these rights, one must submit a verifiable consumer request proving that collected data indeed pertains to them. This action is relatively straightforward for consumers with active accounts with a service provider at the time of data collection, since they can use standard (e.g., password-based) means of authentication to validate their requests. However, a major conundrum arises from the need to support consumers without accounts to exercise their rights. To this end, some service providers began requiring these accountless consumers to reveal and prove their identities (e.g., using government-issued documents, utility bills or credit card numbers) as part of issuing a verifiable consumer request. While understandable as a short-term cure, this approach is, at the same time, cumbersome and expensive for service providers as well as very privacy-invasive for consumers. Consequently, there is a strong need to provide better means of authenticating requests from accountless consumers. To achieve this, we propose VICEROY, a privacy-preserving and scalable framework for producing proofs of data ownership, which can be used as a basis for verifiable consumer requests. Building upon existing web techniques and features (e.g., cookies), VICEROY allows accountless consumers to interact with service providers, and later prove -- in a privacy-preserving manner -- that they are the same person, with minimal requirements for both parties. We design and implement VICEROY with the emphasis on security/privacy, deployability and usability. We also thoroughly assess its practicality via extensive experiments. ",VICEROY: GDPR-/CCPA-compliant Enforcement of Verifiable Accountless   Consumer Requests
"  This paper studies a problem of controlling trajectories of a platoon of vehicles on a highway segment with connected and automated vehicles. This problem is complex because each vehicle trajectory is an infinite-dimensional object and neighboring trajectories have complex interactions (e.g., car-following behavior). A parsimonious shooting heuristic algorithm is proposed to construct vehicle trajectories on a signalized highway segment that comply with boundary conditions for vehicle arrivals, vehicle mechanical limits, traffic lights and vehicle following safety. This algorithm breaks each vehicle trajectory into a few sections and each is analytically solvable. This decomposes the original hard trajectory control problem to a simple constructive heuristic. Then we slightly adapt this shooting heuristic algorithm to efficiently solve a leading vehicle problem on an uninterrupted freeway. To study theoretical properties of the proposed algorithms, the time geography theory is generalized by considering finite accelerations. With this generalized theory, it is found that under mild conditions, these algorithms can always obtain a feasible solution to the original complex trajectory control problem. Further, we discover that the shooting heuristic solution is a generalization of the solution to the classic kinematic wave theory by incorporating finite accelerations. We identify the theoretical bounds to the difference between the shooting heuristic solution and the kinematic wave solution. Numerical experiments are conducted to verify the theoretical results and to draw additional insights into the potential of trajectory control in improving traffic performance. Building upon this foundation, an optimization framework will be presented in a following paper as Part II of this study. ",Parsimonious shooting heuristic for trajectory control of connected   automated traffic part I: Theoretical analysis with generalized time   geography
"  We extend the method of multiscale analysis for resonances introduced in [5] in order to infer analytic properties of resonances and eigenvalues (and their eigenprojections) as well as estimates for the localization of the spectrum of dilated Hamiltonians and norm-bounds for the corresponding resolvent operators, in neighborhoods of resonances and eigenvalues. We apply our method to the massless Spin-Boson model assuming a slight infrared regularization. We prove that the resonance and the ground-state eigenvalue (and their eigenprojections) are analytic with respect to the dilation parameter and the coupling constant. Moreover, we prove that the spectrum of the dilated Spin-Boson Hamiltonian in the neighborhood of the resonance and the ground-state eigenvalue is localized in two cones in the complex plane with vertices at the location of the resonance and the ground-state eigenvalue, respectively. Additionally, we provide norm-estimates for the resolvent of the dilated Spin-Boson Hamiltonian near the resonance and the ground-state eigenvalue. The topic of analyticity of eigenvalues and resonances has let to several studies and advances in the past. However, to the best of our knowledge, this is the first time that it is addressed from the perspective of multiscale analysis. Once the multiscale analysis is set up our method gives easy access to analyticity: Essentially, it amounts to proving it for isolated eigenvalues only and use that uniform limits of analytic functions are analytic. The type of spectral and resolvent estimates that we prove are needed to control the time evolution including the scattering regime. The latter will be demonstrated in a forthcoming publication. The introduced multiscale method to study spectral and resolvent estimates follows its own inductive scheme and is independent (and different) from the method we apply to construct resonances. ",Analyticity of Resonances and Eigenvalues and Spectral Properties of the   massless Spin-Boson Model
"  The reproducibility crisis has led to an increasing number of replication studies being conducted. Sample sizes for replication studies are often calculated using conditional power based on the effect estimate from the original study. However, this approach is not well suited as it ignores the uncertainty of the original result. Bayesian methods are used in clinical trials to incorporate prior information into power calculations. We propose to adapt this methodology to the replication framework and promote the use of predictive instead of conditional power in the design of replication studies. Moreover, we describe how extensions of the methodology to sequential clinical trials can be tailored to replication studies. Conditional and predictive power calculated at an interim analysis are compared and we argue that predictive power is a useful tool to decide whether to stop a replication study prematurely. A recent project on the replicability of social sciences is used to illustrate the properties of the different methods. ",Power Calculations for Replication Studies
"  We study the effects of disorder on the topological Chern insulating phase in the Harper--Hofstadter--Hatsugai (HHH) model. The model with half flux has a bulk band gap and thus exhibits a nontrivial topological phase. We consider two typical types of disorder: on-site random disorder and the Aubry--Andre type quasi-periodic potential. Using the coupling matrix method, we clarify the global topological phase diagram in terms of the Chern number. The disorder modifies the gap closing behavior of the system. This modification induces the Chern insulating phase even in the trivial phase parameter regime of the system in the clean limit. Moreover, we consider an interacting Rice--Mele model with disorder, which can be obtained by dimensional reduction of the HHH model. Moderately strong disorder leads to an increase in revival events of the Chern insulator at a specific parameter point. ",Disorder-induced Chern insulator in Harper--Hofstadter--Hatsugai model
"  We study Fourier multipliers on free group $\mathbb{F}_\infty$ associated with the first segment of the reduced words, and prove that they are completely bounded on the noncommutative $L^p$ spaces $L^p(\hat{\mathbb{F}}_\infty)$ iff their restriction on $L^p(\hat{\mathbb{F}}_1)=L^p(\mathbb{T})$ are completely bounded. As a consequence, every classical Mikhlin multiplier extends to a $L^p$ Fourier multiplier on free groups for all $1<p<\infty$. ",Free Fourier Multipliers associated with the firstSegment
"  Convolutional Neural Networks (CNNs) are the state-of-the-art algorithms for the processing of images. However the configuration and training of these networks is a complex task requiring deep domain knowledge, experience and much trial and error. Using genetic algorithms, competitive CNN topologies for image recognition can be produced for any specific purpose, however in previous work this has come at high computational cost. In this work two novel approaches are presented to the utilisation of these algorithms, effective in reducing complexity and training time by nearly 20%. This is accomplished via regularisation directly on training time, and the use of partial training to enable early ranking of individual architectures. Both approaches are validated on the benchmark CIFAR10 data set, and maintain accuracy. ",Two Novel Performance Improvements for Evolving CNN Topologies
"  We present a model for the kinetics of spontaneous membrane domain (raft) assembly that includes the effect of membrane recycling ubiquitous in living cells. We show that the domains have a broad power-law distribution with an average radius that scales with the 1/4 power of the domain lifetime when the line tension at the domain edges is large. For biologically reasonable recycling and diffusion rates the average domain radius is in the tens of nm range, consistent with observations. This represents one possible link between signaling (involving rafts) and traffic (recycling) in cells. Finally, we present evidence that suggests that the average raft size may be the same for all scale-free recycling schemes. ",Non-equilibrium raft-like membrane domains under continuous recycling
"  In epitaxial (111) oriented Ni$_{80}$Fe$_{20}$/Fe$_{50}$Mn$_{50}$ bilayers, we separate two distinct behaviors: unidirectional anisotropy (exchange bias) in thick Fe$_{50}$Mn$_{50}$, and enhanced coercivity in thin Fe$_{50}$Mn$_{50}$. By measuring the magnetization response to a rotating magnetic field, we quantitatively determine the relevant anisotropies, and demonstrate that the enhanced coercivity is related to the rotatable magnetic anisotropy of Fe$_{50}$Mn$_{50}$. We also demonstrate the consequences of the anisotropy changes with temperature. ",Effects of Antiferromagnetic Spin Rotation on Anisotropy of   Ferromagnetic/Antiferromagnetic Bilayers
"  The occurrence of a molecular Bose-Einstein condensate is studied for an atomic system near a zero energy resonance of the binary scattering process, with a large and positive scattering length. The interaction potential is modeled by a pseudo-potential having one bound state. Using a variational Gaussian ansatz for the $N$-body density operator, we discuss the thermodynamic properties at low temperature and the relative stability of the system towards the formation of an atomic Bose-Einstein condensate. We also derive an approximate Gross-Pitaevskii equation for the molecular condensate leading to the prediction of a Bogoliubov spectrum. ",A toy model for molecular condensates in Bose gases
"  We report on an improved measurement of the 2\nu \beta \beta\ half-life of Xe-136 performed by EXO-200. The use of a large and homogeneous time projection chamber allows for the precise estimate of the fiducial mass used for the measurement, resulting in a small systematic uncertainty. We also discuss in detail the data analysis methods used for double-beta decay searches with EXO-200, while emphasizing those directly related to the present measurement. The Xe-136 2\nu \beta \beta\ half-life is found to be 2.165 +- 0.016 (stat) +- 0.059 (sys) x 10^21 years. This is the most precisely measured half-life of any 2\nu \beta \beta\ decay to date. ",An improved measurement of the 2\nu \beta \beta\ half-life of Xe-136   with EXO-200
"  We study the Decomposition Conjecture posed by Bar\'at and Thomassen (2006), which states that for every tree $T$ there exists a natural number $k_T$ such that, if $G$ is a $k_T$-edge-connected graph and $|E(T)|$ divides $|E(G)|$, then $G$ admits a decomposition into copies of $T$. In a series of papers, Thomassen verified this conjecture for stars, some bistars, paths of length $3$, and paths whose length is a power of $2$. We verify the Decomposition Conjecture for paths of length $5$. ",Decompositions of highly connected graphs into paths of length five
"  We show that a generalized Landau theory for the smectic A and C phases exhibits a biaxiality induced AC tricritical point. Proximity to this tricritical point depends on the degree of orientational order in the system; for sufficiently large orientational order the AC transition is 3D XY-like, while for sufficiently small orientational order, it is either tricritical or 1st order. We investigate each of the three types of AC transitions near tricriticality and show that for each type of transition, small orientational order implies de Vries behavior in the layer spacing, an unusually small layer contraction. This result is consistent with, and can be understood in terms of, the ""diffuse cone"" model of de Vries. Additionally, we show that birefringence grows upon entry to the C phase. For a continuous transition, this growth is more rapid the closer the transition is to tricriticality. Our model also predicts the possibility of a nonmontonic temperature dependence of birefringence. ",De Vries Behavior in Smectics near a Biaxiality Induced Smectic A -   Smectic C Tricritical Point
"  The Piedmont region in Italy was affected by a heavy rainfall event in November 1994. On the 4th convective cells involved the coastal mountains of the region. On the 5th and early 6th, there were abundant precipitations, related to orographic lift and low-level convergences, in the Alpine area. This study aims to evaluate whether a convection-permitting model provides more valuable information with respect to past numerical experiments. Results for the 4th of November show that the cloud-resolving model successfully reconstructs the structure of precipitation systems on the downstream side of the coastal mountains. As regards the precipitations of the 5th of November, no added value is found. However, we provide evidence of the anomalously intense transport of moist air from the tropical and subtropical Atlantic and postulate how such transport is responsible for reducing the stability of the flow impinging on the Alps. ",Reforecasting the November 1994 flooding of Piedmont with a   convection-permitting model
"  We report a reanalysis of the reactor antineutrino energy spectra based on the new relative measurements of the ratio $R=\!^{e}S_5/^{e}S_9$ between cumulative $\beta$ spectra from $^{235}$U and $^{239}$Pu, performed at a research reactor in National Research Centre Kurchatov Institute (KI). A discrepancy with the $\beta$ spectra measured at Institut Laue-Langevin (ILL) was observed, indicating a steady excess of the ILL ratio by the factor of $1.054\pm0.002$. We find a value of the ratio between inverse beta decay cross section per fission for $^{235}$U and $^{239}$Pu: $(^5\sigma_f/^9\sigma_f)_{KI} = 1.45 \pm 0.03$, and then we reevaluate the converted antineutrino spectra for $^{235}$U and $^{238}$U. We conclude that the new predictions are consistent with the results of Daya Bay and STEREO experiments. ",Reevaluating reactor antineutrino spectra with new measurements of the   ratio between $^{235}$U and $^{239}$Pu $\beta$ spectra
"  Perception of the lane boundaries is crucial for the tasks related to autonomous trajectory control. In this paper, several methodologies for lane detection are discussed with an experimental illustration: Hough transformation, Blob analysis, and Bird's eye view. Following the abstraction of lane marks from the boundary, the next approach is applying a control law based on the perception to control steering and speed control. In the following, a comparative analysis is made between an open-loop response, PID control, and a neural network control law through graphical statistics. To get the perception of the surrounding a wireless streaming camera connected to Raspberry Pi is used. After pre-processing the signal received by the camera the output is sent back to the Raspberry Pi that processes the input and communicates the control to the motors through Arduino via serial communication. ",Experimental Analysis of Trajectory Control Using Computer Vision and   Artificial Intelligence for Autonomous Vehicles
"  FRIIb radio galaxies provide a tool to determine the coordinate distance to sources out to redshifts of two. The coordinate distance depends on the present values of global cosmological parameters, quintessence, and the equation of state of quintessence, and provides one of the cleanest determinations of global cosmological parameters because it does not depend on the clustering properties of any mass-energy components. The modified standard candle method (using type Ia supernove) of determining the coordinate distance is compared in detail with the modified standard yardstick method (using FRIIb radio galaxies); the methods are found to be complementary. The most significant difference between the methods is that the radio galaxy method is completely independent of the local distance scale and the properties of local sources, while the supernovae method is very closely tied to the local distance scale and the properties of local sources. FRIIb radio galaxies provide one of the very few reliable probes of the coordinate distance to sources with redshifts out to two. The method indicates that the current value of the density parameter in non-relativistic matter must be low irrespective of whether the universe is spatially flat, and of whether a significant cosmological constant or quintessence pervades the universe at the present epoch. FRIIb radio galaxies indicate that the universe is currently accelerating in its expansion if the primary components of the universe at the present epoch are non-relativistic matter and quintessence, and the universe is spatially flat. ",Cosmological Parameters and Quintessence From Radio Galaxies
"  Monitoring of hybrid systems attracts both scientific and practical attention. However, monitoring algorithms suffer from the methodological difficulty of only observing sampled discrete-time signals, while real behaviors are continuous-time signals. To mitigate this problem of sampling uncertainties, we introduce a model-bounded monitoring scheme, where we use prior knowledge about the target system to prune interpolation candidates. Technically, we express such prior knowledge by linear hybrid automata (LHAs) - the LHAs are called bounding models. We introduce a novel notion of monitored language of LHAs, and we reduce the monitoring problem to the membership problem of the monitored language. We present two partial algorithms - one is via reduction to reachability in LHAs and the other is a direct one using polyhedra - and show that these methods, and thus the proposed model-bounded monitoring scheme, are efficient and practically relevant. ",Model-bounded monitoring of hybrid systems
"  The rapid growth of the solar energy industry has produced a strong demand for high performance, efficient photoelectric materials. Many ferroelectrics, composed of earth-abundant elements, are useful for solar cell applications due to their large internal polarization. However, their wide band gaps prevent them from absorbing light in the visible to mid-infrared range. Here, we address the band gap issue by investigating, in particular, the substitution of sulphur for oxygen in the perovskite structure ZnSnO3 . Using evolutionary methods we identify the stable and metastable structures of ZnSnS3 and compare them to those previously characterized for ZnSnO3 . Our results suggest that ZnSnS3 forms a monoclinic structure followed by metastable ilmenite and lithium-niobate structures. The latter structure is highly polarized and it possesses a significantly reduced band gap of 1.28 eV. These desirable characteristics make it a prime candidate for solar cell applications. ","ZnSnS3 : Structure Prediction, Ferroelectricity, and Solar Cell   Applications"
"  We continue to study twistor spaces on the connected sum of four complex projective planes, whose anticanonical map is of degree two over the image. In particular, we determine the defining equation of the branch divisor of the anticanonical map in an explicit form. Together with previous two articles (arXiv:1009.3153 and arXiv:0705.0060), this completes explicit description of all such twistor spaces. ","Geometry of generic Moishezon twistor spaces on 4CP^2, II: degenerate   cases"
  This survey presents some recent results by the authors and Polterovich on the topological properties of ruled symplectic manifolds. The bundle M \to P \to B that is associated with a ruled manifold has the group of Hamiltonian symplectomorphisms of M as structure group if the base is simply connected. Thus information about Hamiltonian bundles gives stability results for ruled structures as well as obstructions to their existence. ,Cohomological properties of ruled symplectic structures
"  We propose a novel one-dimensional model that includes both shock and turbulence heating and qualify how these processes contribute to heating the corona and driving the solar wind. Compressible MHD simulations allow us to automatically consider shock formation and dissipation, while turbulent dissipation is modeled via a one-point closure based on Alfv\'en wave turbulence. Numerical simulations were conducted with different photospheric perpendicular correlation lengths $\lambda_0$, which is a critical parameter of Alfv\'en wave turbulence, and different root-mean-square photospheric transverse-wave amplitudes $\delta v_0$. For the various $\lambda_0$, we obtain a low-temperature chromosphere, high-temperature corona, and supersonic solar wind. Our analysis shows that turbulence heating is always dominant when $\lambda_0 \lesssim 1{\rm \ Mm}$. This result does not mean that we can ignore the compressibility because the analysis indicates that the compressible waves and their associated density fluctuations enhance the Alfv\'en wave reflection and therefore the turbulence heating. The density fluctuation and the cross helicity are strongly affected by $\lambda_0$, while the coronal temperature and mass loss rate depend weakly on $\lambda_0$. ",A self-consistent model of the coronal heating and solar wind   acceleration including compressible and incompressible heating processes
"  The 5G band allocated in the 26 GHz spectrum referred to as 3GPP band n258, has generated a lot of anxiety and concern in the meteorological data forecasting community including the National Oceanic and Atmospheric Administration (NOAA). Unlike traditional spectrum coexistence problems, the issue here stems from the leakage of n258 band transmissions impacting the observations of passive sensors (e.g. AMSU-A) operating at 23.8 GHz on weather satellites used to detect the amount of water vapor in the atmosphere, which in turn affects weather forecasting and predictions. In this paper, we study the impact of 5G leakage on the accuracy of data assimilation based weather prediction algorithms by using a first order propagation model to characterize the effect of the leakage signal on the brightness temperature (atmospheric radiance) and the induced noise temperature at the receiving antenna of the passive sensor (radiometer) on the weather observation satellite. We then characterize the resulting inaccuracies when using the Weather Research and Forecasting Data Assimilation model (WRFDA) to predict temperature and rainfall. For example, the impact of 5G leakage of -20dBW to -15dBW on the well-known Super Tuesday Tornado Outbreak data set, affects the meteorological forecasting up to 0.9 mm in precipitation and 1.3 {\deg}C in 2m-temperature. We outline future directions for both improved modeling of 5G leakage effects as well as mitigation using cross-layer antenna techniques coupled with resource allocation. ",Modeling the Impact of 5G Leakage on Weather Prediction
"  We investigate the energy loss characteristics of warm dense matter (WDM) and dense plasmas concentrating on the influence of electronic correlations. The basis for our analysis is a recently developed ab initio Quantum Monte-Carlo (QMC) based machine-learning representation of the static local field correction (LFC) [Dornheim et al., J. Chem. Phys. 151, 194104 (2019)], which provides an accurate description of the dynamical density response function of the electron gas at the considered parameters. We focus on the polarization-induced stopping power due to free electrons, the friction function, and the straggling rate. In addition, we compute the friction coefficient which constitutes a key quantity for the adequate Langevin dynamics simulation of ions. Considering typical experimental WDM parameters with partially degenerate electrons, we find that the friction coefficient is of the order of $\gamma/\omega_{pi}=0.01$, where $\omega_{pi}$ is the ionic plasma frequency. This analysis is performed by comparing QMC based data to results from the random phase approximation (RPA), the Mermin dielectric function, and the Singwi-Tosi-Land-Sj\""olander (STLS) approximation. It is revealed that the widely used relaxation time approximation (Mermin dielectric function) has severe limitations regarding the description of the energy loss properties of correlated partially degenerate electrons. Moreover, by comparing QMC based data with the results obtained using STLS, we find that energy loss properties are not sensitive to the inaccuracy of the static LFC at large wave numbers $k/k_{F}>2$ (with $k_F$ being the usual Fermi wave number), but that a correct description of the static LFC at $k/k_{F}\lesssim 1.5$ is important. ",Energy loss and friction characteristics of electrons at warm dense   matter and non-ideal dense plasma conditions
"  In this paper, we shall show that some coincidence point and common fixed point results for three or four mappings could easily be obtained from the corresponding fixed point results for two mappings. ",Common fixed points for three or four mappings via common fixed point   for two mappings
"  This paper gives an extended model of the atomic nucleus - we call it the YY model, which allows a new description for strong forces from the well-known Standard Model. The forces that hold the nucleus together (protons and neutrons) can be expressed in a new way. Based on the YY model, more structural description details for an atomic nucleus will be possible than is the case with the conventional description. The YY model is compatible with the standard model. However, it allows for very delicate considerations when modelling the distribution of protons and neutrons within or around an atomic nucleus. Furthermore, it can explain many subatomic processes in an elegant way. The YY model predicts some subatomic aspects that can be explored in a deeper step. Our approach also includes a native common root for the description of macrophysics (space, dark matter and cosmology).   Following a model-driven approach - a methodology widely used in computer science and informatics - the investigations in this paper will completely dispense with mathematical formulations. In addition, energy balances in the transformations are left out. Many different aspects that can be derived from this new mechanism can then be verified. We hope to gain the confidence of many other physicists in the YY model. They could make detailed theoretical and experimental verifications by adding additional descriptive elements and linking the YY model to the known quantum field theories and the widely accepted big bang theories for space and cosmology, especially for research on dark matter. ",Extending Standard Atomic Kernel Model with New Interpretation of Strong   Forces
"  Open-world query answering is the problem of deciding, given a set of facts, conjunction of constraints, and query, whether the facts and constraints imply the query. This amounts to reasoning over all instances that include the facts and satisfy the constraints. We study finite open-world query answering (FQA), which assumes that the underlying world is finite and thus only considers the finite completions of the instance. The major known decidable cases of FQA derive from the following: the guarded fragment of first-order logic, which can express referential constraints (data in one place points to data in another) but cannot express number restrictions such as functional dependencies; and the guarded fragment with number restrictions but on a signature of arity only two. In this paper, we give the first decidability results for FQA that combine both referential constraints and number restrictions for arbitrary signatures: we show that, for unary inclusion dependencies and functional dependencies, the finiteness assumption of FQA can be lifted up to taking the finite implication closure of the dependencies. Our result relies on new techniques to construct finite universal models of such constraints, for any bound on the maximal query size. ",Finite Open-World Query Answering with Number Restrictions (Extended   Version)
"  A graphene sheet partially covered with a bulk superconductor serves as a normal conductor--superconductor (NS) junction, in which electron transport is mainly governed by Andreev reflection (AR). As excess carriers induced over the covered region penetrate into the uncovered region over a screening length, the charge neutrality point (CNP) in the uncovered region shifts only near the NS interface. We theoretically study the electron transport in a bilayer graphene junction taking account of such spatial variation of the CNP in the electron-doped case. When the Fermi level is close to the CNP away from the NS interface, the AR takes place in a specular manner owing to the diffraction of a reflected hole occurring at a $pn$ junction, which is naturally formed in the uncovered region. It is shown that the differential conductance shows an unusual asymmetric behavior as a function of bias voltage under the influence of the $pn$ junction. It is also shown that, if the Fermi level is located below the CNP, the $pn$ junction gives rise to quasi-bound states near the NS interface, leading to the appearance of resonant peaks in the differential conductance. ",Andreev Reflection in a Bilayer Graphene Junction: Role of Spatial   Variation of the Charge Neutrality Point
"  We use neutron scattering to determine spin excitations in single crystals of nonsuperconducting Li1-xFeAs throughout the Brillouin zone. Although angle resolved photoemission experiments and local density approximation calculations suggest poor Fermi surface nesting conditions for antiferromagnetic(AF) order, spin excitations in Li1-xFeAs occur at the AF wave vectors Q = (1, 0) at low energies, but move to wave vectors Q = (\pm 0.5, \pm0.5) near the zone boundary with a total magnetic bandwidth comparable to that of BaFe2As2. These results reveal that AF spin excitations still dominate the low-energy physics of these materials and suggest both itinerancy and strong electron-electron correlations are essential to understand the measured magnetic excitations. ",Antiferromagnetic spin excitations in single crystals of   nonsuperconducting Li1-xFeAs
"  Ghost-free bimetric gravity is a theory of two interacting spin-2 fields, one massless and one massive, in addition to the standard matter particles and fields, thereby generalizing Einstein's theory of general relativity. To parameterize the theory, we use five observables with specific physical interpretations. We present, for the first time, observational constraints on these parameters that: (i) apply to the full theory, (ii) are consistent with a working screening mechanism (i.e., restoring general relativity locally), (iii) exhibit a continuous, real-valued background cosmology (without the Higuchi ghost). For the cosmological constraints, we use data sets from the cosmic microwave background, baryon acoustic oscillations, and type Ia supernovae. Bimetric cosmology provides a good fit to data even for large values of the mixing angle between the massless and massive gravitons. Interestingly, the best-fit model is a self-accelerating solution where the accelerated expansion is due to the dynamical massive spin-2 field, without a cosmological constant. Due to the screening mechanism, the models are consistent with local tests of gravity such as solar system tests and gravitational lensing by galaxies. We also comment on the possibility of alleviating the Hubble tension with this theory. ",Observational constraints on bimetric gravity
"  In this paper we discuss the computation of Casimir energy on a quantum computer. The Casimir energy is an ideal quantity to calculate on a quantum computer as near term hybrid classical quantum algorithms exist to calculate the ground state energy and the Casimir energy gives physical implications for this quantity in a variety of settings. Depending on boundary conditions and whether the field is bosonic or fermionic we illustrate how the Casimir energy calculation can be set up on a quantum computer and calculated using the Variational Quantum Eigensolver algorithm with IBM QISKit. We compare the results based on a lattice regularization with a finite number of qubits with the continuum calculation for free boson fields, free fermion fields and chiral fermion fields. We use a regularization method introduced by Bergman and Thorn to compute the Casimir energy of a chiral fermion. We show how the accuracy of the calculation varies with the number of qubits. We show how the number of Pauli terms which are used to represent the Hamiltonian on a quantum computer scales with the number of qubits. We discuss the application of the Casimir calculations on quantum computers to cosmology, nanomaterials, string models, Kaluza Klein models and dark energy. ",Casimir energy with chiral fermions on a quantum computer
"  We present a comparison of Spitzer IRS data for 51 OH megamaser (OHM) hosts and 15 non-masing ULIRGs. 10-25% of OHMs show evidence for the presence of an AGN, significantly lower than the estimated AGN fraction from previous optical and radio studies. Non-masing ULIRGs have a higher AGN fraction (50-95%) than OHMs, although some galaxies in both samples show evidence of co-existing starbursts and AGN. Radiative transfer models of the dust environment reveal that non-masing galaxies tend to have clumpy dust geometries commonly associated with AGN, while OHMs have deeper absorption consistent with a smooth, thick dust shell. Statistical analyses show that the major differences between masing and non-masing ULIRGs in the mid-IR relate to the optical depth and dust temperature, which we measure using the 9.7 um silicate depth and 30-20 um spectral slope from the IRS data. Dust temperatures of 40-80 K derived from the IRS data are consistent with predictions of OH pumping models and with a minimum T_dust required for maser production. The best-fit dust opacities ({\tau}_V ~ 100 - 400), however, are nearly an order of magnitude larger than those predicted for OH inversion, and suggest that modifications to the model may be required. These diagnostics offer the first detailed test of an OHM pumping model based only on the properties of its host galaxy and provide important restrictions on the physical conditions relevant to OHM production. ",Mid-infrared properties of OH megamaser host galaxies. II: Analysis and   modeling of the maser environment
  It is argued heuristically -- using an ${\bf S}^3 \times {\bf S}^6$ minisuperspace model -- that there might be a fundamental quantum gravity effect stabilizing internal spaces with non-vanishing Ricci curvature. ,Comments on the multi-dimensional Wheeler-DeWitt equation
"  Measurements in quantum theory exhibit incompatibility, i.e., they can fail to be jointly measurable. An intuitive way to represent the (in)compatibility relations among a set of measurements is via a hypergraph representing their joint measurability structure: its vertices represent measurements and its hyperedges represent (all and only) subsets of compatible measurements. Projective measurements in quantum theory realize (all and only) joint measurability structures that are graphs. On the other hand, general measurements represented by positive operator-valued measures (POVMs) can realize arbitrary joint measurability structures. Here we explore the scope of joint measurability structures realizable with qubit POVMs. We develop a technique that we term marginal surgery to obtain nontrivial joint measurability structures starting from a set of compatible measurements. We show explicit examples of marginal surgery on a special set of qubit POVMs to construct joint measurability structures such as $N$-cycle and $N$-Specker scenarios for any integer $N\geq 3$. We also show the realizability of various joint measurability structures with $N\in\{4,5,6\}$ vertices. In particular, we show that all possible joint measurability structures with $N=4$ vertices are realizable. We conjecture that all joint measurability structures are realizable with qubit POVMs. This contrasts with the unbounded dimension required in R. Kunjwal et al., Phys. Rev. A 89, 052126 (2014). Our results also render this previous construction maximally efficient in terms of the required Hilbert space dimension. We also obtain a sufficient condition for the joint measurability of any set of binary qubit POVMs which powers many of our results and should be of independent interest. ",Joint measurability structures realizable with qubit measurements:   incompatibility via marginal surgery
"  We present models of photometric evolution of galaxies in which the effects of a dusty interstellar medium have been included with particular care. A chemical evolution code follows the star formation rate, the gas fraction and the metallicity, basic ingredients for the stellar population synthesis. The latter is performed with a grid of integrated spectra of simple stellar populations (SSP) of different ages and metallicities, in which the effects of dusty envelopes around asymptotic giant branch (AGB) stars are included. The residual fraction of gas in the galaxy is divided into two phases: the star forming molecular clouds and the cirrus. The relative amount is a model parameter. The molecular gas is sub--divided into clouds of given mass and radius: it is supposed that each SSP is born within the cloud and progressively escapes it. The emitted spectrum of the star forming molecular clouds is computed with a radiative transfer code. The cirrus emission is derived by describing the galaxy as an axially symmetric system, in which the local dust emissivity is consistently calculated as a function of the local field intensity due to the stellar component. Effects of very small grains, subject to temperature fluctuations, as well as PAHs are included. The model is compared and calibrated with available data of normal and starburst galaxies in the local universe, in particular new broad--band and spectroscopic ISO observations. It will be a powerful tool to investigate the star formation, the IMF, supernovae rate in nearby starbursts and normal galaxies, as well as to predict the evolution of luminosity functions of different types of galaxies at wavelengths covering four decades. ",Modelling the effects of dust on galactic SEDs from the UV to the   millimeter band
"  We evaluate the partition function of the free O(N) model on a two-parameter family of squashed three spheres. We also find new solutions of general relativity with negative cosmological constant and the same double squashed boundary geometry and analyse their thermodynamic properties. Remarkably, both systems exhibit a qualitatively similar behaviour over the entire configuration space of boundary geometries. Recent formulations of dS/CFT enable one to interpret the field theory partition function as a function of the two squashing parameters as the Hartle-Hawking wave function in a minisuperspace model of anisotropic deformations of de Sitter space. The resulting probability distribution is normalisable and globally peaked at the round three sphere, with a low amplitude of boundary geometries with negative scalar curvature. ",The NUTs and Bolts of Squashed Holography
"  The course of the Nile in northern Sudan follows a contorted path through bedrocks, creating the Great Bend. Few years ago, the satellite images showed a fertile strip of land with villages, where paleochannels of the river hosted many fields with cultivations and archaeological sites. Now, a huge part of this valley is under the waters of Merowe Dam reservoir. Comparing the images of the region before and after the dam gates were closed, we can see that the reservoir created itself through flooding the paleochannels. ",Merowe Dam and the inundation of paleochannels of the Nile
"  The upcoming generation of SZE surveys will shed fresh light onto the study of clusters. What will this new observational window reveal about cluster properties? What can we learn from combining X-ray, SZE, and optical observations? How do variations in the gas entropy profile, dark matter concentration, accretion pressure, and intracluster medium (ICM) mass fraction affect SZE observables? We investigate the signature of these important cluster parameters with an analytic model of the ICM. Given the current uncertainties in ICM physics, our approach is to span the range of plausible models motivated by observations and a small set of assumptions. We find a tight relation between the central Compton parameter and the X-ray luminosity outside the cluster core, suggesting that these observables carry the same information about the ICM. The total SZE luminosity is proportional to the thermal energy of the gas, and is a surprisingly robust indicator of cluster mass: $L_{SZ} \propto f_{ICM} M^{5/3}$. We show that a combination of $L_{SZ}$ and the half-luminosity radius $r_{SZ}$ provides a measure of the potential energy of the cluster gas, and thus we can deduce the total energy content of the ICM. We caution that any systematic variation of the ICM mass fraction will distort the expected $L_{SZ} - M$ calibration to be used to study the evolution of cluster number density, and propose a technique using kSZ to constrain $f_{ICM}(M,z)$. ",SZE Signals in Cluster Models
"  We study a variant of online convex optimization where the player is permitted to switch decisions at most $S$ times in expectation throughout $T$ rounds. Similar problems have been addressed in prior work for the discrete decision set setting, and more recently in the continuous setting but only with an adaptive adversary. In this work, we aim to fill the gap and present computationally efficient algorithms in the more prevalent oblivious setting, establishing a regret bound of $O(T/S)$ for general convex losses and $\widetilde O(T/S^2)$ for strongly convex losses. In addition, for stochastic i.i.d.~losses, we present a simple algorithm that performs $\log T$ switches with only a multiplicative $\log T$ factor overhead in its regret in both the general and strongly convex settings. Finally, we complement our algorithms with lower bounds that match our upper bounds in some of the cases we consider. ",Lazy OCO: Online Convex Optimization on a Switching Budget
"  We consider families of discrete time birth and death chains on trees, and show that in presence of a drift towards the root of the tree, the chains exhibit cut-off behavior along the drift and escape behavior in the opposite direction. ",Cut-off and Escape Behaviors for Birth and Death Chains on Trees
"  Motivated by the interpretation of the recent results on the TeV gamma radiation from the Galactic center, including the new 2004 HESS data, as a by-product of dark matter particles annihilations, we address the question of the largest possible neutralino masses and pair annihilation cross sections in supersymmetric models. Extending the parameter space of minimal models, such as the mSUGRA and the mAMSB scenarios, to general soft SUSY breaking Higgs masses gives access to the largest possible pair annihilation rates, corresponding to resonantly annihilating neutralinos with maximal gaugino-higgsino mixing. Adopting a model-independent approach, we provide analytical and numerical upper limits for the neutralino pair annihilation cross section. A possible loophole is given by the occurrence of non-perturbative electro-weak resonances, a case we also consider here. We then show that a thorough inclusion of QCD effects in gluino (co-)annihilations can, in extreme scenarios, make neutralinos with masses in the hundreds of TeV range, well beyond the s-wave unitarity bound, viable dark matter candidates. Finally, we outline the ranges of neutralino masses and cross sections for models thermally producing a WMAP relic abundance, thus providing reference values for ``best-case'' indirect SUSY dark matter detection rates. ",TeV gamma-rays and the largest masses and annihilation cross sections of   neutralino dark matter
  We study open equivariant projective embeddings of homogeneous spaces such that the complement of the open orbit does not contain divisors. Criterions of existence of such an embedding are considered and finiteness of isomorphism classes of embeddings for a given homogeneous space is proved. Any embedding with small boundary is realized as a GIT-quotient associated with a linearization of the trivial line bundle on the space of the canonical embedding. The generalized Cox's construction and the theory of bunched rings allow us to describe basic geometric properties of embeddings with small boundary in combinatorial terms. ,Projective embeddings of homogeneous spaces with small boundary
"  Azimuthal anisotropies of muons from charm and bottom hadron decays are measured in Pb+Pb collisions at $\sqrt{s_\mathrm{NN}}= 5.02$ TeV. The data were collected with the ATLAS detector at the Large Hadron Collider in 2015 and 2018 with integrated luminosities of $0.5~\mathrm{nb}^{-1}$ and $1.4~\mathrm{nb^{-1}}$, respectively. The kinematic selection for heavy-flavor muons requires transverse momentum $4 < p_\mathrm{T} < 30$ GeV and pseudorapidity $|\eta|<2.0$. The dominant sources of muons in this $p_\mathrm{T}$ range are semi-leptonic decays of charm and bottom hadrons. These heavy-flavor muons are separated from light-hadron decay muons and punch-through hadrons using the momentum imbalance between the measurements in the tracking detector and in the muon spectrometers. Azimuthal anisotropies, quantified by flow coefficients, are measured via the event-plane method for inclusive heavy-flavor muons as a function of the muon $p_\mathrm{T}$ and in intervals of Pb+Pb collision centrality. Heavy-flavor muons are separated into contributions from charm and bottom hadron decays using the muon transverse impact parameter with respect to the event primary vertex. Non-zero elliptic ($v_{2}$) and triangular ($v_{3}$) flow coefficients are extracted for charm and bottom muons, with the charm muon coefficients larger than those for bottom muons for all Pb+Pb collision centralities. The results indicate substantial modification to the charm and bottom quark angular distributions through interactions in the quark-gluon plasma produced in these Pb+Pb collisions, with smaller modifications for the bottom quarks as expected theoretically due to their larger mass. ",Measurement of azimuthal anisotropy of muons from charm and bottom   hadrons in Pb+Pb collisions at $\sqrt{s_\mathrm{NN}} = 5.02$ TeV with the   ATLAS detector
"  We analyse the origin of the gamma-ray flux from the Fermi Bubbles (FBs) in the framework of the hadronic model in which gamma-rays are produced by collisions of relativistic protons with the protons of background plasma in the Galactic halo. It is assumed in this model that the observed radio emission from the FBs is due to synchrotron radiation of secondary electrons produced by $pp$ collisions. However, if these electrons loose their energy by the synchrotron and inverse-Compton, the spectrum of secondary electrons is too soft, and an additional arbitrary component of primary electrons is necessary in order to reproduce the radio data. Thus, a mixture of the hadronic and leptonic models is required for the observed radio flux. It was shown that if the spectrum of primary electrons is $\propto E_e^{-2}$, the permitted range of the magnetic field strength is within 2 - 7 $\mu$G region. The fraction of gamma-rays produced by $pp$ collisions can reach about 80% of the total gamma-ray flux from the FBs. If magnetic field is <2 $\mu$G or >7 $\mu$G the model is unable to reproduce the data. Alternatively, the electrons in the FBs may lose their energy by adiabatic energy losses if there is a strong plasma outflow in the GC. Then, the pure hadronic model is able to reproduce characteristics of the radio and gamma-ray flux from the FBs. However, in this case the required magnetic field strength in the FBs and the power of CR sources are much higher than those followed from observations. ",Multi-wavelength Emission from the Fermi Bubble II. Secondary Electrons   and the Hadronic Model of the Bubble
"  Due in part to the increased pace of cultural and environmental change, as well as increased competition due to globalization, innovation is become one of the primary concerns of the 21st century. We present an academic course designed to develop cognitive abilities related to creativity within an engineering education context, based on a conceptual framework rooted in cognitive sciences. The course was held at \'Ecole Polytechnique de Montr\'eal (\'EPM), a world renowned engineering school and a pillar in Canada's engineering community. The course was offered twice in the 2014-2015 academic year and more than 30 students from the graduate and undergraduate programs participated. The course incorporated ten pedagogical strategies, including serious games, an observation book, individual and group projects, etc., that were expected to facilitate the development of cognitive abilities related to creativity such as encoding, and associative analytical thinking. The CEDA (Creative Engineering Design Assessment) test was used to measure the students' creativity at the beginning and at the end of the course. Field notes were taken after each of the 15 three-hour sessions to qualitatively document the educative intervention along the semester and students gave anonymous written feedback after completing the last session. Quantitative and qualitative results suggest that an increase in creativity is possible to obtain with a course designed to development cognitive abilities related to creativity. Also, students appreciated the course, found it relevant, and made important, meaningful learnings regarding the creative process, its cognitive mechanism and the approaches available to increase it. ",Creativity Training for Future Engineers: Preliminary Results from an   Educative Experience
"  We discuss how the higher-derivative Starobinsky model of inflation originates from N=1 supergravity. It is known that, in the old-minimal supergravity description written by employing a chiral compensator in the superconformal framework, the Starobinsky model is equivalent to a no-scale model with F-term potential. We show that the Starobinsky model can also be originated within the so-called new-minimal supergravity, where a linear compensator superfield is employed. In this formulation, the Starobinsky model is equivalent to standard supergravity coupled to a massive vector multiplet whose lowest scalar component plays the role of the inflaton and the vacuum energy is provided by a D-term potential. We also point out that higher-order corrections to the supergravity Lagrangian represent a threat to the Starobinsky model as they can destroy the flatness of the inflaton potential in its scalar field equivalent description. ",On the Starobinsky Model of Inflation from Supergravity
"  We investigate time-dependent spherically symmetric solutions of the four-dimensional Einstein-Maxwell-axion-dilaton system, with the dilaton coupling that occurs in low-energy effective heterotic string theory. A class of dilaton-electrovacuum radiating solutions with a trivial axion, previously found by G\""uven and Y\""or\""uk, is re-derived in a simpler manner and its causal structure is clarified. It is shown that such dynamical spacetimes featuring apparent horizons do not possess a regular light-like past null infinity or future null infinity, depending on whether they are radiating or accreting. These solutions are then extended in two ways. First we consider a Vaidya-like generalisation, which introduces a null dust source. Such spacetimes are used to test the status of cosmic censorship in the context of low-energy string theory. We prove that - within this family of solutions - regular black holes cannot evolve into naked singularities by accreting null dust, unless standard energy conditions are violated. Secondly, we employ S-duality to derive new time-dependent dyon solutions with a nontrivial axion turned on. Although they share the same causal structure as their Einstein-Maxwell-dilaton counterparts, these solutions possess both electric and magnetic charges. ",Dynamical black holes in low-energy string theory
"  We have used 3-D smoothed particle hydrodynamical simulations to study the basic properties of the outflow that is created by a protostellar jet in a dense molecular cloud. The dynamics of the jet/cloud interaction is strongly affected by the cooling in the shocked gas behind the bow shock at the head of the jet. We show that this cooling is very rapid, with the cooling distance of the gas much less than the jet radius. Thus, although ambient gas is initially driven away from the jet axis by the high thermal pressure odf the post-shock gas, rapid cooling reduces the pressure and the outflow subsequently evolves in a momentum-conserving snowplow fashion. The velocity of the ambient gas is high in the vicinity of the jet head, but decreases rapidly as more material is swept up. Thus, this type of outflow produces extremely high velocity clumps of post shock gas which resemble the features seen in outflows. We have investigated the transfer of momentum from the jet to the ambient medium as a function of the jet parameters. We show that a low Mach number (<6) jet slows down rapidly because it entrains ambient material along its sides. On the other hand, the beam of a high Mach number jet is separated from the ambient gas by a low density cocoon of post-shock gas, and this jet transfers momentum to the ambient medium principally at the bow-shock. In high Mach number jets, as those from young stellar objects, the dominant interaction is therefore at the bow shock at the head of the jet. ",Momentum Transfer by Astrophysical Jets
"  We compute the full one-loop EW contributions of O(\alpha_S alpha_EM^3) entering the electron-positron into two b-quarks and one gluon cross section at the Z peak and LC energies. We include both factorisable and non-factorisable virtual corrections, photon bremsstrahlung but not the real emission of W^\pm and Z bosons. Their importance for the measurement of alpha_S from jet rates and shape variables is explained qualitatively and illustrated quantitatively. Their impact on the forward-backward asymmetry is also analysed. ",One-loop Electro-Weak Corrections to Three-jet Observables of b-quarks   in e+e- Annihilations
"  A Kondo-lattice theory is applied to the crossover between local-moment magnetism for almost half fillings of electrons and itinerant-electron magnetism away from the half filling. In clean systems with no disorder, the bandwidth W^* of quasiparticles is non-zero and of the order of |J| at T=0K even in the limit of the half filling, with J the superexchange interaction constant between nearest neighbors. The so called Gutzwiller's term also contributes to W^* away from the half filling; it is approximately proportional to doping concentrations measured from the half filling. Magnetism is enhanced by disorder because the renormalization of W^* by J is reduced by disorder. The asymmetry of disorder between electron-doped and hole-doped cuprate oxide superconductors must be, at least partly, responsible for that of antiferromagnetic phases between them. The so called Kumagai phase is characterized as an SDW state in a disordered system rather than a spin glass. The Neel temperature T_N about 300K of non-doped cuprate oxides can be explained by the reduction of T_N by critical thermal antiferromagnetic fluctuations in quasi-two dimensions. ",Crossover between local-moment magnetism and itinerant-electron   magnetism in the t-J model
"  We study the single-spin asymmetry, $A_N(t)$, arising from Coulomb-nuclear interference (CNI) at small 4-momentum transfer squared, $-t=q^2$, aiming at explanation of the recent data from the PHENIX experiment at RHIC on polarized proton-nucleus scattering, exposing a nontrivial $t$-dependence of $A_N$. We found that the failure of previous theoretical attempts to explain these data, was due to lack of absorptive corrections in the Coulomb amplitude of $pA$ elastic scattering. Our prominent observation is that the main contribution to $A_N(t)$ comes from interference of the amplitudes of ultra-peripheral and central collisions. ",Spin Dependence of Small-Angle Proton-Nucleus Scattering
  We investigate the elastic scattering of $^9$Be on $^{208}$Pb at beam energies above (50 MeV) and below (40 MeV) the Coulomb barrier. The reaction is described within a four-body framework using the Continuum-Discretized Coupled-Channels (CDCC) method. The $^9$Be projectile states are generated using the analytical Transformed Harmonic Oscillator (THO) basis in hyperspherical coordinates. Our calculations confirm the importance of continuum effects at low energies. ,Reactions induced by $^9$Be in a four-body continuum-discretized   coupled-channels framework
"  We study properties of neutrino transfer in a remnant of neutron star merger, consisting of a massive neutron star and a surrounding torus. We perform numerical simulations of the neutrino transfer by solving the Boltzmann equation with momentum-space angles and energies of neutrinos for snapshots of the merger remnant having elongated shapes. The evaluation of the neutrino distributions in the multi-dimensions enable us to provide the detailed information of angle and energy spectra and neutrino reaction rates. We demonstrate features of asymmetric neutrino fluxes from the deformed remnant and investigate the neutrino emission region by determining the neutrinosphere for each energy. We examine the emission and absorption of neutrinos to identify important ingredients of heating rates through neutrino irradiation. We show that the contributions of $\mu$- and $\tau$-types neutrinos are important for the heating in the region above the massive neutron star. We also examine the angle moments and the Eddington tensor calculated directly by the neutrino distribution functions and compare them with those obtained by a moment closure approach, which is often used in the study of neutrino-radiation hydrodynamics. We show that the components of the Eddington tensor have non-monotonic behaviors and the approximation of the closure relation may become inaccurate for high energy neutrinos, whose fluxes are highly aspherical due to the extended merger remnant. ",Properties of neutrino transfer in a deformed remnant of neutron star   merger
"  The triple alpha reaction is a key to $^{12}$C production and is expected to occur in weakly-coupled, thermal plasmas as encountered in normal stars. We investigate how Coulomb screening affects the structure of a system of three alpha particles in such a plasma environment by precise three-body calculations within the Debye-H\""uckel approximation. A three-alpha model that has the Coulomb interaction modified in the Yukawa form is employed. Precise three-body wave functions are obtained by a superposition of correlated Gaussian bases with the aid of the stochastic variational method. The energy shifts of the Hoyle state due to the Coulomb screening are obtained as a function of the Debye screening length. The results, which automatically incorporate the finite size effect of the Hoyle state, are consistent with the conventional result based on the Coulomb correction to the chemical potentials of ions that are regarded as point charges in a weakly-coupled, thermal plasma. We have given a theoretical basis to the conventional point-charge approach to the Coulomb screening problem relevant for nuclear reactions in normal stars by providing the first evaluation of the Coulomb corrections to the $Q$ value of the triple alpha process that produces a finite size Hoyle state. ",Coulomb screening correction to the $Q$ value of the triple alpha   process in thermal plasmas
"  Biological systems are modular, and this modularity affects the evolution of biological systems over time and in different environments. We here develop a theory for the dynamics of evolution in a rugged, modular fitness landscape. We show analytically how horizontal gene transfer couples to the modularity in the system and leads to more rapid rates of evolution at short times. The model, in general, analytically demonstrates a selective pressure for the prevalence of modularity in biology. We use this model to show how the evolution of the influenza virus is affected by the modularity of the proteins that are recognized by the human immune system. Approximately 25\% of the observed rate of fitness increase of the virus could be ascribed to a modular viral landscape. ",Modularity Enhances the Rate of Evolution in a Rugged Fitness Landscape
"  In a space of 4-dimensions, I will examine constrained variational problems in which the Lagrangian, and constraint scalar density, are concomitants of a (pseudo-Riemannian) metric tensor and its first two derivatives. The Lagrange multiplier for these constrained extremal problems will be a scalar field. For suitable choices of the Lagrangian, and constraint, we can obtain Euler-Lagrange equations which are second order in the scalar field and third order in the metric tensor. The effect of disformal transformations on the constraint Lagrangians, and their generalizations, is examined. This will yield other second order scalar-tensor Lagrangians which yield field equations which are at most of third order. No attempt is made to construct all possible third order scalar-tensor Euler-Lagrange equations in a 4-space, although nine classes of such field equations are presented. Two of these classes admit subclasses which yield conformally invariant field equations. A few remarks on scalar-tensor-connection theories are also presented. ",Lagrange Multipliers and Third Order Scalar-Tensor Field Theories
"  We present an updated study of transverse single-spin asymmetries for the inclusive large-$P_T$ processes $\ell \, p^\uparrow \to h\, X$ and $\ell\, p^\uparrow \to {\rm jet}\,X$, within a transverse momentum-dependent approach, including the contribution of quasireal (Weizs\""acker-Williams) photons. In the spirit of a unified transverse momentum-dependent scheme, predictions are obtained adopting the Sivers and transversity distributions and the Collins fragmentation functions as extracted from fits to the azimuthal asymmetries measured in semi-inclusive deep inelastic scattering and $e^+e^-$ annihilation processes. The description of the available data is extremely good, showing a clear general improvement with respect to the previous leading-order analysis. Predictions for unpolarized cross sections and single-spin asymmetries for ongoing and future experiments are also given. ","Transverse single-spin asymmetries in $\ell \,p^\uparrow \to h \,X$   within a TMD approach: Role of quasireal photon exchange"
"  The character theory of finite groups has numerous basic questions that are often already quite involved: enumerating of irreducible characters, their character formulas, point-wise product decompositions, and restriction/induction between groups. A supercharacter theory is a framework for simplifying the character theory of a finite group, while ideally not losing all important information. This paper studies one such theory that straddles the gap between retaining valuable group information while reducing the above fundamental questions to more combinatorial lattice constructions. ",The structure of normal lattice supercharacter theories
"  We present simulations of self-avoiding random walks on 2-d lattices with the topology of an infinitely long cylinder, in the limit where the cylinder circumference L is much smaller than the Flory radius. We study in particular the L-dependence of the size h parallel to the cylinder axis, the connectivity constant mu, the variance of the winding number around the cylinder, and the density of parallel contacts. While mu(L) and <W^2(L,h)> scale as as expected (in particular, <W^2(L,h)> \sim h/L), the number of parallel contacts decays as h/L^1.92, in striking contrast to recent predictions. These findings strongly speak against recent speculations that the critical exponent gamma of SAW's might be nonuniversal. Finally, we find that the amplitude for <W^2> does not agree with naive expectations from conformal invariance. ",2-d Self-Avoiding Walks on a Cylinder
"  Current data broadly support trends of galaxy surface brightness profile amplitude and shape with total stellar mass predicted by state-of-the-art Lambda-CDM cosmological simulations, although recent results show signs of interesting discrepancies, particularly for galaxies less massive than the Milky Way. Here I discuss how perhaps the largest contribution to such discrepancies can be inferred almost directly from how well a given model agrees with the observed present-day galaxy stellar mass function. ",Modelling the outskirts of galaxies in a cosmological context
"  Edge caching and computing have been regarded as an efficient approach to tackle the wireless spectrum crunch problem. In this paper, we design a general coded caching with device computing strategy for content computation, e.g., virtual reality (VR) rendering, to minimize the average transmission bandwidth with the caching capacity and the energy constraints of each mobile device, and the maximum tolerable delay constraint of each task. The key enabler is that because both coded data and stored data can be the data before or after computing, the proposed scheme has numerous edge computing and caching paths corresponding to different bandwidth requirement. We thus formulate a joint coded caching and computing optimization problem to decide whether the mobile devices cache the input data or the output data, which tasks to be coded cached and which tasks to compute locally. The optimization problem is shown to be 0-1 nonconvex nonsmooth programming and can be decomposed into the computation programming and the coded caching programming. We prove the convergence of the computation programming problem by utilizing the alternating direction method of multipliers (ADMM), and a stationary point can be obtained. For the coded cache programming, we design a low complexity algorithm to obtain an acceptable solution. Numerical results demonstrate that the proposed scheme provides a significant bandwidth saving by taking full advantage of the caching and computing capability of mobile devices. ","Mobile Communications, Computing and Caching Resources Optimization for   Coded Caching with Device Computing"
"  Neural ODEs and i-ResNet are recently proposed methods for enforcing invertibility of residual neural models. Having a generic technique for constructing invertible models can open new avenues for advances in learning systems, but so far the question of whether Neural ODEs and i-ResNets can model any continuous invertible function remained unresolved. Here, we show that both of these models are limited in their approximation capabilities. We then prove that any homeomorphism on a $p$-dimensional Euclidean space can be approximated by a Neural ODE operating on a $2p$-dimensional Euclidean space, and a similar result for i-ResNets. We conclude by showing that capping a Neural ODE or an i-ResNet with a single linear layer is sufficient to turn the model into a universal approximator for non-invertible continuous functions. ",Approximation Capabilities of Neural ODEs and Invertible Residual   Networks
"  Data-driven research in mobility has prospered in recent years, providing solutions to real-world challenges including forecasting epidemics and planning transportation. These advancements were facilitated by computational tools enabling the analysis of large-scale data-sets of digital traces. One of the challenges when pre-processing spatial trajectories is the so-called stop location detection, that entails the reduction of raw time series to sequences of destinations where an individual was stationary. The most widely adopted solution to this problem was proposed by Hariharan and Toyama (2004) and involves filtering out non-stationary measurements, then applying agglomerative clustering on the stationary points. This state-of-the-art solution, however, suffers of two limitations: (i) frequently visited places located very close (such as adjacent buildings) are likely to be merged into a unique location, due to inherent measurement noise, (ii) traces for multiple users can not be analysed simultaneously, thus the definition of destination is not shared across users. In this paper, we describe the Infostop algorithm that overcomes the limitations of the state-of-the-art solution by leveraging the flow-based network community detection algorithm Infomap. We test Infostop for a population of $\sim 1000$ individuals with highly overlapping mobility. We show that the size of locations detected by Infostop saturates for increasing number of users and that time complexity grows slower than for previous solutions. We demonstrate that Infostop can be used to easily infer social meetings. Finally, we provide an open-source implementation of Infostop, written in Python and C++, that has a simple API and can be used both for labeling time-ordered coordinate sequences (GPS or otherwise), and unordered sets of spatial points. ",Infostop: Scalable stop-location detection in multi-user mobility data
"  We study probability density functions (pdfs) of the circulation of velocity and magnetic fields in magnetohydrodynamics, computed for a circular contour within inertial range scales. The analysis is based on the instanton method as adapted to the Martin-Siggia-Rose field theory formalism. While in the viscous limit the expected gaussian behaviour of fluctuations is indeed verified, the case of vanishing viscosity is not suitable of a direct saddle-point treatment. To study the latter limit, we take into account fluctuations around quasi-static background fields, which allows us to derive a sum rule relating pdfs of the circulation observables and the rate of the strain tensor. A simple inspection of the sum rule definition leads straightforwardly to the algebraic decay $\rho(\Gamma) \sim 1/ \Gamma^2$ at the circulation pdf tails. ",Circulation-Strain Sum Rule in Stochastic Magnetohydrodynamics
"  We develop novel stabilized cut discontinuous Galerkin (CutDG) methods for advection-reaction problems. The domain of interest is embedded into a structured, unfitted background mesh in $\mathbb{R}^d$ where the domain boundary can cut through the mesh in an arbitrary fashion. To cope with robustness problems caused by small cut elements, we introduce ghost penalties in the vicinity of the embedded boundary to stabilize certain (semi)-norms associated with the advection and reaction operator. A few abstract assumptions on the ghost penalties are identified enabling us to derive geometrically robust and optimal a priori error and condition number estimates for the stationary advection-reaction problem which hold irrespective of the particular cut configuration. Possible realizations of suitable ghost penalties are discussed. The theoretical results are corroborated by a number of computational studies for various approximation orders and for two and three-dimensional test problems. ",Stabilized CutDG methods for advection-reaction problems
"  As datasets grow it becomes infeasible to process them completely with a desired model. For giant datasets, we frame the order in which computation is performed as a decision problem. The order is designed so that partial computations are of value and early stopping yields useful results. Our approach comprises two related tools: a decision framework to choose the order to perform computations, and an emulation framework to enable estimation of the unevaluated computations. The approach is applied to the problem of computing similarity matrices, for which the cost of computation grows quadratically with the number of objects. Reasoning about similarities before they are observed introduces difficulties as there is no natural space and hence comparisons are difficult. We solve this by introducing a computationally convenient form of multidimensional scaling we call `data directional scaling'. High quality estimation is possible with massively reduced computation from the naive approach, and can be scaled to very large matrices. The approach is applied to the practical problem of assessing genetic similarity in population genetics. The use of statistical reasoning in decision making for large scale problems promises to be an important tool in applying statistical methodology to Big Data. ",A general decision framework for structuring computation using Data   Directional Scaling to process massive similarity matrices
"  Multivariate analysis of fMRI data has benefited substantially from advances in machine learning. Most recently, a range of probabilistic latent variable models applied to fMRI data have been successful in a variety of tasks, including identifying similarity patterns in neural data (Representational Similarity Analysis and its empirical Bayes variant, RSA and BRSA; Intersubject Functional Connectivity, ISFC), combining multi-subject datasets (Shared Response Mapping; SRM), and mapping between brain and behavior (Joint Modeling). Although these methods share some underpinnings, they have been developed as distinct methods, with distinct algorithms and software tools. We show how the matrix-variate normal (MN) formalism can unify some of these methods into a single framework. In doing so, we gain the ability to reuse noise modeling assumptions, algorithms, and code across models. Our primary theoretical contribution shows how some of these methods can be written as instantiations of the same model, allowing us to generalize them to flexibly modeling structured noise covariances. Our formalism permits novel model variants and improved estimation strategies: in contrast to SRM, the number of parameters for MN-SRM does not scale with the number of voxels or subjects; in contrast to BRSA, the number of parameters for MN-RSA scales additively rather than multiplicatively in the number of voxels. We empirically demonstrate advantages of two new methods derived in the formalism: for MN-RSA, we show up to 10x improvement in runtime, up to 6x improvement in RMSE, and more conservative behavior under the null. For MN-SRM, our method grants a modest improvement to out-of-sample reconstruction while relaxing an orthonormality constraint of SRM. We also provide a software prototyping tool for MN models that can flexibly reuse noise covariance assumptions and algorithms across models. ",Matrix-normal models for fMRI analysis
"  We investigate the subgroup structure of the hyperoctahedral group in six dimensions. In particular, we study the subgroups isomorphic to the icosahedral group. We classify the orthogonal crystallographic representations of the icosahedral group and analyse their intersections and subgroups, using results from graph theory and their spectra. ",On the subgroup structure of the hyperoctahedral group in six dimensions
"  The Stark-induced shift and asymmetry, the so-called pressure shift (PS) of $H_\alpha$ and $H_\beta$ Balmer lines in spectra of DA white dwarfs (WDs), as masking effects in measurements of the gravitational red shift in WDs, have been examined in detail. The results are compared with our earlier ones from before a quarter of a century (Grabowski et al. 1987, hereafter ApJ'87; Madej and Grabowski 1990). In these earlier papers, as a dominant constituent of the Balmer-line-profiles, the standard, symmetrical Stark line profiles, shifted as the whole by PS-effect, were applied to all spectrally active layers of the WD atmosphere. At present, in each of the WD layers, the Stark-line-profiles (especially of $H_\beta$) are immanently asymmetrical and shifted due to the effects of strong inhomogeneity of the perturbing fields in plasma. To calculate the Stark line-profiles in successive layers of the WD atmosphere we used the modified Full Computer Simulation Method (mFCSM), able to take adequately into account the complexity of local elementary quantum processes in plasma. In the case of the $H_\alpha$ line, the present value of Stark-induced shift of the synthetic $H_\alpha$ line-profile is about twice smaller than the previous one (ApJ'87) and it is negligible in comparison with the gravitational red shift. In the case of the $H_\beta$ line, the present value of Stark-induced shift of the synthetic $H_\beta$ line-profile is about twice larger than the previous one. The source of this extra shift is the asymmetry of $H_\beta$ peaks. ",Pressure Shift and Gravitational Red Shift of Balmer Lines in White   Dwarfs. Rediscussion
"  Motivated by the problem of weak collective pinning of vortex lattices in high-temperature superconductors, we study the model system of a four-dimensional elastic manifold with N transverse degrees of freedom (4+N-model) in a quenched disorder environment. We assume the disorder to be weak and short-range correlated, and neglect thermal effects. Using a real-space functional renormalization group (FRG) approach, we derive a RG equation for the pinning-energy correlator up to two-loop correction. The solution of this equation allows us to calculate the size R_c of collectively pinned elastic domains as well as the critical force F_c, i.e., the smallest external force needed to drive these domains. We find R_c prop. to delta_p^alpha_2 exp(alpha_1/delta_p) and F_c prop. to delta_p^(-2 alpha_2) exp(-2 alpha_1/delta_p), where delta_p <<1 parametrizes the disorder strength, alpha_1=(2/pi)^(N/2) 8 pi^2/(N+8), and alpha_2=2(5N+22)/(N+8)^2. In contrast to lowest-order perturbation calculations which we briefly review, we thus arrive at determining both alpha_1 (one-loop) and alpha_2 (two-loop). ",(4+N)-Dimensional Elastic Manifolds in Random Media: a   Renormalization-Group Analysis
"  We analyze large sets of energy-release data created by stress-induced brittle fracture in a pure sapphire crystal at close to zero temperature where stochastic fluctuations are minimal. The waiting-time distribution follows that observed for fracture in rock and for earthquakes. Despite strong time correlations of the events and the presence of large-event precursors, simple prediction algorithms only succeed in a very weak probabilistic sense. We also discuss prospects for further cryogenic experiments reaching close to single-bond sensitivity and able to investigate the existence of a transition-stress regime. ",Brittle fracture down to femto-Joules - and below
"  Network coding-based link failure recovery techniques provide near-hitless recovery and offer high capacity efficiency. Diversity coding is the first technique to incorporate coding in this field and is easy to implement over small arbitrary networks. However, its capacity efficiency is restricted by its systematic coding and high design complexity even though its design complexity is lower than the other coding-based recovery techniques. Alternative techniques mitigate some of these limitations, but they are difficult to implement over arbitrary networks. In this paper, we propose a simple column generation-based design algorithm and a novel advanced diversity coding technique to achieve near-hitless recovery over arbitrary networks. The design framework consists of two parts: a main problem and subproblem. Main problem is realized with Linear Programming (LP) and Integer Linear Programming (ILP), whereas the subproblem can be realized with different methods. The simulation results suggest that both the novel coding structure and the novel design algorithm lead to higher capacity efficiency for near-hitless recovery. The novel design algorithm simplifies the capacity placement problem which enables implementing diversity coding-based techniques on very large arbitrary networks. ",Link Failure Recovery over Very Large Arbitrary Networks: The Case of   Coding
"  Image demosaicking and denoising are the two key steps for color image production pipeline. The classical processing sequence consists of applying denoising first, and then demosaicking. However, this sequence leads to oversmoothing and unpleasant checkerboard effect. Moreover, it is very difficult to change this order, because once the image is demosaicked, the statistical properties of the noise will be changed dramatically. This is extremely challenging for traditional denoising models that strongly rely on statistical assumptions. In this paper, we attempt to tackle this prickly problem. Indeed, here we invert the traditional CFA processing pipeline by first demosaicking and then denoising. In the first stage, we design a demosaicking algorithm that combines traditional methods and a convolutional neural network (CNN) to reconstruct a full color image ignoring the noise. To improve the performance in image demosaicking, we modify an Inception architecture for fusing R, G and B three channels information. This stage retains all known information that is the key point to obtain pleasurable final results. After demosaicking, we get a noisy full-color image and use another CNN to learn the demosaicking residual noise (including artifacts) of it, that allows to obtain a restored full color image. Our proposed algorithm completely avoids the checkerboard effect and retains more image detail. Furthermore, it can process very high-level noise while the performances of other CNN based methods for noise higher than 20 are rather limited. Experimental results show clearly that our method outperforms state-of-the-art methods both quantitatively as well as in terms of visual quality. ",Residual Learning for Effective joint Demosaicing-Denoising
"  We study the behavior of the random walk on the infinite cluster of independent long range percolation in dimensions $d=1,2$, where $x$ and $y$ a re connected with probability $\sim\beta/\|x-y\|^{-s}$. We show that when $d<s<2d$ the walk is transient, and when $s\geq 2d$, the walk is recurrent. The proof of transience is based on a renormalization argument. As a corollary of this renormalization argument, we get that for every dimension $d$, if $d<s<2d$, then critical percolation has no infinite clusters. This result is extended to the free random cluster model. A second corollary is that when $d\geq 2$ and $d<s<2d$ we can erase all long enough bonds and still have an infinite cluster. The proof of recurrence in two dimensions is based on general stability results for recurrence in random electrical networks. In particular, we show that i.i.d. conductances on a recurrent graph of bounded degree yield a recurrent electrical network. ","Transience, Recurrence and Critical Behavior for Long-Range Percolation"
"  Microbes can affect processes from food production to human health. Such microbes are not isolated, but rather interact with each other and establish connections with their living environments. Understanding these interactions is essential to an understanding of the organization and complex interplay of microbial communities, as well as the structure and dynamics of various ecosystems. A common and essential approach toward this objective involves the inference of microbiome interaction networks. Although network inference methods in other fields have been studied before, applying these methods to estimate microbiome associations based on compositional data will not yield valid results. On the one hand, features of microbiome data such as compositionality, sparsity and high-dimensionality challenge the data normalization and the design of computational methods. On the other hand, several issues like microbial community heterogeneity, external environmental interference and biological concerns also make it more difficult to deal with the network inference. In this paper, we provide a comprehensive review of emerging microbiome interaction network inference methods. According to various assumptions and research targets, estimated networks are divided into four main categories: correlation networks, conditional correlation networks, mixture networks and differential networks. Their scope of applications, advantages and limitations are presented in this review. Since real microbial interactions can be complex and dynamic, no unifying method has captured all the aspects of interest to date. In addition, we discuss the challenges now confronting current microbial associations study and future prospects. Finally, we highlight that the research in microbial network inference requires the joint promotion of statistical computation methods and experimental techniques. ",Statistical computation methods for microbiome compositional data   network inference
"  Quantum Hall (QH) states are predicted to display an intriguing non-dissipative stress response to a shear deformation rate, a phenomenon variously known as asymmetric or Hall viscosity, or Lorentz shear response. Just as the QH effect results from the coupling of Chern-Simons fields of the effective theory to the electromagnetic field, so also Hall viscosity is found to arise from coupling of these fields to the 'metric' of the quadratic kinetic energy. In this paper I derive new physical insights for Hall viscosity by using an extended semiclassical approach to compute the conductivity of a single Landau level in a nonuniform electric field. I demonstrate that the inhomogeneity of an applied electric field is a viable experimentally tunable parameter for altering the metric, and hence creating strain in the QH state. Using these results, I argue that Hall viscosity arises from the shearing of local cyclotron orbits by the applied nonuniform electric fields. ",Semiclassical theory of viscosity in quantum Hall states
"  In this paper, I review the experimental situation for both glueballs and hybrid mesons. Theoretical expectations are discussed, and a survey of what is known about hybrid mesons and glueballs is undertaken. Good experimental evidence exists for both states with exotic quantum numbers and a glueball which is mixed with the nearby mesons, but a full understanding of these still requires additional information. ",An Experimental Overview of Gluonic Mesons
"  We study the origin of the soft X-ray excess seen in the 'simple' Narrow Line Seyfert 1 galaxy PG1244+026 using all available spectral-timing information. This object shows the standard switch between soft leading the hard band on long timescales, to the opposite behaviour on short timescales. This is interpreted as a combination of intrinsic fluctuations propagating down through the accretion flow giving the soft lead, together with reflection of the hard X-rays giving the soft lag. We build a full model of the spectral and time variability including both propagation and reflection, and compare our model with the observed power spectra, coherence, covariance, lag-frequency and lag-energy spectra. We compare models based on a separate soft excess component with those based on reflection dominated soft emission.   Reflection dominated spectra have difficulty reproducing the soft lead at low frequency since reflection will always lag. They also suffer from high coherence and nearly identical hard and soft band power spectra in disagreement with the observations. This is a direct result of the power law and reflection components both contributing to the hard and soft energy bands, and the small radii over which the relativistically smeared reflection is produced transmitting too much high frequency power into the soft band.   Conversely, we find the separate soft excess models (where the inner disc radius is $>6R_g$) have difficulty reproducing the soft lag at high frequency, as reflected flux does not contribute enough signal to overwhelm the soft lead. However, reflection should also be accompanied by reprocessing and this should add to the soft excess at low energies. This model can quantitatively reproduce the switch from soft lead to soft lag seen in the data and reproduces well the observed power spectra and other timing features which reflection dominated models cannot. ",A Physical Model for the X-ray Time Lags of Narrow Line Seyfert Type 1   Active Galactic Nuclei
"  Within five-dimensional compactified theories we discuss generalized periodicity and orbifold boundary conditions that allow for mixing between particles and anti-particles after a shift by the size of extra dimensions or after the orbifold reflection. A systematic strategy for constructing 4-dimensional models is presented, in particular we find a general form of the periodicity and orbifold conditions that are allowed by consistency requirements. We formulate general conditions for a presence of massless Kaluza-Klein modes and discuss remaining gauge symmetry of the zero-mode sector. It is shown that if the orbifold twist operation transforms particles into anti-particles then the zero-mode fermions are 4-dimensional Majorana fermions. The possibility of explicit and spontaneous CP violation is discussed. General considerations are illustrated by many Abelian and non-Abelian examples. ",Majorana Fermions and CP Violation from 5-dimensional Theories; a   Systematic Approach
"  We investigate the merging rates of compact binaries in galaxies, and the related detection rate of gravitational wave (GW) events with AdvLIGO/Virgo and with the Einstein Telescope. To this purpose, we rely on three basic ingredients: (i) the redshift-dependent galaxy statistics provided by the latest determination of the star formation rate functions from UV+far-IR/(sub)millimeter/radio data; (ii) star formation and chemical enrichment histories for individual galaxies, modeled on the basis of observations; (iii) compact remnant mass distribution and prescriptions for merging of compact binaries from stellar evolution simulations. We present results for the intrinsic birthrate of compact remnants, the merging rates of compact binaries, GW detection rates and GW counts, attempting to differentiate the outcomes among BH-BH, NS-NS, and BH-NS mergers, and to estimate their occurrence in disk and spheroidal host galaxies. We compare our approach with the one based on cosmic SFR density and cosmic metallicity, exploited by many literature studies; the merging rates from the two approaches are in agreement within the overall astrophysical uncertainties. We also investigate the effects of galaxy-scale strong gravitational lensing of GW in enhancing the rate of detectable events toward high-redshift. Finally, we discuss the contribution of undetected GW emission from compact binary mergers to the stochastic background. ",Merging Rates of Compact Binaries in Galaxies: Perspectives for   Gravitational Wave Detections
"  We report HST/NICMOS coronagraphic images of the HD 15115 circumstellar disk at 1.1\micron. We find a similar morphology to that seen in the visible and at H band--an edge-on disk that is asymmetric in surface brightness. Several aspects of the 1.1\micron data are different, highlighting the need for multi-wavelength images of each circumstellar disk. We find a flattening to the western surface brightness profile at 1.1\micron interior to 2\arcsec (90 AU) and a warp in the western half of the disk. We measure the surface brightness profiles of the two disk lobes and create a measure of the dust scattering efficiency between 0.55-1.65\micron at 1\arcsec, 2\arcsec, and 3\arcsec. At 2\arcsec the western lobe has a neutral spectrum up to 1.1\micron and a strong absorption or blue spectrum $>$1.1\micron, while a blue trend is seen in the eastern lobe. At 1\arcsec the disk has a red F110W-H color in both lobes. ",Color Gradients Detected in the HD 15115 Circumstellar Disk
"  The ability to rank candidate architectures is the key to the performance of neural architecture search~(NAS). One-shot NAS is proposed to reduce the expense but shows inferior performance against conventional NAS and is not adequately stable. We investigate into this and find that the ranking correlation between architectures under one-shot training and the ones under stand-alone full training is poor, which misleads the algorithm to discover better architectures. Further, we show that the training of architectures of different sizes under the current one-shot method is imbalanced, which causes the evaluated performances of the architectures to be less predictable of their ground-truth performances and affects the ranking correlation heavily. Consequently, we propose Balanced NAO where we introduce balanced training of the supernet during the search procedure to encourage more updates for large architectures than small architectures by sampling architectures in proportion to their model sizes. Comprehensive experiments verify that our proposed method is effective and robust which leads to a more stable search. The final discovered architecture shows significant improvements against baselines with a test error rate of 2.60\% on CIFAR-10 and top-1 accuracy of 74.4% on ImageNet under the mobile setting. Code and model checkpoints will be publicly available. The code is available at github.com/renqianluo/NAO_pytorch. ",Balanced One-shot Neural Architecture Optimization
"  The Young double-slit interference pattern produced by quantum objects, like photons, that move through a double-slit is regarded, by the conventional Copenhagen interpretation of Quantum Mechanics, as the evidence of the wave-like behaviour potentially contained in the wave function. On the contrary, a more realistic view of this phenomenon considers the quantum object a particle accompanied by a pilot wave which would be the cause of the interference fringes. This paper proposes a feasible experiment, based on an easy variation of the nowadays common double-slit experimental set-ups, aimed at detecting the effects of the pilot wave once 'detached' from the particles that it steers. Besides, a further realistic idea, based on the geometrical violation of Local Lorentz Invariance (LLI), is put forward as to the intrinsic nature of the photon. This new idea along with the possibly positive results of the experiment would allow us to shed new light on the real nature of quantum objects in term of the geometrical violation of LLI. ",Clues to detect the Pilot Wave in a photon double-slit interference   experiment
"  This note presents a novel approach to maintain three-dimensional multi-tethered satellite formation in space. For a formation consisting of a main body connected by tethers with several deputy satellites (the so-called ""hub-and-spoke"" configuration) we demonstrate that under proper choice of the system's parameters the deputy satellites can move along Lissajous curves in the plane normal to the local vertical with all tethers stretched, the total force due to the tension forces acting on the main satellite is balanced in a way allowing it to be in relative equilibrium strictly below or strictly above the system's center of mass. We analyze relations between the system's essential parameters and obtain conditions under which the proposed motion does take place. We also study analytically the motion stability for different configurations and whether the deputy satellites can collide or the tethers can entangle. Our theoretical findings are corroborated and validated by numerical experiments. ",Three-Dimensional Multi-Tethered Satellite Formation with the Elements   Moving Along Lissajous Curves
"  By dimensional reduction of a massive supersymmetric B$\wedge $F theory, a manifestly N=1 supersymmetric completion of a massive antisymmetric tensor gauge theory is constructed in (2+1) dimensions. In the N=1-D=3 superspace, a new topological term is used to give mass for the Kalb-Ramond field. We have introduced a massive gauge invariant model using the Stuckelberg formalism and an abelian topologically massive theory for the Kalb-Ramond superfield. An equivalence of both massive models is suggested. Further, a component field analysis is performed, showing a second supersymmetry in the model. ",A superspace gauge-invariant formulation of a massive tridimensional   2-form field
"  We present the first detection of molecular emission from a galaxy selected to be near a projected background quasar using the Atacama Large Millimeter/submillimeter Array (ALMA). The ALMA detection of CO(1$-$0) emission from the $z=0.101$ galaxy toward quasar PKS 0439-433 is coincident with its stellar disk and yields a molecular gas mass of $M_{\rm mol} \approx 4.2 \times 10^9 M_\odot$ (for a Galactic CO-to-H$_2$ conversion factor), larger than the upper limit on its atomic gas mass. We resolve the CO velocity field, obtaining a rotational velocity of $134 \pm 11$ km s$^{-1}$, and a resultant dynamical mass of $\geq 4 \times 10^{10} M_\odot$. Despite its high metallicity and large molecular mass, the $z=0.101$ galaxy has a low star formation rate, implying a large gas consumption timescale, larger than that typical of late-type galaxies. Most of the molecular gas is hence likely to be in a diffuse extended phase, rather than in dense molecular clouds. By combining the results of emission and absorption studies, we find that the strongest molecular absorption component toward the quasar cannot arise from the molecular disk, but is likely to arise from diffuse gas in the galaxy's circumgalactic medium. Our results emphasize the potential of combining molecular and stellar emission line studies with optical absorption line studies to achieve a more complete picture of the gas within and surrounding high-redshift galaxies. ",First Connection between Cold Gas in Emission and Absorption: CO   Emission from a Galaxy-Quasar Pair
"  The structure of a single vortex in a FeAs superconductor is studied in the framework of two formulations of superconductivity for the recently proposed sign-reversed $s$ wave ($s^\pm$) scenario: {\it (i)} a continuum model taking into account the existence of an electron and a hole band with a repulsive local interaction between the two; {\it (ii)} a lattice tight-binding model with two orbitals per unit cell and a next-nearest-neighbour attractive interaction. In the first model, the local density of states (LDOS) at the vortex centre, as a function of energy, exhibits a peak at the Fermi level, while in the second model such LDOS peak is deviated from the Fermi level and its energy depends on band filling. An impurity located outside the vortex core has little effect on the LDOS peak, but an impurity close to the vortex core can almost suppress it and modify its position. ",Single vortex structure in two models of iron pnictide $s^\pm$   superconductivity
"  Neural networks are popular state-of-the-art models for many different tasks.They are often trained via back-propagation to find a value of the weights that correctly predicts the observed data. Although back-propagation has shown good performance in many applications, it cannot easily output an estimate of the uncertainty in the predictions made. Estimating the uncertainty in the predictions is a critical aspect with important applications, and one method to obtain this information is following a Bayesian approach to estimate a posterior distribution on the model parameters. This posterior distribution summarizes which parameter values are compatible with the data, but is usually intractable and has to be approximated. Several mechanisms have been considered for solving this problem. We propose here a general method for approximate Bayesian inference that is based on minimizing{\alpha}-divergences and that allows for flexible approximate distributions. The method is evaluated in the context of Bayesian neural networks on extensive experiments. The results show that, in regression problems, it often gives better performance in terms of the test log-likelihoodand sometimes in terms of the squared error. In classification problems, however, it gives competitive results. ",Adversarial $\alpha$-divergence Minimization for Bayesian Approximate   Inference
"  We consider the non-hermitian 2D Dirac Hamiltonian with (A): real random mass, imaginary scalar potential and imaginary gauge field potentials, and (B) arbitrary complex random potentials of all three kinds. In both cases this Hamiltonian gives rise to a delocalization transition at zero energy with particle-hole symmetry in every realization of disorder. Case (A) is in addition time-reversal invariant, and can also be interpreted as the random-field XY Statistical Mechanics model in two dimensions. The supersymmetric approach to disorder averaging results in current-current perturbations of $gl(N|N)$ super-current algebras. Special properties of the $gl(N|N)$ algebra allow the exact computation of the beta-functions, and of the correlation functions of all currents. One of them is the Edwards-Anderson order parameter. The theory is `nearly conformal' and possesses a scale-invariant subsector which is not a current algebra. For N=1, in addition, we obtain an exact solution of all correlation functions. We also study the delocalization transition of case (B), with broken time reversal symmetry, in the Gade-Wegner (Random-Flux) universality class, using a GL(N|N;C)/U(N|N) sigma model, as well as its PSL(N|N) variant, and a corresponding generalized random XY model. For N=1 the sigma model is shown to be identical to the current-current perturbation. For the delocalization transitions (case (A) and (B)) a density of states, diverging at zero energy, is found. ",gl(N|N) Super-Current Algebras for Disordered Dirac Fermions in Two   Dimensions
"  We consider the leading finite-size effects on some structure constants for the $\eta$ - deformed $AdS_5\times S^5$ background in the framework of the semiclassical approach. The leading finite-size corrections are derived for the cases when we have two heavy string states represented by giant magnons and for two different choices of the light states corresponding to dilaton operator with nonzero momentum and primary scalar operators. Since the dual field theory is still unknown, the results obtained here must be considered as conjectures or as predictions from the string theory side. ",Semiclassical structure constants in the eta-deformed AdS_5 x S^5:   Leading finite-size corrections
"  We propose a new production mechanism for keV sterile neutrino Dark Matter. In our setting, we assume the existence of a scalar singlet particle which never entered thermal equilibrium in the early Universe, since it only couples to the Standard Model fields by a really small Higgs portal interaction. For suitable values of this coupling, the scalar can undergo the so-called freeze-in process, and in this way be efficiently produced in the early Universe. These scalars can then decay into keV sterile neutrinos and produce the correct Dark Matter abundance. While similar settings in which the scalar does enter thermal equilibrium and then freezes out have been studied previously, the mechanism proposed here is new and represents a versatile extension of the known case. We perform a detailed numerical calculation of the DM production using a set of coupled Boltzmann equations, and we illustrate the successful regions in the parameter space. Our production mechanism notably can even work in models where active-sterile mixing is completely absent. ",New Production Mechanism for keV Sterile Neutrino Dark Matter by Decays   of Frozen-In Scalars
"  We explore the predictions of the standard hierarchical clustering scenario of galaxy formation, regarding the numbers and metallicities of PopIII stars likely to be found within our Galaxy today. By PopIII we shall be referring to stars formed at large redshift ($z>4$), with low metallicities ($[Z/Z_{\odot}]<-2.5$) and in small systems (total mass $\simlt$ $2\times 10^{8} M_{\odot}$) that are extremely sensitive to stellar feedback, and which through a prescribed merging history (Lacey & Cole 1993) end up becoming part of the Milky Way today. An analytic, extended Press-Schechter formalism is used to get the mass functions of halos which will host PopIII stars at a given redshift, and which will end up in Milky Way sized systems today. Each of these is modeled as a mini galaxy, with a detailed treatment of the dark halo structure, angular momentum distribution, final gas temperature and disk instabilities, all of which determine the fraction of the baryons which are subject to star formation. Use of new primordial metallicity stellar evolutionary models allows us to trace the history of the stars formed, give accurate estimates of their expected numbers today, and their location in $L/L_{\odot}$ vs. $T/K$ HR diagrams. A first comparison with observational data suggests that the IMF of the first stars was increasingly high mass weighted towards high redshifts, levelling off at $z\simgt 9$ at a characteristic stellar mass scale $m_s=10-15 M_\odot$. ",Cosmological Origin of the Lowest Metallicity Halo Stars
"  Stress analysis and assessment of affective states of mind using ECG as a physiological signal is a burning research topic in biomedical signal processing. However, existing literature provides only binary assessment of stress, while multiple levels of assessment may be more beneficial for healthcare applications. Furthermore, in present research, ECG signal for stress analysis is examined independently in spatial domain or in transform domains but the advantage of fusing these domains has not been fully utilized. To get the maximum advantage of fusing diferent domains, we introduce a dataset with multiple stress levels and then classify these levels using a novel deep learning approach by converting ECG signal into signal images based on R-R peaks without any feature extraction. Moreover, We made signal images multimodal and multidomain by converting them into time-frequency and frequency domain using Gabor wavelet transform (GWT) and Discrete Fourier Transform (DFT) respectively. Convolutional Neural networks (CNNs) are used to extract features from different modalities and then decision level fusion is performed for improving the classification accuracy. The experimental results on an in-house dataset collected with 15 users show that with proposed fusion framework and using ECG signal to image conversion, we reach an average accuracy of 85.45%. ",Multi-level Stress Assessment Using Multi-domain Fusion of ECG Signal
"  In this paper, we introduce a method for computing rigorous local inclusions of solutions of Cauchy problems for nonlinear heat equations for complex time values. Using a solution map operator, we construct a simplified Newton operator and show that it has a unique fixed point. The fixed point together with its rigorous bounds provides the local inclusion of the solution of the Cauchy problem. The local inclusion technique is then applied iteratively to compute solutions over long time intervals. This technique is used to prove the existence of a branching singularity in the nonlinear heat equation. Finally, we introduce an approach based on the Lyapunov-Perron method to calculate part of a center-stable manifold and prove that an open set of solutions of the Cauchy problem converge to zero, hence yielding the global existence of the solutions in the complex plane of time. ",Rigorous numerics for nonlinear heat equations in the complex plane of   time
"  In the conventional ferromagnetic systems, topological magnon bands and thermal Hall effect are due to the Dzyaloshinskii-Moriya interaction (DMI). In principle, however, the DMI is either negligible or it is not allowed by symmetry in some quantum magnets. Therefore, we expect that topological magnon features will not be present in those systems. In addition, quantum magnets on the triangular-lattice are not expected to possess topological features as the DMI or spin-chirality cancels out due to equal and opposite contributions from adjacent triangles. Here, however, we predict that the isomorphic frustrated honeycomb-lattice and bilayer triangular-lattice antiferromagnetic system will exhibit topological magnon bands and topological thermal Hall effect in the absence of an intrinsic DMI. These unconventional topological magnon features are present as a result of magnetic-field-induced non-coplanar spin configurations with nonzero scalar spin chirality. The relevance of the results to realistic bilayer triangular antiferromagnetic materials are discussed. ",Topological Magnon Bands and Unconventional Thermal Hall Effect on the   Frustrated Honeycomb and Bilayer Triangular Lattice
"  Studying all non-redundant proteins in 76 most-commonly found structural domains, the present work attempts to decipher latent patterns that characterize acceptable and unacceptable symmetries in residue-residue interactions in functional proteins. We report that cutting across the structural classes, a select set of pairwise interactions are universally favored by geometrical and evolutionary constraints, termed 'acceptable' structural and evolutionary tunnels, respectively. An equally small subset of residue-residue interactions, the 'unacceptable' structural and evolutionary tunnels, is found to be universally disliked by structural and evolutionary constraints. Non-trivial overlapping is detected among acceptable structural and evolutionary tunnels, as also among unacceptable structural and evolutionary tunnels. A subset of tunnels is found to have equal relative importance, structurally and evolutionarily, in different structural classes. The MET-MET tunnel is detected to be universally most unacceptable by both structural and evolutionary constraints, whereas the ASP-LEU tunnel was found to be the closest approximation to be universally most acceptable. Residual populations in structural and evolutionary tunnels are found to be independent of stereochemical properties of individual residues. It is argued with examples that tunnels are emergent features that connect extent of symmetry in residue-residue interactions to the level of quaternary structural organization. ",Structural and evolutionary tunnels of pairwise residue-interaction   symmetries connect different structural classes of proteins
"  Let $G/K$ be a Riemannian symmetric space of noncompact type, and let $\nu_{a_j}$, $j=1,...,r$ be some orbital measures on $G$ (see the definition below). The aim of this paper is to study the $L^{2}$-regularity (resp. $C^k$-smoothness) of the Radon-Nikodym derivative of the convolution $\nu_{a_{1}}\ast...\ast\nu_{a_{r}}$ with respect to a fixed left Haar measure $\mu_G$ on $G$. As a consequence of a result of Ragozin, \cite{ragozin}, we prove that if $r \geq \, \max_{1\leq i \leq s}\dim {G_i}/K_i$, then $\nu_{a_{1}}\ast...\ast\nu_{a_{r}}$ is absolutely continuous with respect to $\mu_G$, i.e., $d\big(\nu_{a_{1}}\ast...\ast\nu_{a_{r}}\big)/d\mu_G$ is in $L^1(G)$, where $G_i/K_i$, $i=1,...,s$, are the irreducible components in the de Rham decomposition of $G/K$. The aim of this paper is to prove that $d\big(\nu_{a_{1}}\ast...\ast\nu_{a_{r}}\big)/d\mu_G$ is in $L^2(G)$ (resp. $C^k\left(G \right) $) for $r \geq \max_{1\leq i \leq s}\dim \left( {G_i}/{K_i}\right) + 1$\, (resp. $r \geq \max_{1\leq i \leq s} \dim\left( {G_i}/{K_i}\right) +k+1$). The case of a compact symmetric space of rank one was considered in \cite{AGP} and \cite{AG}, and the case of a complex Grassmannian was considered in \cite{AA}. ",Regularity of the Radon-Nikodym Derivative of a Convolution of Orbital   Measures on Noncompact Symmetric Spaces
"  It has been known for a long time that the satellite galaxies of the Milky Way (MW) show a significant amount of phase-space correlation, they are distributed in a highly inclined Disc of Satellites (DoS). We have extended the previous studies on the DoS by analysing for the first time the orientations of streams of stars and gas, and the distributions of globular clusters within the halo of the MW. It is shown that the spatial distribution of MW globular clusters classified as young halo clusters (YH GC) is very similar to the DoS, while 7 of the 14 analysed streams align with the DoS. The probability to find the observed clustering of streams is only 0.3 per cent when assuming isotropy. The MW thus is surrounded by a vast polar structure (VPOS) of subsystems (satellite galaxies, globular clusters and streams), spreading from Galactocentric distances as small as 10 kpc out to 250 kpc. These findings demonstrate that a near-isotropic infall of cosmological sub-structure components onto the MW is essentially ruled out because a large number of infalling objects would have had to be highly correlated, to a degree not natural for dark matter sub-structures. The majority of satellites, streams and YH GCs had to be formed as a correlated population. This is possible in tidal tails consisting of material expelled from interacting galaxies. We discuss the tidal scenario for the formation of the VPOS, including successes and possible challenges. The potential consequences of the MW satellites being tidal dwarf galaxies are severe. If all the satellite galaxies and YH GCs have been formed in an encounter between the young MW and another gas-rich galaxy about 10-11 Gyr ago, then the MW does not have any luminous dark-matter substructures and the missing satellites problem becomes a catastrophic failure of the standard cosmological model. ","The VPOS: a vast polar structure of satellite galaxies, globular   clusters and streams around the Milky Way"
"  Energy storage systems for transportation and grid applications, and in the future for aeronautical applications, require the ability of providing accurate diagnosis to insure system availability and reliability. In such applications, battery packs may consist of hundreds or thousands of interconnected cells, and of the associated electrical/electronic hardware. This paper presents a systematic methodology for approaching some aspects of the design of battery packs, and in particular understanding the degree of analytical redundancy (AR) in the system that can be used for diagnostic strategies. First, the degree of AR that is intrinsic in the battery system is determined. Then, structural analysis tools are used to study how different measurements (current, voltage, and temperature) may improve the ability of monitoring and diagnosis of a battery system. Possible sensor placement strategies that would enable the diagnosis of individual sensor faults and individual cell faults for different battery pack topologies are analyzed as well. The work presented in this paper illustrates how to achieve the required fault detection and isolation (FDI) capabilities using a minimal or optimal sensor set, which is a critical step in the design of a large battery pack. ",Optimal Sensor Placement in Lithium-Ion Battery Pack for Fault Detection   and Isolation
"  The number of neurons that can be simultaneously recorded doubles every seven years. This ever increasing number of recorded neurons opens up the possibility to address new questions and extract higher dimensional stimuli from the recordings. Modeling neural spike trains as point processes, this task of extracting dynamical signals from spike trains is commonly set in the context of nonlinear filtering theory. Particle filter methods relying on importance weights are generic algorithms that solve the filtering task numerically, but exhibit a serious drawback when the problem dimensionality is high: they are known to suffer from the 'curse of dimensionality' (COD), i.e. the number of particles required for a certain performance scales exponentially with the observable dimensions. Here, we first briefly review the theory on filtering with point process observations in continuous time. Based on this theory, we investigate both analytically and numerically the reason for the COD of weighted particle filtering approaches: Similarly to particle filtering with continuous-time observations, the COD with point-process observations is due to the decay of effective number of particles, an effect that is stronger when the number of observable dimensions increases. Given the success of unweighted particle filtering approaches in overcoming the COD for continuous- time observations, we introduce an unweighted particle filter for point-process observations, the spike-based Neural Particle Filter (sNPF), and show that it exhibits a similar favorable scaling as the number of dimensions grows. Further, we derive rules for the parameters of the sNPF from a maximum likelihood approach learning. We finally employ a simple decoding task to illustrate the capabilities of the sNPF and to highlight one possible future application of our inference and learning algorithm. ",Particle-filtering approaches for nonlinear Bayesian decoding of   neuronal spike trains
"  Given a probability measure on a finitely generated group, its Martin boundary is a way to compactify the group using the Green function of the corresponding random walk. It is known from the work of W. Woess that when a finitely supported random walk on a free product of abelian groups is adapted to the free product structure, the Martin boundary coincides with the geometric boundary. The main goal of this paper is to deal with non-adapted finitely supported random walks, for which there is no explicit formula for the Green function. Nevertheless, we show that the Martin boundary still coincides with the geometric boundary. We also prove that the Martin boundary is minimal. ",The martin boundary of a free product of abelian groups
  The motion of neutral particles with magnetic moments in an inhomogeneous magnetic field is described in a quantum mechanical framework. The validity of the semi-classical approximations which are generally used to describe these phenomena is discussed. Approximate expressions for the evolution operator are derived and compared to the exact calculations. Focusing and spin-flip phenomena are predicted. The reliability of Stern-Gerlach experiments to measure spin projections is assessed in this framework. ,Quantum mechanical description of Stern-Gerlach experiments
"  We present 100 year light curves of Kepler planet-candidate host stars from the Digital Access to a Sky Century at Harvard (DASCH) project. 261 out of 997 host stars have at least 10 good measurements on DASCH scans of the Harvard plates. 109 of them have at least 100 good measurements, including 70% (73 out of 104) of all host stars with g<=13 mag, and 44% (100 out of 228) of all host stars with g<=14 mag. Our typical photometric uncertainty is ~0.1-0.15 mag. No variation is found at 3-sigma level for these host stars, including 21 confirmed or candidate hot Jupiter systems which might be expected to show enhanced flares from magnetic interactions between dwarf primaries and their close and relatively massive planet companions. ",100-year DASCH Light Curves of Kepler Planet-Candidate Host Stars
"  In this paper, we present a novel unsupervised algorithm for word sense disambiguation (WSD) at the document level. Our algorithm is inspired by a widely-used approach in the field of genetics for whole genome sequencing, known as the Shotgun sequencing technique. The proposed WSD algorithm is based on three main steps. First, a brute-force WSD algorithm is applied to short context windows (up to 10 words) selected from the document in order to generate a short list of likely sense configurations for each window. In the second step, these local sense configurations are assembled into longer composite configurations based on suffix and prefix matching. The resulted configurations are ranked by their length, and the sense of each word is chosen based on a voting scheme that considers only the top k configurations in which the word appears. We compare our algorithm with other state-of-the-art unsupervised WSD algorithms and demonstrate better performance, sometimes by a very large margin. We also show that our algorithm can yield better performance than the Most Common Sense (MCS) baseline on one data set. Moreover, our algorithm has a very small number of parameters, is robust to parameter tuning, and, unlike other bio-inspired methods, it gives a deterministic solution (it does not involve random choices). ",ShotgunWSD: An unsupervised algorithm for global word sense   disambiguation inspired by DNA sequencing
"  In a recent paper, Andrews and Newman extended the mex-function to integer partitions and proved many partition identities connected with these functions. In this paper, we present parity considerations of one of the families of functions they studied, namely $p_{t,t}(n)$. Among our results, we provide complete parity characterizations of $p_{1,1}(n)$ and $p_{3,3}(n)$. ",Parity Considerations for Mex-Related Partition Functions of Andrews and   Newman
"  We quantitatively analyze the meson mass inequality relations of two dimensional gauged four fermi models in the large N limit. The class of models we study includes the 't Hooft model, the chiral and non-chiral Gross-Neveu models as special points in the space of field theories. Cases where the chiral symmetry is spontaneously or explicitly broken are both studied. We study the meson mass inequality quantitatively and define a susceptibility which allows us to systematically analyze the inequality. In the generalized Gross-Neveu model limit, we derive an analytic expression for this susceptibility. Even though no analytic proof of the validity of the classic mass inequality exists for the generic case, the mass inequality is found to be positive throughout most of the parameter space. We point out that the inequality might be negative in certain cases. ",Mass inequalities in two dimensional gauged four fermi models
"  The experimental study of the CO$_2$ phase diagram is hampered by strong kinetic effects leading to wide regions of metastability and to large uncertainties in the location of phase boundaries. Here we determine the CO$_2$ phase boundaries by means of {\it ab initio} calculations of the Gibbs free energy of several molecular and non-molecular solid phases of CO$_2$. Temperature effects are included in the quasi-harmonic approximation. Contrary to previous results, we find that the boundary between non-molecular phases and phase V has a positive slope and starts at 21.5 GPa at $T$ = 0 K. A triple point between phase IV, V, and the liquid phase is found at 35 GPa and 1600 K, indicating a broader region of stability for the non-molecular phases than previously thought. The experimentally determined boundary line between CO$_{2}$-II and CO$_{2}$-IV phases is reproduced by our calculations, indicating that kinetic effects are not relevant in that transition. ",{\it Ab initio} determination of the phase diagram of CO$_2$ at high   pressures and temperatures
"  A Lorentz invariant statistical model is presented for rotational fluctuations in the local inertial frame that arise from new quantum degrees of freedom of space-time. The model assumes invariant classical causal structure, and a Planck information density in invariant proper time determined by the world line of an observer. It describes macroscopic spacelike correlations that appear as observable timelike correlations in phase differences of light propagating on paths that begin and end on the same world line. The model allows an exact prediction for the autocorrelation of any interferometer time signal from the shape of the light paths. Specific examples computed for configurations that approximate realistic experiments show that the model can be rigorously tested, allowing a direct experimental probe of Planck scale degrees of freedom. ",Statistical Model of Exotic Rotational Correlations in Emergent   Space-Time
"  The goal of this article is to survey various results concerning stochastic completeness of graphs. In particular, we present a variety of formulations of stochastic completeness and discuss how a discrepancy between uniqueness class and volume growth criteria in the continuous and discrete settings was ultimately resolved via the use of intrinsic metrics. Along the way, we discuss some equivalent notions of boundedness in the sense of geometry and of analysis. We also discuss various curvature criteria for stochastic completeness and discuss how weakly spherically symmetric graphs establish the sharpness of results. ","Stochastic completeness of graphs: bounded Laplacians, intrinsic   metrics, volume growth and curvature"
"  Recent studies show the existing clinical tests to detect Cardio/cerebrovascular diseases (CVD) are ineffectual as they do not consider different stages of platelet activation or the molecular dynamics involved in platelet interactions. Further they are also incapable to consider inter-individual variability. A physical description of platelets deposition was introduced recently in Chopard et. al. [2017], by integrating fundamental understandings of how platelets interact in a numerical model, parameterized by five parameters. These parameters specify the deposition process and are relevant for a biomedical understanding of the phenomena. One of the main intuition is that these parameters are precisely the information needed for a pathological test identifying CVD captured and that they capture the inter-individual variability. Following this intuition, here we devise a Bayesian inferential scheme for estimation of these parameters. As the likelihood function of the numerical model is intractable due to the complex stochastic nature of the model, we use a likelihood-free inference scheme approximate Bayesian computation (ABC) to calibrate the parameters in a data-driven manner. As ABC requires the generation of many pseudo-data by expensive simulation runs, we use a high performance computing (HPC) framework for ABC to make the inference possible for this model. We illustrate that our mean posterior prediction of platelet deposition pattern matches the experimental dataset closely with a tight posterior prediction error margin for a collective dataset of 7 volunteers. The present approach can be used to build a new generation of personalized platelet functionality tests for CVD detection, using numerical modeling of platelet deposition, Bayesian uncertainty quantification and High performance computing. ",Parameter estimation of platelets deposition: Approximate Bayesian   computation with high performance computing
  In this paper we consider the numerical solution of Fractional Differential Equations by means of $m$-step recursions. The construction of such formulas can be obtained in many ways. Here we study a technique based on the rational approximation of the generating functions of Fractional Backward Differentiation Formulas (FBDFs). Accurate approximations allow to define methods which simulate the theoretical properties of the underlying FBDF with important computational advantages. Numerical experiments are presented. ,On the construction of $m$-step methods for FDEs
"  In this paper, we study the algorithmic complexity of the Mastermind game, where results are single-color black pegs. This differs from the usual dual-color version of the game, but better corresponds to applications in genetics. We show that it is NP-complete to determine if a sequence of single-color Mastermind results have a satisfying vector. We also show how to devise efficient algorithms for discovering a hidden vector through single-color queries. Indeed, our algorithm improves a previous method of Chvatal by almost a factor of 2. ",On the Algorithmic Complexity of the Mastermind Game with Black-Peg   Results
"  We investigate the low-energy $^9$Be elastic scattering on two different targets (heavy, light) within a four-body framework using the Continuum-Discretized Coupled-Channels (CDCC) method. The $^9$Be projectile is described in a $\alpha + \alpha + n$ three-body model using the analytical transformed harmonic oscillator (THO) basis in hyperspherical coordinates. We show that continuum couplings are important to describe the elastic cross section, especially at low energies and on heavy targets. The dipolar contribution to the elastic cross section at energies around the Coulomb barrier is important but small compared to the case of halo nuclei. The effect of the projectile low-energy resonances is also relevant. The agreement with the available experimental data supports the reliability of the method to describe reactions induced by three-body projectiles including more than one charged particle. ",$^9$Be elastic scattering on $^{208}$Pb and $^{27}$Al within a four-body   reaction framework
"  In the version 1 of this paper, we claimed that 4D ${\cal N}=1$ supergravity formulations with different auxiliary fields can be unified using U(1) gauge symmetry, whose gauge superfield does not have a kinetic term. However, after submission, we found a critical error in our statement. This is the note on the paper of the version 1. ","Note on ""Equivalence Between Different Auxiliary Field Formulations of   ${\cal N}=1$ Supergravity Coupled to Matter"""
"  We study reflected entropy as a correlation measure in black hole evaporation. As a measure for bipartite mixed states, reflected entropy can be computed between black hole and radiation, radiation and radiation. We compute reflected entropy curves in three different models: 3-side wormhole model, End-of-the-World (EOW) brane model in three dimensions and two-dimensional eternal black hole plus CFT model. For 3-side wormhole model, we find that reflected entropy is dual to island cross sections. The reflected entropy between radiation and black hole increases at early time and then decreases to zero, similar to Page curve, but with a later transition time. The reflected entropy between radiation and radiation first increases and then saturates. For the EOW brane model, similar behaviors of reflected entropy are found.   We propose a quantum extremal surface for reflected entropy, which we call quantum extremal cross section. In the eternal black hole plus CFT model, we find a generalized formula for reflected entropy with island cross section as its area term by considering the right half as the canonical purification of the left. Interestingly, the reflected entropy curve between the left black hole and the left radiation is nothing but the Page curve. We also find that reflected entropy between the left black hole and the right black hole decreases and goes to zero at late time. The reflected entropy between radiation and radiation increases at early time and saturates at late time. ",Reflected Entropy for an Evaporating Black Hole
"  We examine the extent to which Gaussian relay networks can be approximated by deterministic networks, and present two results, one negative and one positive.   The gap between the capacities of a Gaussian relay network and a corresponding linear deterministic network can be unbounded. The key reasons are that the linear deterministic model fails to capture the phase of received signals, and there is a loss in signal strength in the reduction to a linear deterministic network.   On the positive side, Gaussian relay networks are indeed well approximated by certain discrete superposition networks, where the inputs and outputs to the channels are discrete, and channel gains are signed integers.   As a corollary, MIMO channels cannot be approximated by the linear deterministic model but can be by the discrete superposition model. ",On approximating Gaussian relay networks by deterministic networks
"  In strong-field physics experiments with intense lasers, it is of paramount importance to single-shot diagnose the temporal contrast between laser pulse peak and its noise pedestal. This allows fast optimization of pulse contrast and meaningful comparison with theory for each pulse shot, and it can help new outcomes from clean laser-plasma interactions. Thus far, high contrast ratios up to ~10^10, required by present petawatt (PW) class lasers, have been accessible in both generation and single-shot characterization. However, ultrahigh contrast ~10^13, required by the planned 200-PW lasers, challenges intense laser technology and remains an open question. This paper reports on the first demonstration of such an ultrahigh-contrast measurement by adapting single-shot cross-correlator (SSCC). We introduce an ultrafast method that enables to determine the SSCC detection limit. Our strategy mimics the test laser having known ultrahigh contrast in the measurement frame of time-to-space mapping. The ultimate contrast-measurement limit of 10^13 is achieved, which corresponds to the highest pulse intensity set by SSCC damage threshold and the lowest noise pedestal set by single-photon detection. As a consequence, photon noise in the detection is observed and increases as the noise pedestal reduces. The demonstrated measurement ability at the photon noise limit is applied to a high-contrast laser system based on second-harmonic generation and optical parametric chirped-pulse amplification, suggesting accessible of ultrahigh contrast pulses. ",Resolving ultrahigh-contrast ultrashort pulses with single-shot   cross-correlator at the photon noise limit
"  We study the dispersion of the ""temporally stable"" coherent states for the hydrogen atom introduced by Klauder. These are states which under temporal evolution by the hydrogen atom Hamiltonian retain their coherence properties. We show that in the hydrogen atom such wave packets do not move quasi-classically; i.e., they do not follow with no or little dispersion the Keplerian orbits of the classical electron. The poor quantum-classical correspondence does not improve in the semiclassical limit. ",Dispersion of Klauder's temporally stable coherent states for the   hydrogen atom
"  Given data drawn from an unknown distribution, $D$, to what extent is it possible to ``amplify'' this dataset and output an even larger set of samples that appear to have been drawn from $D$? We formalize this question as follows: an $(n,m)$ $\text{amplification procedure}$ takes as input $n$ independent draws from an unknown distribution $D$, and outputs a set of $m > n$ ``samples''. An amplification procedure is valid if no algorithm can distinguish the set of $m$ samples produced by the amplifier from a set of $m$ independent draws from $D$, with probability greater than $2/3$. Perhaps surprisingly, in many settings, a valid amplification procedure exists, even when the size of the input dataset, $n$, is significantly less than what would be necessary to learn $D$ to non-trivial accuracy. Specifically we consider two fundamental settings: the case where $D$ is an arbitrary discrete distribution supported on $\le k$ elements, and the case where $D$ is a $d$-dimensional Gaussian with unknown mean, and fixed covariance. In the first case, we show that an $\left(n, n + \Theta(\frac{n}{\sqrt{k}})\right)$ amplifier exists. In particular, given $n=O(\sqrt{k})$ samples from $D$, one can output a set of $m=n+1$ datapoints, whose total variation distance from the distribution of $m$ i.i.d. draws from $D$ is a small constant, despite the fact that one would need quadratically more data, $n=\Theta(k)$, to learn $D$ up to small constant total variation distance. In the Gaussian case, we show that an $\left(n,n+\Theta(\frac{n}{\sqrt{d}} )\right)$ amplifier exists, even though learning the distribution to small constant total variation distance requires $\Theta(d)$ samples. In both the discrete and Gaussian settings, we show that these results are tight, to constant factors. Beyond these results, we formalize a number of curious directions for future research along this vein. ",Sample Amplification: Increasing Dataset Size even when Learning is   Impossible
"  The present paper is based on the modified part of the review ""Random Dynamics and Multiple Point Model"" by L.V.Laperashvili, H.B.Nielsen, D.A.Ryzhikh and N.Stillits, in preparation for publication in Russian, which contains the results of our joint activity with H.B.Nielsen concerning the investigations of phase transitions in gauge theories. In this review we have presented the main ideas of the Nielsen's Random Dynamics (RD) and his achievements (with co-authors) in the Anti-Grand Unification Theory (AGUT) and Multiple Point Model (MPM). We have considered also the theory of Scale Relativity (SR) by L.Nottale, which has a lot in common with RD: both theories lead to the discreteness of our space-time, giving rise to the new description of physics at very small distances. In this paper we have demonstrated the possibility of [SU(5)]$^3$ SUSY unification with superparticles of masses $M\approx 10^{18.3}$ GeV and calculated its critical point -- critical value of the inverse finestucture constant -- at $\alpha_{5,crit}^{-1} = \alpha_5^{-1}(\mu_{Pl})\approx 34.0$ (close to $\alpha_{GUT}^{-1}\approx 34.4$) with a hope that such an unified theory approaches the (multi)critical point at the Planck scale. ",Phase Transition in Gauge Theories and the Planck Scale Physics
"  Emotion being a subjective thing, leveraging knowledge and science behind labeled data and extracting the components that constitute it, has been a challenging problem in the industry for many years. With the evolution of deep learning in computer vision, emotion recognition has become a widely-tackled research problem. In this work, we propose two independent methods for this very task. The first method uses autoencoders to construct a unique representation of each emotion, while the second method is an 8-layer convolutional neural network (CNN). These methods were trained on the posed-emotion dataset (JAFFE), and to test their robustness, both the models were also tested on 100 random images from the Labeled Faces in the Wild (LFW) dataset, which consists of images that are candid than posed. The results show that with more fine-tuning and depth, our CNN model can outperform the state-of-the-art methods for emotion recognition. We also propose some exciting ideas for expanding the concept of representational autoencoders to improve their performance. ",Facial Emotion Detection Using Convolutional Neural Networks and   Representational Autoencoder Units
"  The present paper continues the study of infinite dimensional calculus via regularization, started by C. Di Girolami and the second named author, introducing the notion of ""weak Dirichlet process"" in this context. Such a process $\X$, taking values in a Hilbert space $H$, is the sum of a local martingale and a suitable ""orthogonal"" process. The new concept is shown to be useful in several contexts and directions. On one side, the mentioned decomposition appears to be a substitute of an It\^o type formula applied to $f(t, \X(t))$ where $f:[0,T] \times H \rightarrow \R$ is a $C^{0,1}$ function and, on the other side, the idea of weak Dirichlet process fits the widely used notion of ""mild solution"" for stochastic PDE. As a specific application, we provide a verification theorem for stochastic optimal control problems whose state equation is an infinite dimensional stochastic evolution equation. ","Infinite dimensional weak Dirichlet processes, stochastic PDEs and   optimal control"
  We show that for a simple surface with boundary the attenuated ray transform in the presence of a unitary connection and a skew-Hermitian Higgs field is injective modulo the natural obstruction for functions and vector fields. We also show that the connection and the Higgs field are uniquely determined by the scattering relation modulo a gauge transformation. The proofs involve a Pestov type energy identity for connections together with holomorphic gauge transformations which arrange the curvature of the connection to have definite sign. ,The attenuated ray transform for connections and Higgs fields
"  Entanglement properties of two uncoupled atoms embedded in a coherent field distribution through one quantum transition process is studied. A case of non-linear Hamiltonian of the problem is considered through which the effect of a non-linear media is illustrated. Moreover, the effect of the frequency difference between the interatomic transition and the electromagnetic field is also analyzed. We show that, adjusting the considered parametres of the non-linear media and frequency difference leads to a strong control of the degree of entanglement where excellent periodicity of entanglement evolution can be obtained which is very important in predicting the behavior of transmitted information through the application of various information processing schemes. We present a detailed and comparative study of atom-atom entanglement for two cases corresponding to different injections of the two atoms into the cavity field. Moreover, we present an answer to the question: How does the quantum phase space structure for a composite system relate to the entanglement characteristics of the corresponding quantum system? We demonstrate how the entanglement in nonlinear tripartite systems can be associated with a delocalization in the phase space distribution. ",An investigation of a nonlocal entanglement of two uncoupled atoms   embedded in a coherent cavity field and the associated phase space   distribution: one quantum non-linear process
"  A real time Wall Monitoring System (WMS) is used on the WEST tokamak during the C4 experimental campaign. The WMS uses the wall surface temperatures from 6 fields of view of the Infrared viewing system. It extracts the raw digital data from selected areas, converts it to temperatures using the calibration and write it on the shared memory network being used by the Plasma Control System (PCS). The PCS feeds back to actuators, namely the injected power from 5 antennae's of the lower hybrid and ion cyclotron resonance radiofrequency (RF) heating systems. WMS activates feed back control 63 times during C4, which is 14% of the plasma discharges. It activates mainly as the result of a direct RF loss to the upper divertor pipes. The feedback control maintains the wall temperature within the operation envelope during 97% of the occurrences, while enabling plasma discharge continuation. The false positive rate establishes at 0.2%. WMS significantly facilitated the operation path to high power operation during C4, by managing the technical risks to critical wall components. ",WEST operation with real time feed back control based on wall component   temperature toward machine protection in a steady state tungsten environment
"  We study different properties of an anti-Hermitian Yukawa interaction, motivated by a scenario of radiative anomalous generation of masses for the right-handed sterile neutrinos. The model, involving either a pseudo-scalar or a scalar, is consistent both at the classical and quantum levels, and particular attention is given to its properties under improper Lorentz transformations. The path integral is consistently defined with a Euclidean signature, and we discuss the energetics of the model, which show that no dynamical mass generation can occur, unless extra interactions are considered. ",On the consistency of a non-Hermitian Yukawa interaction
"  We prove the existence of global analytic solutions to the nonlinear Schr\""odinger equation in one dimension for a certain type of analytic initial data in $L^2$. ","Global Analytic Solutions for the Nonlinear Schr\""odinger Equation"
"  So far, no supersymmetric particles have been detected at the Large Hadron Collider (LHC). However, the recent Higgs results have interesting implications for the SUSY parameter space. In this paper, we study the consequences of an LHC Higgs signal for a model with non-universal gaugino masses in the context of SU(5) unification. The gaugino mass ratios associated with the higher representations produce viable spectra that are largely inaccessible to the current LHC and direct dark matter detection experiments. Thus, in light of the Higgs results, the non-observation of SUSY is no surprise. ",Higgs and non-universal gaugino masses: no SUSY signal expected yet?
"  We consider the exchange of spin and orbital angular momenta between a circularly polarized Laguerre-Gaussian beam of light and a single atom trapped in a two-dimensional harmonic potential. The radiation field is treated classically but the atomic center-of-mass motion is quantized. The spin and orbital angular momenta of the field are individually conserved upon absorption, and this results in the entanglement of the internal and external degrees of freedom of the atom. We suggest applications of this entanglement in quantum information processing. ",Entanglement of internal and external angular momenta of a single atom
"  \noindent Let $\mu(f)$ resp. $c(f)$ be the Milnor number resp. the degree of the conductor of an irreducible power series $f\in \bK[[x,y]]$, where $\bK$ is an algebraically closed field of characteristic $p\geq 0$. It is well-known that $\mu(f)\geq c(f)$. We give necessary and sufficient conditions for the equality $\mu(f)=c(f)$ in terms of the semigroup associated with $f$, provided that $p>\ord f$. ",The Milnor number of plane irreducible singularities in positive   characteristic
"  In this thesis we study two-dimensional supersymmetric non-linear sigma-models with boundaries. We derive the most general family of boundary conditions in the non-supersymmetric case. Next we show that no further conditions arise when passing to the N = 1 model and we present a manifest N = 1 off-shell formulation. Subsequently, we determine under which conditions a second supersymmetry exists. Finally we recast some of our results in N = 2 superspace. Leaning on these results we then calculate the beta-functions through three loops for an open string sigma-model in the presence of U(1) background. Requiring them to vanish is then reinterpreted as the string equations of motion for the background. Upon integration this yields the low energy effective action. Doing the calculation in N = 2 boundary superspace significantly simplifies the calculation. The one loop contribution gives the effective action to all orders in alpha' in the limit of a constant fieldstrength. The result is the well known Born-Infeld action. The absence of a two loop contribution to the beta-function shows the absence of two derivative terms in the action. Finally the three loop contribution gives the four derivative terms in the effective action to all orders in alpha'. Modulo a field redefinition we find complete agreement with the proposal made in the literature. By doing the calculation in N = 2 superspace, we get a nice geometric characterization of UV finiteness of the non-linear sigma-model: UV finiteness is guaranteed provided that the background is a deformed stable holomorphic bundle. ",Higher Derivative Corrections to the Abelian Born-Infeld Action using   Superspace Methods
"  The body of work presented here revolves around the investigation of the existence and nature of extra-solar planetary systems. The fitting of stellar radial velocity time series data is attempted by constructing a model to quantify the orbital properties of a star-planetary system. This is achieved with the Planetary Orbit Fitting Process (POFP). Though specific to the investigated problem, the POFP is founded on two separate, more general ideas. One is a Solver producing the gravitational dynamics of a Three-Body system by integrating its Newtonian equations of motion. The other is an independent optimisation scheme. Both have been devised using MATLAB. Applying the optimisation to the Solver results in a realistic Three-Body dynamics that best describes the radial velocity data under the model-specific orbital-observational constraints. Combining these aspects also allows for the study of dynamical instability derived from interaction, which is reaffirmed as a necessary criterion for evaluating the fit. The validity of POFP solutions with respect to the observations and other models is discussed in this context. The underlying generality and fundamental principles demonstrate a larger frame of operation where problems in Physics and Mathematics can be solved with a multitude of techniques. ",Optimisation of the 3-body dynamics applied to extra-solar planetary   systems
"  Besides the Higgs particle discovered in 2012, with mass 125 GeV, recent LHC data show tentative signals for new resonances in diboson as well as diphoton searches at high center-of-mass energies (2 TeV and 750 GeV, respectively). If these signals are confirmed (or other new resonances are discovered at the TeV scale), the large hierarchies between masses of new bosons require a dynamical explanation. Motivated by these tentative signals of new physics, we investigate the theoretical possibility that large hierarchies in the masses of glueballs could arise dynamically in new strongly-coupled gauge theories extending the standard model of particle physics. We study lattice data on non-Abelian gauge theories in the (near-)conformal regime as well as a simple toy model in the context of gauge/gravity dualities. We focus our attention on the ratio $R$ between the mass of the lightest spin-2 and spin-0 resonances, that for technical reasons is a particularly convenient and clean observable to study. For models in which (non-perturbative) large anomalous dimensions arise dynamically, we show indications that this mass ratio can be large, with $R>5$. Moreover, our results suggest that $R$ might be related to universal properties of the IR fixed point. Our findings provide an interesting step towards understanding large mass ratios in the non-perturbative regime of quantum field theories with (near) IR conformal behaviour. ",Large mass hierarchies from strongly-coupled dynamics
"  For the Jacobian resulting from the previously considered problem of the path integral reduction in Wiener path integrals for a mechanical system with symmetry describing the motion of two interacting scalar particles on a manifold that is the product of a smooth compact finite-dimensional Riemannian manifold and a finite-dimensional vector space, a geometric representation is obtained. This representation follows from the formula for the scalar curvature of the original manifold endowed by definition with a free isometric smooth action of a compact semisimple Lie group. The derivation of this formula is performed using adapted coordinates, which can be determined in the principal fiber bundle associated with the problem under the study. These coordinates are similar to those used in the standard approach to quantization of Yang-Mills fields interacting with scalar fields. ",On the geometric representation of the path integral reduction Jacobian   for a mechanical system with symmetry given on a manifold that is a product   of the total space of the principal fiber bundle and the vector space
"  In this paper we study the vanishing inertia and viscosity limit of a second order system set in an Euclidean space, driven by a possibly nonconvex time-dependent potential satisfying very general assumptions. By means of a variational approach, we show that the solutions of the singularly perturbed problem converge to a curve of stationary points of the energy and characterize the behavior of the limit evolution at jump times. At those times, the left and right limits of the evolution are connected by a finite number of heteroclinic solutions to the unscaled equation. ",A variational approach to the quasistatic limit of viscous dynamic   evolutions in finite dimension
"  Antideuteron production cross-sections estimated using EPOS-LHC with a coalescence afterburner, tuned to reproduce published experimental data over a wide range of energy were used here as input to the galactic propagator code GALPROP, validated with comparing to existing proton, helium fluxes as well as boron-to-carbon ratio data. The resulting near-Earth antideuteron flux, including solar modulation, is compared to previous estimates. An overall factor of two increments in the antideuteron flux is predicted, the origin of which is also discussed. However, this standard model source of antideuteron background still lies well below the AMS-02, and the expected GAPS, sensitivities, as well as the fluxes predicted by several dark matter models. ",SM antideuteron background to indirect dark matter signals in galactic   cosmic rays
  We provide an algorithm for computing the centered Hausdorff measure of self-similar sets satisfying the strong separation condition. We prove the convergence of the algorithm and test its utility on some examples. ,An algorithm for computing the centered Hausdorff measure of   self-similar sets
"  Over the last few years, we have witnessed tremendous progress on many subtasks of autonomous driving, including perception, motion forecasting, and motion planning. However, these systems often assume that the car is accurately localized against a high-definition map. In this paper we question this assumption, and investigate the issues that arise in state-of-the-art autonomy stacks under localization error. Based on our observations, we design a system that jointly performs perception, prediction, and localization. Our architecture is able to reuse computation between both tasks, and is thus able to correct localization errors efficiently. We show experiments on a large-scale autonomy dataset, demonstrating the efficiency and accuracy of our proposed approach. ","Deep Multi-Task Learning for Joint Localization, Perception, and   Prediction"
"  We demonstrate a novel quantum sensor for measuring non-magnetic spin-dependent interactions. This sensor utilizes $^{131}$Xe, $^{129}$Xe, and $^{85}$Rb which are continuously polarized transverse to a pulsed bias field. The transverse geometry of this spin-exchange pumped comagnetometer suppresses longitudinal polarization, which is an important source of systematic error. Simultaneous excitation of both Xe isotopes is accomplished by frequency modulating the repetition rate of the bias field pulses at subharmonics of the Xe Larmor resonance frequencies. The area of each bias pulse causes $2\pi$ Larmor precession of the Rb. We present continuous dual-species Xe excitation and discuss a temperature-dependent wall interaction that limits the $^{129}$Xe polarization. The Rb atoms serve as an embedded magnetometer for detection of the Xe precession. We discuss Rb magnetometer phase shifts, and show that even first-order treatments of these phase shifts can result in order-of-magnitude improvements in the achieved field suppression when performing comagnetometry. The sensing bandwidth of the presented device is 1 Hz, and we demonstrate a white-noise level of 7 $\mu$Hz/$\sqrt{\text{Hz}}$ and a bias instability of $\sim1$ $\mu$Hz. ",Dual-Species Synchronous Spin-Exchange Optical Pumping
"  Asymmetric magnetization reversal is an unusual phenomenon in antiferromagnet / ferromagnet (AF/FM) exchange biased bilayers. We investigated this phenomenon in a simple model system experimentally and by simulation assuming inhomogeneously distributed interfacial AF moments. The results suggest that the observed asymmetry originates from the intrinsic broken symmetry of the system, which results in local incomplete domain walls parallel to the interface in reversal to negative saturation of the FM. Magneto-optic Kerr effect unambiguously confirms such an asymmetric reversal and a depth-dependent FM domain wall in accord with the magnetometry and simulations. ",Asymmetric Reversal in Inhomogeneous Magnetic Heterostructures
"  We propose a mechanism of a long-range coherent interaction between two singlet-triplet qubits dipolarly coupled to a dogbone-shaped ferromagnet. An effective qubit-qubit interaction Hamiltonian is derived and the coupling strength is estimated. Furthermore we derive the effective coupling between two spin-1/2 qubits that are coupled via dipolar interaction to the ferromagnet and that lie at arbitrary positions and deduce the optimal positioning. We consider hybrid systems consisting of spin-1/2 and ST qubits and derive the effective Hamiltonian for this case. We then show that operation times vary between 1MHz and 100MHz and give explicit estimates for GaAs, Silicon, and NV-center based spin qubits. Finally, we explicitly construct the required sequences to implement a CNOT gate. The resulting quantum computing architecture retains all the single qubit gates and measurement aspects of earlier approaches, but allows qubit spacing at distances of order 1$\,\mu$m for two-qubit gates, achievable with current semiconductor technology. ",Long-Range Interaction of Singlet-Triplet Qubits via Ferromagnets
"  The treatment of malaria is a global health challenge that stands to benefit from the widespread introduction of a vaccine for the disease. A method has been developed to create a live organism vaccine using the sporozoites (SPZ) of the parasite Plasmodium falciparum (Pf), which are concentrated in the salivary glands of infected mosquitoes. Current manual dissection methods to obtain these PfSPZ are not optimally efficient for large-scale vaccine production. We propose an improved dissection procedure and a mechanical fixture that increases the rate of mosquito dissection and helps to deskill this stage of the production process. We further demonstrate the automation of a key step in this production process, the picking and placing of mosquitoes from a staging apparatus into a dissection assembly. This unit test of a robotic mosquito pick-and-place system is performed using a custom-designed micro-gripper attached to a four degree of freedom (4-DOF) robot under the guidance of a computer vision system. Mosquitoes are autonomously grasped and pulled to a pair of notched dissection blades to remove the head of the mosquito, allowing access to the salivary glands. Placement into these blades is adapted based on output from computer vision to accommodate for the unique anatomy and orientation of each grasped mosquito. In this pilot test of the system on 50 mosquitoes, we demonstrate a 100% grasping accuracy and a 90% accuracy in placing the mosquito with its neck within the blade notches such that the head can be removed. This is a promising result for this difficult and non-standard pick-and-place task. ",A Mosquito Pick-and-Place System for PfSPZ-based Malaria Vaccine   Production
"  What is the relationship between brain and behavior? The answer to this question necessitates characterizing the mapping between structure and function. The aim of this paper is to discuss broad issues surrounding the link between structure and function in the brain that will motivate a network perspective to understanding this question. As others in the past, I argue that a network perspective should supplant the common strategy of understanding the brain in terms of individual regions. Whereas this perspective is needed for a fuller characterization of the mind-brain, it should not be viewed as panacea. For one, the challenges posed by the many-to-many mapping between regions and functions is not dissolved by the network perspective. Although the problem is ameliorated, one should not anticipate a one-to-one mapping when the network approach is adopted. Furthermore, decomposition of the brain network in terms of meaningful clusters of regions, such as the ones generated by community-finding algorithms, does not by itself reveal 'true' subnetworks. Given the hierarchical and multi-relational relationship between regions, multiple decompositions will offer different 'slices' of a broader landscape of networks within the brain. Finally, I described how the function of brain regions can be characterized in a multidimensional manner via the idea of diversity profiles. The concept can also be used to describe the way different brain regions participate in networks. ",Understanding brain networks and brain organization
"  The widely-studied radio network model [Chlamtac and Kutten, 1985] is a graph-based description that captures the inherent impact of collisions in wireless communication. In this model, the strong assumption is made that node $v$ receives a message from a neighbor if and only if exactly one of its neighbors broadcasts.   We relax this assumption by introducing a new noisy radio network model in which random faults occur at senders or receivers. Specifically, for a constant noise parameter $p \in [0,1)$, either every sender has probability $p$ of transmitting noise or every receiver of a single transmission in its neighborhood has probability $p$ of receiving noise.   We first study single-message broadcast algorithms in noisy radio networks and show that the Decay algorithm [Bar-Yehuda et al., 1992] remains robust in the noisy model while the diameter-linear algorithm of Gasieniec et al., 2007 does not. We give a modified version of the algorithm of Gasieniec et al., 2007 that is robust to sender and receiver faults, and extend both this modified algorithm and the Decay algorithm to robust multi-message broadcast algorithms.   We next investigate the extent to which (network) coding improves throughput in noisy radio networks. We address the previously perplexing result of Alon et al. 2014 that worst case coding throughput is no better than worst case routing throughput up to constants: we show that the worst case throughput performance of coding is, in fact, superior to that of routing -- by a $\Theta(\log(n))$ gap -- provided receiver faults are introduced. However, we show that any coding or routing scheme for the noiseless setting can be transformed to be robust to sender faults with only a constant throughput overhead. These transformations imply that the results of Alon et al., 2014 carry over to noisy radio networks with sender faults. ",Broadcasting in Noisy Radio Networks
"  We present results from a large global VLBI(Very Long Baseline Interferometry) survey of compact radio sources at 86 GHz which started in October 2001. The main goal of the survey is to increase the total number of objects accessible for future 3mm-VLBI imaging by factors of 3-5. The survey data reach the baseline sensitivity of 0.1 Jy, and image sensitivity of better than 10 mJy/beam. To date, a total of 127 compact radio sources have been observed. The observations have yielded images for 109 sources, and only 6 sources have not been detected. Flux densities and sizes of core and jet components of all detected sources have been measured using Gaussian model fitting. From these measurements, brightness temperatures have been estimated, taking into account resolution limits of the data. Here, we compare the brightness temperatures of the cores and secondary jet components with similar estimates obtained from surveys at longer wavelengths (e.g. 15 GHz). This approach can be used to study questions related to mechanisms of initial jet acceleration (accelerating or decelerating sub-pc jets?) and jet composition (electron-positron or electron-proton plasma?). ",A global 86 GHz VLBI survey
"  I review the recent calculations and current status of the hadronic light-by-light scattering contribution to muon g-2. In particular, I discuss the main results obtained in a recent work together with Eduardo de Rafael and Arkady Vainshtein where we came to the estimate a^{\rm HLbL}_\mu = (10.5 +- 2.6) x 10^{-10}. How the two-photon physics program of low energy facilities can help to reduce the present model dependence is also emphasized. ",The Hadronic Light-by-Light Contribution to Muon g-2: A Short Review
"  This paper presents a novel partial differential equation (PDE)-based framework for controlling an ensemble of robots, which have limited sensing and actuation capabilities and exhibit stochastic behaviors, to perform mapping and coverage tasks. We model the ensemble population dynamics as an advection-diffusion-reaction PDE model and formulate the mapping and coverage tasks as identification and control problems for this model. In the mapping task, robots are deployed over a closed domain to gather data, which is unlocalized and independent of robot identities, for reconstructing the unknown spatial distribution of a region of interest. We frame this task as a convex optimization problem whose solution represents the region as a spatially-dependent coefficient in the PDE model. We then consider a coverage problem in which the robots must perform a desired activity at a programmable probability rate to achieve a target spatial distribution of activity over the reconstructed region of interest. We formulate this task as an optimal control problem in which the PDE model is expressed as a bilinear control system, with the robots' coverage activity rate and velocity field defined as the control inputs. We validate our approach with simulations of a combined mapping and coverage scenario in two environments with three target coverage distributions. ",PDE-Based Optimization for Stochastic Mapping and Coverage Strategies   using Robotic Ensembles
"  We explore the use of first and second order same-time atomic spatial correlation functions as a diagnostic for probing the small scale spatial structure of atomic samples trapped in optical lattices. Assuming an ensemble of equivalent atoms, properties of the local wave function at a given lattice site can be measured using same-position first-order correlations. Statistics of atomic distributions over the lattice can be measured via two-point correlations, generally requiring the averaging of multiple realizations of statistically similar but distinct realizations in order to obtain sufficient signal to noise. Whereas two-point first order correlations are fragile due to phase fluctuations from shot-to-shot in the ensemble, second order correlations are robust. We perform numerical simulations to demonstrate these diagnostic tools. ",Spatial Correlation Diagnostics for Atoms in Optical Lattices
"  Magnetically active stars are the sites of efficient particle acceleration and plasma heating, processes that have been studied in detail in the solar corona. Investigation of such processes in young stellar objects is much more challenging due to various absorption processes. There is, however, evidence for violent magnetic energy release in very young stellar objects. The impact on young stellar environments (e.g., circumstellar disk heating and ionization, operation of chemical networks, photoevaporation) may be substantial. Hard X-ray devices like those carried on Simbol-X will establish a basis for detailed studies of these processes. ",Young stellar objects from soft to hard X-rays
"  We study the joint density of eigenvalues for products of independent rectangular real, complex and quaternionic Ginibre matrices. In the limit where the number of matrices tends to infinity, it is shown that the joint probability density function for the eigenvalues forms a permanental point process for all three classes. The moduli of the eigenvalues become uncorrelated and log-normal distributed, while the distribution for the phases of the eigenvalues depends on whether real, complex or quaternionic Ginibre matrices are considered. In the derivation for a product of real matrices, we explicitly use the fact that all eigenvalues become real when the number of matrices tends to infinity. Finally, we compare our results with known results for the Lyapunov exponents as well as numerical simulations. ","Lyapunov exponents for products of rectangular real, complex and   quaternionic Ginibre matrices"
"  Consider the space $R_{\Delta}$ of rational functions of several variables with poles on a fixed arrangement $\Delta$ of hyperplanes. We obtain a decomposition of $R_{\Delta}$ as a module over the ring of differential operators with constant coefficients. We generalize to the space $R_{\Delta}$ the notions of principal part and of residue, and we describe its relations to Laplace transforms of locally polynomial functions. This explains algebraic aspects of work by L. Jeffreys and F. Kirwan about integrals of equivariant cohomology classes on Hamiltonian manifolds. As another application, we will construct multidimensional versions of Eisenstein series in a subsequent article, and we will obtain another proof of a residue formula of A. Szenes for Witten zeta functions. ",Arrangements of hyperplanes I: Rational functions and Jeffrey-Kirwan   residue
"  We present an alternate proof of Giraud's Theorem based on the fact that given the conditions on a category E for being a topos, its objects are sheaves by construction. Generalizing sets to R-modules for R a commutative ring, we prove that a category with small hom-sets and finite limits is equivalent to a category of sheaves of R-modules on a site if and only if it satisfies Giraud's axioms and in addition is enriched in a certain symmetric monoidal category parametrized by an R-module. ",Giraud's Theorem and Categories of Representations
  Linear reaction-diffusion equations with inhomogeneous boundary and transmission conditions are shown to possess the property of maximal Lp regularity. The new feature is the fact that the transmission interface is allowed to intersect the boundary of the domain transversally. ,Maximal Regularity of Parabolic Transmission Problems
"  Various parametric representations have been proposed to model the speech signal. While the performance of such vocoders is well-known in the context of speech processing, their extrapolation to singing voice synthesis might not be straightforward. The goal of this paper is twofold. First, a comparative subjective evaluation is performed across four existing techniques suitable for statistical parametric synthesis: traditional pulse vocoder, Deterministic plus Stochastic Model, Harmonic plus Noise Model and GlottHMM. The behavior of these techniques as a function of the singer type (baritone, counter-tenor and soprano) is studied. Secondly, the artifacts occurring in high-pitched voices are discussed and possible approaches to overcome them are suggested. ",Parametric Representation for Singing Voice Synthesis: a Comparative   Evaluation
"  In this paper we study a subfamily of a classic lattice path, the \emph{Dyck paths}, called \emph{restricted $d$-Dyck} paths, in short $d$-Dyck. A valley of a Dyck path $P$ is a local minimum of $P$; if the difference between the heights of two consecutive valleys (from left to right) is at least $d$, we say that $P$ is a restricted $d$-Dyck path. The \emph{area} of a Dyck path is the sum of the absolute values of $y$-components of all points in the path. We find the number of peaks and the area of all paths of a given length in the set of $d$-Dyck paths. We give a bivariate generating function to count the number of the $d$-Dyck paths with respect to the the semi-length and number of peaks. After that, we analyze in detail the case $d=-1$. Among other things, we give both, the generating function and a recursive relation for the total area. ",Restricted Dyck Paths on Valleys Sequence
"  Massive stars likely played an important role in the reionization of the Universe, and the formation of the first black holes. Massive stars in low-metallicity environments in the local Universe are reminiscent of their high redshift counterparts. In a previous paper, we reported on indications that the stellar winds of low-metallicity O stars may be stronger than predicted, which would challenge the current paradigm of massive star evolution. In this paper, we aim to extend our initial sample of six O stars in low-metallicity environments by four. We aim to derive their stellar and wind parameters, and compare these to radiation-driven wind theory and stellar evolution models. We have obtained intermediate-resolution VLT/X-Shooter spectra of our sample of stars. We derive the stellar parameters by fitting synthetic fastwind line profiles to the VLT/X-Shooter spectra using a genetic fitting algoritm. We compare our parameters to evolutionary tracks and obtain evolutionary masses and ages. We also investigate the effective temperature versus spectral type calibration for SMC and lower metallicities. Finally, we reassess the wind momentum versus luminosity diagram. The derived parameters of our target stars indicate stellar masses that reach values of up to 50 $M_{\odot}$. The wind strengths of our stars are, on average, stronger than predicted from radiation-driven wind theory and reminiscent of stars with an LMC metallicity. We discuss indications that the iron content of the host galaxies is higher than originally thought and is instead SMC-like. We find that the discrepancy with theory is lessened, but remains significant for this higher metallicity. This may imply that our current understanding of the wind properties of massive stars, both in the local universe as well as at cosmic distances, remains incomplete. ","The properties of ten O-type stars in the low-metallicity galaxies IC   1613, WLM and NGC 3109"
  We present the notion of asymptotically large depth for a metric space which is (a priory) weaker than having subexponential asymptotic dimension growth and (a priory) stronger than property A. ,An intermediate quasi-isometric invariant between subexponential   asymptotic dimension growth and Yu's Property A
"  A pointwise bound for local weak solutions to the p-Laplace system is established in terms of data on the right-hand side in divergence form. The relevant bound involves a Havin-Maz'ya- Wulff potential of the datum, and is a counterpart for data in divergence form of a classical result of [KiMa], that has recently been extended to systems in [KuMi2]. A local bound for oscillations is also provided. These results allow for a unified approach to regularity estimates for broad classes of norms, including Banach function norms (e.g. Lebesgue, Lorentz and Orlicz norms), and norms depending on the oscillation of functions (e.g. Holder, BMO and, more generally, Campanato type norms). In particular, new regularity properties are exhibited, and well-known results are easily recovered. ",Potential estimates for the p-Laplace system with data in divergence   form
"  In this short note, we investigate the relationship between so-called regular families of cardinal interpolators and multiresolution analyses. We focus our studies on examples of regular families of cardinal interpolators whose Fourier transform is unbounded at the origin. In particular, we show that when this is the case there is a multiresolution analysis corresponding to each member of a regular family of cardinal interpolators. ",On regular families of cardinal interpolators and multiresolution   analyses
"  Implementing embedded neural network processing at the edge requires efficient hardware acceleration that couples high computational performance with low power consumption. Driven by the rapid evolution of network architectures and their algorithmic features, accelerator designs are constantly updated and improved. To evaluate and compare hardware design choices, designers can refer to a myriad of accelerator implementations in the literature. Surveys provide an overview of these works but are often limited to system-level and benchmark-specific performance metrics, making it difficult to quantitatively compare the individual effect of each utilized optimization technique. This complicates the evaluation of optimizations for new accelerator designs, slowing-down the research progress. This work provides a survey of neural network accelerator optimization approaches that have been used in recent works and reports their individual effects on edge processing performance. It presents the list of optimizations and their quantitative effects as a construction kit, allowing to assess the design choices for each building block separately. Reported optimizations range from up to 10'000x memory savings to 33x energy reductions, providing chip designers an overview of design choices for implementing efficient low power neural network accelerators. ",A Construction Kit for Efficient Low Power Neural Network Accelerator   Designs
"  Globular Clusters (GCs) are natural laboratories where stellar and chemical evolution can be studied in detail. In addition, their chemical patterns and kinematics can tell us wich Galactic structure (Disk, Bulge, Halo or extragalactic) the cluster belongs to. NGC 5927 is one of most metal-rich GCs in the Galaxy and its kinematics links it to the Thick Disk. We present abundance analysis based on high resolution spectra of 7 giant stars. The data were obtained using FLAMES/UVES spectrograph mounted on UT2 telescope of the European Southern Observatory. The principal motivation of this work is to perform a wide and detailed chemical abundance analysis of the cluster and look for possible Multiple Populations (MPs). We determined stellar parameters and measured 22 elements corresponding to light (Na, Al), alpha (O, Mg, Si, Ca, Ti), iron-peak (Sc, V, Cr, Mn, Fe, Co, Ni, Cu, Zn) and heavy elements (Y, Zr, Ba, Ce, Nd, Eu). We found a mean iron content of [Fe/H]=-0.47 $\pm$0.02 (error on the mean). We confirm the existence of MPs in this GC with an O-Na anti-correlation, and moderate spread in Al abundances. We estimate a mean [$\alpha$/Fe]=0.25 $\pm$0.08. Iron-peak elements shows no significant spread. The [Ba/Eu] ratios indicate a predominant contribution from SNeII for the formation of the cluster. ",Chemical Study of the Metal-rich Globular Cluster NGC 5927
"  We report a first search for weakly interacting massive particles (WIMPs) using the background rejection capabilities of SuperCDMS. An exposure of 577 kg-days was analyzed for WIMPs with mass < 30 GeV/c2, with the signal region blinded. Eleven events were observed after unblinding. We set an upper limit on the spin-independent WIMP-nucleon cross section of 1.2e-42 cm2 at 8 GeV/c2. This result is in tension with WIMP interpretations of recent experiments and probes new parameter space for WIMP-nucleon scattering for WIMP masses < 6 GeV/c2. ",Search for Low-Mass WIMPs with SuperCDMS
"  Local symmetries of the action for a relativistic particle with curvature and torsion of its world curve in the (2+1)-dimensional space-time are studied. With the help of the method, worked out recently by the authors (Phys.Rev., D56, 1135, 1142 (1997)), first the local-symmetry transformations are obtained both in the phase and configuration space. At the classical level, the dependence of the particle mass on the parameters of curvature and torsion and the Regge trajectory are obtained. It is shown that the tachyonic sector can be removed by a proper gauge choice. ",The relativistic particle with curvature and torsion of world trajectory
"  A huge enhancement of the superconducting transition temperature Tc was observed in tetragonal FeSe superconductor under high pressure. The onset temperature became as high as 27 K at 1.48 GPa and the pressure coefficient showed a huge value of 9.1 K/GPa. The upper critical field Hc2 was estimated to be ~ 72 T at 1.48 GPa. Because of the high Hc2, FeSe system may be a candidate for application as superconducting wire rods. Moreover, the investigation of superconductivity on simple structured FeSe may provide important clues to the mechanism of superconductivity in iron-based superconductors. ",Superconductivity at 27 K in tetragonal FeSe under high pressure
"  We address the question of how to deal with confusion limited surveys in the mid-infrared domain by using informations from higher frequency observations over the same sky regions. Such informations, once applied to apparently extended mid-infrared sources, which are indeed ``blends'' of two or more different sources, allow us to disentangle the single counterparts and to split the measured flux density into different components. We present the application of this method to the 24 micron Spitzer archival data in the GOODS-EN1 test field, where apparently extended, ``blended'' sources constitute about 20% of a reliable sample of 983 sources detected above the 5-sigma threshold down to 23 microJy. As higher frequency data-set we have considered the public IRAC images and catalogues on the same field. We show that the 24 micron sample is almost unbiased down to ~40 microJy and the careful application of the deblending procedure does not require any statistical completeness correction (at least at the flux level considered). This is probed by direct comparison of our results with those of Chary et al. (2004), who analysed the same data-set through extensive Monte Carlo simulations. The deblending procedure reduces of about 30% the confusion limit of the MIPS 24 micron survey, allowing one to obtain reliable source counts down to ~40 microJy. The extrapolation of the source counts down to fainter fluxes suggests that our 24 micron sample is able to resolve ~62% of the cosmic background down to a flux level of 38 microJy. ",Counting individual galaxies from deep 24 micron Spitzer surveys: beyond   the confusion limit
"  About ten years ago the use of standard functional manipulations was demonstrated to imply an unexpected property satisfied by the fermionic Green's functions of QCD and dubbed effective locality. This feature of QCD is non-perturbative as it results from a full gauge invariant summation of the gluonic degrees of freedom. This astounding result has lead to suspect that in a way or other, the famous Gribov copy problem had been somewhat overlooked. It is argued that it is not so. ",On the absence of the Gribov copy problem in `effective locality' QCD   calculations
"  Nutritional regulation by ants emerges from a distributed process: food is collected by a small fraction of workers, stored within the crops of individuals, and spreads via local ant-to-ant interactions. The precise individual level underpinnings of this collective regulation have remained unclear mainly due to difficulties in measuring food within ants crops. Here we image fluorescent liquid food in individually tagged Camponotus sanctus ants, and track the real-time food flow from foragers to their gradually satiating colonies. We show how the feedback between colony satiation level and food inflow is mediated by individual crop loads; specifically, the crop loads of recipient ants control food flow rates, while those of foragers regulate the frequency of foraging trips. Interestingly, these effects do not rise from pure physical limitations of crop capacity. Our findings suggest that the emergence of food intake regulation does not require individual foragers to assess the global state of the colony. ",Individual crop loads provide local control for collective food intake   in ant colonies
  An estimation of the sensitivity to measure Bs-Bsbar oscillations with the ATLAS detector is given for the detector geometry of initial layout. The delta ms reach is derived from unbinned maximum likelihood amplitude fits using Bs0 events generated with a simplified Monte Carlo method. ,Prospects of the measurement of Bs0 oscillations with the ATLAS detector   at LHC
"  On the basis of the Poincare-Weyl gauge theory of gravitation, a new conformal Weyl-Dirac theory of gravitation is proposed, which is a gravitational theory in Cartan-Weyl spacetime with the Dirac scalar field representing the dark matter model. A static approximate axially symmetric solution of the field equations in vacuum is obtained. On the base of this solution in the Newtonian approximation one considers the problem of rotation velocities in spiral components of galaxies. ",Approximate axially symmetric solution of the Weyl-Dirac theory of   gravitation and the spiral galactic rotation problem
"  The transmission of correlated electrons through a domain wall in ferromagnetic quasi-one-dimensional systems is studied theoretically in the case when the domain wall width is comparable with the Fermi wavelength of the charge carriers. The wall gives rise to both potential and spin dependent scattering. Using a poor man's renormalization group approach, we obtain scaling equations for the scattering amplitudes. For repulsive interactions, the wall is shown to reflect all incident electrons at the zero temperature fixed points. In one of the fixed points the wall additionally flips the spin of all incident electrons, generating a finite spin current without associated charge current. ",Role of electron correlations in transport through domain walls in   magnetic nanowires
"  We investigate the finite-temperature properties of attractive three-component (colors) fermionic atoms in optical lattices using a self-energy functional approach. As the strength of the attractive interaction increases in the low temperature region, a second-order transition occurs from a Fermi liquid to a color superfluid (CSF). In the strong attractive region, a first-order transition occurs from a CSF to a trionic state. In the high temperature region, a crossover between a Fermi liquid and a trionic state is observed with increasing the strength of the attractive interaction. The crossover region for fixed temperature is almost independent of filling. ",Color Superfluid and Trionic State of Attractive Three-Component Lattice   Fermionic Atoms at Finite Temperatures
"  Proper motion measurements of the cool and ultracool populations in the Upper Scorpius OB association are crucial to confirm membership and to identify possible run-away objects.   We cross-match samples of photometrically selected and spectroscopically confirmed cool and ultracool (K5<SpT<M8.5) candidate members in the Upper Scorpius OB association using the literature and the USNO-B and the UCAC2 catalogues. 251 of these objects have a USNO-B and/or UCAC2 counterpart with proper motion measurements.   A significant fraction (19 objects, 7.6+-1.8%) of spectroscopically confirmed young objects show discrepant proper motion. They must either belong to unidentified coincident foreground associations, or originate from neighboring star forming regions or have recently experienced dynamical interactions within the association. The observed accretor and disc frequencies are lower among outliers, but with only 19 objects it is unreliable to draw firm statistical conclusions. Finally, we note that transverse velocities of very low mass members are indistinguishable from those of low mass members within 4km/s ",Proper motions of cool and ultracool candidate members in the Upper   Scorpius OB association
"  Many problems can be formulated as recovering a low-rank tensor. Although an increasingly common task, tensor recovery remains a challenging problem because of the delicacy associated with the decomposition of higher order tensors. To overcome these difficulties, existing approaches often proceed by unfolding tensors into matrices and then apply techniques for matrix completion. We show here that such matricization fails to exploit the tensor structure and may lead to suboptimal procedure. More specifically, we investigate a convex optimization approach to tensor completion by directly minimizing a tensor nuclear norm and prove that this leads to an improved sample size requirement. To establish our results, we develop a series of algebraic and probabilistic techniques such as characterization of subdifferetial for tensor nuclear norm and concentration inequalities for tensor martingales, which may be of independent interests and could be useful in other tensor related problems. ",On Tensor Completion via Nuclear Norm Minimization
"  The distance-redshift relation determined by means of gravitational waves in the clumpy universe is simulated numerically by taking into account the effects of gravitational lensing. It is assumed that all of the matter in the universe takes the form of randomly distributed point masses, each of which has the identical mass $M_L$. Calculations are carried out in two extreme cases: $\lambda\gg GM_L/c^2$ and $\lambda\ll GM_L/c^2$, where $\lambda$ denotes the wavelength of gravitational waves. In the first case, the distance-redshift relation for the fully homogeneous and isotropic universe is reproduced with a small distance dispersion, whereas in the second case, the distance dispersion is larger. This result suggests that we might obtain information about the typical mass of lens objects through the distance-redshift relation gleaned through observation of gravitational waves of various wavelengths. In this paper, we show how to set limitations on the mass $M_L$ through the observation of gravitational waves in the clumpy universe model described above. ",Lensing Effects on Gravitational Waves in a Clumpy Universe -Effects of   Inhomogeneity on the Distance-Redshift Relation-
"  (abridged) In this paper, we express the relativistic propagational delay of light in the space-time of a binary system (commonly known as the ""Shapiro delay"") as a sum of harmonics of the orbital period of the system. We do this first for near-circular orbits as a natural expansion of an existing orbital model for low-eccentricity binary systems. The amplitudes of the 3rd and higher harmonics can be described by two new post-Keplerian (PK) parameters proportional to the amplitudes of the third and fourth harmonics (h_3, h_4). For high orbital inclinations we use a PK parameter proportional to the ratio of amplitudes of successive harmonics (sigma) instead of h_4. The new PK parameters are much less correlated with each other than r and s and provide a superior description of the constraints introduced by the Shapiro delay on the orbital inclination and the masses of the components of the binary (...). We extend the h_3,sigma parameterisation to eccentric binaries with high orbital inclinations. For some such binaries we can measure extra PK parameters and test general relativity using the Shapiro delay parameters. In this case we can use the measurement of h_3 as a test of general relativity. We show that this new test is not only more stringent than the r test, but it is even more stringent than the previous s test. Until now this new parametric test could only be derived statistically from an analysis of a probabilistic chi2 map. ",The orthometric parameterisation of the Shapiro delay and an improved   test of general relativity with binary pulsars
"  In early clinical test evaluations the potential benefits of the introduction of a new technology into the healthcare system are assessed in the challenging situation of limited available empirical data. The aim of these evaluations is to provide additional evidence for the decision maker, who is typically a funder or the company developing the test, to evaluate which technologies should progress to the next stage of evaluation. In this paper we consider the evaluation of a diagnostic test for patients suffering from Chronic Obstructive Pulmonary Disease (COPD). We describe the use of graphical models, prior elicitation and uncertainty analysis to provide the required evidence to allow the test to progress to the next stage of evaluation. We specifically discuss inferring an influence diagram from a care pathway and conducting an elicitation exercise to allow specification of prior distributions over all model parameters. We describe the uncertainty analysis, via Monte Carlo simulation, which allowed us to demonstrate that the potential value of the test was robust to uncertainties. This paper provides a case study illustrating how a careful Bayesian analysis can be used to enhance early clinical test evaluations. ",Uncertainty representation for early phase clinical test evaluations: a   case study
"  We study arithmetic intersections on twisted (quaternionic) Hilbert modular surfaces and Shimura curves over a real quadratic field. Our first main result is the determination of the degree of the top arithmetic Todd class of an arithmetic twisted Hilbert modular surface. This quantity is then related to the arithmetic volume of a Shimura curve, via the arithmetic Grothendieck-Riemann-Roch theorem and the Jacquet-Langlands correspondence. ","Twisted Hilbert modular surfaces, arithmetic intersections and the   Jacquet-Langlands correspondence"
"  Evolutionary scenarios suggest that the progenitor of the new binary pulsar J0737-3039B \cite{ref1,ref2} was a He-star with $M > 2.1-2.3~\Ms$ \cite{ref3,ref4}. We show that this case implies that the binary must have a large ($>120$ km/s) center of mass velocity. However, the location, $\sim 50$ pc from the Galactic plane, suggests that the system has, at high likelihood, a significantly smaller center of mass velocity and a progenitor more massive than 2.1~$\Ms$ is ruled out (at 97% c.l.). A progenitor mass around 1.45~$\Ms$, involving a new previously unseen gravitational collapse, is kinematically favored. The low mass progenitor is consistent with the recent scintillations based velocity measurement of 66$\pm 15$ km/s \cite{ref12new} (and which also rules out the high mass solution at 99% c.l.) and inconsistent with the higher earlier estimates of 141$\pm 8.5$ km/s \cite{ref11new}. Direct proper motion measurements, that should be available within a year or so, should better help to distinguish between the two scenarios. ",The Origin of the Binary Pulsar J0737-3039B
"  BackgroundLowering the gut exposure to antibiotics during treatments can prevent microbiota disruption. We evaluated the effect of an activated charcoal-based adsorbent, DAV131A, on fecal free moxifloxacin concentration and mortality in a hamster model of moxifloxacin-induced C. difficile infection.Methods215 hamsters receiving moxifloxacin subcutaneously (D1-D5) were orally infected at D3 with C. difficile spores. They received various doses (0-1800mg/kg/day) and schedules (BID, TID) of DAV131A (D1-D8). Moxifloxacin concentration and C. difficile counts were determined at D3, and mortality at D12. We compared mortality, moxifloxacin concentration and C. difficile counts according to DAV131A regimens, and modelled the link between DAV131A regimen, moxifloxacin concentration and mortality. ResultsAll hamsters that received no DAV131A died, but none of those that received 1800mg/kg/day. A significant dose-dependent relationship between DAV131A dose and (i) mortality rates, (ii) moxifloxacin concentration and (iii) C. difficile counts was evidenced. Mathematical modeling suggested that (i) lowering moxifloxacin concentration at D3, which was 58$\mu$g/g (95%CI=50-66) without DAV131A, to 17$\mu$g/g (14-21) would reduce mortality by 90% and (ii) this would be achieved with a daily DAV131A dose of 703mg/kg (596-809).ConclusionsIn this model of C. difficile infection, DAV131A reduced mortality in a dose-dependent manner by decreasing fecal free moxifloxacin concentration. ",Protection of hamsters from mortality by reducing fecal moxifloxacin   concentration with DAV131A in a model of moxifloxacin-induced Clostridium   difficile colitis
"  A very sensitive X-ray investigation of the giant HII region N11 in the LMC was performed using the Chandra X-ray Observatory. The 300ks observation reveals X-ray sources with luminosities down to 10^32 erg/s, increasing by more than a factor of 5 the number of known point sources in the field. Amongst these detections are 13 massive stars (3 compact groups of massive stars, 9 O-stars and one early B-star) with log(Lx/Lbol)~-6.5 to -7, which may suggest that they are highly magnetic or colliding wind systems. On the other hand, the stacked signal for regions corresponding to undetected O-stars yields log(Lx/Lbol)~-7.3, i.e., an emission level comparable to similar Galactic stars despite the lower metallicity. Other point sources coincide with 11 foreground stars, 6 late-B/A stars in N11, and many background objects. This observation also uncovers the extent and detailed spatial properties of the soft, diffuse emission regions but the presence of some hotter plasma in their spectra suggests contamination by the unresolved stellar population. ",A Deep Chandra Observation of the Giant HII Region N11 I. X-ray Sources   in the Field
"  The authors of the title proved an elegant identity expressing a Toeplitz determinant in terms of the Fredholm determinant of an infinite matrix which (although not described as such) is the product of two Hankel matrices. The proof used combinatorial theory, in particular a theorem of Gessel expressing a Toeplitz determinant as a sum over partitions of products of Schur functions. The purpose of this note is to give two other proofs of the identity. The first uses an identity of the second author for the quotient of Toeplitz determinants in which the same product of Hankel matrices appears and the second, which is more direct and extends the identity to the case of block Toeplitz determinants, consists of carrying the first author's collaborative proof of the strong Szeg\""o limit theorem one step further. ",On a Toeplitz determinant identity of Borodin and Okounkov
"  Ubiquitous personalized recommender systems are built to achieve two seemingly conflicting goals, to serve high quality content tailored to individual user's taste and to adapt quickly to the ever changing environment. The former requires a complex machine learning model that is trained on a large amount of data; the latter requires frequent update to the model. We present an incremental learning solution to provide both the training efficiency and the model quality. Our solution is based on sequential Bayesian update and quadratic approximation. Our focus is on large-scale personalized logistic regression models, with extensions to deep learning models. This paper fills in the gap between the theory and the practice by addressing a few implementation challenges that arise when applying incremental learning to large personalized recommender systems. Detailed offline and online experiments demonstrated our approach can significantly shorten the training time while maintaining the model accuracy. The solution is deployed in LinkedIn and directly applicable to industrial scale recommender systems. ",Incremental Learning for Personalized Recommender Systems
"  In supervised machine learning, an agent is typically trained once and then deployed. While this works well for static settings, robots often operate in changing environments and must quickly learn new things from data streams. In this paradigm, known as streaming learning, a learner is trained online, in a single pass, from a data stream that cannot be assumed to be independent and identically distributed (iid). Streaming learning will cause conventional deep neural networks (DNNs) to fail for two reasons: 1) they need multiple passes through the entire dataset; and 2) non-iid data will cause catastrophic forgetting. An old fix to both of these issues is rehearsal. To learn a new example, rehearsal mixes it with previous examples, and then this mixture is used to update the DNN. Full rehearsal is slow and memory intensive because it stores all previously observed examples, and its effectiveness for preventing catastrophic forgetting has not been studied in modern DNNs. Here, we describe the ExStream algorithm for memory efficient rehearsal and compare it to alternatives. We find that full rehearsal can eliminate catastrophic forgetting in a variety of streaming learning settings, with ExStream performing well using far less memory and computation. ",Memory Efficient Experience Replay for Streaming Learning
"  We discuss a number of topics relevant to disk-magnetosphere interaction and how numerical simulations illuminate them. The topics include: (1) disk-magnetosphere interaction and the problem of disk-locking; (2) the wind problem; (3) structure of the magnetospheric flow, hot spots at the star's surface, and the inner disk region; (4) modeling of spectra from 3D funnel streams; (5) accretion to a star with a complex magnetic field; (6) accretion through 3D instabilities; (7) magnetospheric gap and survival of protoplanets. Results of both 2D and 3D simulations are discussed. ",MHD simulations of disk-star interaction
"  For any complex number $\alpha$ and any even-size skew-symmetric matrix $B$, we define a generalization $\pfa{\alpha}(B)$ of the pfaffian $\pf(B)$ which we call the $\alpha$-pfaffian. The $\alpha$-pfaffian is a pfaffian analogue of the $\alpha$-determinant. It gives the pfaffian at $\alpha=-1$. We give some formulas for $\alpha$-pfaffians and study the positivity. Further we define point processes determined by the $\alpha$-pfaffian. Also we provide a linear algebraic proof of the explicit pfaffian expression for the correlation function of the shifted Schur measure. ","Alpha-Pfaffian, pfaffian point process and shifted Schur measure"
"  In this article, we study the vertexes $\Xi_Q^*\Xi'_Q V$ and $\Sigma_Q^* \Sigma_Q V$ with the light-cone QCD sum rules, then assume the vector meson dominance of the intermediate $\phi(1020)$, $\rho(770)$ and $\omega(782)$, and calculate the radiative decays $\Xi_Q^*\to \Xi'_Q \gamma$ and $\Sigma_Q^*\to \Sigma_Q \gamma$. ","Analysis of the vertexes $\Xi_Q^*\Xi'_Q V$, $\Sigma_Q^*\Sigma_Q V$ and   radiative decays $\Xi_Q^*\to \Xi'_Q \gamma$, $\Sigma_Q^*\to \Sigma_Q \gamma$"
"  The goal of this work is to find the asymptotics of the hitting probability of a distant point for the voter model on the integer lattice started from a single 1 at the origin. In dimensions 2 or 3, we obtain the precise asymptotic behavior of this probability. We use the scaling limit of the voter model started from a single 1 at the origin in terms of super-Brownian motion under its excursion measure. This invariance principle was stated by Bramson, Cox and Le Gall, as a consequence of a theorem of Cox, Durrett and Perkins. Less precise estimates are derived in dimensions greater than 4. ",Probability of hitting a distant point for the voter model started with   a single one
"  We consider a family of functionals $J$ to be maximized over the planar convex sets $K$ for which the perimeter and Steiner point have been fixed. Assuming that $J$ is the integral of a quadratic expression in the support function $h$, we show that the maximizer is always either a triangle or a line segment (which can be considered as a collapsed triangle). Among the concrete consequences of the main theorem is the fact that, given any convex body $K_1$ of finite perimeter, the set in the class we consider that is farthest away in the sense of the $L^2$ distance is always a line segment. We also prove the same property for the Hausdorff distance. ","On the maximization of a class of functionals on convex regions, and the   characterization of the farthest convex set"
"  This paper presents the preliminary findings of a study researching the diffusion and the adoption of online retailing in Saudi Arabia. It reports new research that identifies and explores the key issues that positively and negatively influence the decision of Saudi customers to buy from online retailers in Saudi Arabia. Although Saudi Arabia has the largest and fastest growth of ICT marketplaces in the Arab region, e-commerce activities are not progressing at the same speed. While the overall research project involves exploratory research using mixed methods, the focus of this paper is on a quantitative analysis of responses obtained from a survey of Saudi customers, with the design of the questionnaire instrument being based on the findings of a qualitative analysis reported in a previous paper. The main findings of the current analysis include a list of key factors that affect Saudi customers' purchase from Saudi online retailers, and quantitative indications of the relative strengths of the various relationships. ",Factors influencing the decision of Saudi consumers to purchase form   online retailers: Quantitative Analysis
"  In this work we present some results of the treatment of polydimethylsiloxane (PDMS) surfaces using pulsed dielectric barrier discharge plasmas. The results of plasma treatment using different gases and mixtures, argon, argon plus water vapor, helium, helium plus water vapor, nitrogen and nitrogen plus water vapor, were compared testing the adhesion between two PDMS samples for each kind of plasma. We also studied the water contact angle in function of plasma process time of PDMS surfaces with each kind of plasma treatment. The plasma was characterized by optical emission spectroscopy (OES) to identify the emitting species and determine the plasma temperatures. The plasma temperature for each process was estimated comparing the spectrum obtained by OES with the spectrum generated by SpecAir simulation code. Measurements of power delivered to the plasmas were also performed. As the results, all the process using different gases show good adhesion efficacy between PDMS samples when long exposure time (larger than 150 seconds) is applied. However, when only a few discharges are applied to PDMS samples the helium plasma process presented best results. Atomic Force Microscopy (AFM) analysis of PDMS samples treated with helium plasma showed reduction in the surface roughness, which increase the surface contact area and improves the adhesion. ",Treatment of PDMS surfaces using pulsed DBD plasmas: comparing the use   of different gases and its influence on adhesion
"  We present a study of new Australian Telescope Compact Array (ATCA) observations of supernova remnant, SNR J0536-6735. This remnant appears to follow a shell morphology with a diameter of D=36x29 pc (with 1 pc uncertainty in each direction). There is an embedded Hii region on the northern limb of the remnant which made various analysis and measurements (such as flux density, spectral index and polarisation) difficult. The radio-continuum emission followed the same structure as the optical emission, allowing for extent and flux density estimates at 20 cm. We estimate a surface brightness for the SNR at 1 GHz of 2.55x10^-21 W m^-2 Hz^-1 sr^-1. Also, we detect a distinctive radio-continuum point source which confirms the previous suggestion of this remnant being associated with a pulsar wind nebulae (PWN). The tail of this remnant isn't seen in the radio-continuum images and is only seen in the optical and X-ray images. ",Multifrequency radio observations of SNR J0536-6735 (N 59B) with   associated pulsar
"  Kinematical distributions of decay products of the top quark carry information on the polarisation of the top as well as on any possible new physics in the decay of the top quark. We construct observables in the form of asymmetries in the kinematical distributions to probe their effects. Charged-lepton angular distributions in the decay are insensitive to anomalous couplings to leading order. Hence these can be a robust probe of top polarisation. However, these are difficult to measure in the case of highly boosted top quarks as compared to energy distributions of decay products. These are then sensitive, in general, to both top polarisation and top anomalous couplings. We compare various asymmetries for their sensitivities to the longitudinal polarisation of the top quark as well as to possible new physics in the $Wtb$ vertex, paying special attention to the case of highly boosted top quarks. We perform a $\chi ^2$- analysis to determine the regions in the longitudinal polarisation of the top quark and the couplings of the $Wtb$ vertex constrained by different combinations of the asymmetries. Moreover, we find that use of observables sensitive to the longitudinal top polarisation can add to the sensitivity to which the $Wtb$ vertex can be probed. ",Longitudinal top polarisation measurement and anomalous $Wtb$ coupling
"  We built three models for the gravitational field of the Galactic bar. These models are an inhomogeneous ellipsoid, an inhomogeneous prolate spheroid, and a superposition of four inhomogeneous ellipsoids. Among the three models, the superposition provides our best approximation to the observed boxy mass distribution of the Galactic bar. Adding the bar component to an axisymmetric Galactic model, we have calculated stellar midplane orbits and orbits of some globular clusters with known kinematical data. For all models we find a secular dispersion effect upon the orbital energy and angular momentum, as measured in the Galactic inertial frame. This effect might be relevant to explain the orbital prograde-retrograde distribution of globular clusters. For the stellar kinematics, we study the connection between the sense of orbital motion in the midplane and the onset of chaos in the presence of the bar. In the inner region of the bar, chaos is induced by an axisymmetric central component (bulge) and it arises in orbits that change its orbital sense from prograde to retrograde and vice versa as seen from an inertial reference frame. Outside the bar region, chaos appears only in prograde orbits. Our results concerning such connection are consistent and extend those obtained for midplane orbits in the presence of only a spiral pattern in the axisymmetric Galactic model. ",Models for the Gravitational Field of the Galactic Bar. An Application   to Stellar Orbits in the Galactic Plane and Orbits of Some Globular Clusters
"  This paper studies marijuana-related tweets in social network Twitter. We collected more than 300,000 marijuana related tweets during November 2016 in our study. Our text-mining based algorithms and data analysis unveil some interesting patterns including: (i) users' attitudes (e.g., positive or negative) can be characterized by the existence of outer links in a tweet; (ii) 67% users use their mobile phones to post their messages while many users publish their messages using third-party automatic posting services; and (3) the number of tweets during weekends is much higher than during weekdays. Our data also showed the impact of the political events such as the U.S. presidential election or state marijuana legalization votes on the marijuana-related tweeting frequencies. ",Evaluating Marijuana-Related Tweets On Twitter
  We report the implementation of the central building block of the Schulman-Vazirani procedure for fully polarizing a subset of two-level quantum systems which are initially only partially polarized. This procedure consists of a sequence of unitary operations and incurs only a quasi-linear overhead in the number of quantum systems and operations required. The key building block involves three quantum systems and was implemented on a homonuclear three-spin system using room temperature liquid state nuclear magnetic resonance (NMR) techniques. This work was inspired by the state initialization challenges in current NMR quantum computers but also shines new light on polarization transfer in NMR. ,NMR implementation of a building block for scalable quantum computation
"  Developing advanced diagnosis tools to detect cyber attacks is the key to security of power systems. It has been shown that multivariate data injection attacks can bypass bad data detection schemes typically built on static behavior of the systems, which misleads operators to disruptive decisions. In this article, we depart from the existing static viewpoint to develop a diagnosis filter that captures the dynamics signatures of such a multivariate intrusion. To this end, we introduce a dynamic residual generator approach formulated as robust optimization programs in order to detect a class of disruptive multivariate attacks that potentially remain stealthy in view of a static bad data detector. We investigate two possible desired features: (i) a non-zero transient and (ii) a non-zero steady-state behavior of the residual generator in the presence of an attack. In case (i), the problem is reformulated as a finite, but possibly non-convex, optimization program. We further develop a linear programming relaxation that improves the scalability, and as such practicality, of the diagnosis filter design. In case (ii), it turns out that the resulting robust program admits an exact convex reformulation, yielding a Nash equilibrium between the attacker and the residual generator. This assertion has an interesting implication: the proposed approach is not conservative in the sense that the additional knowledge of the worst-case attack does not improve the diagnosis performance. To illustrate our theoretical results, we implement the proposed diagnosis filter to detect multivariate attacks on the system measurements deployed to generate the so-called Automatic Generation Control signals in a three-area IEEE 39-bus system. ",From Static to Dynamic Anomaly Detection with Application to Power   System Cyber Security
"  High-fidelity quantum operations are a key requirement for fault-tolerant quantum information processing. In electron spin resonance, manipulation of the quantum spin is usually achieved with time-dependent microwave fields. In contrast to the conventional dynamic approach, adiabatic geometric phase operations are expected to be less sensitive to certain kinds of noise and field inhomogeneities. Here, we investigate such phase gates applied to electron spins both through simulations and experiments, showing that the adiabatic geometric phase gate is indeed inherently robust against inhomogeneity in the applied microwave field strength. While only little advantage is offered over error-correcting composite pulses for modest inhomogeneities <=10%, the adiabatic approach reveals its potential for situations where field inhomogeneities are unavoidably large. ",Geometric Phase Gates with Adiabatic Control in Electron Spin Resonance
"  Dynamics of the disordered heavy Fermion model of Dobrosavljevic et al. are calculated using an expression for the spectral function of the Anderson model which is consistent with quantum Monte Carlo results. We compute the self-energy for three distributions of Kondo scales including the distribution of Bernal et al. for UCu{5-x}Pd{x}. The corresponding low temperature optical conductivity shows a low-frequency pseudogap, a negative optical mass enhancement, and a linear in frequency transport scattering rate, consistent with results in Y{1-x}U{x}Pd{3} and UCu{5-x}Pd{x}. ",Dynamics of disordered heavy Fermion systems
"  We present an extensive numerical study of the Sherrington-Kirkpatrick model in transverse field. Recent numerical studies of quantum spin-glasses have focused on exact diagonalization of the full Hamiltonian for small systems ($\approx$ 20 spins). However, such exact numerical treatments are difficult to apply on larger systems. We propose making an approximation by using only a subspace of the full Hilbert space spanned by low-lying excitations consisting of one-spin flipped and two-spin flipped states. The approximation procedure is carried out within the theoretical framework of Hartree-Fock approximation and Configuration Interaction. Although not exact, our approach allows us to study larger system sizes comparable to that achievable by state of the art Quantum Monte Carlo simulations. We calculate two quantities of interest due to recent advances in quantum annealing, the ground-state energy and the energy gap between the ground and first excited state. For the energy gap, we derive a novel formula that enables it to be calculated using just the ground-state wavefunction, thereby circumventing the need to diagonalize the Hamiltonian. We calculate the scalings of the energy gap and the leading correction to the extensive part of the ground-state energy with system size, which are difficult to obtain with current methods. ",Effects of low-lying excitations on ground-state energy and energy gap   of Sherrington-Kirkpatrick model in transverse field
"  We propose a correspondence between brane-antibrane systems and stable triples (E_1,E_2,T), where E_1,E_2 are holomorphic vector bundles and the tachyon T is a map between them. We demonstrate that, under the assumption of holomorphicity, the brane-antibrane field equations reduce to a set of vortex equations, which are equivalent to the mathematical notion of stability of the triple. We discuss some examples and show that the theory of stable triples suggests a new notion of BPS bound states and stability, and curious relations between brane-antibrane configurations and wrapped branes in higher dimensions. ",Brane-Antibrane Systems on Calabi-Yau Spaces
"  A thorough critical literature survey has been carried out for reliable measurements of oxygen and neon abundances of planetary nebulae (PNe) and HII regions. By contrasting the results of PNe and of HII regions, we aim to address the issues of the evolution of oxygen and neon in the interstellar medium (ISM) and in the late evolutionary phases of low- and intermediate-mass stars (LIMS), as well as the currently hotly disputed solar Ne/O abundance ratio. Through the comparisons, we find that neon abundance and Ne/O ratio increase with increasing oxygen abundance in both types of nebulae, with positive correlation coefficients larger than 0.75. The correlations suggest different enrichment mechanisms for oxygen and neon in the ISM, in the sense that the growth of neon is delayed compared to oxygen. The differences of abundances between PNe and HII regions, are mainly attributed to the results of nucleosynthesis and dredge-up processes that occurred in the progenitor stars of PNe. We find that both these alpha-elements are significantly enriched at low metallicity (initial oxygen abundance <= 8.0) but not at metallicity higher than the SMC. The fact that Ne/O ratios measured in PNe are almost the same as those in HII regions, regardless of the metallicity, suggests a very similar production mechanism of neon and oxygen in intermediate mass stars (IMS) of low initial metallicities and in more massive stars, a conjecture that requires verification by further theoretical studies. This result also strongly suggests that both the solar neon abundance and the Ne/O ratio should be revised upwards by ~0.22 dex from the Asplund, Grevesse & Sauval values or by ~0.14 dex from the Grevesse & Sauval values. ",Are oxygen and neon enriched in PNe and is the current solar Ne/O   abundance ratio underestimated?
"  A diagonalization scheme for the Rabi Hamiltonian, which describes a qubit interacting with a single-mode radiation field via a dipole interaction, is proposed. It is shown that the Rabi Hamiltonian can be solved almost exactly using a progressive scheme that involves a finite set of one variable polynomial equations. The scheme is especially efficient for lower part of the spectrum. Some low-lying energy levels of the model with several sets of parameters are calculated and compared to those provided by the recently proposed generalized rotating-wave approximation and full matrix diagonalization. ",A progressive diagonalization scheme for the Rabi Hamiltonian
"  The observability of gravitational waves from supermassive and intermediate-mass black holes by the forecoming Laser Interferometer Space Antenna (LISA), and the physics we can learn from the observations, will depend on two basic factors: the event rates for massive black hole mergers occurring in the LISA best sensitivity window, and our theoretical knowledge of the gravitational waveforms. We first provide a concise review of the literature on LISA event rates for massive black hole mergers, as predicted by different formation scenarios. Then we discuss what (in our view) are the most urgent issues to address in terms of waveform modelling. For massive black hole binary inspiral these include spin precession, eccentricity, the effect of high-order Post-Newtonian terms in the amplitude and phase, and an accurate prediction of the transition from inspiral to plunge. For black hole ringdown, numerical relativity will ultimately be required to determine the relative quasinormal mode excitation, and to reduce the dimensionality of the template space in matched filtering. ",LISA observations of massive black hole mergers: event rates and issues   in waveform modelling
"  The amplitudes for boson-boson and fermion-boson interactions are calculated in the second order of perturbation theory in the Lobachevsky space. An essential ingredient of the used model is the Weinberg's $2(2j+1)$ component formalism for describing a particle of spin $j$, recently developed substantially. The boson-boson amplitude is then compared with the two-fermion amplitude obtained long ago by Skachkov on the ground of the hamiltonian formulation of quantum field theory on the mass hyperboloid, $p_0^2 -{\bf p}^2=M^2$, proposed by Kadyshevsky. The parametrization of the amplitudes by means of the momentum transfer in the Lobachevsky space leads to same spin structures in the expressions of $T$ matrices for the fermion and the boson cases. However, certain differences are found. Possible physical applications are discussed. ",Interactions of a $j=1$ boson in the $2(2j+1)$ component theory
"  The use of specific tracers of the dense molecular gas phase can help to explore the feedback of activity on the interstellar medium (ISM) in galaxies. This information is a key to any quantitative assessment of the efficiency of the star formation process in galaxies. We present the results of a survey devoted to probe the feedback of activity through the study of the excitation and chemistry of the dense molecular gas in a sample of local universe starbursts and active galactic nuclei (AGNs). Our sample includes also 17 luminous and ultraluminous infrared galaxies (LIRGs and ULIRGs). From the analysis of the LIRGs/ULIRGs subsample, published in Gracia-Carpio et al.(2007) we find the first clear observational evidence that the star formation efficiency of the dense gas, measured by the L_FIR/L_HCN ratio, is significantly higher in LIRGs and ULIRGs than in normal galaxies. Mounting evidence of overabundant HCN in active environments would even reinforce the reported trend, pointing to a significant turn upward in the Kennicutt-Schmidt law around L_FIR=10^11 L_sun. This result has major implications for the use of HCN as a tracer of the dense gas in local and high-redshift luminous infrared galaxies. ",Molecular line probes of activity in galaxies
"  For the ring of differential operators on a smooth affine algebraic variety $X$ over a field of characteristic zero a finite set of algebra generators and a finite set of defining relations are found explicitly. As a consequence, a finite set of generators and a finite set of defining relations are given for the module $\Der_K(\OO (X))$ of derivations on the algebra $\OO (X)$ of regular functions on the variety $X$. For the variety $X$ which is not necessarily smooth, a set of natural derivations ${\rm der}_K(\OO (X))$ of the algebra $\OO (X)$ and a ring $\gD (\OO (X))$ of natural differential operators on $\OO (X)$ are introduced. The algebra $\gD (\OO (X))$ is a Noetherian algebra of Gelfand-Kirillov dimension $2\dim (X)$. When $X$ is smooth then ${\rm der}_K(\OO (X))=\Der_K(\OO (X))$ and $\gD (\OO (X))=\CD (\OO (X))$. A criterion of smoothness of $X$ is given when $X$ is irreducible ($X$ is smooth iff $\gD (\OO (X))$ is a simple algebra iff $\OO (X)$ is a simple $\gD (\OO (X))$-module). The same results are true for regular algebras of essentially finite type. For a singular irreducible affine algebraic variety $X$, in general, the algebra of differential operators $\CD (\OO (X))$ needs not be finitely generated nor (left or right) Noetherian, it is proved that each term $\CD (\OO (X))_i$ of the order filtration $\CD (\OO (X))=\cup_{i\geq 0}\CD (\OO (X))_i$ is a finitely generated left $\OO (X)$-module. ",Generators and defining relations for the ring of differential operators   on a smooth affine algebraic variety
"  Lower bounds on the proof-theoretic strength of the graph minor theorem were found over 30 years ago by Friedman, Robertson and Seymour 1987, but upper bounds have always been elusive. We present recently found upper bounds on the graph minor theorem and other theorems appearing in the Graph Minors series. Further, we give some ideas as to how the lower bounds on some of these theorems might be improved. ",Upper bounds on the graph minor theorem
"  In this article we address the theoretical study of a multiscale drift-diffusion (DD) model for the description of photoconversion mechanisms in organic solar cells. The multiscale nature of the formulation is based on the co-presence of light absorption, conversion and diffusion phenomena that occur in the three-dimensional material bulk, of charge photoconversion phenomena that occur at the two-dimensional material interface separating acceptor and donor material phases, and of charge separation and subsequent charge transport in each three-dimensional material phase to device terminals that are driven by drift and diffusion electrical forces. The model accounts for the nonlinear interaction among four species: excitons, polarons, electrons and holes, and allows to quantitatively predict the electrical current collected at the device contacts of the cell. Existence and uniqueness of weak solutions of the DD system, as well as nonnegativity of all species concentrations, are proved in the stationary regime via a solution map that is a variant of the Gummel iteration commonly used in the treatment of the DD model for inorganic semiconductors. The results are established upon assuming suitable restrictions on the data and some regularity property on the mixed boundary value problem for the Poisson equation. The theoretical conclusions are numerically validated on the simulation of three-dimensional problems characterized by realistic values of the physical parameters. ",Solution Map Analysis of a Multiscale Drift-Diffusion Model for Organic   Solar Cells
"  The next generation of CMB experiments can measure cosmological parameters with unprecedented accuracy - in principle. To achieve this in practice when faced with such gigantic data sets, elaborate data analysis methods are needed to make it computationally feasible. An important step in the data pipeline is to make a map, which typically reduces the size of the data set my orders of magnitude. We compare ten map-making methods, and find that for the Gaussian case, both the method used by the COBE DMR team and various variants of Wiener filtering are optimal in the sense that the map retains all cosmological information that was present in the time-ordered data (TOD). Specifically, one obtains just as small error bars on cosmological parameters when estimating them from the map as one could have obtained by estimating them directly from the TOD. The method of simply averaging the observations of each pixel (for total-power detectors), on the contrary, is found to generally destroy information, as does the maximum entropy method and most other non-linear map-making techniques.   Since it is also numerically feasible, the COBE method is the natural choice for large data sets. Other lossless (e.g. Wiener-filtered) maps can then be computed directly from the COBE method map. ",How to make maps from CMB data without losing information
"  We use the techniques of effective field theory in an expanding universe to examine the effect of choosing an excited inflationary initial state built over the Bunch-Davies state on the CMB bi-spectrum. We find that even for Hadamard states, there are unexpected enhancements in the bi-spectrum for certain configurations in momentum space due to interactions of modes in the early stages of inflation. These enhancements can be parametrically larger than the standard ones and are potentially observable in current and future data. These initial state effects have a characteristic signature in $l$-space which distinguishes them from the usual contributions, with the enhancement being most pronounced for configurations corresponding to flattened triangles for which two momenta are collinear. ",Enhanced Non-Gaussianity from Excited Initial States
"  We provide an atomic decomposition of the product Hardy spaces $H^p(\widetilde{X})$ which were recently developed by Han, Li, and Ward in the setting of product spaces of homogeneous type $\widetilde{X} = X_1 \times X_2$. Here each factor $(X_i,d_i,\mu_i)$, for $i = 1$, $2$, is a space of homogeneous type in the sense of Coifman and Weiss.   These Hardy spaces make use of the orthogonal wavelet bases of Auscher and Hyt\""onen and their underlying reference dyadic grids.   However, no additional assumptions on the quasi-metric or on the doubling measure for each factor space are made. To carry out this program, we introduce product $(p,q)$-atoms on $\widetilde{X}$ and product atomic Hardy spaces $H^{p,q}_{{\rm at}}(\widetilde{X})$. As consequences of the atomic decomposition of $H^p(\widetilde{X})$, we show that for all $q > 1$ the product atomic Hardy spaces coincide with the product Hardy spaces, and we show that the product Hardy spaces are independent of the particular choices of both the wavelet bases and the reference dyadic grids. Likewise, the product Carleson measure spaces ${\rm CMO}^p(\widetilde{X})$, the bounded mean oscillation space ${\rm BMO}(\widetilde{X})$, and the vanishing mean oscillation space ${\rm VMO}(\widetilde{X})$, as defined by Han, Li, and Ward, are also independent of the particular choices of both wavelets and reference dyadic grids. ",Atomic decomposition of product Hardy spaces via wavelet bases on spaces   of homogeneous type
"  Job transitions and upskilling are common actions taken by many industry working professionals throughout their career. With the current rapidly changing job landscape where requirements are constantly changing and industry sectors are emerging, it is especially difficult to plan and navigate a predetermined career path. In this work, we implemented a system to automate the collection and classification of training videos to help job seekers identify and acquire the skills necessary to transition to the next step in their career. We extracted educational videos and built a machine learning classifier to predict video relevancy. This system allows us to discover relevant videos at a large scale for job title-skill pairs. Our experiments show significant improvements in the model performance by incorporating embedding vectors associated with the video attributes. Additionally, we evaluated the optimal probability threshold to extract as many videos as possible with minimal false positive rate. ",Automated Discovery and Classification of Training Videos for Career   Progression
"  We examine whether we can make a black hole in Fisher information spacetime and what kind of quantum states produce the black hole solution in terms of the anti-de Sitter spacetime/conformal field theory correspondence. Here we focus on the Banados-Teitelboim-Zanelli black hole. There exists a mathematical representation of entanglement spectra that define the Fisher geometry as the black hole spacetime. We find that this representation is quite similar to the entanglement spectra in a conformal field theory at finite temperature except for minor corrections, and then the inverse temperature corresponds to the position of the event horizon in the Poincare coordinate. ",BTZ Black Hole in Fisher Information Spacetime
"  Pure three-qubit states have five algebraically independent and one algebraically dependent polynomial invariants under local unitary transformations and an arbitrary entanglement measure is a function of these six invariants. It is shown that if the reduced density operator of a some qubit is a multiple of the unit operator, than the geometric entanglement measure of the pure three-qubit state is absolutely independent of the polynomial invariants and is a constant for such tripartite states. Hence a one-particle completely mixed state is a critical point for the geometric measure of entanglement. ",Completely mixed state is a critical point for three-qubit entanglement
"  This paper proposes a genetic algorithm assisted hybrid signal to leakage plus noise ratio (SLNR) beamforming design for wireless fronthaul scenario. The digital precoder of the proposed hybrid SLNR beamforming is expressed in closed-form. Highly limited phase resolution (one-bit resolution) is assumed at the phase shifters at the analog precoder. The analog precoders maximizing the approximated sum rate are presented. Genetic algorithms are used to search for optimal solutions of one-bit analog precoders. In contrast to common assumptions on perfect knowledge of the true channel matrix at the transmitter, the proposed method relies only on the distorted channel matrix after the analog precoder. Performance of the proposed hybrid SLNR beamforming with limited phase resolution at the analog precoder can achieve performance close to digital beamforming in single cell wireless fronthaul scenarios. It is also shown that hybrid beamforming can result in undesired beams causing intercell interference in multicell wireless fronthaul scenarios. ",Genetic Algorithm Assisted Hybrid Beamforming for Wireless Fronthaul
"  The purpose of the paper is to predict the temperature at the fundamental blue edge (FBE) of the instability strip for RR Lyrae (RRL) variables from the pulsation equation that relates temperature to period, luminosity, and mass. Modern data for the correlations between period, luminosity, and metallicity at the FBE for field and cluster RRL are used for the temperature calculation. The predicted temperatures are changed to B-V colors using an adopted color transformation. The predicted temperatures at the FBE become hotter as [Fe/H] changes from 0 to -1.5, and thereafter cooler as the metallicity decreases to -2.5 and beyond. The temperature range over this interval of metallicity is $\Delta$log $T_e$ = 0.04, or 640 K at 6900K. The predicted color variation is at the level of 0.03 mag in B-V. The predictions are compared with the observed RRL colors at the FBE for both the field and cluster variables, showing general agreement at the level of 0.02 mag in (B-V)$_o$, which, however, is the uncertainty of the reddening corrections.   The focus of the problem is then reversed by fitting a better envelope to the observed FBE relation between color and metallicity for metallicities smaller than -1.8 which, when inserted in the pulsation equation, gives a non-linear calibration .... ",On the Predicted and Observed Color Boundaries of the RR Lyrae   Instability Strip as a Function of Metallicity
  We give coordinate-minimal geometric realizations in general position for 17 of the 20 vertex-minimal triangulations of the orientable surface of genus 3 in the 5x5x5-cube. ,Polyhedra of genus 3 with 10 vertices and minimal coordinates
"  The \textit{Distinguishing Chromatic Number} of a graph $G$, denoted $\chi_D(G)$, was first defined in \cite{collins} as the minimum number of colors needed to properly color $G$ such that no non-trivial automorphism $\phi$ of the graph $G$ fixes each color class of $G$. In this paper, we consider random Cayley graphs $\Gamma(A,S)$ defined over certain abelian groups $A$ and show that with probability at least $1-n^{-\Omega(\log n)}$ we have, $\chi_D(\Gamma)\le\chi(\Gamma) + 1$. ",Distinguishing Chromatic Number of Random Cayley graphs
"  Using a sample of 9.7 million B meson pairs collected with the CLEO detector, we study B decays to the chi_c1 and chi_c2 charmonia states, which are reconstructed via their radiative decays to J/psi. We first measure the branching fraction for inclusive chi_c1 production in B decays to be Br(B->chi_c1 X)=(4.14+-0.31+-0.40)*10^-3, where the first uncertainty is statistical and the second one is systematic. We derive the branching fractions for direct chi_c1 and chi_c2 production in B decays by subtracting the known contribution of the decay chain B->psi(2S)X with psi(2S)->chi_c1,2 gamma. We obtain Br[B->chi_c1(direct) X]=(3.83+-0.31+-0.40)*10^-3. No statistically significant signal for chi_c2 production is observed in either case. Using the Feldman-Cousins approach, we determine the 95% confidence intervals to be [0.2, 2.0]*10^-3 for Br(B->chi_c2 X), [0.0,1.7]*10^-3 for Br[B->chi_c2(direct) X], and [0.00,0.44] for the ratio Br[B->chi_c2(direct) X]/Br[B->chi_c1(direct) X]. We also measure the branching ratio Br[B->chi_c2(direct) X_s]/Br[B->chi_c1(direct) X_s] for different X_s configurations by reconstructing B decays into exclusive final states with J/psi, a photon, a kaon, and up to four pions. For all the X_s configurations we observe a strong chi_c1 signal yet no statistically significant chi_c2 signal. We discuss how our results compare with theoretical predictions in different models of charmonium production. ",Study of $\chi_{c1}$ and $\chi_{c2}$ Meson Production in B Meson Decays
"  Calculations of B(E2)'s and quadruplole moments in the g_{9/2 region below ^{100} Sn are hampered by the fact that the inclusion of the g_{7/2}configuration leads to model spaces that are too large to handle. We therefore examine lighter nuclei if the fp region where one can easily include all the orbitals, f,{}_{7/2}, p_{3/2}, p_{1/2}and f_{5/2} . We perform such calculations but then take a step back and exclude the f_{5/2} orbital. By comparing the 2 calculations we can hope to get insight into the importance of the missing spin-orbit partner in other regions. ",Consequences of omitting spin-orbit partner configurations on B(E2)'s   and quadrupole moments in nuclei
"  Here, we study the paramagnetic ions behavior in presence of a strong microwave electromagnetic field sustained inside a cryogenic sapphire whispering gallery mode resonator. The high frequency measurement resolution that can be now achieved by comparing two CSOs permit for the first time to observe clearly the non-linearity of the resonator power sensitivity. These observations that in turn allow us to optimize the CSO operation, are well explained by the Electron Spin Resonance (ESR) saturation of the paramagnetic impurities contained in the sapphire crystal. ",Influence of the ESR saturation on the power sensitivity of cryogenic   sapphire resonators
"  Parity is a key observable in nuclear spectroscopy. Linear polarization measurements of $\gamma$-rays are a probe to access the parities of energy levels. Utilizing the segmentation of detectors in the Segmented Germanium Array (SeGA) at the NSCL and analyzing the positions of interaction therein allows the detectors to be used as Compton polarimeters. Unlike other segmented detectors, SeGA detectors are irradiated from the side to utilize the transversal segmentation for better Doppler corrections. Sensitivity in such an orientation has previously been untested. A linear polarization sensitivity $Q \approx 0.14$ has been measured in the 350-keV energy range for SeGA detectors using $\alpha$-$\gamma$ correlations from a \nuc{249}{Cf} source. ",Linear polarization sensitivity of SeGA detectors
"  We successfully demonstrate a quantum gas microscopy using the Faraday effect which has an inherently non-destructive nature. The observed Faraday rotation angle reaches 3.0(2) degrees for a single atom. We reveal the non-destructive feature of this Faraday imaging method by comparing the detuning dependence of the Faraday signal strength with that of the photon scattering rate. We determine the atom distribution with deconvolution analysis. We also demonstrate the absorption and the dark field Faraday imaging, and reveal the different shapes of the point spread functions for these methods, which are fully explained by theoretical analysis. Our result is an important first step towards an ultimate quantum non-demolition site-resolved imaging and furthermore opens up the possibilities for quantum feedback control of a quantum many-body system with a single-site resolution. ",Site-resolved imaging of single atoms with a Faraday quantum gas   microscope
"  Within the framework of perturbation theory, we explore in detail the mixing of orbital angular momentum(OAM) modes due to a fiber bend in a step-index multimode fiber. Using scalar wave equation, we develop a complete set of analytic expressions for mode-mixing, including those for the $2\pi$ walk-off length, which is the distance traveled within the bent fiber before an OAM mode transforms into its negative topological charge counterpart, and back into itself. The derived results provide insight into the nature of the bend effects, clearly revealing the mathematical dependence on the bend radius and the topological charge. We numerically simulate the theoretical results with applications to a few-mode fiber and a multimode fiber, and calculate bend-induced modal crosstalk with implications for mode-multiplexed systems. The presented perturbation technique is general enough to be applicable to other perturbations like ellipticity and easily extendable to other fibers with step-index-like profile as in the ring fiber. ",Orbital Angular Momentum (OAM) Mode Mixing in a Bent Step Index Fiber in   Perturbation Theory
"  In this paper, we have extended the well-established universal approximator theory to neural networks that use the unbounded ReLU activation function and a nonlinear softmax output layer. We have proved that a sufficiently large neural network using the ReLU activation function can approximate any function in $L^1$ up to any arbitrary precision. Moreover, our theoretical results have shown that a large enough neural network using a nonlinear softmax output layer can also approximate any indicator function in $L^1$, which is equivalent to mutually-exclusive class labels in any realistic multiple-class pattern classification problems. To the best of our knowledge, this work is the first theoretical justification for using the softmax output layers in neural networks for pattern classification. ",On Approximation Capabilities of ReLU Activation and Softmax Output   Layer in Neural Networks
"  We address the problem of generating a high-resolution surface reconstruction from a single image. Our approach is to learn a Higher Order Function (HOF) which takes an image of an object as input and generates a mapping function. The mapping function takes samples from a canonical domain (e.g. the unit sphere) and maps each sample to a local tangent plane on the 3D reconstruction of the object. Each tangent plane is represented as an origin point and a normal vector at that point. By efficiently learning a continuous mapping function, the surface can be generated at arbitrary resolution in contrast to other methods which generate fixed resolution outputs. We present the Surface HOF in which both the higher order function and the mapping function are represented as neural networks, and train the networks to generate reconstructions of PointNet objects. Experiments show that Surface HOF is more accurate and uses more efficient representations than other state of the art methods for surface reconstruction. Surface HOF is also easier to train: it requires minimal input pre-processing and output post-processing and generates surface representations that are more parameter efficient. Its accuracy and convenience make Surface HOF an appealing method for single image reconstruction. ",Surface HOF: Surface Reconstruction from a Single Image Using Higher   Order Function Networks
"  The study of social networks is a burgeoning research area. However, most existing work deals with networks that simply encode whether relationships exist or not. In contrast, relationships in signed networks can be positive (""like"", ""trust"") or negative (""dislike"", ""distrust""). The theory of social balance shows that signed networks tend to conform to some local patterns that, in turn, induce certain global characteristics. In this paper, we exploit both local as well as global aspects of social balance theory for two fundamental problems in the analysis of signed networks: sign prediction and clustering. Motivated by local patterns of social balance, we first propose two families of sign prediction methods: measures of social imbalance (MOIs), and supervised learning using high order cycles (HOCs). These methods predict signs of edges based on triangles and \ell-cycles for relatively small values of \ell. Interestingly, by examining measures of social imbalance, we show that the classic Katz measure, which is used widely in unsigned link prediction, actually has a balance theoretic interpretation when applied to signed networks. Furthermore, motivated by the global structure of balanced networks, we propose an effective low rank modeling approach for both sign prediction and clustering. For the low rank modeling approach, we provide theoretical performance guarantees via convex relaxations, scale it up to large problem sizes using a matrix factorization based algorithm, and provide extensive experimental validation including comparisons with local approaches. Our experimental results indicate that, by adopting a more global viewpoint of balance structure, we get significant performance and computational gains in prediction and clustering tasks on signed networks. Our work therefore highlights the usefulness of the global aspect of balance theory for the analysis of signed networks. ",Prediction and Clustering in Signed Networks: A Local to Global   Perspective
"  We investigate multiplicity and symmetry properties of higher eigenvalues and eigenfunctions of the $p$-Laplacian under homogeneous Dirichlet boundary conditions on certain symmetric domains $\Omega \subset \mathbb{R}^N$. By means of topological arguments, we show how symmetries of $\Omega$ help to construct subsets of $W_0^{1,p}(\Omega)$ with suitably high Krasnosel'ski\u{\i} genus. In particular, if $\Omega$ is a ball $B \subset \mathbb{R}^N$, we obtain the following chain of inequalities: $$ \lambda_2(p;B) \leq \dots \leq \lambda_{N+1}(p;B) \leq \lambda_\ominus(p;B). $$ Here $\lambda_i(p;B)$ are variational eigenvalues of the $p$-Laplacian on $B$, and $\lambda_\ominus(p;B)$ is the eigenvalue which has an associated eigenfunction whose nodal set is an equatorial section of $B$. If $\lambda_2(p;B)=\lambda_\ominus(p;B)$, as it holds true for $p=2$, the result implies that the multiplicity of the second eigenvalue is at least $N$. In the case $N=2$, we can deduce that any third eigenfunction of the $p$-Laplacian on a disc is nonradial. The case of other symmetric domains and the limit cases $p=1$, $p=\infty$ are also considered. ",On multiplicity of eigenvalues and symmetry of eigenfunctions of the   $p$-Laplacian
"  The amount of data generated by scientific and commercial applications is growing at an ever-increasing pace. This data is often moved between geographically distributed sites for various purposes such as collaboration and backup which has led to significant increase in data transfer rates. Surge in data transfer rates when combined with proliferation of scientific applications that cannot tolerate data corruption triggered enhanced integrity verification techniques to be developed. End-to-end integrity verification minimizes the likelihood of silent data corruption by comparing checksum of files at source and destination servers using secure hash algorithms such as MD5 and SHA1. However, it imposes significant performance penalty due to overhead of checksum computation. In this paper, we propose Fast Integrity VERification (FIVER) algorithm which overlaps checksum computation and data transfer operations of files to minimize the cost of integrity verification. Extensive experiments show that FIVER is able to bring down the cost from 60% by the state-of-the-art solutions to below 10% by concurrently executing transfer and checksum operations and enabling file I/O share between them. We also implemented FIVER-Hybrid to mimic disk access patterns of sequential integrity verification approach to capture possible data corruption that may occur during file write operations which FIVER may miss. Results show that FIVER-Hybrid is able to reduce execution time by 20% compared to sequential approach without compromising the reliability of integrity verification. ",Fast Integrity Verification for High-Speed File Transfers
"  We study the phase behavior of hard spheres confined between two parallel hard plates using extensive computer simulations. We determine the full equilibrium phase diagram for arbitrary densities and plate separations from one to five hard-sphere diameters using free energy calculations. We find a first-order fluid-solid transition, which corresponds to either capillary freezing or melting depending on the plate separation. The coexisting solid phase consists of crystalline layers with either triangular or square symmetry. Increasing the plate separation, we find a sequence of crystal structures from n triangular to (n+1) square to (n+1) triangular, where n is the number of crystal layers, in agreement with experiments on colloids. At high densities, the transition between square to triangular phases are intervened by intermediate structures, e.g., prism, buckled, and rhombic phases. ",Phase behavior of hard spheres confined between parallel hard plates:   Manipulation of colloidal crystal structures by confinement
"  The surface chemical composition of this remarkable star shows that it is hydrogen-deficient, carbon-rich and enriched in the light s-process elements. Spectra taken in May and October 1996 indicate a decrease in the surface hydrogen abundance by 0.7 dex in five months along with an increase in the abundances of Li, Sr, Y and Zr. The abundance changes are in agreement with the hypothesis of the star being a rapidly evolving ``born-again'' AGB star experiencing a final He-shell flash, similar to FG Sge. The C^12/C^13 ratio in October is very low, also suggesting hydrogen ingestion. By chemical composition, Sakurai's object resembles the R Coronae Borealis (R CrB) stars. ",A stellar endgame -- the born-again Sakurai's object
"  We consider self-similar potential flow for compressible gas with polytropic pressure law. Self-similar solutions arise as large-time asymptotes of general solutions, and as exact solutions of many important special cases like Mach reflection, multidimensional Riemann problems, or flow around corners. Self-similar potential flow is a quasilinear second-order PDE of mixed type which is hyperbolic at infinity (if the velocity is globally bounded). The type in each point is determined by the local pseudo-Mach number L, with L<1 resp. L>1 corresponding to elliptic resp. hyperbolic regions. We prove an ellipticity principle: the interior of a parabolic-elliptic region of a sufficiently smooth solution must be elliptic; in fact $L$ must be bounded above away from 1 by a domain-dependent function. In particular there are no open parabolic regions. We also discuss the case of slip boundary conditions at straight solid walls. ",The ellipticity principle for selfsimilar polytropic potential flow
"  Recently there has been a lot of attention focussed on a virialized halo-based approach to understanding the properties of the matter and galaxy power spectrum. We show that this model allows a natural treatment of the large and small scale redshift space distortions, which we develop here, which extends the pedagogical value of the approach. ",The redshift space power spectrum in the halo model
"  In general the experiments on the linear optical properties of a single-layer two-dimensional atomic crystal are interpreted by modeling it as a homogeneous slab with an effective thickness. Here I fit the most remarkable experiments in graphene optics by using the Fresnel coefficients, fixing both the surface susceptibility and the surface conductivity of graphene. It is shown that the Fresnel coefficients and the slab model are not equivalent. Experiments indicate that the Fresnel coefficients are able to simulate the overall experiments here analyzed, while the slab model fails to predict absorption and the phase of the reflected light. ",Fresnel coefficients of a two-dimensional atomic crystal
"  Lattice Monte Carlo simulations now include the effects of 2 light sea quarks and 1 strange sea quark through the use of an improved staggered fermion action. Consequently, results important to phenomenology are free of the approximate 10% errors inherent in the quenched approximation. This talk reports on calculations of the B and Bs decay constants and B -> pi l nu form factors. Accurate determinations of these quantities will lead to tighter constraints on CKM matrix elements. ",B Decays on the Lattice and Results for Phenomenology
"  Modern numerical simulations of the formation of the first stars predict that the first stars formed in multiples. In those cases, the chemical yields of multiple supernova explosions may have contributed to the formation of a next generation star. We match the chemical abundances of the oldest observed stars in the universe to a database of theoretical supernova models, to show that it is likely that the first stars formed from the ashes of two or more progenitors. ",Combined Nucleosynthetic Yields of Multiple First Stars
"  We construct a locally compact groupoid with the properties in the title. Our example is based closely on constructions used by Higson, Lafforgue, and Skandalis in their work on counterexamples to the Baum-Connes conjecture. It is a bundle of countable groups over the one point compactification of the natural numbers, and is Hausdorff, second countable and \'{e}tale. ",A non-amenable groupoid whose maximal and reduced $C^*$-algebras are the   same
"  The use of multivalued controls derived from a special maximal monotone operator are studied in this note. Starting with a strictly passive linear system (with possible parametric uncertainty and external disturbances) a multivalued control law is derived, ensuring regulation of the output to a desired value. The methodology used falls in a passivity-based control context, where we study how the multivalued control affects the dissipation equation of the closed-loop system, from which we derive its robustness properties. Finally, some numerical examples together with implementation issues are presented to support the main result. ",Robust Output Regulation of Linear Passive Systems with Multivalued   Upper Semicontinuous Controls
"  The mammalian olfactory system learns rapidly from very few examples, presented in unpredictable online sequences, and then recognizes these learned odors under conditions of substantial interference without exhibiting catastrophic forgetting. We have developed a brain-mimetic algorithm that replicates these properties, provided that sensory inputs adhere to a common statistical structure. However, in natural, unregulated environments, this constraint cannot be assured. We here present a series of signal conditioning steps, inspired by the mammalian olfactory system, that transform diverse sensory inputs into a regularized statistical structure to which the learning network can be tuned. This pre-processing enables a single instantiated network to be applied to widely diverse classification tasks and datasets - here including gas sensor data, remote sensing from spectral characteristics, and multi-label hierarchical identification of wild species - without adjusting network hyperparameters. ",Signal Conditioning for Learning in the Wild
"  The Sierpinski gasket admits a locally isometric ramified self-covering. A semifinite spectral triple is constructed on the resulting solenoidal space, and its main geometrical features are discussed. ",A Spectral Triple for a Solenoid Based on the Sierpinski Gasket
"  Laman graphs are fundamental to rigidity theory. A graph G with n vertices and m edges is a generic minimally rigid graph (Laman graph), if m=2n-3 and every induced subset of k vertices spans at most 2k-3 edges. We consider the verification problem: Given a graph G with n vertices, decide if it is Laman. We present an algorithm that takes O(T(n)+n log n) time, where T(n) is the best time to extract two edge disjoint spanning trees from G or decide no such trees exist. Our algorithm exploits a known construction called red-black hierarchy (RBH), that is a certificate for Laman graphs. First, we show how to verify if G admits an RBH and argue this is enough to conclude whether G is Laman or not. Second, we show how to construct the RBH using a two steps procedure that is simple and easy to implement. Finally, we point out some difficulties in using red-black hierarchies to compute a Henneberg construction, which seem to imply super-quadratic time algorithms when used for embedding a planar Laman graph as a pointed pseudo-triangulation. ",Towards an optimal algorithm for recognizing Laman graphs
"  We investigate weakly coupled spin-1/2 ladders in a magnetic field. The work is motivated by recent experiments on the compound (C5H12N)2CuBr4 (BPCB). We use a combination of numerical and analytical methods, in particular the density matrix renormalization group (DMRG) technique, to explore the phase diagram and the excitation spectra of such a system. We give detailed results on the temperature dependence of the magnetization and the specific heat, and the magnetic field dependence of the nuclear magnetic resonance (NMR) relaxation rate of single ladders. For coupled ladders, treating the weak interladder coupling within a mean-field or quantum Monte Carlo approach, we compute the transition temperature of triplet condensation and its corresponding antiferromagnetic order parameter. Existing experimental measurements are discussed and compared to our theoretical results. Furthermore we compute, using time dependent DMRG, the dynamical correlations of a single spin ladder. Our results allow to directly describe the inelastic neutron scattering cross section up to high energies. We focus on the evolution of the spectra with the magnetic field and compare their behavior for different couplings. The characteristic features of the spectra are interpreted using different analytical approaches such as the mapping onto a spin chain, a Luttinger liquid (LL) or onto a t-J model. For values of parameters for which such measurements exist, we compare our results to inelastic neutron scattering experiments on the compound BPCB and find excellent agreement. We make additional predictions for the high energy part of the spectrum that are potentially testable in future experiments. ",Statics and dynamics of weakly coupled antiferromagnetic spin-1/2   ladders in a magnetic field
"  The directional spiking infrared and ultraviolet emission from sodium vapors excited to the 4D5/2 level by a continuous-wave resonant laser pump, that constitute a novel feature of the cooperative effects, has been analyzed. Cascade mirrorless lasing at 2207 and 2338 nm on population-inverted transitions and ultraviolet radiation at 330 nm that is generated due to four-wave mixing process demonstrate a high degree of intensity correlation. ",Intensity-correlated spiking infrared and ultraviolet emission from   sodium vapors
"  Spatial modes of light can potentially carry a vast amount of information, making them promising candidates for both classical and quantum communication. However, the distribution of such modes over large distances remains difficult. Intermodal coupling complicates their use with common fibers, while free-space transmission is thought to be strongly influenced by atmospheric turbulence. Here we show the transmission of orbital angular momentum modes of light over a distance of 143 kilometers between two Canary Islands, which is 50 times greater than the maximum distance achieved previously. As a demonstration of the transmission quality, we use superpositions of these modes to encode a short message. At the receiver, an artificial neural network is used for distinguishing between the different twisted light superpositions. The algorithm is able to identify different mode superpositions with an accuracy of more than 80% up to the third mode order, and decode the transmitted message with an error rate of 8.33%. Using our data, we estimate that the distribution of orbital angular momentum entanglement over more than 100 kilometers of free space is feasible. Moreover, the quality of our free-space link can be further improved by the use of state-of-the-art adaptive optics systems. ",Twisted Light Transmission over 143 kilometers
"  In this paper, we present the observations of two successive fast-mode extreme ultraviolet (EUV) wave events observed on 2016 July 23. Both fast-mode waves were observed by the Atmospheric Imaging Assembly (AIA) instrument on board the Solar Dynamics Observatory (SDO) satellite, with a traveling speed of ~ 675 and 640 km/s, respectively. These two wave events were associated with two filament eruptions and two GOES M-class solar flares from the NOAA active region 12565, which was located near the western limb. The EUV waves mainly move toward the south direction. We observed the interaction of the EUV waves with a helmet streamer further away in the south. When either or one of the EUV waves penetrates into the helmet streamer, a slowly propagating wave with a traveling speed of ~ 150 km/s is observed along the streamer. We suggest that the slowly-moving waves are slow-mode waves, and interpret this phenomenon as the magnetohydrodynamic (MHD) wave mode conversion from the fast mode to the slow mode. Besides, we observed several stationary fronts in the north and south of the source region. ",Observations of Two Successive EUV Waves and their Mode Conversion
"  Data recorded by the JADE experiment at the PETRA e^+e^- collider were used to measure distributions of new event shape observables. The distributions were compared with resummed QCD calulations (O(alpha_s^2)+NLLA), and the strong coupling constant alpha_s was determined at \sqrt{s}= 22, 35 and 44 GeV. The results are in agreement with previous combined results of PETRA but have smaller uncertainties. Together with corresponding data from LEP, the energy dependence of alpha_s is significantly tested and is found to be in good agreement with the QCD expectation. ",Determinations of alpha_s using JADE data of e^+e^- Annihilations at   sqrt{s} = 22 to 44 GeV
"  The basic ingredients of the `consistent histories' approach to quantum theory are a space $\UP$ of `history propositions' and a space $\D$ of `decoherence functionals'. In this article we consider such history quantum theories in the case where $\UP$ is given by the set of projectors $\P(\V)$ on some Hilbert space $\V$. We define the notion of a `physical symmetry of a history quantum theory' (PSHQT) and specify such objects exhaustively with the aid of an analogue of Wigner's theorem. In order to prove this theorem we investigate the structure of $\D$, define the notion of an `elementary decoherence functional' and show that each decoherence functional can be expanded as a certain combination of these functionals. We call two history quantum theories that are related by a PSHQT `physically equivalent' and show explicitly, in the case of history quantum mechanics, how this notion is compatible with one that has appeared previously. ",Symmetry and History Quantum Theory: An analogue of Wigner's Theorem
"  We address the problem of disentangled representation learning with independent latent factors in graph convolutional networks (GCNs). The current methods usually learn node representation by describing its neighborhood as a perceptual whole in a holistic manner while ignoring the entanglement of the latent factors. However, a real-world graph is formed by the complex interaction of many latent factors (e.g., the same hobby, education or work in social network). While little effort has been made toward exploring the disentangled representation in GCNs. In this paper, we propose a novel Independence Promoted Graph Disentangled Networks (IPGDN) to learn disentangled node representation while enhancing the independence among node representations. In particular, we firstly present disentangled representation learning by neighborhood routing mechanism, and then employ the Hilbert-Schmidt Independence Criterion (HSIC) to enforce independence between the latent representations, which is effectively integrated into a graph convolutional framework as a regularizer at the output layer. Experimental studies on real-world graphs validate our model and demonstrate that our algorithms outperform the state-of-the-arts by a wide margin in different network applications, including semi-supervised graph classification, graph clustering and graph visualization. ",Independence Promoted Graph Disentangled Networks
"  We propose the first real-time approach for the egocentric estimation of 3D human body pose in a wide range of unconstrained everyday activities. This setting has a unique set of challenges, such as mobility of the hardware setup, and robustness to long capture sessions with fast recovery from tracking failures. We tackle these challenges based on a novel lightweight setup that converts a standard baseball cap to a device for high-quality pose estimation based on a single cap-mounted fisheye camera. From the captured egocentric live stream, our CNN based 3D pose estimation approach runs at 60Hz on a consumer-level GPU. In addition to the novel hardware setup, our other main contributions are: 1) a large ground truth training corpus of top-down fisheye images and 2) a novel disentangled 3D pose estimation approach that takes the unique properties of the egocentric viewpoint into account. As shown by our evaluation, we achieve lower 3D joint error as well as better 2D overlay than the existing baselines. ",Mo2Cap2: Real-time Mobile 3D Motion Capture with a Cap-mounted Fisheye   Camera
"  In this note we develop a numerical method for partial differential equations with changing type. Our method is based on a unified solution theory found by Rainer Picard for several linear equations from mathematical physics. Parallel to the solution theory already developed, we frame our numerical method in a discontinuous Galerkin approach in space-time with certain exponentially weighted spaces. ",Numerical methods for changing type systems
"  The Moliere theory of multiple Coulomb scattering is modified to take into account difference between scattering off atomic nuclei and electron. A simple analytical expression for angular distribution of charged particles passing through a thick absorber is found. It does not assume any special form for a differential cross section and has wider range of applicability than a Gaussian approximation. A well-known method to simulate multiple Coulomb scattering is based on the different treatment of soft and hard collisions. An angular deflection in a large number of soft collisions is sampled using the proposed distribution function, a small number of hard collisions are simulated directly. A boundary between hard and soft collisions is defined providing a precise sampling of scattering angle (1% level) and small number of hard collisions. A corresponding simulation module takes into account projectile and nucleus charge distributions and exact kinematics of a projectile-electron interaction. ",On the Theory and Simulation of Multiple Coulomb Scattering of Heavy   Charged Particles
"  The task of controlling a quantum system under time and bandwidth limitations is made difficult by unwanted excitations of spectrally neighboring energy levels. In this article we review the Derivative Removal by Adiabatic Gate (DRAG) framework. DRAG is a multi-transition variant of counterdiabatic driving, where multiple low-lying gapped states in an adiabatic evolution can be avoided simultaneously, greatly reducing operation times compared to the adiabatic limit. In its essence, the method corresponds to a convergent version of the superadiabatic expansion where multiple counterdiabaticity conditions can be met simultaneously. When transitions are strongly crowded, the system of equations can instead be favorably solved by an average Hamiltonian (Magnus) expansion, suggesting the use of additional sideband control. We give some examples of common systems where DRAG and variants thereof can be applied to improve performance. ",Counteracting systems of diabaticities using DRAG controls: The status   after 10 years
"  We first show that hypergeometric functions appear naturally as spectral functions when applying pseudo-differential calculus to decipher heat kernel asymptotic in the situation where the symbol algebra is noncommutative. Such observation leads to a unified (works for arbitrary dimension) method of computing the modular curvature on toric noncommutative manifolds. We show that the spectral functions that define the quantum part of the curvature have closed forms in terms of hypergeometric functions. As a consequence, we are able to obtained explicit expressions (as functions in the dimension parameter) for those spectral functions without using symbolic integration. A surprising geometric consequence is that the functional relations coming from the variation of the associated Einstein-Hilbert action still hold when the dimension parameter takes real values. ",Hypergeometric function and modular curvature
"  Tractable models of human perception have proved to be challenging to build. Hand-designed models such as MS-SSIM remain popular predictors of human image quality judgements due to their simplicity and speed. Recent modern deep learning approaches can perform better, but they rely on supervised data which can be costly to gather: large sets of class labels such as ImageNet, image quality ratings, or both. We combine recent advances in information-theoretic objective functions with a computational architecture informed by the physiology of the human visual system and unsupervised training on pairs of video frames, yielding our Perceptual Information Metric (PIM). We show that PIM is competitive with supervised metrics on the recent and challenging BAPPS image quality assessment dataset and outperforms them in predicting the ranking of image compression methods in CLIC 2020. We also perform qualitative experiments using the ImageNet-C dataset, and establish that PIM is robust with respect to architectural details. ",An Unsupervised Information-Theoretic Perceptual Quality Metric
"  The hydrodynamic equation of a spinor Bose-Einstein condensate (BEC) gives a simple description of spin dynamics in the condensate. We introduce the hydrodynamic equation of a ferromagnetic BEC with dissipation originating from the energy dissipation of the condensate. The dissipative hydrodynamic equation has the same form as an extended Landau-Lifshitz-Gilbert (LLG) equation, which describes the magnetization dynamics of ferromagnets interacting with spin-polarized currents. Employing the dissipative hydrodynamic equation, we demonstrate the magnetic domain pattern dynamics of a ferromagnetic BEC in the presence and absence of a current of particles, and discuss the effects of the current on domain pattern formation. We also discuss the characteristic lengths of domain patterns that have domain walls with and without finite magnetization. ",Dissipative hydrodynamic equation of a ferromagnetic Bose-Einstein   condensate: Analogy to magnetization dynamics in conducting ferromagnets
"  In this paper, we study the Ricci flow on manifolds with boundary. In the first part of the paper, we prove short-time existence and uniqueness of the solution, in which the boundary becomes instantaneously umbilic for positive time. In the second part of the paper, we prove that the flow we constructed in the first part preserves natural boundary conditions. More specifically, if the initial metric has a convex boundary, then the flow preserves positive curvature operator and the PIC1, PIC2 conditions. Moreover, if the initial metric has a two-convex boundary, then the flow preserves the PIC condition. ",Ricci Flow on Manifolds with Boundary with Arbitrary Initial Metric
"  The optical conductivity of La(2-x)Sr(x)NiO(4) has been interpreted in various ways, but so far the proposed interpretations have neglected the fact that the holes doped into the NiO(2) planes order in diagonal stripes, as established by neutron and X-ray scattering. Here we present a study of optical conductivity in La(2)NiO(4+d) with d=2/15, a material in which the charge stripes order three-dimensionally. We show that the conductivity can be decomposed into two components, a mid-infrared peak that we attribute to transitions from the filled valence band into empty mid-gap states associated with the stripes, and a Drude peak that appears at higher temperatures as carriers are thermally excited into the mid-gap states. The shift of the mid-IR peak to lower energy with increasing temperature is explained in terms of the Franck-Condon effect. The relevance of these results to understanding the optical conductivity in the cuprates is discussed. ",Mid-Infrared Conductivity from Mid-Gap States Associated with Charge   Stripes
"  We interface a spontaneous parametric down conversion (SPDC) crystal and a cold atomic ensemble and demonstrate a highly efficient quantum memory through polarization-encoded single-photon qubits. Specifically, narrowband heralded single photons from a cavity-enhanced SPDC source is stored using cold atomic ensemble, with ~70% storage-and-retrieval efficiency and ~10$\mu$s storage time at 50% efficiency. To prevent the degradation after storage, we also manipulate the single-photon wave profile so that the retrieved non-classical nature of single photon is preserved. On the other hand, the dual-rail storage is used for storing polarization-encoded qubits, and the corrected fidelity of flying qubits after storage reaches ~97%. The results pave the way toward large-scale quantum network. ",Efficient quantum memory for heralded single photons generated by   cavity-enhanced spontaneous parametric downconversion
"  The main result of this article is the decomposition of tensor products of representations of SL(2) in the sum of irreducible representations parametrized by outerplanar graphs. An outerplanar graph is a graph with the vertices 0, 1, 2, ..., m, edges of which can be drawn in the upper half-plane without intersections. I allow for a graph to have multiple edges, but don't allow loops. ",Tensor decompositions for SL(2) and outerplanar graphs
"  We study a new class of infinite-dimensional Lie algebras W_\infty(p,q) generalizing the standard W_\infty algebra, viewed as a tensor operator algebra of SU(1,1) in a group-theoretic framework. Here we interpret W_\infty(p,q) either as an infinite continuation of the pseudo-unitary symmetry U(p,q), or as a ""higher-U(p,q)-spin extension"" of the diffeomorphism algebra diff(p,q) of the N=p+q torus U(1)^N. We highlight this higher-spin structure of W_\infty(p,q) by developing the representation theory of U(p,q) (discrete series), calculating higher-spin representations, coherent states and deriving K\""ahler structures on flag manifolds. They are essential ingredients to define operator symbols and to infer a geometric pathway between these generalized W_\infty symmetries and algebras of symbols of U(p,q)-tensor operators. Classical limits (Poisson brackets on flag manifolds) and quantum (Moyal) deformations are also discussed. As potential applications, we comment on the formulation of diffeomorphism-invariant gauge field theories, like gauge theories of higher-extended objects, and non-linear sigma models on flag manifolds. ",Generalized W(infinity) Higher-Spin Algebras and Symbolic Calculus on   Flag Manifolds
"  Given an n x n integer matrix A whose eigenvalues are strictly greater than 1 in absolute value, let \sigma_A be the transformation of the n-torus T^n=R^n/Z^n defined by \sigma_A(e^{2\pi ix})=e^{2\pi iAx} for x\in R^n. We study the associated crossed-product C*-algebra, which is defined using a certain transfer operator for \sigma_A, proving it to be simple and purely infinite and computing its K-theory groups. ",Purely infinite simple C*-algebras associated to integer dilation   matrices
"  The pulsar wind nebula (PWN) HESS~J1825-137, known to exhibit strong energy dependent morphology, was discovered by HESS in 2005. Powered by the pulsar PSR~B1823-13, the TeV gamma-ray emitting nebula is significantly offset from the pulsar. The asymmetric shape and 21~kyr characteristic age of the pulsar suggest that HESS~J1825-137 is in an evolved state, having possibly already undergone reverse shock interactions from the progenitor supernova. Given its large angular extent, despite its 4~kpc distance, it may have the largest intrinsic size of any TeV PWN so far detected. A rich dataset is currently available with H.E.S.S., including H.E.S.S. II data with a low energy threshold, enabling detailed studies of the source properties and environment. We present new views of the changing nature of the PWN with energy, including maps of the region and spectral studies. ",Detailed VHE Studies of the Pulsar Wind Nebula HESS J1825-137
"  We show that a surface term should be added to the Einstein-Hilbert action in order to properly describe quantum transitions occurring around a black hole. The introduction of this boundary term has been advocated by Teitelboim and collaborators and it has been used in the computation of the black hole entropy. Here, we use it to compute the gravitational corrections to the transition amplitudes giving rise to Hawking radiation. This surface term implies that the probability to emit a particle is given by $e^{- \Delta A/4}$ where $\Delta A$ is the change in the area of the black hole horizon induced by the emission. Its inclusion at the level of the amplitudes therefore relates quantum black hole radiation to the first law of black hole dynamics. In both cases indeed, the term expressing the change in area directly results from the same boundary term introduced for the same reason: to obtain a well defined action principle. ",On the Gravitational Back Reaction to Hawking Radiation
"  In the Shortest-Superstring problem, we are given a set of strings S and want to find a string that contains all strings in S as substrings and has minimum length. This is a classical problem in approximation and the best known approximation factor is 2 1/2, given by Sweedyk in 1999. Since then no improvement has been made, howerever two other approaches yielding a 2 1/2-approximation algorithms have been proposed by Kaplan et al. and recently by Paluch et al., both based on a reduction to maximum asymmetric TSP path (Max-ATSP-Path) and structural results of Breslauer et al.   In this paper we give an algorithm that achieves an approximation ratio of 2 11/23, breaking through the long-standing bound of 2 1/2.   We use the standard reduction of Shortest-Superstring to Max-ATSP-Path. The new, somewhat surprising, algorithmic idea is to take the better of the two solutions obtained by using: (a) the currently best 2/3-approximation algorithm for Max-ATSP-Path and (b) a naive cycle-cover based 1/2-approximation algorithm. To prove that this indeed results in an improvement, we further develop a theory of string overlaps, extending the results of Breslauer et al. This theory is based on the novel use of Lyndon words, as a substitute for generic unbordered rotations and critical factorizations, as used by Breslauer et al. ",Lyndon Words and Short Superstrings
"  We introduce dodecaDialogue: a set of 12 tasks that measures if a conversational agent can communicate engagingly with personality and empathy, ask questions, answer questions by utilizing knowledge resources, discuss topics and situations, and perceive and converse about images. By multi-tasking on such a broad large-scale set of data, we hope to both move towards and measure progress in producing a single unified agent that can perceive, reason and converse with humans in an open-domain setting. We show that such multi-tasking improves over a BERT pre-trained baseline, largely due to multi-tasking with very large dialogue datasets in a similar domain, and that the multi-tasking in general provides gains to both text and image-based tasks using several metrics in both the fine-tune and task transfer settings. We obtain state-of-the-art results on many of the tasks, providing a strong baseline for this challenge. ",The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded   Conversational Agents
"  Dynamical decoupling has been actively investigated since Viola first suggested using a pulse sequence to protect a qubit from decoherence. Since then, many schemes of dynamical decoupling have been proposed to achieve high-order suppression, both analytically and numerically. However, hitherto, there has not been a systematic framework to understand all existing uniform $\pi$-pulse dynamical decoupling schemes. In this report, we use the projection pulse sequences as basic building blocks and concatenation as a way to combine them. We derived a new concatenated-projection dynamical decoupling (CPDD), a framework in which we can systematically construct pulse sequences to achieve arbitrary high suppression order. All previously known uniform dynamical decoupling sequences using $\pi$ pulse can be fit into this framework. Understanding uniform dynamical decoupling as successive projections on the Hamiltonian will also give insights on how to invent new ways to construct better pulse sequences. ",A Method for Generating All Uniform $\pi$-Pulse Sequences Used in   Deterministic Dynamical Decoupling
"  We develop U(1) slave spin-rotor theory, suggesting a metal-metal transition from Landau's Fermi-liquid state to a bad metal phase, as U(1) slave charge-rotor theory [Phys. Rev. B {\bf 70}, 035114 (2004)] describes a metal-insulator transition from Landau's Fermi-liquid state to a spin-liquid phase. U(1) slave spin-rotor formulation allows us to generalize Hertz-Moriya-Millis theory for ferromagnetic quantum phase transitions, replacing Landau's Fermi-liquid state with an incoherent metallic phase. As a result, we argue that localized magnetic moments emerge to govern quantum critical physics in bad metals. ",Critical field theory for ferromagnetic quantum criticality in the   strong coupling regime of Hertz-Moriya-Millis theory
"  We study resource allocation algorithm design for energy-efficient communication in an OFDMA downlink network with hybrid energy harvesting base station. Specifically, an energy harvester and a constant energy source driven by a non-renewable resource are used for supplying the energy required for system operation. We first consider a deterministic offline system setting. In particular, assuming availability of non-causal knowledge about energy arrivals and channel gains, an offline resource allocation problem is formulated as a non-convex optimization problem taking into account the circuit energy consumption, a finite energy storage capacity, and a minimum required data rate. We transform this non-convex optimization problem into a convex optimization problem by applying time-sharing and fractional programming which results in an efficient asymptotically optimal offline iterative resource allocation algorithm. In each iteration, the transformed problem is solved by using Lagrange dual decomposition. The obtained resource allocation policy maximizes the weighted energy efficiency of data transmission. Subsequently, we focus on online algorithm design. A stochastic dynamic programming approach is employed to obtain the optimal online resource allocation algorithm which requires a prohibitively high complexity. To strike a balance between system performance and computational complexity, we propose a low complexity suboptimal online iterative algorithm which is motivated by the offline optimization. ",Energy-Efficient Resource Allocation in OFDMA Systems with Hybrid Energy   Harvesting Base Station
"  Inspired by the combinatorial constructions in earlier work of the authors that generalized the classical Alexander polynomial to a large class of spatial graphs with a balanced weight on edges, we show that the value of the Alexander polynomial evaluated at $t=1$ gives the weighted number of the spanning trees of the graph. ",Alexander polynomial and spanning trees
"  Magnetic excitations in an array of (VO)2P2O7 single crystals have been measured using inelastic neutron scattering. Until now, (VO)2P2O7 has been thought of as a two-leg antiferromagnetic Heisenberg spin ladder with chains running in the a-direction. The present results show unequivocally that (VO)2P2O7 is best described as an alternating spin-chain directed along the crystallographic b-direction. In addition to the expected magnon with magnetic zone-center energy gap DE = 3.1$ meV, a second excitation is observed at an energy just below 2DE. The higher mode may be a triplet two-magnon bound state. Numerical results in support of bound modes are presented. ",Excitations and Possible Bound States in the S=1/2 Alternating Chain   Compound (VO)2P2O7
"  Accurate and precise radius estimates of transiting exoplanets are critical for understanding their compositions and formation mechanisms. To know the planet, we must know the host star in as much detail as possible. We present first results from the K2-HERMES project, which uses the HERMES multi-object spectrograph on the Anglo-Australian Telescope to obtain R$\sim$28,000 spectra of up to 360 stars in one exposure. This ongoing project aims to derive self-consistent spectroscopic parameters for about half of K2 target stars. We present complete stellar parameters and isochrone-derived masses and radii for 46 stars hosting 57 K2 candidate planets in Campaigns 1-3. Our revised host-star radii cast severe doubt on three candidate planets: EPIC\,201407812.01, EPIC\,203070421.01, and EPIC\,202843107.01, all of which now have inferred radii well in excess of the largest known inflated Jovian planets. ",The K2-HERMES Survey. I. Planet Candidate Properties from K2 Campaigns   1-3
"  The validity of the tree-unitarity criterion for scattering amplitudes on the noncommutative space-time is considered, as a condition that can be used to shed light on the problem of unitarity violation in noncommutative quantum field theories when time is noncommutative. The unitarity constraints on the partial wave amplitudes in the noncommutative space-time are also derived. ",Tree Unitarity and Partial Wave Expansion in Noncommutative Quantum   Field Theory
"  Results obtained by the ZEUS collaboration on leading baryon production in the proton fragmentation region are presented. The reaction $\gamma p \to N X$, with N a proton or a neutron, is examined both at low and high photon virtuality. ",Leading Baryons at Low x_L in DIS and Photoproduction at ZEUS
"  In this note we describe conditions under which, in idempotent functional analysis, linear operators have integral representations in terms of idempotent integral of V. P. Maslov. We define the notion of nuclear idempotent semimodule and describe idempotent analogs of the classical kernel theorems of L. Schwartz and A. Grothendieck. Our results provide a general description of a class of subsemimodules of the semimodule of all bounded functions with values in the Max-Plus algebra where some kind of kernel theorem holds, thus addressing an open problem posed by J. Gunawardena. Previously, some theorems on integral representations were obtained for a number of specific semimodules consisting of continuous or bounded functions taking values mostly in the Max-Plus algebra. In this work, a rather general case of semimodules over boundedly complete idempotent semirings is considered. ",Nuclear semimodules and kernel theorems in idempotent analysis. An   algebraic approach
"  The effectiveness of learning-based point cloud upsampling pipelines heavily relies on the upsampling modules and feature extractors used therein. For the point upsampling module, we propose a novel model called NodeShuffle, which uses a Graph Convolutional Network (GCN) to better encode local point information from point neighborhoods. NodeShuffle is versatile and can be incorporated into any point cloud upsampling pipeline. Extensive experiments show how NodeShuffle consistently improves state-of-the-art upsampling methods. For feature extraction, we also propose a new multi-scale point feature extractor, called Inception DenseGCN. By aggregating features at multiple scales, this feature extractor enables further performance gain in the final upsampled point clouds. We combine Inception DenseGCN with NodeShuffle into a new point upsampling pipeline called PU-GCN. PU-GCN sets new state-of-art performance with much fewer parameters and more efficient inference. ",PU-GCN: Point Cloud Upsampling using Graph Convolutional Networks
"  We study the sensitivity to the CP/T-violation search in the presence of ambiguities of the theoretical parameters. Three generations of neutrinos are considered. The parameters whose ambiguities are considered are the differences of the squared masses, the mixing angles, and the density of matter.   We first consider the statistics that are sensitive to the genuine CP-violation effect originating from the imaginary coupling. No ambiguity of the parameters is considered in this part. It is argued that the widely-adopted usual statistics are not necessarily sensitive to the genuine CP-violation effect. Two statistics that are sensitive to the imaginary coupling are proposed. The qualitative difference between these statistics and the usual one are discussed.   Next we proceed to the case where the ambiguity of the parameters is present. The sensitivity of the CP-violation search is greatly spoiled when the baseline length is longer than about one thousand kilometers, which turns out to be due to the ambiguity of the matter effect. Thus the CP-violation search by use of CP conjugate channels turns out to require a low energy neutrino and short baseline length. It is also shown that such a loss of sensitivity is avoided by using T-conjugate oscillation channels. ",Ambiguities of theoretical parameters and CP/T violation in neutrino   factories
"  The conjecture of a hidden $E_{10}$ symmetry of M-theory is supported by the close connection between the dynamics of D=11 supergravity near a spacelike singularity and a truncation of an one-dimensional $\sigma$-model with $E_{10}$ symmetry where all representations beyond SL(10) level $\ell=3$ are omitted. If this conjecture is right, higher-level representations should especially capture the dynamics of further M-theory degrees of freedom. Unfortunately, the level by level determination of $E_{10}$ commutators which is necessary to extend the model to higher levels is both an involved and toilsome task that requires computer aid. In this work, some of the relevant problems are exposed and algorithmic methods are developed which simplify key steps in the determination of explicit $E_{10}$ commutators at higher levels. As an application, we compute the commutator of the level-two six-form with itself. ",The structure of E10 at higher A9 levels - a first algorithmic approach
"  We consider the role of spontaneous lattice symmetry breaking in strongly interacting two dimensional Dirac systems. The fermion induced quantum (multi-)criticality is described by Dirac fermions coupled to a dynamical order parameter that is composed of mass and emergent gauge fields. This is illustrated for the example of translational symmetry breaking due to charge-density wave order on the honeycomb lattice. Using a renormalization-group analysis we find that the putative emergent Lorentz invariance is violated. Finally, we identify that topological phase transitions are well described by this effective field theory. ",Novel criticality of Dirac fermions from lattice symmetry breaking
"  Once in its non-equilibrium steady state, a nanoscale system coupled to several heat baths may be thought-of as a quantum heat pump. Depending on the direction of its stationary heat flows it may function as e.g. a refrigerator or a heat transformer. These continuous heat devices can be arbitrarily complex multipartite systems, and yet their working principle is always the same: They are made up of several elementary three-level stages operating in parallel. As a result, it is possible to devise external black-box testing strategies to learn about their functionality and performance regardless of any internal details. In particular, one such heat pump can be tested by coupling a two-level spin to one of its contact transitions. The steady state of this external probe contains information about the presence of heat leaks and internal dissipation in the device, and also, about the direction of its steady-state heat currents. Provided that the irreversibility of the heat pump is low, one can further estimate its coefficient of performance. These techniques may find applications in the emerging field of quantum thermal engineering, as they facilitate the diagnosis and design optimization of complex thermodynamic cycles. ",Testing a Quantum Heat Pump with a Two-Level Spin
"  It is frequently assumed that in the limit of vanishing cooling rate, the glass transition phenomenon becomes a thermodynamic transition at a temperature $T_{K}$. However, with any finite cooling rate, the system falls out of equilibrium at temperatures near $T_g(>T_{K})$, implying that the very existence of the putative thermodynamic phase transition at $T_{K}$ can be questioned. Recent studies of systems with randomly pinned particles have hinted that the thermodynamic glass transition may be observed in simulations and experiments carried out for liquids with randomly pinned particles. This expectation is based on the results of approximate calculations that suggest that the temperature of the thermodynamic glass transition increases as the concentration of pinned particles is increased and it may be possible to equilibrate the system at temperatures near the increased transition temperature. We test the validity of this prediction through extensive molecular dynamics simulations of two model glass-forming liquids in the presence of random pinning. We fit the temperature-dependence of the structural relaxation time to the Vogel-Fulcher-Tammann form that predicts a divergence of the relaxation time at a temperature $T_{VFT}$ and identify this temperature with the thermodynamic transition temperature $T_K$. We find that $T_{VFT}$ does not show any sign of increasing with increasing concentration of pinned particles. The main effect of pinning is found to be a rapid decrease in the kinetic fragility of the system with increasing pin concentration. Implications of these observations for current theories of the glass transition are discussed. ",Dynamics of Glass Forming Liquids with Randomly Pinned Particles
"  This paper is replaced by arXiv:0907.2826, by these authors and M. Vavilov and A. Chubukov. A sign mistake in the original paper led to incorrect conclusions. The paper arXiv:0907.2826 supersedes this paper arXiv:0904.3926. ",Spin density wave coexistence and nodal lines in superconducting   pnictides
"  The X(3872) radiative decay is discussed by employing a two-meson multichannel model with the charmonium components, which explains many of the other observed features of X(3872). We have found that the ratio of the branching fractions of the X(3872) radiative decays, $R_\gamma =\text{Br}(X(3872)\rightarrow\psi(2S)\gamma)$ / Br$(X(3872)\rightarrow J/\psi\gamma)$, is 1.1 $\sim$ 3.4 if one assumes that the decay occurs only from the charmonium components. The invariant mass spectra of $cc^{bar}$($2P$)$\rightarrow J/\psi \gamma$ and $cc^{bar}$($2P$)$\rightarrow \psi(2S) \gamma$ are also investigated. It is found that an enhancement appears at around $E\sim 3960$ MeV in the $\psi(2S) \gamma$ spectrum but not in the $J/\psi\gamma$ spectrum. This corresponds to the missing $cc^{bar}$($2P$) pole which was predicted by the quark models but has not been observed due to the coupling to the $DD^{bar}$ states. We argue that the fluctuation seen in the experimental $\psi(2S) \gamma$ spectrum reported by LHCb may correspond to this $cc^{bar}$($2P$) pole. ",Radiative Decays of the $X(3872)$ in the Charmonium-Molecule Hybrid   Picture
"  In this research, attempts are made to conduct concrete muscle fatigue analysis of arbitrary motions on OpenSim, a digital human modeling platform. A plug-in is written on the base of a muscle fatigue model, which makes it possible to calculate the decline of force-output capability of each muscle along time. The plug-in is tested on a three-dimensional, 29 degree-of-freedom human model. Motion data is obtained by motion capturing during an arbitrary running at a speed of 3.96 m/s. Ten muscles are selected for concrete analysis. As a result, the force-output capability of these muscles reduced to 60%-70% after 10 minutes' running, on a general basis. Erector spinae, which loses 39.2% of its maximal capability, is found to be more fatigue-exposed than the others. The influence of subject attributes (fatigability) is evaluated and discussed. ",Muscle Fatigue Analysis Using OpenSim
"  We introduce multilinear localization operators in terms of the short-time Fourier transform, and multilinear Weyl pseudodifferential operators. We prove that such localization operators are in fact Weyl pseudodifferential operators whose symbols are given by the convolution between the symbol of the localization operator and the multilinear Wigner transform. For such interpretation we use the kenrel theorem for the Gelfand-Shilov space. Furthermore, we study the continuity properties of the multilinear localization operators on modulation spaces. Our results extend some known results when restricted to the linear case. ",Continuity properties of multilinear localization operators on   modulation spaces
"  This paper is devoted to solve the galactic rotation problem for ESO138-G014 galaxy based on two theories: dark matter and Modified Newtonian Dynamics. Here we did the rotation curve analysis with two possible choices for the dark matter density profile, namely Burkert and Navarro, Frenk and White profiles. The analysis shows the dark matter distribution favored to Burkert profile (cored dark matter). The standard hypothesis for most spiral galaxies are known to be embedded in dark matter haloes has now been overshadowed by Modified Newtonian Dynamics, known as MOND, the leading alternative of dark matter. MOND addresses the problem of a new fundamental constant $a_0$, called the acceleration constant, at which acceleration scale of Newton second law fails to hold. In this respect, we investigate this issue by testing the rotation curve within the MOND framework with the observations to obtain the reliable disk mass, $M_D$. We investigate whether ESO138-G014 is compatible with MOND or dark matter is still favorable for the galactic rotation problem. ",Rotation Curve with MOND and Dark Matter Halo profile for ESO138-G014
"  This paper presents an acoustic study of a standard NACA 0012 aerofoil with additional self-oscillating passive flaplets attached to the trailing edge. The tests with varying geometries of the flaplets were conducted in the anechoic wind tunnel at Brandenburg University of Technology, at chord based Reynolds numbers, $Re_c = 100,000 - 900,000$ at three geometric angles of attack $\alpha_g = 0^\circ, 10^\circ$ and $15^\circ$. It was observed that all flaplet configurations reduce tonal noise and that the key geometric parameter to reduce this noise component is the width of the flaplets. The narrowest configuration tested almost completely removed the tonal noise, leading to an average overall sound pressure level reduction of up to 9 dB across the entire $Re_c$ range at $\alpha_g = 10^\circ$. It was also observed that, in the low frequency regime, a further noise reduction can be achieved by tuning the natural frequency of the oscillating flaplets. The thereby affected frequency range in the noise spectrum moves to higher frequencies when the natural frequency of the flaplets is increased and vice versa. Hence we show a novel way to target specific frequencies in passive aerofoil self-noise cancellation. ",Effect of different geometries of self-oscillating trailing-edge   flaplets on aerofoil self-noise
"  Galaxy formation depends on a complex interplay between gravitational collapse, gas accretion, merging, and feedback processes. Yet, after many decades of investigation, these concepts are poorly understood. This paper presents the argument that warm H$_2$ can be used as a tool to unlock some of these mysteries. Turbulence, shocks and outflows, driven by star formation, AGN activity or inflows, may prevent the rapid buildup of star formation in galaxies. Central to our understanding of how gas is converted into stars is the process by which gas can dissipate its mechanical energy through turbulence and shocks in order to cool. H$_2$ lines provide direct quantitative measurements of kinetic energy dissipation in molecular gas in galaxies throughout the Universe. Based on the detection of very powerful H$_2$ lines from z = 2 galaxies and proto-clusters at the detection limits of {\it Spitzer}, we are confident that future far-IR and UV H$_2$ observations will provide a wealth of new information and insight into galaxy evolution to high-z. Finally, at the very earliest epoch of star and galaxy formation, warm H$_2$ may also provide a unique glimpse of molecular gas collapse at 7 $<$ z $<$ 12 in massive dark matter (DM) halos on their way to forming the very first galaxies. Such measurements are beyond the reach of existing and planned observatories. ",Warm H$_2$ as a probe of massive accretion and feedback through shocks   and turbulence across cosmic time
"  Exchange symmetry in acceleration partitions the configuration space of an N particle, one-dimensional, gravitational system into N! equivalent cells. We take advantage of the resulting small angular extent of each cell to construct a related integrable version of the system that takes the form of a central force problem in N-1 dimensions. The properties of the latter, including the construction of trajectories, as well as several continuum limits, are developed. Dynamical simulation is employed to compare the two models. For a class of initial conditions, excellent agreement is observed. ",Exactly Integrable Analogue of a One-dimensional Gravitating System
"  We study an N=(4,4) supersymmetric gauged linear sigma model which gives rise to the nonlinear sigma model for multi-centered KK-monopoles. We find a new T-duality transformation of the model even in the presence of F-terms. Performing T-duality, we find the gauged linear sigma model whose IR limit describes the exotic 522-brane with B-field. ",Gauged Linear Sigma Model for Exotic Five-brane
"  Cognitive radio transceiver can opportunistically access the underutilized spectrum resource of primary systems for new wireless services. With interweave cognitive implementation, the secondary transmission may be interrupted by the primary user's transmission. To facilitate the packet delay analysis of such secondary transmission, we study the resulting extended delivery time that includes both transmission time and waiting time. In particular, we derive the exact distribution function of extended delivery time of a fixed-size secondary packet with non-work-preserving strategy i.e. interrupted packets will be retransmitted. Both continuous sensing and periodic sensing with and without missed detection cases are considered. Selected numerical and simulation results are presented for verifying the mathematical formulation. Finally, we apply the results to secondary queuing analysis with a generalized M/G/1 queue set-up. The analytical results will greatly facilitate the design of the secondary system for particular target application. ",Extended Delivery Time Analysis for Non-work-preserving Packet   Transmission in Cognitive Environment
"  For a semidualizing module $C$ over a ring $R$, we study the following classes modulo exact zero divisors: $\g_C$--projectives, $\mathcal G_C$; the Auslander class $\mathcal A_C$; the Bass class $\mathcal B_C$; $\mathcal{P}_C$--projective; $ {\mathcal F}_C$--projective; and ${\mathcal I}_C$--injective dimensions. ","Auslander class, $\g_C$ and $C$--projective modules modulo exact   zero-divisors"
"  We discuss $(n+1)$-dimensional dynamical wormholes in an evolving cosmological background with a throat expanding with time. These solutions are examined in the general relativity framework. A linear relation between diagonal elements of an anisotropic energy-momentum tensor is used to obtain the solutions. The energy-momentum tensor elements approach the vacuum case when we are far from the central object for one class of solutions. Finally, we discuss the energy-momentum tensor which supports this geometry, taking into account the energy conditions . ",$(n+1)$-Dimensional Lorentzian Wormholes in an Expanding Cosmological   Background
"  Quantum crystals abound in the whole range of solid-state species. Below a certain threshold temperature the physical behavior of rare gases (4He and Ne), molecular solids (H2 and CH4), and some ionic (LiH), covalent (graphite), and metallic (Li) crystals can be only explained in terms of quantum nuclear effects (QNE). A detailed comprehension of the nature of quantum solids is critical for achieving progress in a number of fundamental and applied scientific fields like, for instance, planetary sciences, hydrogen storage, nuclear energy, quantum computing, and nanoelectronics. This review describes the current physical understanding of quantum crystals and the wide variety of simulation techniques that are used to investigate them. Relevant aspects in these materials such as phase transformations, energy and structural properties, elasticity, and the effects of crystalline defects and dimensionality, are discussed thoroughly. An introduction to quantum Monte Carlo techniques, which in the present context are the simulation methods of choice, and other quantum simulation approaches (e. g., path-integral molecular dynamics and quantum thermal baths) is provided. The overarching objective of this article is twofold. First, to clarify in which crystals and physical situations the disregard of QNE may incur in important bias and erroneous interpretations. And second, to promote the study and appreciation of QNE, a topic that traditionally has been treated in the context of condensed matter physics, within the broad and interdisciplinary areas of materials science. ",Simulation and understanding of quantum crystals
"  Planets in close proximity to their parent star, such as those in the habitable zones around M dwarfs, could be subject to particularly high doses of particle radiation. We have carried out test-particle simulations of ~GeV protons to investigate the propagation of energetic particles accelerated by flares or travelling shock waves within the stellar wind and magnetic field of a TRAPPIST-1-like system. Turbulence was simulated with small-scale magnetostatic perturbations with an isotropic power spectrum. We find that only a few percent of particles injected within half a stellar radius from the stellar surface escape, and that the escaping fraction increases strongly with increasing injection radius. Escaping particles are increasingly deflected and focused by the ambient spiralling magnetic field as the superimposed turbulence amplitude is increased. In our TRAPPIST-1-like simulations, regardless of the angular region of injection, particles are strongly focused onto two caps within the fast wind regions and centered on the equatorial planetary orbital plane. Based on a scaling relation between far-UV emission and energetic protons for solar flares applied to M dwarfs, the innermost putative habitable planet, TRAPPIST-1e, is bombarded by a proton flux up to 6 orders of magnitude larger than experienced by the present-day Earth. We note two mechanisms that could strongly limit EP fluxes from active stars: EPs from flares are contained by the stellar magnetic field; and potential CMEs that might generate EPs at larger distances also fail to escape. ",Stellar energetic particles in the magnetically turbulent habitable   zones of TRAPPIST-1-like planetary systems
"  Studying the scattering of excitations around a dynamical background has a long history in the context of integrable models. The Gubser-Klebanov-Polyakov string solution provides such a background for the string/gauge correspondence. Taking the conjectured all-loop asymptotic equations for the AdS_4/CFT_3 correspondence as the starting point, we derive the S-matrix and a set of spectral equations for the lowest-lying excitations. We find that these equations resemble closely the analogous equations for AdS_5/CFT_4, which are also discussed in this paper. At large values of the coupling constant we show that they reproduce the Bethe equations proposed to describe the spectrum of the low-energy limit of the AdS_4xCP^3 sigma model. ",Bethe Ansaetze for GKP strings
"  In modern cosmology, the precision of the theoretical prediction is increasingly required. In cosmological $N$-body simulations, the effect of higher-order Lagrangian perturbation on the initial conditions appears in terms of statistical quantities of matter density field. We have considered the effect of third-order Lagrangian perturbation (3LPT) on the initial conditions, which can be applied to Gadget-2 code. Then, as statistical quantities, non-Gaussianity of matter density field has been compared between cases of different order perturbations for the initial conditions. Then, we demonstrate the validity of the initial conditions with second-order Lagrangian perturbation (2LPT). ",Transients from Initial Conditions Based on Lagrangian Perturbation   Theory in $N$-body Simulations III: The Case of GADGET-2 Code
"  We consider the dynamics of a parabolic and a hyperbolic equation coupled on a common interface and develop time-stepping schemes that can use different time-step sizes for each of the subproblems. The problem is formulated in a strongly coupled (monolithic) space-time framework. Coupling two different step sizes monolithically gives rise to large algebraic systems of equations where multiple states of the subproblems must be solved at once. For efficiently solving these algebraic systems, we inherit ideas from the partitioned regime and present two decoupling methods, namely a partitioned relaxation scheme and a shooting method. Furthermore, we develop an a posteriori error estimator serving as a mean for an adaptive time-stepping procedure. The goal is to optimally balance the time step sizes of the two subproblems. The error estimator is based on the dual weighted residual method and relies on the space-time Galerkin formulation of the coupled problem. As an example, we take a linear set-up with the heat equation coupled to the wave equation. We formulate the problem in a monolithic manner using the space-time framework. In numerical test cases, we demonstrate the efficiency of the solution process and we also validate the accuracy of the a posteriori error estimator and its use for controlling the time step sizes. ",Adaptive time-step control for a monolithic multirate scheme coupling   the heat and wave equation
"  We show a novel systematic way to construct conservative finite difference schemes for quasilinear first-order system of ordinary differential equations with conserved quantities. In particular, this includes both autonomous and non-autonomous dynamical systems with conserved quantities of arbitrary forms, such as time-dependent conserved quantities. Sufficient conditions to construct conservative schemes of arbitrary order are derived using the multiplier method. General formulas for first-order conservative schemes are constructed using divided difference calculus. New conservative schemes are found for various dynamical systems such as Euler's equation of rigid body rotation, Lotka-Volterra systems, the planar restricted three-body problem and the damped harmonic oscillator. ",Conservative methods for dynamical systems
"  The Dirac equation is solved in the $z=0$ Lifshitz black hole ($Z0$LBH) spacetime. The set of equations representing the Dirac equation in the Newman-Penrose (NP) formalism is decoupled into a radial set and an angular set. The separation constant is obtained with the aid of the spin weighted spheroidal harmonics. The radial set of equations, which is independent of mass, is reduced to Zerilli equations (ZEs)\ with their associated potentials. In the near horizon (NH) region, these equations solved in terms of the Bessel functions of the first and second kinds arising from the fermionic perturbation on the background geometry. For computing the BQNMs instead of the ordinary quasinormal modes (QNMs), we first impose the purely ingoing wave condition at the event horizon. And then, Dirichlet boundary condition (DBC) and Newmann boundary condition (NBC) are applied in order to get the resonance conditions. For solving the resonance conditions we follow an iteration method. Finally, Maggiore's method (MM) is employed to derive the entropy/area spectra of the $Z0$LBH which are shown to be equidistant. ",Fermion Clouds Around $z=0$ Lifshitz Black Holes
"  We consider the pandemic spreading of COVID-19 in India after the outbreak of the coronavirus in Wuhan city, China. We estimate the transmission rate of the initial infecting individuals of COVID-19 in India by using the officially reported data at the early stage of the epidemic with the help of Susceptible (S), Exposed (E), Infected (I), and Removed (R) population model, the so-called SEIR dynamical model. Numerical analysis and model verification are performed to calibrate the system parameters with official public information about the number of people infected, and then to evaluate several COVID -19 scenarios potentially applicable to India. Our findings provide an estimation of disease occurrence in the near future and also demonstrate the importance of governmental and individual efforts to control the effects and time of the pandemic-related critical situations. We also give special emphasis to individual reactions in the containment process. ",Dynamical modelling and analysis of COVID-19 in India
"  Rapid and luminous flares of non-thermal radiation observed in blazars require an efficient mechanism of energy dissipation and particle acceleration in relativistic active galactic nuclei (AGN) jets. Particle acceleration in relativistic magnetic reconnection is being actively studied by kinetic numerical simulations. Relativistic reconnection produces hard power-law electron energy distributions N(gamma) = N_0 gamma^(-p) exp(-gamma/gamma_max) with index p -> 1 and exponential cut-off Lorentz factor gamma_max ~ sigma in the limit of magnetization sigma = B^2/(4 pi w) >> 1 (where w is the relativistic enthalpy density). Reconnection in electron-proton plasma can additionally boost gamma_max by the mass ratio m_p/m_e. Hence, in order to accelerate particles to gamma_max ~ 10^6 in the case of BL Lacs, reconnection should proceed in plasma of very high magnetization sigma_max >~ 10^3. On the other hand, moderate mean jet magnetization values are required for magnetic bulk acceleration of relativistic jets, sigma_mean ~ Gamma_j <~ 20 (where Gamma_j is the jet bulk Lorentz factor). I propose that the systematic dependence of gamma_max on blazar luminosity class -- the blazar sequence -- may result from a systematic trend in sigma_max due to homogeneous loading of leptons by pair creation regulated by the energy density of high-energy external radiation fields. At the same time, relativistic AGN jets should be highly inhomogeneous due to filamentary loading of protons, which should determine the value of sigma_mean roughly independently of the blazar class. ",Applying Relativistic Reconnection to Blazar Jets
"  While many classical traffic models treat the spatial extension of streets continuously or by discretization into cells of a certain length, we will subdivide roads into comparatively long homogeneous road sections of constant capacity with an inhomogeneity at the end. The related model is simple and numerically efficient. It is inspired by models of dynamic queueing networks and takes into account essential features of traffic flows. Instead of treating single vehicles or velocity profiles, it focusses on flows at specific cross sections and average travel times of vehicles. ",A Section-Based Queueing-Theoretical Traffic Model for Congestion and   Travel Time Analysis in Networks
"  Statistical methods such as the Box-Jenkins method for time-series forecasting have been prominent since their development in 1970. Many researchers rely on such models as they can be efficiently estimated and also provide interpretability. However, advances in machine learning research indicate that neural networks can be powerful data modeling techniques, as they can give higher accuracy for a plethora of learning problems and datasets. In the past, they have been tried on time-series forecasting as well, but their overall results have not been significantly better than the statistical models especially for intermediate length times series data. Their modeling capacities are limited in cases where enough data may not be available to estimate the large number of parameters that these non-linear models require. This paper presents an easy to implement data augmentation method to significantly improve the performance of such networks. Our method, Augmented-Neural-Network, which involves using forecasts from statistical models, can help unlock the power of neural networks on intermediate length time-series and produces competitive results. It shows that data augmentation, when paired with Automated Machine Learning techniques such as Neural Architecture Search, can help to find the best neural architecture for a given time-series. Using the combination of these, demonstrates significant enhancement in the forecasting accuracy of three neural network-based models for a COVID-19 dataset, with a maximum improvement in forecasting accuracy by 21.41%, 24.29%, and 16.42%, respectively, over the neural networks that do not use augmented data. ",Improving Neural Networks for Time Series Forecasting using Data   Augmentation and AutoML
"  The $\gamma^\ast \gamma \to \pi^0$ transition form factor, $G(Q^2)$, is computed on the entire domain of spacelike momenta using a continuum approach to the two valence-body bound-state problem in relativistic quantum field theory: the result agrees with data obtained by the CELLO, CLEO and Belle Collaborations. The analysis unifies this prediction with that of the pion's valence-quark parton distribution amplitude (PDA) and elastic electromagnetic form factor, and demonstrates, too, that a fully self-consistent treatment can readily connect a pion PDA that is a broad, concave function at the hadronic scale with the perturbative QCD prediction for the transition form factor in the hard photon limit. The normalisation of that limit is set by the scale of dynamical chiral symmetry breaking, which is a crucial feature of the Standard Model. Understanding of the latter will thus remain incomplete until definitive transition form factor data is available on $Q^2>10\,$GeV$^2$. ",Structure of the neutral pion and its electromagnetic transition form   factor
  We give meaning to the first and second laws of thermodynamics in case of mesoscopic out-of-equilibrium systems which are driven by diffusion processes. The notion of the entropy production is analyzed. The role of the Helmholtz extremum principle is contrasted to that of the more familiar entropy extremum principles. ,Entropy and time: Thermodynamics of diffusion processes
"  Neural Networks are being used for character recognition from last many years but most of the work was confined to English character recognition. Till date, a very little work has been reported for Handwritten Farsi Character recognition. In this paper, we have made an attempt to recognize handwritten Farsi characters by using a multilayer perceptron with one hidden layer. The error backpropagation algorithm has been used to train the MLP network. In addition, an analysis has been carried out to determine the number of hidden nodes to achieve high performance of backpropagation network in the recognition of handwritten Farsi characters. The system has been trained using several different forms of handwriting provided by both male and female participants of different age groups. Finally, this rigorous training results an automatic HCR system using MLP network. In this work, the experiments were carried out on two hundred fifty samples of five writers. The results showed that the MLP networks trained by the error backpropagation algorithm are superior in recognition accuracy and memory usage. The result indicates that the backpropagation network provides good recognition accuracy of more than 80% of handwritten Farsi characters. ",Handwritten Farsi Character Recognition using Artificial Neural Network
"  Let N be a normal subgroup of a finite group G. We prove that under certain (unavoidable) conditions the subgroup [N,G] is a product of commutators [N,y] (with prescribed values of y from a given set Y) of length bounded by a function of d(G) and |Y| only. This has several applications: 1. A new proof that G^n is closed (and hence open) in any finitely generated profinite group G. 2. A finitely generated abstract quotient of a compact Hausdorff group must be finite. 3. Let G be a topologically finitely generated compact Hausdorff group. Then G has a countably infinite abstract quotient if and only if G has an infinite virtually abelian continuous quotient. ",Generators and commutators in finite groups; abstract quotients of   compact groups
"  The loop-induced processes gg -> h,H,A provide the dominant Higgs boson production mechanisms at the Tevatron and LHC in a large range of the minimal supersymmetric extension of the Standard Model. For squark masses below \sim 400 GeV squark loop contributions become important in addition to the top and bottom quark loops. The next-to-leading order QCD corrections to the squark contributions of these processes are determined including the full squark and Higgs mass dependences. They turn out to be large and thus important for the Tevatron and LHC experiments. Squark mass effects of the K factors can be of O(20%). In addition we derive the QCD corrections to the squark contributions of the rare photonic Higgs decays h,H -> gamma gamma, which play a role for the Higgs searches at the LHC. ",Higgs Boson Production via Gluon Fusion: Squark Loops at NLO QCD
"  Indexing of static and dynamic sets is fundamental to a large set of applications such as information retrieval and caching. Denoting the characteristic vector of the set by B, we consider the problem of encoding sets and multisets to support approximate versions of the operations rank(i) (i.e., computing sum_{j <= i}B[j]) and select(i) (i.e., finding min{p | rank(p) >= i}) queries. We study multiple types of approximations (allowing an error in the query or the result) and present lower bounds and succinct data structures for several variants of the problem. We also extend our model to sliding windows, in which we process a stream of elements and compute suffix sums. This is a generalization of the window summation problem that allows the user to specify the window size at query time. Here, we provide an algorithm that supports updates and queries in constant time while requiring just (1+o(1)) factor more space than the fixed-window summation algorithms. ",Approximate Query Processing over Static Sets and Sliding Windows
"  We propose a method to split the ground state of an attractively interacting atomic Bose-Einstein condensate into two bright solitary waves with controlled relative phase and velocity. We analyze the stability of these waves against their subsequent re-collisions at the center of a cylindrically symmetric, prolate harmonic trap as a function of relative phase, velocity, and trap anisotropy. We show that the collisional stability is strongly dependent on relative phase at low velocity, and we identify previously unobserved oscillations in the collisional stability as a function of the trap anisotropy. An experimental implementation of our method would determine the validity of the mean field description of bright solitary waves, and could prove an important step towards atom interferometry experiments involving bright solitary waves. ",Realizing bright matter-wave soliton collisions with controlled relative   phase
"  To provide adequate multivariate measures of information flow between neural structures, modified expressions of Partial Directed Coherence (PDC) and Directed Transfer Function (DTF), two popular multivariate connectivity measures employed in neuroscience, are introduced and their formal relationship to mutual information rates are proved. ",Information theoretic interpretation of frequency domain connectivity   measures
  We argue that that the folding criterion suggested by Klimov and Thirumalai is similar to the one published earlier and that their conclusion of invalidity of the ``gap criterion'' is due to misunderstanding of previous work ,"Comment on ""A Criterion that determines foldability of proteins"" by D.   Klimov and D. Thirumalai (PRL,v.76, p.4070 (1996))"
"  In a compact space with non-trivial cycles, for sufficiently small values of the compact dimensions, charge conjugation (C), spatial reflection (P) and time reversal (T) are spontaneously broken in QCD. The order parameter for the symmetry breaking is the trace of the Wilson line wrapping around the compact dimension, which acquires an imaginary part in the broken phase. We show that a physical signature for the symmetry breaking is a persistent baryonic current wrapping in the compact directions. The existence of such a current is derived analytically at first order in perturbation theory and confirmed in the non-perturbative regime by lattice simulations. ",Spontaneous breaking of discrete symmetries in QCD on a small volume
"  The new dual-pivot Quicksort by Vladimir Yaroslavskiy - used in Oracle's Java runtime library since version 7 - features intriguing asymmetries in its behavior. They were shown to cause a basic variant of this algorithm to use less comparisons than classic single-pivot Quicksort implementations. In this paper, we extend the analysis to the case where the two pivots are chosen as fixed order statistics of a random sample and give the precise leading term of the average number of comparisons, swaps and executed Java Bytecode instructions. It turns out that - unlike for classic Quicksort, where it is optimal to choose the pivot as median of the sample - the asymmetries in Yaroslavskiy's algorithm render pivots with a systematic skew more efficient than the symmetric choice. Moreover, the optimal skew heavily depends on the employed cost measure; most strikingly, abstract costs like the number of swaps and comparisons yield a very different result than counting Java Bytecode instructions, which can be assumed most closely related to actual running time. ",Pivot Sampling in Dual-Pivot Quicksort
"  The most promising concepts for power and particle control in tokamaks and other fusion experiments rely upon atomic processes to transfer the power and momentum from the edge plasma to the plasma chamber walls. This places a new emphasis on processes at low temperatures (1-200 eV) and high densities (10^20-10^22 m^-3). The most important atomic processes are impurity and hydrogen radiation, ionization, excitation, recombination, charge exchange, radiation transport, molecular collisions, and elastic scattering of atoms, molecules and ions. Important new developments have occurred in each of these areas. The best available data for these processes and an assessment of their role in plasma wall interactions are summarized, and the major areas where improved data are needed are reviewed. ",A Review of Recent Developments in Atomic Processes for Divertors and   Edge Plasmas
  Let W be a Weyl group. We define a new basis for the Grothendieck group of representations of W. This basis contains on the one hand the special representations of W and on the other hand the representations carried by the left cells of W. We show that the representations in the new basis have a certain bipositivity property. ,A new basis for the representation ring of a Weyl group
"  We generalize the background gauge in the Matrix model to propose a new gauge which is useful for discussing the conformal symmetry. In this gauge, the special conformal transformation (SCT) as the isometry of the near-horizon geometry of the D-particle solution is directly reproduced with the correct coefficient as the quantum correction to the SCT in the Matrix model. We also present a general argument for the relation between the gauge choice and the field redefinition in the Matrix model. ",Conformal Symmetry and A New Gauge in the Matrix Model
"  The past, present and future are not fundamental properties of Minkowski spacetime. It has been suggested that they are properties of a class of information gathering and utilizing systems (IGUSs).The past, present and future are psychologically created phenomena not actually properties of spacetime. A human is a model IGUS robot. We develop a way to establish that the past, present, and future do not follow from the laws of physics by constructing robots that process information differently and therefore experience different nows (presents). We construct a customized virtual reality (VR) system which allows an observer to switch between present and past. This robot (human with VR system) can experience immersion in the immediate past ad libitum. Being able to actually construct an IGUS that has the same present at two different coordinates along the worldline lends support to the IGUS hypothesis. ",An Experimental Information Gathering and Utilization Systems (IGUS)   Robot to Demonstrate the Physics of Now
"  Going from a scaling approach for birth/death processes, we investigate the scaling limit of solutions to non-Markovian stochastic control problems by studying the convergence of solutions to BSDEs driven a sequence of converging martingales. In particular we manage to describe how the values and optimal controls of control problems converge when the models converge towards a continuous population model. ",Scaling limit for stochastic control problems in population dynamics
"  One of the possible mechanisms of high Tc superconductivity is Cooper pairing with the help of bosons, which change the slope of the electronic dispersion as observed by photoemission. Giustino et al. calculated that in the high temperature superconductor La1.85Sr0.15CuO4 crystal lattice vibrations (phonons) should have a negligible effect on photoemission spectra and concluded that phonons do not play an important role. We show that the calculations employed by Giustino et al. fail to reproduce huge influence of electron-phonon coupling on important phonons observed in experiments. Thus one would expect these calculations to similarly fail in explaining the role of electron-phonon coupling for the electronic dispersion. ",Photoemission kinks and phonons in cuprates
"  Solar coronal jets are small, transient, collimated ejections most easily observed in coronal holes (CHs). The upcoming Parker Solar Probe (PSP) mission provides the first opportunity to encounter CH jets in situ near the Sun and examine their internal structure and dynamics. Using projected mission orbital parameters, we have simulated PSP encounters with a fully three-dimensional magnetohydrodynamic (MHD) model of a CH jet. We find that three internal jet regions, featuring different wave modes and levels of compressibility, have distinct identifying signatures detectable by PSP. The leading Alfv\'{e}n wave front and its immediate wake are characterized by trans-Alfv\'{e}nic plasma flows with mild density enhancements. This front exhibits characteristics of a fast switch-on MHD shock, whose arrival is signaled by the sudden onset of large-amplitude transverse velocity and magnetic-field oscillations highly correlated in space and time. The trailing portion is characterized by supersonic but sub-Alfv\'{e}nic outflows of dense plasma with uncorrelated velocity and magnetic-field oscillations. This compressible region contains most of the jet's mass. The volume between the immediate wake and dense jet, the remote wake, mixes and transitions the characteristics of the two other regions. In addition to probing each region separately, we also simulate a co-rotational PSP-jet encounter. In this scenario, the simulated spacecraft hovers over the jet-producing CH, as may occur during the mission's co-rotational phases, sampling each jet region in turn. We estimate that PSP will encounter numerous CH jets over the lifetime of the mission. ",Simulated Encounters of Parker Solar Probe with A Coronal-Hole Jet
"  We discuss the science drivers for ALMA Band 2 which spans the frequency range from 67 to 90 GHz. The key science in this frequency range are the study of the deuterated molecules in cold, dense, quiescent gas and the study of redshifted emission from galaxies in CO and other species. However, Band 2 has a range of other applications which are also presented. The science enabled by a single receiver system which would combine ALMA Bands 2 and 3 covering the frequency range 67 to 116 GHz, as well as the possible doubling of the IF bandwidth of ALMA to 16 GHz, are also considered. ",The Science Case for ALMA Band 2 and Band 2+3
"  Hierarchical structure formation leads to a clumpy distribution of dark matter in the Milky Way. These clumps are possible targets to search for dark matter annihilation with present and future $\gamma$-ray instruments. Many uncertainties exist on the clump distribution, leading to disputed conclusions about the expected number of detectable clumps and the ensuing limits that can be obtained from non-detection. In this paper, we use the CLUMPY code to simulate thousands of skymaps for several clump distributions. This allows us to statistically assess the typical properties (mass, distance, angular size, luminosity) of the detectable clumps. Varying parameters of the clump distributions allows us to identify the key quantities to which the number of detectable clumps is the most sensitive. Focusing our analysis on two extreme clump configurations, yet consistent with results from numerical simulations, we revisit and compare various calculations made for the Fermi-LAT instrument, in terms of number of dark clumps expected and the angular power spectrum for the Galactic signal. We then focus on the prospects of detecting dark clumps with the future CTA instrument, for which we make a detailed sensitivity analysis using open-source CTA software. Based on a realistic scenario for the foreseen CTA extragalactic survey, and accounting for a post-trial sensitivity in the survey, we show that we obtain competitive and complementary limits to those based on long observation of a single bright dwarf spheroidal galaxy. ",Dark matter substructure modelling and sensitivity of the Cherenkov   Telescope Array to Galactic dark halos
"  Positive-definite matrix-variate data is becoming popular in computer vision. The computer vision data descriptors in the form of Region Covariance Descriptors (RCD) are positive definite matrices, which extract the key features of the images. The RCDs are extensively used in image set classification. Some classification methods treating RCDs as Wishart distributed random matrices are being proposed. However, the majority of the current methods preclude the potential correlation among the RCDs caused by the so-called non-voxel information (e.g., subjects' ages and nose widths, etc). Modeling correlated Wishart matrices is difficult since the joint density function of correlated Wishart matrices is difficult to be obtained. In this paper, we propose an Expectation-Maximization composite likelihood-based algorithm of Wishart matrices to tackle this issue. Given the numerical studies based on the synthetic data and the real data (Chicago face data-set), our proposed algorithm performs better than the alternative methods which do not consider the correlation caused by the so-called non-voxel information. All these above demonstrate our algorithm's compelling potential in image set classification in the coming future. ",Correlated Wishart Matrices Classification via an   Expectation-Maximization Composite Likelihood-Based Algorithm
"  Van der Waals (vdW) heterojunctions, based on two-dimensional (2D) materials, show great potential for the development of eco-friendly and high-efficiency nano-devices. Considerable research has been performed and has reported valuable applications of photovoltaic cells, photodetectors, etc. However, simultaneous energy conversion and storage in a single device has not been achieved. Here, we demonstrate a simple strategy to construct a vdW p-n junction between a WSe2 layer and quasi-2D electron gas. After once optical illumination, the device stores the light-generated electrons and holes for up to seven days, and then releases a very large photocurrent of 2.9 mA with bias voltage applied in darkness; this is referred to as chargeable photoconductivity (CPC), which completely differs from any previously observed photoelectric phenomenon. In normal photoconductivity, the recombination of electron-hole pairs takes place at the end of their lifetime, causing a release of heat; in contrast, infinite-lifetime photocarriers can be generated in CPC devices without a thermal loss. The photoelectric conversion and storage are completely self-excited during the charging process. The ratio between currents in full- and empty-energy states below the critical temperature reaches as high as 109, with an external quantum efficiency of 4410000% during optical charging. A theoretical model developed to explain the mechanism of this effect is in good agreement with the experimental data. This work paves a path towards storage-type photoconductors and high-efficiency entropy-decreasing devices. ",Chargeable photoconductivity in Van der Waals heterojunctions
"  Open source software (OSS) is essential for modern society and, while substantial research has been done on individual (typically central) projects, only a limited understanding of the periphery of the entire OSS ecosystem exists. For example, how are the tens of millions of projects in the periphery interconnected through. technical dependencies, code sharing, or knowledge flow? To answer such questions we: a) create a very large and frequently updated collection of version control data in the entire FLOSS ecosystems named World of Code (WoC), that can completely cross-reference authors, projects, commits, blobs, dependencies, and history of the FLOSS ecosystems and b) provide capabilities to efficiently correct, augment, query, and analyze that data. Our current WoC implementation is capable of being updated on a monthly basis and contains over 18B Git objects. To evaluate its research potential and to create vignettes for its usage, we employ WoC in conducting several research tasks. In particular, we find that it is capable of supporting trend evaluation, ecosystem measurement, and the determination of package usage. We expect WoC to spur investigation into global properties of OSS development leading to increased resiliency of the entire OSS ecosystem. Our infrastructure facilitates the discovery of key technical dependencies, code flow, and social networks that provide the basis to determine the structure and evolution of the relationships that drive FLOSS activities and innovation. ",World of Code: Enabling a Research Workflow for Mining and Analyzing the   Universe of Open Source VCS data
"  Writers read Einstein's letter to Mari\'c from 1901 in which he wrote: ""bringing our work on relative motion to a successful conclusion!"" What came afterwards was boosted by a claim that Joffe had seen the original relativity paper manuscript, and that it was signed ""Einstein-Marity"" (i.e., ""Mari\'c""). This drew the attention of some writers to develop a theory according to which Mileva Mari\'c assisted Albert Einstein in solving his physics problems, but her name was left out of the published article and only Einstein's name appears in the journal as author. Historical and primary sources do not support this scenario. ",Did Mileva Mari\'c assist Einstein in writing his 1905 path breaking   papers?
"  Deep reinforcement learning requires a heavy price in terms of sample efficiency and overparameterization in the neural networks used for function approximation. In this work, we use tensor factorization in order to learn more compact representation for reinforcement learning policies. We show empirically that in the low-data regime, it is possible to learn online policies with 2 to 10 times less total coefficients, with little to no loss of performance. We also leverage progress in second order optimization, and use the theory of wavelet scattering to further reduce the number of learned coefficients, by foregoing learning the topmost convolutional layer filters altogether. We evaluate our results on the Atari suite against recent baseline algorithms that represent the state-of-the-art in data efficiency, and get comparable results with an order of magnitude gain in weight parsimony. ",Biologically inspired architectures for sample-efficient deep   reinforcement learning
"  This paper advances the state of the art in human examination of iris images by (1) assessing the impact of different iris conditions in identity verification, and (2) introducing an annotation step that improves the accuracy of people's decisions. In a first experimental session, 114 subjects were asked to decide if pairs of iris images depict the same eye (genuine pairs) or two distinct eyes (impostor pairs). The image pairs sampled six conditions: (1) easy for algorithms to classify, (2) difficult for algorithms to classify, (3) large difference in pupil dilation, (4) disease-affected eyes, (5) identical twins, and (6) post-mortem samples. In a second session, 85 of the 114 subjects were asked to annotate matching and non-matching regions that supported their decisions. Subjects were allowed to change their initial classification as a result of the annotation process. Results suggest that: (a) people improve their identity verification accuracy when asked to annotate matching and non-matching regions between the pair of images, (b) images depicting the same eye with large difference in pupil dilation were the most challenging to subjects, but benefited well from the annotation-driven classification, (c) humans performed better than iris recognition algorithms when verifying genuine pairs of post-mortem and disease-affected eyes (i.e., samples showing deformations that go beyond the distortions of a healthy iris due to pupil dilation), and (d) annotation does not improve accuracy of analyzing images from identical twins, which remain confusing for people. ",Performance of Humans in Iris Recognition: The Impact of Iris Condition   and Annotation-driven Verification
"  Let $\mathbf{G}$ be a connected split reductive group over a field of characteristic zero or sufficiently large characteristic, $\gamma_0\in(\operatorname{Lie}\mathbf{G})((t))$ be any topologically nilpotent regular semisimple element, and $\gamma=t\gamma_0$. Using methods from $p$-adic orbital integrals, we show that the number of components of the Iwahori affine Springer fiber over $\gamma$ modulo $Z_{\mathbf{G}((t))}(\gamma)$ is equal to the order of the Weyl group. ",Components of affine Springer fibers
"  In this paper we develop an adaptive procedure for the numerical solution of general, semilinear elliptic problems with possible singular perturbations. Our approach combines both a prediction-type adaptive Newton method and an adaptive finite element discretization (based on a robust a posteriori error analysis), thereby leading to a fully adaptive Newton-Galerkin scheme. Numerical experiments underline the robustness and reliability of the proposed approach for different examples. ",Fully Adaptive Newton-Galerkin Methods for Semilinear Elliptic Partial   Differential Equations
"  The exposure and consumption of information during epidemic outbreaks may alter risk perception, trigger behavioural changes, and ultimately affect the evolution of the disease. It is thus of the uttermost importance to map information dissemination by mainstream media outlets and public response. However, our understanding of this exposure-response dynamic during COVID-19 pandemic is still limited. In this paper, we provide a characterization of media coverage and online collective attention to COVID-19 pandemic in four countries: Italy, United Kingdom, United States, and Canada. For this purpose, we collect an heterogeneous dataset including 227,768 online news articles and 13,448 Youtube videos published by mainstream media, 107,898 users posts and 3,829,309 comments on the social media platform Reddit, and 278,456,892 views to COVID-19 related Wikipedia pages. Our results show that public attention, quantified as users activity on Reddit and active searches on Wikipedia pages, is mainly driven by media coverage and declines rapidly, while news exposure and COVID-19 incidence remain high. Furthermore, by using an unsupervised, dynamical topic modeling approach, we show that while the attention dedicated to different topics by media and online users are in good accordance, interesting deviations emerge in their temporal patterns. Overall, our findings offer an additional key to interpret public perception/response to the current global health emergency and raise questions about the effects of attention saturation on collective awareness, risk perception and thus on tendencies towards behavioural changes. ",Collective response to the media coverage of COVID-19 Pandemic on Reddit   and Wikipedia
"  Lubricants are widely used in macroscopic mechanical systems to reduce friction and wear. However, on the microscopic scale, it is not clear to what extent lubricants are beneficial. Therefore, in this study, we consider two diamond solid-state gears at the nanoscale immersed in different lubricant molecules and perform classical MD simulations to investigate the rotational transmission of motion. We find that lubricants can help to synchronize the rotational transmission between gears regardless of the molecular species and the center-of-mass distance. Moreover, the influence of the angular velocity of the driving gear is investigated and shown to be related to the bond formation process between gears. ",Effect of Lubricants on the Rotational Transmission between Solid-State   Gears
"  We are faced with data comprised of entities interacting over time: this can be individuals meeting, customers buying products, machines exchanging packets on the IP network, among others. Capturing the dynamics as well as the structure of these interactions is of crucial importance for analysis. These interactions can almost always be labeled with content: group belonging, reviews of products, abstracts, etc. We model these stream of interactions as stream graphs, a recent framework to model interactions over time. Formal Concept Analysis provides a framework for analyzing concepts evolving within a context. Considering graphs as the context, it has recently been applied to perform closed pattern mining on social graphs. In this paper, we are interested in pattern mining in sequences of interactions. After recalling and extending notions from formal concept analysis on graphs to stream graphs, we introduce algorithms to enumerate closed patterns on a labeled stream graph, and introduce a way to select relevant closed patterns. We run experiments on two real-world datasets of interactions among students and citations between authors, and show both the feasibility and the relevance of our method. ",Exploring and mining attributed sequences of interactions
"  Video captioning is a challenging task that requires a deep understanding of visual scenes. State-of-the-art methods generate captions using either scene-level or object-level information but without explicitly modeling object interactions. Thus, they often fail to make visually grounded predictions, and are sensitive to spurious correlations. In this paper, we propose a novel spatio-temporal graph model for video captioning that exploits object interactions in space and time. Our model builds interpretable links and is able to provide explicit visual grounding. To avoid unstable performance caused by the variable number of objects, we further propose an object-aware knowledge distillation mechanism, in which local object information is used to regularize global scene features. We demonstrate the efficacy of our approach through extensive experiments on two benchmarks, showing our approach yields competitive performance with interpretable predictions. ",Spatio-Temporal Graph for Video Captioning with Knowledge Distillation
"  This first part of the series treats the Maxwell equations in the exterior of a slowly rotating Kerr black hole. By performing a first-order differential operator on each extreme Newman-Penrose (N-P) scalar in a Kinnersley tetrad, the resulting equation and the Teukolsky master equation for the extreme N-P component are both in the form of an inhomogeneous \textquotedblleft{spin-weighted Fackerell-Ipser equation\textquotedblright} (SWFIE) and constitute a weakly coupled system. We first prove energy estimate and integrated local energy decay (Morawetz) estimate for this type of inhomogeneous SWFIE following the method in (Dafermos and Rodnianski in Decay for solutions of the wave equation on Kerr exterior spacetimes I-II: the cases $|a|\ll M$ or axisymmetry, 2010, arXiv:1010.5132), and then utilize these estimates to achieve both a uniform bound of a positive definite energy and a Morawetz estimate for the coupled system of each extreme N-P component. The same type of estimates for the regular extreme N-P components defined in the regular Hawking-Hartle tetrad is also proved. The hierarchy here is generalized in our second part (Ma in Uniform energy bound and Morawetz estimates for extreme components of spin fields in the exterior of a slowly rotating Kerr black hole II: linearized gravity, 2017, arXiv:1708.07385) of this series to treat the extreme components of linearized gravity. ",Uniform energy bound and Morawetz estimate for extreme components of   spin fields in the exterior of a slowly rotating Kerr black hole I: Maxwell   field
"  First measurements of the azimuthal anisotropy of neutral pions produced in PbPb collisions at a center-of-mass energy of sqrt(s(NN)) = 2.76 TeV are presented. The amplitudes of the second Fourier component (v2) of the neutral pion azimuthal distributions are extracted using an event-plane technique. The values of v2 are studied as a function of the neutral pion transverse momentum (pt) for different classes of collision centrality in the kinematic range 1.6 < pt < 8.0 GeV, within the pseudorapidity interval abs(eta) < 0.8. The CMS measurements of v2(pt) are similar to previously reported neutral pion azimuthal anisotropy results from sqrt(s(NN)) = 200 GeV AuAu collisions at RHIC, despite a factor of about 14 increase in the center-of-mass energy. In the momentum range 2.5 < pt < 5.0 GeV, the neutral pion anisotropies are found to be smaller than those observed by CMS for inclusive charged particles. ",Measurement of the azimuthal anisotropy of neutral pions in PbPb   collisions at sqrt(s(NN)) = 2.76 TeV
"  We give a characterization of the class of gapped Hamiltonians introduced in PartI [O]. The Hamiltonians in this class are given as MPS (Matrix product state) Hamiltonians. In [O], we list up properties of ground state structures of Hamiltonians in this class. In this Part II, we show the converse. Namely, if a (not necessarily MPS) Hamiltonian $H$ satisfies five of the listed properties, there is a Hamiltonian $H'$ from the class in [O], satisfying the followings: The ground state spaces of the two Hamiltonians on the infinite intervals coincide. The spectral projections onto the ground state space of $H$ on each finite intervals are approximated by that of $H'$ exponentially well, with respect to the interval size. The latter property has an application to the classification problem. ",A class of asymmetric gapped Hamiltonians on quantum spin chains and its   characterization II
"  This work is a follow-up and a complement to arXiv:1912.08899 [math.OC] for solving polynomial optimization problems (POPs). The chordal-TSSOS hierarchy that we propose is a new sparse moment-SOS framework based on term-sparsity and chordal extension. By exploiting term-sparsity of the input polynomials we obtain a two-level hierarchy of semidefinite programming relaxations. The novelty and distinguishing feature of such relaxations is to obtain quasi block-diagonal matrices obtained in an iterative procedure that performs chordal extension of certain adjacency graphs. The graphs are related to the terms arising in the original data and not to the links between variables. Various numerical examples demonstrate the efficiency and the scalability of this new hierarchy for both unconstrained and constrained POPs. The two hierarchies are complementary. While the former TSSOS arXiv:1912.08899 [math.OC] has a theoretical convergence guarantee, the chordal-TSSOS has superior performance but lacks this theoretical guarantee. ",Chordal-TSSOS: a moment-SOS hierarchy that exploits term sparsity with   chordal extension
"  It is challenging to bridge the performance gap between Binary CNN (BCNN) and Floating point CNN (FCNN). We observe that, this performance gap leads to substantial residuals between intermediate feature maps of BCNN and FCNN. To minimize the performance gap, we enforce BCNN to produce similar intermediate feature maps with the ones of FCNN. This training strategy, i.e., optimizing each binary convolutional block with block-wise distillation loss derived from FCNN, leads to a more effective optimization to BCNN. It also motivates us to update the binary convolutional block architecture to facilitate the optimization of block-wise distillation loss. Specifically, a lightweight shortcut branch is inserted into each binary convolutional block to complement residuals at each block. Benefited from its Squeeze-and-Interaction (SI) structure, this shortcut branch introduces a fraction of parameters, e.g., 10\% overheads, but effectively complements the residuals. Extensive experiments on ImageNet demonstrate the superior performance of our method in both classification efficiency and accuracy, e.g., BCNN trained with our methods achieves the accuracy of 60.45\% on ImageNet. ",Distillation Guided Residual Learning for Binary Convolutional Neural   Networks
"  We consider an alternative cold dark matter candidate, ultralight bosons ($m>10^{-22}$eV) described by a complex scalar field (SFDM) with global U(1) symmetry, with comoving particle number density conserved after particle production during standard reheating. We allow for repulsive self-interaction. In a Lambda-SFDM universe, SFDM starts relativistic, evolving from stiff (w=1) to radiation-like (w=1/3), becoming nonrelativistic (w=0) at late times. Thus, a stiff-SFDM-dominated era precedes the familiar radiation-dominated era. SFDM particle mass $m$ and quartic self-interaction strength \lambda, are therefore constrained by cosmological observables, N_{eff}, the effective number of neutrino species during BBN, and z_{eq}, the matter-radiation equality redshift. Since the stochastic gravitational wave background (SGWB) from inflation is amplified during the stiff-SFDM-dominated era, it can also contribute a radiationlike component large enough to affect these observables. Remarkably, this amplification makes this SGWB detectable by current GW experiments, e.g., aLIGO/Virgo and LISA, for Lambda-SFDM models satisfying cosmological constraints, for a range of reheat temperatures T_{re} and currently allowed values of tensor-to-scalar ratio $r$. For given r and $\lambda/(mc^2)^2$, the marginally-allowed Lambda-SFDM model for each T_{re} has the smallest m that satisfies cosmological constraints. For example, for marginally-allowed models with r=0.01 and $\lambda/(mc^2)^2=10^{-18}$eV$^{-1}$cm$^3$, null detection by the aLIGO O1 run excludes 8.75*10^3<T_{re} (GeV)<1.7*10^5 at 95% confidence, demonstrating that GW experiments already place a new kind of cosmological constraint on SFDM. A wider parameter range should be accessible to aLIGO/Virgo O5, with potential to detect this signature of Lambda-SFDM. For this same illustrative family, 3-sigma detection is predicted for 600<T_{re} (GeV)<10^7. ",Bose-Einstein-condensed scalar field dark matter and the gravitational   wave background from inflation: new cosmological constraints and its   detectability by LIGO
"  The tectonic regime of rocky planets fundamentally influences their long-term evolution and cycling of volatiles between interior and atmosphere. Earth is the only known planet with active plate tectonics, but observations of exoplanets may deliver insights into the diversity of tectonic regimes beyond the solar system. Observations of the thermal phase curve of super-Earth LHS 3844b reveal a solid surface and lack of a substantial atmosphere, with a temperature contrast between the substellar and antistellar point of around 1000 K. Here, we use these constraints on the planet's surface to constrain the interior dynamics and tectonic regimes of LHS 3844b using numerical models of interior flow. We investigate the style of interior convection by assessing how upwellings and downwellings are organized and how tectonic regimes manifest. We discover three viable convective regimes with a mobile surface: (1) spatially uniform distribution of upwellings and downwellings, (2) prominent downwelling on the dayside and upwellings on the nightside, and (3) prominent downwelling on the nightside and upwellings on the dayside. Hemispheric tectonics is observed for regimes (2) and (3) as a direct consequence of the day-to-night temperature contrast. Such a tectonic mode is absent in the present-day solar system and has never been inferred from astrophysical observations of exoplanets. Our models offer distinct predictions for volcanism and outgassing linked to the tectonic regime, which may explain secondary features in phase curves and allow future observations to constrain the diversity of super-Earth interiors. ",Hemispheric Tectonics on super-Earth LHS 3844b
"  We propose a new method for the Maximum Likelihood Estimator (MLE) of nonlinear mixed effects models when the variance matrix of Gaussian random effects has a prescribed pattern of zeros (PPZ). The method consists in coupling the recently developed Iterative Conditional Fitting (ICF) algorithm with the Expectation Maximization (EM) algorithm. It provides positive definite estimates for any sample size, and does not rely on any structural assumption on the PPZ. It can be easily adapted to many versions of EM. ",A new method for the estimation of variance matrix with prescribed zeros   in nonlinear mixed effects models
"  The minimal conductivity of graphene is a quantity measured in the DC limit. It is shown, using the Kubo formula, that the actual value of the minimal conductivity is sensitive to the order in which certain limits are taken. If the DC limit is taken before the integration over energies is performed, the minimal conductivity of graphene is $4/\pi$ (in units of $e^2/h$) and it is $\pi/2$ in the reverse order. The value $\pi$ is obtained if weak disorder is included via a small frequency-dependent selfenergy. In the high-frequency limit the minimal conductivity approaches $\pi/2$ and drops to zero if the frequency exceeds the cut-off energy of the particles. ",On the minimal conductivity of graphene
"  We demonstrate a scalable device architecture that facilitates indirect exchange between singlet-triplet spin qubits, mediated by an intermediate quantum state. The device comprises five quantum dots, which can be independently loaded and unloaded via tunneling to adjacent reservoirs, avoiding charge latch-up common in linear dot arrays. In a step towards realizing two-qubit entanglement based on indirect exchange, the architecture permits precise control over tunnel rates between the singlet-triplet qubits and the intermediate state. We show that by separating qubits by 1 um, the residual capacitive coupling between them is reduced to 7 ueV. ",Device Architecture for Coupling Spin Qubits Via an Intermediate Quantum   State
"  In this note, we describe the backward shift invariant subspaces for a large class of reproducing kernel Hilbert spaces. This class includes in particular de Branges-Rovnyak spaces (the non-extreme case) and the range space of co-analytic Toeplitz operators. ",Backward Shift Invariant Subspaces in Reproducing Kernel Hilbert Spaces
  We study ruled surfaces in R3 which are obtained from dual spher- ical indicatrix curves of dual Frenet vector fields. We find the Gaussian and mean curvatures of the ruled surfaces and give some results of being Wein- garten surface. ,Ruled Weingarten Surfaces Related to Dual Spherical Curves
"  To examine the previously claimed fast cooling of the Central Compact Object (CCO) in the Cas A supernova remnant (SNR), we analyzed two Chandra observations of this CCO, taken in a setup minimizing instrumental spectral distortions. We fit the two CCO X-ray spectra from 2006 and 2012 with hydrogen and carbon neutron star atmosphere models. The temperature and flux changes in the 5.5 years between the two epochs depend on the adopted constraints on the fitting parameters and the uncertainties of the effective area calibrations. If we allow a change of the equivalent emitting region size, R_Em, the effective temperature remains essentially the same. If R_Em is held constant, the best-fit temperature change is negative, but its statistical significance ranges from 0.8sigma to 2.5sigma, depending on the model. If we assume that the optical depth of the ACIS filter contaminant in 2012 was +/-10% different from its default calibration value, the significance of the temperature drop becomes 0.8sigma to 3.1sigma, for the carbon atmospheres with constant R_Em. Thus, we do not see a statistically significant temperature drop in our data, but the involved uncertainties are too large to firmly exclude the previously reported fast cooling. Our analysis indicate a decrease of 4%-6% (1.9-2.9sigma significance) for the absorbed flux in the energy range 0.6-6keV between 2006 and 2012, most prominent in the 1.4-1.8 keV energy range. It could be caused by unaccounted changes of the detector response or contributions from unresolved SNR material along the line of sight to the CCO. ",New constraints on the cooling of the Central Compact Object in Cas A
"  Distributed optimization is often widely attempted and innovated as an attractive and preferred methodology to solve large-scale problems effectively in a localized and coordinated manner. Thus, it is noteworthy that the methodology of distributed model predictive control (DMPC) has become a promising approach to achieve effective outcomes, e.g., in decision-making tasks for multi-agent systems. However, the typical deployment of such distributed MPC frameworks would lead to the involvement of nonlinear processes with a large number of nonconvex constraints. To address this important problem, the development and innovation of a hierarchical three-block alternating direction method of multipliers (ADMM) approach is presented in this work to solve this nonconvex cooperative DMPC problem in multi-agent systems. Here firstly, an additional slack variable is introduced to transform the original large-scale nonconvex optimization problem. Then, a hierarchical ADMM approach, which contains outer loop iteration by the augmented Lagrangian method (ALM) and inner loop iteration by three-block semi-proximal ADMM, is utilized to solve the resulting transformed nonconvex optimization problem. Additionally, it is analytically shown and established that the requisite desired stationary point exists for convergence in the algorithm. Finally, an approximate optimization stage with a barrier method is then applied to further significantly improve the computational efficiency, yielding the final improved hierarchical ADMM. The effectiveness of the proposed method in terms of attained performance and computational efficiency is demonstrated on a cooperative DMPC problem of decision-making process for multiple unmanned aerial vehicles (UAVs). ",Improved Hierarchical ADMM for Nonconvex Cooperative Distributed Model   Predictive Control
"  In the game of Matching Pennies, Alice and Bob each hold a penny, and at every tick of the clock they simultaneously display the head or the tail sides of their coins. If they both display the same side, then Alice wins Bob's penny; if they display different sides, then Bob wins Alice's penny. To avoid giving the opponent a chance to win, both players seem to have nothing else to do but to randomly play heads and tails with equal frequencies. However, while not losing in this game is easy, not missing an opportunity to win is not. Randomizing your own moves can be made easy. Recognizing when the opponent's moves are not random can be arbitrarily hard.   The notion of randomness is central in game theory, but it is usually taken for granted. The notion of outsmarting is not central in game theory, but it is central in the practice of gaming. We pursue the idea that these two notions can be usefully viewed as two sides of the same coin. ",Testing Randomness by Matching Pennies
"  Large prospective epidemiological studies acquire cardiovascular magnetic resonance (CMR) images for pre-symptomatic populations and follow these over time. To support this approach, fully automatic large-scale 3D analysis is essential. In this work, we propose a novel deep neural network using both CMR images and patient metadata to directly predict cardiac shape parameters. The proposed method uses the promising ability of statistical shape models to simplify shape complexity and variability together with the advantages of convolutional neural networks for the extraction of solid visual features. To the best of our knowledge, this is the first work that uses such an approach for 3D cardiac shape prediction. We validated our proposed CMR analytics method against a reference cohort containing 500 3D shapes of the cardiac ventricles. Our results show broadly significant agreement with the reference shapes in terms of the estimated volume of the cardiac ventricles, myocardial mass, 3D Dice, and mean and Hausdorff distance. ",3D Cardiac Shape Prediction with Deep Neural Networks: Simultaneous Use   of Images and Patient Metadata
"  In the first part of the paper, we define an approximated Brunn-Minkowski inequality which generalizes the classical one for length spaces. Our new definition based only on distance properties allows us also to deal with discrete spaces. Then we show the stability of our new inequality under a convergence of metric measure spaces. This result gives as a corollary the stability of the classical Brunn-Minkowski inequality for geodesic spaces. The proof of this stability was done for different inequalities (curvature dimension inequality, metric contraction property) but as far as we know not for the Brunn-Minkowski one. In the second part of the paper, we show that every metric measure space satisfying classical Brunn-Minkowski inequality can be approximated by discrete spaces with some approximated Brunn-Minkowski inequalities. ",A discrete version and stability of Brunn Minkowski inequality
"  Ganymede's atmosphere is produced by radiative interactions with its surface, sourced by the Sun and the Jovian plasma. The sputtered and thermally desorbed molecules are tracked in our Exospheric Global Model (EGM), a 3-D parallelized collisional model. This program was developed to reconstruct the formation of the upper atmosphere/exosphere of planetary bodies interacting with solar photon flux and magnetospheric and/or the solar wind plasmas. Here, we describe the spatial distribution of the H$_2$O and O$_2$ components of Ganymede's atmosphere, and their temporal variability along Ganymede's rotation around Jupiter. In particular, we show that Ganymede's O$_2$ atmosphere is characterized by time scales of the order of Ganymede's rotational period with Jupiter's gravity being a significant driver of the spatial distribution of the heaviest exospheric components. Both the sourcing and the Jovian gravity are needed to explain some of the characteristics of the observed aurora emissions. As an example, the O$_2$ exosphere should peak at the equator with systematic maximum at the dusk equator terminator. The sputtering rate of the H$_2$O exosphere should be maximum on the leading hemisphere because of the shape of the open/close field lines boundary and displays some significant variability with longitude. ",On the orbital variability of Ganymede's atmosphere
"  We define the characteristic cycle of an etale sheaf as a cycle on the cotangent bundle of a smooth variety in positive characteristic using the singular support recently defined by Beilinson. We prove a formula a la Milnor for the total dimension of the space of vanishing cycles and an index formula computing the Euler-Poincare characteristic, generalizing the Grothendieck-Ogg-Shafarevich formula to higher dimension.   An essential ingredient of the construction and the proof is a partial generalization to higher dimension of the semi-continuity of the Swan conductor due to Deligne-Laumon. We prove the index formula by establishing certain functorial properties of characteristic cycles. ",The characteristic cycle and the singular support of a constructible   sheaf
"  We discuss the relation of the specific heat, the energy density and the thermodynamic Casimir effect in the case of thin films in the three dimensional XY universality class. The finite size scaling function $\theta(x)$ of the thermodynamic Casimir force can be expressed in terms of the scaling functions h'(x) and h(x) of the excess energy density and the excess free energy density. A priori these quantities depend on the reduced temperature t and the thickness L_0 of the film. However finite size scaling theory predicts that the scaling functions depend only on the combination x=t [L_0/\xi_0]^{1/\nu}, where \nu is the critical exponent and $\xi_0$ the amplitude of the correlation length. We exploit this fact to compute \theta from Monte Carlo data for the excess energy density of the improved two-component \phi^4 model on the simple cubic lattice with free boundary conditions in the short direction. We repeat this exercise using experimental data for the excess specific heat of 4He films. The finite size scaling behaviour of the excess specific heat is governed by h''(x), which is proportional to the scaling function $f_2$ discussed in the literature. We compare our results with previous work, where the Casimir force has been computed by taking the derivative of the excess free energy with respect to the thickness of the film. As a preparative study we have also computed the scaling functions h'(x) and h(x) for finite L^3 systems with periodic boundary conditions in all directions, where L is the linear extension of the system. ","The specific heat, the energy density and the thermodynamic Casimir   force in the neighbourhood of the lambda-transition"
"  In order to explain the Tevatron anomaly of the top quark forward-backward asymmetry $A_{FB}^t$ in the left-right twin Higgs model, we choose to give up the lightest neutral particle of $\hat{h}$ field as a stable dark matter candidate. Then a new Yukawa interaction for $\hat{h}$ is allowed, which can be free from the constraint of same-sign top pair production and contribute sizably to $A_{FB}^t$. Considering the constraints from the production rates of the top pair ($t\bar t$), the top decay rates and $t\bar{t}$ invariant mass distribution, we find that this model with such new Yukawa interaction can explain $A_{FB}^t$ measured at the Tevatron while satisfying the charge asymmetry $A_{C}^t$ measured at the LHC.Moreover, this model predicts a strongly correlation between $A_{C}^t$ at the LHC and $A_{FB}^t$ at the Tevatron, i.e., $A_{C}^t$ increases as $A_{FB}^t$ increases. ",Top quark forward-backward asymmetry and charge asymmetry in left-right   twin Higgs model
"  Realizing a strong interaction between individual optical photons is an important objective of research in quantum science and technology. Since photons do not interact directly, this goal requires, e.g., an optical medium in which the light experiences a phase shift that depends nonlinearly on the photon number. Once the additional phase shift for two photons reaches pi, such an ultra-strong nonlinearity could even enable the direct implementation of high-fidelity quantum logic operations. However, the nonlinear response of standard optical media is many orders of magnitude too weak for this task. Here, we demonstrate the realization of an optical fiber-based nonlinearity that leads to an additional two-photon phase shift close to the ideal value of pi. Our scheme employs a whispering-gallery-mode resonator, interfaced by an optical nanofiber, where the presence of a single rubidium atom in the resonator results in a strongly nonlinear response. We experimentally show that this results in entanglement of initially independent incident photons. The demonstration of this ultra-strong nonlinearity in a fiber-integrated system is a decisive step towards scalable quantum logics with optical photons. ",Nonlinear pi phase shift for single fiber-guided photons interacting   with a single atom
"  In this article, we calculate the form factors and the coupling constant of the vertex $D_{s}^{*}D_{s}\phi$ using the three-point QCD sum rules. We consider the contributions of the vacuum condensates up to dimension $7$ in the operator product expansion(OPE). And all possible off-shell cases are considered, $\phi$, $D_{s}$ and $D_{s}^{*}$, resulting in three different form factors. Then we fit the form factors into analytical functions and extrapolate them into time-like regions, which giving the coupling constant for the process. Our analysis indicates that the coupling constant for this vertex is $G_{Ds*Ds\phi}=4.12\pm0.70 GeV^{-1}$. The results of this work are very useful in the other phenomenological analysis. As an application, we calculate the coupling constant for the decay channel $D_{s}^{*}\rightarrow D_{s}\gamma$ and analyze the width of this decay with the assumption of the vector meson dominance of the intermediate $\phi(1020)$. Our final result about the decay width of this decay channel is $\Gamma=0.59\pm0.15keV$. ",Analysis of the strong coupling constant $G_{D_{s}^{*}D_{s}\phi}$ and   the decay width of $D_{s}^{*}\rightarrow D_{s}\gamma$ with QCD sum rules
"  This paper presents an experimental study of different instability scenarios in a parallelogram-shaped internal wave attractor in a trapezoidal domain filled with a uniformly stratified fluid. Energy is injected into the system via the oscillatory motion of a vertical wall of the trapezoidal domain. Whole-field velocity measurements are performed with the conventional PIV technique. In the linear regime, the total kinetic energyof the fluid system is used to quantify the strength of attractors as a function of coordinates in the parameter spacedefining their zone of existence, the so-called Arnold tongue. In the nonlinear regime, the choice of the operational point in the Arnold tongue is shown to have a significant impact on the scenario of the onset of triadic instability, most notably on the influence of confinement on secondary waves. The onset of triadic resonance instability may occur as a spatially localized event similar to Scolan, Ermanyuk and Dauxois (2013) in the case of strong focusing or in form of growing normal modes as in McEwan (1971) for the limiting case of rectangular domain. In the present paper, we describe also a new intermediate scenario for the case of weak focusing. We explore the long-term behaviour of cascades of triadic instabilities in wave attractors and show a persistent trend toward formation of standing-wave patterns corresponding to some discrete peaks of the frequency spectrum. At sufficiently high level of energy injection the system exhibits a ""mixing box"" regime which has certain qualitatively universal properties regardless to the choiceof the operating point in the Arnold tongue. In particular, for this regime, we observe a statisticsof events with high horizontal vorticity, which serve as kinematic indicators of mixing. ",Internal wave attractors: different scenarios of instability
"  We link the recent computation beyond leading twist of the impact factor of the transition gamma*T -> rhoT performed in the light-cone collinear approach, to the dipole picture by expressing the hard part of the process through its Fourier transform in coordinate space. We show that in the Wandzura-Wilczek approximation the impact factor up to twist 3 factorises in the wave function of the photon combined with the distribution amplitudes of the rho-meson and the colour dipole scattering amplitude with the t-channel gluons. We show also that beyond the Wandzura-Wilczek approximation, the hard contribution of the amplitude still exhibits the signature of the interaction of a single colour dipole with the t-channel gluons. This result allows a phenomenological approach of the helicity amplitudes of the leptoproduction of vector meson, by combining our results to a dipole/target scattering amplitude model. ",The dipole representation of vector meson electroproduction beyond   leading twist
"  Let $M_n$ be a homology 3-sphere obtained by $\frac1n$-Dehn surgery along a $(p,q)$-torus knot. We consider a polynomial $\sigma_{(p,q,n)}(t)$ whose zeros are the inverses of the Reideimeister torsion of $M_n$ for $\mathit{SL}(2;\mathbb{C})$-irreducible representations. We give an explicit formula of this polynomial by using Tchebychev polynomials of the first kind. Further we also give a 3-term relations of these polynomials. ",A polynomial defined by the $\mathit{SL}(2;\mathbb{C})$-Reidemeister   torsion for a homology 3-sphere obtained by Dehn-surgery along a torus knot
"  Optical and infrared interferometers definitively established that the photometric standard Vega (alpha Lyrae) is a rapidly rotating star viewed nearly pole-on. Recent independent spectroscopic analyses could not reconcile the inferred inclination angle with the observed line profiles, preferring a larger inclination. In order to resolve this controversy, we observed Vega using the six-beam Michigan Infrared Combiner on the Center for High Angular Resolution Astronomy Array. With our greater angular resolution and dense (u,v)-coverage, we find Vega is rotating less rapidly and with a smaller gravity darkening coefficient than previous interferometric results. Our models are compatible with low photospheric macroturbulence and also consistent with the possible rotational period of ~0.71 days recently reported based on magnetic field observations. Our updated evolutionary analysis explicitly incorporates rapid rotation, finding Vega to have a mass of 2.15+0.10_-0.15 Msun and an age 700-75+150 Myrs, substantially older than previous estimates with errors dominated by lingering metallicity uncertainties (Z=0.006+0.003-0.002). ",Resolving Vega and the inclination controversy with CHARA/MIRC
"  The amount of non-unique sequence (non-singletons) in a genome directly affects the difficulty of read alignment to a reference assembly for high throughput-sequencing data. Although a greater length increases the chance for reads being uniquely mapped to the reference genome, a quantitative analysis of the influence of read lengths on mappability has been lacking. To address this question, we evaluate the k-mer distribution of the human reference genome. The k-mer frequency is determined for k ranging from 20 to 1000 basepairs. We use the proportion of non-singleton k-mers to evaluate the mappability of reads for a corresponding read length. We observe that the proportion of non-singletons decreases slowly with increasing k, and can be fitted by piecewise power-law functions with different exponents at different k ranges. A faster decay at smaller values for k indicates more limited gains for read lengths > 200 basepairs. The frequency distributions of k-mers exhibit long tails in a power-law-like trend, and rank frequency plots exhibit a concave Zipf's curve. The location of the most frequent 1000-mers comprises 172 kilobase-ranged regions, including four large stretches on chromosomes 1 and X, containing genes with biomedical implications. Even the read length 1000 would be insufficient to reliably sequence these specific regions. ",Diminishing Return for Increased Mappability with Longer Sequencing   Reads: Implications of the k-mer Distributions in the Human Genome
"  We study opportunities for future high-precision experiments in kaon physics using a high-intensity proton driver, which could be part of the front-end of a muon storage ring complex. We discuss in particular the rare decays $K_L\to\pi^0\nu\bar\nu$, $K^+\to\pi^+\nu\bar\nu$, $K_L\to\pi^0e^+e^-$, and lepton-flavour violating modes such as $K_L\to\mu e$ and $K\to\pi\mu e$. The outstanding physics potential and long-term interest of these modes is emphasized. We review status and prospects of current and planned experiments for the processes under consideration, and indicate possible improvements and strategies towards achieving the necessary higher sensitivity. Finally, we outline the machine requirements needed to perform these high-precision kaon experiments in the context of a muon storage ring facility. ",Kaon physics with a high-intensity proton driver
"  The Bethe-Peierls asymptotic approach which models pairwise short-range forces by contact conditions is introduced in arbitrary representation for spatial dimensions less than or equal to 3. The formalism is applied in various situations and emphasis is put on the momentum representation. In the presence of a transverse harmonic confinement, dimensional reduction toward two-dimensional (2D) or one-dimensional (1D) physics is derived within this formalism. The energy theorem relating the mean energy of an interacting system to the asymptotic behavior of the one-particle density matrix illustrates the method in its second quantized form. Integral equations that encapsulate the Bethe-Peierls contact condition for few-body systems are derived. In three dimensions, for three-body systems supporting Efimov states, a nodal condition is introduced in order to obtain universal results from the Skorniakov Ter-Martirosian equation and the Thomas collapse is avoided. Four-body bound state eigenequations are derived and the 2D '3+1' bosonic ground state is computed as a function of the mass ratio. ",Isotropic contact forces in arbitrary representation: heterogeneous   few-body problems and low dimensions
  We show that the vanishing of the higher dimensional homology groups of a manifold ensures that every almost CR structure of codimension $k$ may be homotoped to a CR structure. This result is proved by adapting a method due to Haefliger used to study foliations (and previously applied to study the relation between almost complex and complex structures on manifolds) to the case of (almost) CR structures on open manifolds. ,CR structures on open manifolds
"  Let $F_q$ be a finite field of characteristic $p=2,3$. We give the number of irreducible polynomials $x^m+a_{m-1}x^{m-1}+...+a_0\in\F_q[x]$ with $a_{m-1}$ and $a_{m-3}$ prescribed for any given $m$ if $p=2$, and with $a_{m-1}$ and $a_1$ prescribed for $m=1,...,10$ if $p=2,3$. ",Elliptic curves and explicit enumeration of irreducible polynomials with   two coefficients prescribed
"  In this paper, we consider the state-dependent reflecting random walk on a half-strip. We provide explicit criteria for (positive) recurrence, and an explicit expression for the stationary distribution. As a consequence, the light-tailed behavior of the stationary distribution is proved under appropriate conditions. The key idea of the method employed here is the decomposition of the trajectory of the random walk and the main tool is the intrinsic branching structure buried in the random walk on a strip, which is different from the matrix-analytic method. ",Light-tailed behavior of stationary distribution for state-dependent   random walks on a strip
"  We investigate the properties of correlation based networks originating from economic complex systems, such as the network of stocks traded at the New York Stock Exchange (NYSE). The weaker links (low correlation) of the system are found to contribute to the overall connectivity of the network significantly more than the strong links (high correlation). We find that nodes connected through strong links form well defined communities. These communities are clustered together in more complex ways compared to the widely used classification according to the economic activity. We find that some companies, such as General Electric (GE), Coca Cola (KO), and others, can be involved in different communities. The communities are found to be quite stable over time. Similar results were obtained by investigating markets completely different in size and properties, such as the Athens Stock Exchange (ASE). The present method may be also useful for other networks generated through correlations. ",The structural role of weak and strong links in a financial market   network
  We study type IIB orientifolds on T^{2d}/Z_N with supersymmetry broken by the compactification. We determine tadpole cancellation conditions including anti-branes and considering different actions for the parity Omega. Using these conditions we then obtain the spectrum of tachyons and massless states. Various examples with N even correspond to type 0B orientifolds. ,A class of non-supersymmetric orientifolds
"  We show that, in many situations, a homeomorphism $f$ of a manifold $M$ may be recovered from the (marked) isomorphism class of a finitely generated group of homeomorphisms containing $f$. As an application, we relate the notions of {\em critical regularity} and of {\em differentiable rigidity}, give examples of groups of diffeomorphisms of 1-manifolds with strong differential rigidity, and in so doing give an independent, short proof of a recent result of Kim and Koberda that there exist finitely generated groups of $C^\alpha$ diffeomorphisms of a 1-manifold $M$, not embeddable into $\mathrm{Diff}^\beta(M)$ for any $\beta > \alpha > 1$. ",Reconstructing maps out of groups
"  Most of the deep learning-based speech enhancement models are learned in a supervised manner, which implies that pairs of noisy and clean speech are required during training. Consequently, several noisy speeches recorded in daily life cannot be used to train the model. Although certain unsupervised learning frameworks have also been proposed to solve the pair constraint, they still require clean speech or noise for training. Therefore, in this paper, we propose MetricGAN-U, which stands for MetricGAN-unsupervised, to further release the constraint from conventional unsupervised learning. In MetricGAN-U, only noisy speech is required to train the model by optimizing non-intrusive speech quality metrics. The experimental results verified that MetricGAN-U outperforms baselines in both objective and subjective metrics. ",MetricGAN-U: Unsupervised speech enhancement/ dereverberation based only   on noisy/ reverberated speech
"  With the advancement in computing and robotics, it is necessary to develop fluent and intuitive methods for interacting with digital systems, AR/VR interfaces, and physical robotic systems. Hand movement recognition is widely used to enable this interaction. Hand configuration classification and Metacarpophalangeal (MCP) joint angle detection are important for a comprehensive reconstruction of the hand motion. Surface electromyography and other technologies have been used for the detection of hand motions. Ultrasound images of the forearm offer a way to visualize the internal physiology of the hand from a musculoskeletal perspective. Recent work has shown that these images can be classified using machine learning to predict various hand configurations. In this paper, we propose a Convolutional Neural Network (CNN) based deep learning pipeline for predicting the MCP joint angles. We supplement our results by using a Support Vector Classifier (SVC) to classify the ultrasound information into several predefined hand configurations based on activities of daily living (ADL). Ultrasound data from the forearm was obtained from 6 subjects who were instructed to move their hands according to predefined hand configurations relevant to ADLs. Motion capture data was acquired as the ground truth for hand movements at different speeds (0.5 Hz, 1 Hz, & 2 Hz) for the index, middle, ring, and pinky fingers. We were able to get promising SVC classification results on a subset of our collected data set. We demonstrated a correspondence between the predicted MCP joint angles and the actual MCP joint angles for the fingers, with an average root mean square error of 7.35 degrees. We implemented a low latency (6.25 - 9.1 Hz) pipeline for the prediction of both MCP joint angles and hand configuration estimation aimed at real-time control of digital devices, AR/VR interfaces, and physical robots. ",Prediction of Metacarpophalangeal joint angles and Classification of   Hand configurations based on Ultrasound Imaging of the Forearm
"  We study the module categories of a tilted algebra C and the corresponding cluster-tilted algebra B. In particular, we study which $\tau$-rigid C-modules are also $\tau$-rigid B-modules. ",$\tau$-Rigid Modules from Tilted to Cluster-Tilted Algebras
"  Neutron inelastic scattering and diffraction techniques have been used to study the MnV2O4 spinel system. Our measurements show the existence of two transitions to long-range ordered ferrimagnetic states; the first collinear and the second noncollinear. The lower temperature transition, characterized by development of antiferromagnetic components in the basal plane, is accompanied by a tetragonal distortion and the appearance of a gap in the magnetic excitation spectrum. The low-temperature noncollinear magnetic structure has been definitively resolved. Taken together, the crystal and magnetic structures indicate a staggered ordering of the V d orbitals. The anisotropy gap is a consequence of unquenched V orbital angular momentum. ",Magnetic and orbital ordering in the spinel MnV2O4
"  Arrays are such a rich and fundamental data type that they tend to be built into a language, either in the compiler or in a large low-level library. Defining this functionality at the user level instead provides greater flexibility for application domains not envisioned by the language designer. Only a few languages, such as C++ and Haskell, provide the necessary power to define $n$-dimensional arrays, but these systems rely on compile-time abstraction, sacrificing some flexibility. In contrast, dynamic languages make it straightforward for the user to define any behavior they might want, but at the possible expense of performance.   As part of the Julia language project, we have developed an approach that yields a novel trade-off between flexibility and compile-time analysis. The core abstraction we use is multiple dispatch. We have come to believe that while multiple dispatch has not been especially popular in most kinds of programming, technical computing is its killer application. By expressing key functions such as array indexing using multi-method signatures, a surprising range of behaviors can be obtained, in a way that is both relatively easy to write and amenable to compiler analysis. The compact factoring of concerns provided by these methods makes it easier for user-defined types to behave consistently with types in the standard library. ",Array operators using multiple dispatch: a design methodology for array   implementations in dynamic languages
"  The motion of a C60 molecule over a graphene sheet at finite temperature is investigated both theoretically and computationally. We show that a graphene sheet generates a van der Waals laterally periodic potential, which directly influences the motion of external objects in its proximity. The translational motion of a C60 molecule near a graphene sheet is found to be diffusive in the lateral directions. While, in the perpendicular direction, the motion may be described as diffusion in an effective harmonic potential which is determined from the distribution function of the position of the C60 molecule. We also examine the rotational diffusion of C60 and show that its motion over the graphene sheet is not a rolling motion. ",Diffusive motion of C60 on a graphene sheet
"  The formation of the giant planets in our solar system, and likely a majority of giant exoplanets, is commonly explained by the accretion of nebular hydrogen and helium onto a large core of terrestrial-like composition. The fate of this core has important consequences for the evolution of the interior structure of the planet. It has recently been shown that H2O, MgO and SiO2 dissolve in liquid metallic hydrogen at high temperature and pressure. In this study, we perform ab initio calculations to study the solubility of an innermost metallic core. We find dissolution of iron to be strongly favored above 2000 K over the entire pressure range (0.4-4 TPa) considered. We compare with and summarize the results for solubilities on other probable core constituents. The calculations imply that giant planet cores are in thermodynamic disequilibrium with surrounding layers, promoting erosion and redistribution of heavy elements. Differences in solubility behavior between iron and rock may influence evolution of interiors, particularly for Saturn-mass planets. Understanding the distribution of iron and other heavy elements in gas giants may be relevant in understanding mass-radius relationships, as well as deviations in transport properties from pure hydrogen-helium mixtures. ",Solubility of Iron in Metallic Hydrogen and Stability of Dense Cores in   Giant Planets
  We present a method of discrete modeling and analysis of multilevel dynamics of complex large-scale hierarchical dynamic systems subject to external dynamic control mechanism. Architectural model of information system supporting simulation and analysis of dynamic processes and development scenarios (strategies) of complex large-scale hierarchical systems is also proposed. ,Mathematical and computer tools of discrete dynamic modeling and   analysis of complex systems in control loop
"  Scalable and fault-tolerant quantum computation will require error correction. This will demand constant measurement of many-qubit observables, implemented using a vast number of CNOT gates. Indeed, practically all operations performed by a fault-tolerant device will be these CNOTs, or equivalent two-qubit controlled operations. It is therefore important to devise benchmarks for these gates that explicitly quantify their effectiveness at this task. Here we develop such benchmarks, and demonstrate their use by applying them to a range of differently implemented controlled gates and a particular quantum error correcting code. Specifically, we consider spin qubits confined to quantum dots that are coupled either directly or via floating gates to implement the minimal 17-qubit instance of the surface code. Our results show that small differences in the gate fidelity can lead to large differences in the performance of the surface code. This shows that gate fidelity is not, in general, a good predictor of code performance. ",Benchmarks for approximate CNOTs based on a 17-Qubit Surface Code
"  Upcoming million-star spectroscopic surveys have the potential to revolutionize our view of the formation and chemical evolution of the Milky Way. Realizing this potential requires automated approaches to optimize estimates of stellar properties, such as chemical element abundances, from the spectra. The volume and quality of the observations strongly motivate that these approaches should be data-driven. With this in mind, we introduce SSSpaNG: a data-driven non-Gaussian Process model of stellar spectra. We demonstrate the capabilities of SSSpaNG using a sample of APOGEE red clump stars, whose model parameters we infer via Gibbs sampling. Pooling information between stars to infer their covariance, we permit clear identification of the correlations between spectral pixels. Harnessing these correlations, we infer the true spectrum of each star, inpainting missing regions and denoising by a factor of at least 2 for stars with signal-to-noise of ~20. As we marginalize over the covariance matrix of the spectra, the effective prior on these true spectra is non-Gaussian and sparsifying, favouring typically small but occasionally large excursions from the mean. The high-fidelity inferred spectra produced will enable improved elemental abundance measurements for individual stars. Our model also allows us to quantify the information gained by observing portions of a star's spectrum, and thereby define the most mutually informative spectral regions. Using 25 windows centred on elemental absorption lines, we demonstrate that the iron-peak and alpha-process elements are particularly mutually informative for these spectra, and that the majority of information about a target window is contained in the 10-or-so most informative windows. Such mutual-information estimates have the potential to inform models of nucleosynthetic yields and the design of future observations. ","SSSpaNG! Stellar Spectra as Sparse, data-driven, Non-Gaussian processes"
"  The CALICE Semi-Digital Hadronic Calorimeter (SDHCAL) prototype, built in 2011, was exposed to beams of hadrons, electrons and muons in two short periods in 2012 on two different beam lines of the CERN SPS. The prototype with its 48 active layers, made of Glass Resistive Plate Chambers and their embedded readout electronics, was run in triggerless and power-pulsing mode. The performance of the SDHCAL during the test beam was found to be very satisfactory with an efficiency exceeding 90% for almost all of the 48 active layers. A linear response (within 5%) and a good energy resolution are obtained for a large range of hadronic energies (5-80GeV) by applying appropriate calibration coefficients to the collected data for both the Digital (Binary) and the Semi-Digital (Multi-threshold) modes of the SDHCAL prototype. The Semi-Digital mode shows better performance at energies exceeding 30GeV ",First results of the CALICE SDHCAL technological prototype
"  A bandwidth puzzle was recently proposed to defend against colluding adversaries in peer-to-peer networks. The colluding adversaries do not do actual work but claim to have uploaded contents for each other to gain free credits from the system. The bandwidth puzzle guarantees that if the adversaries can solve the puzzle, they must have spent substantial bandwidth, the size of which is comparable to the size of the contents they claim to have uploaded for each other. Therefore, the puzzle discourages the collusion. In this paper, we study the performance of the bandwidth puzzle and give a lower bound on the average number of bits the adversaries must receive to be able to solve the puzzles with a certain probability. We show that our bound is tight in the sense that there exists a strategy to approach this lower bound asymptotically within a small factor. The new bound gives better security guarantees than the existing bound, and can be used to guide better choices of puzzle parameters to improve the system performance. ",A New Bound on the Performance of the Bandwidth Puzzle
"  We investigate a recently proposed Higgs-like model (arXiv:0811.4423 [hep-th]), in the framework of a gauge-invariant but path-dependent variables formalism. We compute the static potential between test charges in a condensate of scalars and fermions. In the case of charged massive scalar we recover the screening potential. On the other hand, in the Higgs case, with a ""tachyonic"" mass term and a quartic potential in the Lagrangian, unexpected features are found. It is observed that the interaction energy is the sum of an effective-Yukawa and a linear potential, leading to the confinement of static charges. ",From screening to confinement in a Higgs-like model
"  In a 1916 paper, Ramanujan studied the additive convolution $S_{a, b}(n)$ of sum-of-divisors functions $\sigma_a(n)$ and $\sigma_b(n)$, and proved an asymptotic formula for it when $a$ and $b$ are positive odd integers. He also conjectured that his asymptotic formula should hold for all positive real $a$ and $b$. Ramanujan's conjecture was subsequently proved by Ingham, and then by Halberstam with a power saving error term.   In this paper, we give a new proof of Ramanujan's conjecture that obtains lower order terms in the asymptotics for most ranges of the parameters. We also describe a connection to a counting problem in geometric topology that was studied in the second author's thesis and which served as our initial motivation in studying this sum. ",Asymptotic identities for additive convolutions of sums of divisors
"  We give estimates on the length of paths defined in the sphere model of outer space using a surgery process, and show that they make definite progress in some sense when they remain in some thick part of outer space. To do so, we relate the Lipschitz metric on outer space to a notion of intersection numbers. ",Sphere paths in outer space
"  An $s$-subset of codewords of a binary code $X$ is said to be an {\em $(s,\ell)$-bad} in $X$ if the code $X$ contains a subset of other $\ell$ codewords such that the conjunction of the $\ell$ codewords is covered by the disjunctive sum of the $s$ codewords. Otherwise, the $s$-subset of codewords of $X$ is said to be an {\em $(s,\ell)$-good} in~$X$.mA binary code $X$ is said to be a cover-free $(s,\ell)$-code if the code $X$ does not contain $(s,\ell)$-bad subsets. In this paper, we introduce a natural {\em probabilistic} generalization of cover-free $(s,\ell)$-codes, namely: a binary code is said to be an almost cover-free $(s,\ell)$-code if {\em almost all} $s$-subsets of its codewords are $(s,\ell)$-good. We discuss the concept of almost cover-free $(s,\ell)$-codes arising in combinatorial group testing problems connected with the nonadaptive search of defective supersets (complexes). We develop a random coding method based on the ensemble of binary constant weight codes to obtain lower bounds on the capacity of such codes. ",Almost Cover-Free Codes and Designs
"  The efficiency of bio-molecular motors stems from reversible interactions $\sim$ $k_B T$; weak bonds stabilizing intermediate states (enabling $direct$ conversion of chemical into mechanical energy). For their (unknown) origins, we suggest that a magnetically structured phase (MSP) formed via accretion of super-paramagnetic particles (S-PPs) by magnetic rocks on the Hadean Ocean floor had hosted motor-like diffusion of ligand-bound S-PPs through its template-layers; its ramifications range from optical activity to quantum coherence. A gentle flux gradient offers both detailed-balance breaking non-equilibrium and $asymmetry$ to a magnetic dipole, undergoing infinitesimal spin-alignment changes. Periodic perturbation of this background by local H-fields of template-partners can lead to periodic high and low-template affinity states, due to the dipole's magnetic degree of freedom. An accompanying magnetocaloric effect allows interchange between system-entropy and bath temperature. We speculate on a magnetic reproducer in a setting close to the mound-scenario of Russell and coworkers that could evolve bio- ratchets. ","Magnetism, entropy, and the first nano-machines"
"  We report on some extensive computations and experiments concerning the moments of quadratic Dirichlet $L$-functions at the critical point. We computed the values of $L(1/2,\chi_d)$ for $- 5\times 10^{10} < d < 1.3 \times 10^{10}$ in order to numerically test conjectures concerning the moments $\sum_{|d|<X} L(1/2,\chi_d)^k$. Specifically, we tested the full asymptotics for the moments conjectured by Conrey, Farmer, Keating, Rubinstein, and Snaith, as well as the conjectures of Diaconu, Goldfeld, Hoffstein, and Zhang concerning additional lower terms in the moments. We also describe the algorithms used for this large scale computation. ","Conjectures and experiments concerning the moments of $L(1/2,\chi_d)$"
"  The imbalance of an edge $e=\{u,v\}$ in a graph is defined as $i(e)=|d(u)-d(v)|$, where $d(\cdot)$ is the vertex degree. The irregularity $I(G)$ of $G$ is then defined as the sum of imbalances over all edges of $G$. This concept was introduced by Albertson who proved that $I(G) \leq \frac{n^{3}}{27}$ (where $n=|V(G)|$) and obtained stronger bounds for bipartite and triangle-free graphs. Since then a number of additional bounds were given by various authors. In this paper we prove a new upper bound, which improves a bound found by Zhou and Luo in 2011. Our bound involves the Laplacian spectral radius $\lambda$. ",A spectral bound for graph irregularity
"  This paper is motivated by the desire to study package management using the toolkit of the semantics of functional languages. As it transpires, this is deeply related to the semantics of concurrent computation. The models we produce are not solely of theoretical interest, but amenable to analysis and computation. This work makes a number of related contributions. First, it relates the specification of branching dependency structures, which exist in fields from knowledge-representation to package management, to the specification of semantics of concurrent computation. Second, it relates dependency structures to lattices in a precise way, establishing a full correspondence with a particular subclass of lattices. It then makes use of this as a key ingredient, coupled with the underappreciated Bruns-Lakser completion, in relating dependency structures to locales -- objects equipped with both topological and logical properties. It then provides an example of how this interplay of properties can be of use -- using topological properties of the dependency structure to equip internal logics of associated locales with a modality representing contraction relations (i.e. ""versioning""). This approach lets us see linking (or rather, the choice of what to link against, i.e. ""solving"") as an effect. Finally, it discusses how such constructions may relate to important questions in complexity theory, including solutions of satisfiability problems. Along the way, we will see how this approach relates to familiar objects such as package version policies, Merkle-trees, the nix operating system, and distributed version control tooling like git. ",The Topological and Logical Structure of Concurrency and Dependency via   Distributive Lattices
"  The inclusion of semantic information in any similarity measures improves the efficiency of the similarity measure and provides human interpretable results for further analysis. The similarity calculation method that focuses on features related to the text's words only, will give less accurate results. This paper presents three different methods that not only focus on the text's words but also incorporates semantic information of texts in their feature vector and computes semantic similarities. These methods are based on corpus-based and knowledge-based methods, which are: cosine similarity using tf-idf vectors, cosine similarity using word embedding and soft cosine similarity using word embedding. Among these three, cosine similarity using tf-idf vectors performed best in finding similarities between short news texts. The similar texts given by the method are easy to interpret and can be used directly in other information retrieval applications. ",A Comparison of Semantic Similarity Methods for Maximum Human   Interpretability
"  Cet article est consacre a l'etude des mesures limites associees a la solution de l'equation de Helmholtz avec un terme source se concentrant en un point. Le potentiel est suppose regulier et l'operateur non-captif. La solution de l'equation de Schrodinger semi-classique s'ecrit alors micro-localement comme somme finie de distributions lagrangiennes.   Sous une hypothese geometrique, qui generalise l'hypothese du viriel, on en deduit que la mesure limite existe et qu'elle verifie des proprietes standard. Enfin, on donne un exemple d'operateur qui ne verifie pas l'hypothese geometrique et pour lequel la mesure limite n'est pas unique. Le cas de deux termes sources est aussi traite. ",Mesures limites pour l'equation de Helmholtz dans le cas non captif
"  Let $f\in L^2(S^2)$ be an arbitrary fixed function with small norm on the unit sphere $S^2$, and $D\subset \R^3$ be an arbitrary fixed bounded domain. Let $k>0$ and $\alpha\in S^2$ be fixed.   It is proved that there exists a potential $q\in L^2(D)$ such that the corresponding scattering amplitude $A(\alpha')=A_q(\alpha')=A_q(\alpha',\alpha,k)$ approximates $f(\alpha')$ with arbitrary high accuracy: $\|f(\alpha')-A_q(\alpha')_{L^2(S^2)}\|\leq\ve$ where $\ve>0$ is an arbitrarily small fixed number. This means that the set $\{A_q(\alpha')\}_{\forall q\in L^2(D)}$ is complete in $L^2(S^2)$. The results can be used for constructing nanotechnologically ""smart materials"". ",Completeness of the set of scattering amplitudes
"  Boolean networks have been the object of much attention, especially since S. Kauffman proposed them in the 1960's as models for gene regulatory networks. These systems are characterized by being defined on a Boolean state space and by simultaneous updating at discrete time steps. Of particular importance for biological applications are networks in which the indegree for each variable is bounded by a fixed constant, as was stressed by Kauffman in his original papers.   An important question is which conditions on the network topology can rule out exponentially long periodic orbits in the system. In this paper, we consider systems with positive feedback interconnections among all variables (known as cooperative systems), which in a continuous setting guarantees a very stable dynamics. We show that for an arbitrary constant 0<c<2 and sufficiently large n there exist n-dimensional cooperative Boolean networks in which both the indegree and outdegree of each variable is bounded by two, and which nevertheless contain periodic orbits of length at least c^n. In Part II of this paper we will prove an inverse result showing that any system with such a dynamic behavior must in a sense be similar to the example described. ",Large attractors in cooperative bi-quadratic Boolean networks. Part I
"  Multiple-spiral-wave solutions of the general cubic complex Ginzburg-Landau equation in bounded domains are considered. We investigate the effect of the boundaries on spiral motion under homogeneous Neumann boundary conditions, for small values of the twist parameter $q$. We derive explicit laws of motion for rectangular domains and we show that the motion of spirals becomes exponentially slow when the twist parameter exceeds a critical value depending on the size of the domain. The oscillation frequency of multiple-spiral patterns is also analytically obtained. ",Dynamics of spiral waves in the complex Ginzburg-Landau equation in   bounded domains
"  Van der Waals heterostructures composed of transition metal dichalcogenide monolayers (TMDs) are characterized by their truly rich excitonic properties which are determined by their structural, geometric and electronic properties: In contrast to pure monolayers, electrons and holes can be hosted in different materials, resulting in highly tunable dipolar manyparticle complexes. However, for genuine spatially indirect excitons, the dipolar nature is usually accompanied by a notable quenching of the exciton oscillator strength. Via electric and magnetic field dependent measurements, we demonstrate, that a slightly biased pristine bilayer MoS$_2$ hosts strongly dipolar excitons, which preserve a strong oscillator strength. We scrutinize their giant dipole moment, and shed further light on their orbital- and valley physics via bias-dependent magnetic field measurements. ",Dipolar and magnetic properties of strongly absorbing hybrid interlayer   excitons in pristine bilayer MoS$_2$
  We find geometric conditions on a four-dimensional almost Hermitian manifold under which the almost complex structure is a harmonic map or a minimal isometric imbedding of the manifold into its twistor space. ,Almost complex structures that are harmonic maps
"  Composition optimization has drawn a lot of attention in a wide variety of machine learning domains from risk management to reinforcement learning. Existing methods solving the composition optimization problem often work in a sequential and single-machine manner, which limits their applications in large-scale problems. To address this issue, this paper proposes two asynchronous parallel variance reduced stochastic compositional gradient (AsyVRSC) algorithms that are suitable to handle large-scale data sets. The two algorithms are AsyVRSC-Shared for the shared-memory architecture and AsyVRSC-Distributed for the master-worker architecture. The embedded variance reduction techniques enable the algorithms to achieve linear convergence rates. Furthermore, AsyVRSC-Shared and AsyVRSC-Distributed enjoy provable linear speedup, when the time delays are bounded by the data dimensionality or the sparsity ratio of the partial gradients, respectively. Extensive experiments are conducted to verify the effectiveness of the proposed algorithms. ",Asynchronous Stochastic Composition Optimization with Variance Reduction
"  In this paper, a Cognitive Radio Network (CRN) based on artificial intelligence is proposed to distribute the limited radio spectrum resources more efficiently. The CRN framework can analyze the time-sensitive signal data close to the signal source using fog computing with different types of machine learning techniques. Depending on the computational capabilities of the fog nodes, different features and machine learning techniques are chosen to optimize spectrum allocation. Also, the computing nodes send the periodic signal summary which is much smaller than the original signal to the cloud so that the overall system spectrum source allocation strategies are dynamically updated. Applying fog computing, the system is more adaptive to the local environment and robust to spectrum changes. As most of the signal data is processed at the fog level, it further strengthens the system security by reducing the communication burden of the communications network. ",Machine Learning based Intelligent Cognitive Network using Fog Computing
"  We study the PageRank mass of principal components in a bow-tie Web Graph, as a function of the damping factor c. Using a singular perturbation approach, we show that the PageRank share of IN and SCC components remains high even for very large values of the damping factor, in spite of the fact that it drops to zero when c goes to one. However, a detailed study of the OUT component reveals the presence ``dead-ends'' (small groups of pages linking only to each other) that receive an unfairly high ranking when c is close to one. We argue that this problem can be mitigated by choosing c as small as 1/2. ",Distribution of PageRank Mass Among Principle Components of the Web
"  A recent survey of the inner $0.35\times0.35$pc of the NGC 2024 star forming region revealed two distinct millimetre continuum disc populations that appear to be spatially segregated by the boundary of a dense cloud. The eastern (and more embedded) population is $\sim0.2-0.5$Myr old, with an ALMA mm continuum disc detection rate of about $45\,$per cent. However this drops to only $\sim15$per cent in the 1Myr western population. When presenting this result, van Terwisga et al. (2020) suggested that the two main UV sources, IRS 1 (a B0.5V star in the western region) and IRS 2b (an O8V star in the eastern region, but embedded) have both been evaporating the discs in the depleted western population.   In this paper we report the firm discovery in archival HST data of 4 proplyds and 4 further candidate proplyds in NGC 2024, confirming that external photoevaporation of discs is occurring. However, the locations of these proplyds changes the picture. Only three of them are in the depleted western population and their evaporation is dominated by IRS 1, with no obvious impact from IRS 2b. The other 5 proplyds are in the younger eastern region and being evaporated by IRS 2b. We propose that both populations are subject to significant external photoevaporation, which happens throughout the region wherever discs are not sufficiently shielded by the interstellar medium. The external photoevaporation and severe depletion of mm grains in the 0.2-0.5Myr eastern part of NGC 2024 would be in competition even with very early planet formation. ",Proplyds in the Flame Nebula NGC 2024
"  The soft dipole modes in neutron rich even-even Ni-isotopes are investigated in the quasiparticle relativistic random phase approximation. We study the evolution of strengths distribution, centroid energies of dipole excitation in low-lying and normal GDR regions with the increase of the neutron excess. It is found in the present study that the centroid energies of the soft dipole strengths strongly depend on the thickness of neutron skin along with the neutron rich even-even Ni-isotopes. ",Soft Dipole Modes in Neutron-rich Ni-isotopes in QRRPA
"  The third (or organismic) view of space states that space is neither lifeless nor neutral, but a living structure capable of being more living or less living, thus different fundamentally from the first two mechanistic views of space: Newtonian absolute space and Leibnizian relational space. The living structure is defined as a physical and mathematical structure or simply characterized by the recurring notion (or inherent hierarchy) of far more small substructures than large ones. This paper seeks to lay out a new geography as a science of the Earth's surface founded on the third view of space. The new geography aims not only to better understand geographic forms and processes but also - maybe more importantly - to make geographic space or the Earth's surface to be living or more living. After introducing two fundamental laws of geography: Tobler's law on spatial dependence (or homogeneity) and scaling law on spatial heterogeneity, we argue that these two laws are fundamental laws of living structure that favor statistics over exactitude, because the former (or statistics) tends to make a structure more living than the latter (or exactitute). We present the concept of living structure through some working examples and make it clear how a living structure differs from a non-living structure, under the organismic worldview that was first conceived by the British philosopher Alfred Whitehead (1861-1947). In order to make a structure or space living or more living, we introduce two design principles - differentiation and adaptation - using two paintings and two city plans. The new geography is a science of living structure, dealing with a wide range of scales, from the smallest scale of ornaments on walls to the scale of the entire Earth's surface.   Keywords: Scaling law, Tobler's law, differentiation, adaptation, head/tail breaks, natural streets, the third view of space ",Geography as a Science of the Earth's Surface Founded on the Third View   of Space
  The concordance group of algebraically slice knots is the subgroup of the classical knot concordance group formed by algebraically slice knots. Results of Casson and Gordon and of Jiang showed that this group contains in infinitely generated free (abelian) subgroup. Here it is shown that the concordance group of algebraically slice knots also contain elements of finite order; in fact it contains an infinite subgroup generated by elements of order 2. ,Order 2 Algebraically Slice Knots
  We present results for the three-loop universal anomalous dimension of Wilson twist-2 operators in the N=4 Supersymmetric Yang-Mills theory. These expressions are obtained by extracting the most complicated contributions from the three-loop anomalous dimensions in QCD. This result is in an agreement with the hypothesis of the integrability of N=4 Supersymmetric Yang-Mills theory in the context of AdS/CFT-correspondence. ,Three-loop universal anomalous dimension of the Wilson operators in N=4   Supersymmetric Yang-Mills theory
"  In this work, we report on hot carrier diffusion in graphene across large enough length scales that the carriers are not thermalized across the crystal. The carriers are injected into graphene at one site and their thermal transport is studied as a function of applied power and distance from the heating source, up to tens of micrometers away. Superconducting contacts prevent out-diffusion of hot carriers to isolate the electron-phonon coupling as the sole channel for thermal relaxation. As local thermometers, we use the amplitude of the Universal Conductance Fluctuations, which varies monotonically as a function of temperature. By measuring the electron temperature simultaneously along the length we observe a thermal gradient which results from the competition between electron-phonon cooling and lateral heat flow. ",Sub-Kelvin Lateral Thermal Transport in Diffusive Graphene
  The performance of mid-infrared erbium doped fiber lasers has dramatically improved in the last few years. In this paper we present a numerical model that provides valuable insight into the dynamics of a dual-wavelength pumped fiber laser that can operate on the 3.5 micron and 2.8 micron bands. This model is a much needed tool for optimizing and understanding the performance of these laser systems. Comparisons between simulation and experimental results for three different systems are presented. ,Numerical Modeling of 3.5 micron Dual-Wavelength Pumped Erbium Doped   Mid-Infrared Fiber Lasers
"  Abnormal airway dilatation, termed traction bronchiectasis, is a typical feature of idiopathic pulmonary fibrosis (IPF). Volumetric computed tomography (CT) imaging captures the loss of normal airway tapering in IPF. We postulated that automated quantification of airway abnormalities could provide estimates of IPF disease extent and severity. We propose AirQuant, an automated computational pipeline that systematically parcellates the airway tree into its lobes and generational branches from a deep learning based airway segmentation, deriving airway structural measures from chest CT. Importantly, AirQuant prevents the occurrence of spurious airway branches by thick wave propagation and removes loops in the airway-tree by graph search, overcoming limitations of existing airway skeletonisation algorithms. Tapering between airway segments (intertapering) and airway tortuosity computed by AirQuant were compared between 14 healthy participants and 14 IPF patients. Airway intertapering was significantly reduced in IPF patients, and airway tortuosity was significantly increased when compared to healthy controls. Differences were most marked in the lower lobes, conforming to the typical distribution of IPF-related damage. AirQuant is an open-source pipeline that avoids limitations of existing airway quantification algorithms and has clinical interpretability. Automated airway measurements may have potential as novel imaging biomarkers of IPF severity and disease extent. ",Evaluation of automated airway morphological quantification for   assessing fibrosing lung disease
"  We show that under certain astrophysical conditions a binary system consisting of two compact objects can be stabilized against indefinite shrinking of orbits due to the emission of gravitational radiation. In this case, the lighter binary companion settles down to a stable orbit when the loss of the angular momentum due to gravitational radiation becomes equal to its gain from the accreting matter from the disk around the more massive primary. We claim that such systems can be stable against small perturbations and can be regarded as steady emitters of gravitational waves of constant frequency and amplitude. Furthermore, X-rays emitted by the secondary can also produce astrophysically interesting situations when coupled with gravitational lensing and Doppler effects. ",Binary Black Holes in Stationary Orbits
  Systematic experimental data on resonant inelastic X-ray scattering (RIXS) in GaN near the N K-edge are presented for the first time. Excitation energy dependence of the spectral structures manifests the band structure effects originating from momentum selectivity of the RIXS process. This finding allows obtaining k-resolved band structure information for GaN crystals and nanostructures. ,Band structure effects in nitrogen K-edge resonant inelastic X ray   scattering from GaN
"  Seismic noise cross correlations are used to image crustal structure and heterogeneity. Typically, seismic networks are only anisotropically illuminated by seismic noise, a consequence of the non-uniform distribution of sources. Here, we study the sensitivity of such a seismic network to structural heterogeneity in a 2-D setting. We compute finite-frequency cross-correlation sensitivity kernels for travel-time, waveform-energy and waveform-difference measurements. In line with expectation, wavespeed anomalies are best imaged using travel times and the source distribution using cross-correlation energies. Perturbations in attenuation and impedance are very difficult to image and reliable inferences require a high degree of certainty in the knowledge of the source distribution and wavespeed model (at least in the case of transmission tomography studied here). We perform single-step Gauss-Newton inversions for the source distribution and the wavespeed, in that order, and quantify the associated Cram\'{e}r-Rao lower bound. The inversion and uncertainty estimate are robust to errors in the source model but are sensitive to the theory used to interpret of measurements. We find that when classical source-receiver kernels are used instead of cross-correlation kernels, errors appear in the both the inversion and uncertainty estimate, systematically biasing the results. We outline a computationally tractable algorithm to account for distant sources when performing inversions. ",Measurements and Kernels for Source-Structure Inversions in Noise   Tomography
"  The statistical properties of the ellipticities of galaxy images depend on how galaxies form and evolve, and therefore constrain models of galaxy morphology, which are key to the removal of the intrinsic alignment contamination of cosmological weak lensing surveys, as well as to the calibration of weak lensing shape measurements. We construct such models based on the halo properties of the Millennium Simulation and confront them with a sample of 90,000 galaxies from the COSMOS Survey, covering three decades in luminosity and redshifts out to z=2. The ellipticity measurements are corrected for effects of point spread function smearing, spurious image distortions, and measurement noise. Dividing galaxies into early, late, and irregular types, we find that early-type galaxies have up to a factor of two lower intrinsic ellipticity dispersion than late-type galaxies. None of the samples shows evidence for redshift evolution, while the ellipticity dispersion for late-type galaxies scales strongly with absolute magnitude at the bright end. The simulation-based models reproduce the main characteristics of the intrinsic ellipticity distributions although which model fares best depends on the selection criteria of the galaxy sample. We observe fewer close-to-circular late-type galaxy images in COSMOS than expected for a sample of randomly oriented circular thick disks and discuss possible explanations for this deficit. ",Intrinsic galaxy shapes and alignments I: Measuring and modelling COSMOS   intrinsic galaxy ellipticities
"  We review recent results on the linear and non-linear optical response of realistic quantum-wire structures. Our theoretical approach is based on a set of generalized semiconductor Bloch equations, and allows a full three-dimensional multisubband description of Coulomb correlation for any shape of the confinement profile, thus permitting a direct comparison with experiments for available state-of-the-art wire structures.   Our results show that electron-hole Coulomb correlation removes the one-dimensional band-edge singularities from the absorption spectra, whose shape results to be heavily modified with respect to the ideal free-particle case over the whole range of photoexcited carrier densities. ",Coulomb-correlation effects on the non-linear optical properties of   realistic quantum wires
"  Strominger and Vafa have used D-brane technology to identify and precisely count the degenerate quantum states responsible for the entropy of certain extremal, BPS-saturated black holes. Here we give a Type-II D-brane description of a class of extremal {\it and} non-extremal five-dimensional Reissner-Nordstr\""om solutions and identify a corresponding set of degenerate D-brane configurations. We use this information to do a string theory calculation of the entropy, radiation rate and ``Hawking'' temperature. The results agree perfectly with standard Hawking results for the corresponding nearly extremal Reissner-Nordstr\""om black holes. Although these calculations suffer from open-string strong coupling problems, we give some reasons to believe that they are nonetheless qualitatively reliable. In this optimistic scenario there would be no ``information loss'' in black hole quantum evolution. ",D-brane Approach to Black Hole Quantum Mechanics
"  Recently Pascal Baseilhac and Stefan Kolb obtained a PBW basis for the $q$-Onsager algebra $\mathcal O_q$. They defined the PBW basis elements recursively, and it is obscure how to express them in closed form. To mitigate the difficulty, we bring in the universal Askey-Wilson algebra $\Delta_q$. There is a natural algebra homomorphism $\natural \colon \mathcal O_q \to \Delta_q$. We apply $\natural $ to the above PBW basis, and express the images in closed form. Our results make heavy use of the Chebyshev polynomials of the second kind. ",The $q$-Onsager Algebra and the Universal Askey-Wilson Algebra
"  We propose to amplify and compress an ultrashort Light Spring laser seed with a long Gaussian-shaped laser pump through Raman amplification. This Light Spring, which has a helical spatio-temporal intensity profile, can be built on the superposition of three distinct laser frequency components. In order to get an independent frequency amplification, two criteria are established. Besides these criteria, a non equal frequency separation is necessary to avoid resonance overlapping when three or more frequencies are involved. The independent set of equations, which describes the wave-wave interaction in a plasma, is solved numerically for two different Light Spring configurations. In both cases, the amplification and transversal compression of the seed laser pulse have been observed, with a final profile similar to that of the usual Gaussian-shaped seed pulses. In addition, two different kinds of helical plasma waves are excited. ",Light Spring amplification in a multi-frequency Raman amplifier
"  Autonomous vehicles usually consume a large amount of computational power for their operations, especially for the tasks of sensing and perception with artificial intelligence algorithms. Such a computation may not only cost a significant amount of energy but also cause performance issues when the onboard computational resources are limited. To address this issue, this paper proposes an adaptive optimization method to online allocate the onboard computational resources of an autonomous vehicle amongst multiple vehicular subsystems depending on the contexts of the situations that the vehicle is facing. Different autonomous driving scenarios were designed to validate the proposed approach and the results showed that it could help improve the overall performance and energy consumption of autonomous vehicles compared to existing computational arrangement. ",Adaptive Optimization of Autonomous Vehicle Computational Resources for   Performance and Energy Improvement
  The irreducible character values of the spin wreath products of the symmetric group and an arbitrary finite group are completely determined. ,Irreducible projective characters of wreath products
"  Previously Casetti, Clementi and Pettini [\textbf{Phys.Rev.E \textbf{54},6,(1996)}] have investigated the Lyapunov spectrum of Hamiltonian flows for several Hamiltonian systems by making use of the Riemannian geometry. Basically the Lyapunov stability analysis was substituted by the Ricci sectional curvature analysis. In this report we apply Pettini's geometrical framework to determine the potential energy of a twisted magnetic flux tube, from its curved Riemannian geometry. Actually the Lyapunov exponents, are connected to a Riemann metric tensor, of the twisted magnetic flux tubes (MFTs). The Hamiltonian flow inside the tube is actually given by Perelman Ricci flows constraints in twisted magnetic flux tubes, where the Lyapunov eigenvalue spectra for the Ricci tensor associated with the Ricci flow equation in MFTs leads to a finite-time Lyapunov exponential stretching along the toroidal direction of the tube and a contraction along the radial direction of the tube. The Jacobi equation for the MFTs is shown to have a constant sectional Ricci curvature which allows us to compute the Jacobi-Levi-Civita (JLC) geodesic deviation for the spread of lines on the tube manifold and chaotic action through the greatest of its Lyapunov exponents. By analyzing the spectra of the twisted MFT, it is shown that the greater exponent is positive and proportional to the random radial flow of the tube, which allows the onset of chaos is guaranted. The randomness in the twisted flow reminds a discussed here is similar of a recent work by Shukurov, Stepanov, and Sokoloff on dynamo action on Moebius flow [\textbf{Phys Rev E 78 (2008)}]. The dynamo action in twisted flux tubes discussed here may also serve as model for dynamo experiments in laboratory. ",Lyapunov spectra instability of chaotic dynamo Ricci flows in twisted   magnetic flux tubes
  The nucleon form factors of the energy-momentum tensor are studied in the large-Nc limit in the framework of the Skyrme model. ,The nucleon form-factors of the energy momentum tensor in the Skyrme   model
"  In this note, we extend the connection between the hydrogen atom and $\pi$ to the number $e$ via the Lerch's transcendent. ","The Hydrogen Atom, Pi and Lerch's Transcendent"
  This article gives a self-contained exposition on Ribet's construction of a Hecke eigenform of weight 2 with certain congruence properties. ,Ribet's construction of a suitable cusp eigenform
"  Using a parametrisation of $sl_2$ given by the second prolongation of the group action of unimodular fractional linear transformations as presented in an article of Clarkson and Olver, we find a Monge normal form describing the rolling of two hyperboloid surfaces over each other. ",A Monge normal form for the rolling distribution
"  Estimating the value function for a fixed policy is a fundamental problem in reinforcement learning. Policy evaluation algorithms---to estimate value functions---continue to be developed, to improve convergence rates, improve stability and handle variability, particularly for off-policy learning. To understand the properties of these algorithms, the experimenter needs high-confidence estimates of the accuracy of the learned value functions. For environments with small, finite state-spaces, like chains, the true value function can be easily computed, to compute accuracy. For large, or continuous state-spaces, however, this is no longer feasible. In this paper, we address the largely open problem of how to obtain these high-confidence estimates, for general state-spaces. We provide a high-confidence bound on an empirical estimate of the value error to the true value error. We use this bound to design an offline sampling algorithm, which stores the required quantities to repeatedly compute value error estimates for any learned value function. We provide experiments investigating the number of samples required by this offline algorithm in simple benchmark reinforcement learning domains, and highlight that there are still many open questions to be solved for this important problem. ",High-confidence error estimates for learned value functions
"  Inspired by Kronheimer and Mrowka's approach to monopole Floer homology, we develop a model for $\mathbb{Z}/2$-equivariant symplectic Floer theory using equivariant almost complex structures, which admits a localization map to a twisted version of Floer cohomology in the invariant set. We then present applications to Steenrod operations on Lagrangian Floer cohomology, and to the Heegaard Floer homology of double covers of three-manifolds. ",Equivariant Floer theory and double covers of three-manifolds
"  We use gravitational lensing of the cosmic microwave background (CMB) to measure the mass of the most distant blindly-selected sample of galaxy clusters on which a lensing measurement has been performed to date. In CMB data from the the Atacama Cosmology Telescope (ACT) and the Planck satellite, we detect the stacked lensing effect from 677 near-infrared-selected galaxy clusters from the Massive and Distant Clusters of WISE Survey (MaDCoWS), which have a mean redshift of $ \langle z \rangle = 1.08$. There are no current optical weak lensing measurements of clusters that match the distance and average mass of this sample. We detect the lensing signal with a significance of $4.2 \sigma$. We model the signal with a halo model framework to find the mean mass of the population from which these clusters are drawn. Assuming that the clusters follow Navarro-Frenk-White density profiles, we infer a mean mass of $\langle M_{500c}\rangle = \left(1.7 \pm 0.4 \right)\times10^{14}\,\mathrm{M}_\odot$. We consider systematic uncertainties from cluster redshift errors, centering errors, and the shape of the NFW profile. These are all smaller than 30% of our reported uncertainty. This work highlights the potential of CMB lensing to enable cosmological constraints from the abundance of distant clusters populating ever larger volumes of the observable Universe, beyond the capabilities of optical weak lensing measurements. ",The Atacama Cosmology Telescope: Weighing distant clusters with the most   ancient light
"  In this paper, we study the azimuthal asymmetry in the $J/\psi$ leptoproduction in unpolarized $ep$ collisions. There are two independent azimuthal asymmetry modulations, namely $\mathrm{cos}(\psi)$ and $\mathrm{cos}(2\psi)$, where $\psi$ is the azimuthal angle of the lepton scattering plane with respect to the hadron-interacting plane. We calculate the two modulations as functions of four kinematic variables, and find that they provide a very good laboratory to distinguish several models describing the heavy quarkonium production, including the color-singlet (CS) model, the nonrelativistic QCD (NRQCD) associated with the $^1S_0^{[8]}$ dominance picture, and the NRQCD in which the values of all the three color-octet (CO) long-distance matrix elements are of the same order. In order to make definite conclusions, we restrict our calculation in a specific kinematic region, where the CS and CO mechanisms can be distinguished by scrutinizing the values of the $\mathrm{cos}(\psi)$ modulation, while the $^1S_0^{[8]}$ dominance picture can be tested by measuring the values of the $\mathrm{cos}(2\psi)$ modulation. Calculating their values and carrying out a meticulous statistical analysis, we find that at an integrated luminosity $\mathcal{L}=1000\mathrm{pb}^{-1}$, the statistical uncertainties of the two quantities are small enough to tell the three models apart. When this experiment is implemented at the future $ep$ colliders such as the EIC, crucial information for the $J/\psi$ production mechanism might be discovered. ",Statistical analysis of the azimuthal asymmetry in the $J/\psi$   leptoproduction in unpolarized $ep$ collisions
"  We give a semiclassical analysis of a nonlinear eigenvalue problem arising from the study of the failure of analytic hypoellipticity and obtain a general family of hypoelliptic, but not analytic hypoelliptic operators. ",Semiclassical analysis of a nonlinear eigenvalue problem and non   analytic hypoellipticity
"  An average adult is exposed to hundreds of digital advertisements daily (https://www.mediadynamicsinc.com/uploads/files/PR092214-Note-only-150-Ads-2mk.pdf), making the digital advertisement industry a classic example of a big-data-driven platform. As such, the ad-tech industry relies on historical engagement logs (clicks or purchases) to identify potentially interested users for the advertisement campaign of a partner (a seller who wants to target users for its products). The number of advertisements that are shown for a partner, and hence the historical campaign data available for a partner depends upon the budget constraints of the partner. Thus, enough data can be collected for the high-budget partners to make accurate predictions, while this is not the case with the low-budget partners. This skewed distribution of the data leads to ""preferential attachment"" of the targeted display advertising platforms towards the high-budget partners. In this paper, we develop ""domain-adaptation"" approaches to address the challenge of predicting interested users for the partners with insufficient data, i.e., the tail partners. Specifically, we develop simple yet effective approaches that leverage the similarity among the partners to transfer information from the partners with sufficient data to cold-start partners, i.e., partners without any campaign data. Our approaches readily adapt to the new campaign data by incremental fine-tuning, and hence work at varying points of a campaign, and not just the cold-start. We present an experimental analysis on the historical logs of a major display advertising platform (https://www.criteo.com/). Specifically, we evaluate our approaches across 149 partners, at varying points of their campaigns. Experimental results show that the proposed approaches outperform the other ""domain-adaptation"" approaches at different time points of the campaigns. ",Targeted display advertising: the case of preferential attachment
"  We entertain the idea that a suitable background of cold (very low momentum) pseudoscalar particles or condensate, may trigger a background that effectively generates Lorentz-invariance violation. This aether-like background induces a Chern-Simons modification of QED. Physics is different in different frames and, in the rest frame of the pseudoscalar background, high momentum photons can decay into pairs. The threshold for such decay depends quadratically on the rest mass of the particles. This mechanism could explain in a natural way why antiprotons are absent in recent cosmic ray measurements. A similar signal could be used as a probe of pseudoscalar condensation in heavy ion collisions. ",Anomalous positron excess from Lorentz-violating QED
"  Using the formalism of noncommutative geometric gauge theory based on the superconnection concept, we construct a new type of vector gauge theory possessing a shift-like symmetry and the usual gauge symmetry. The new shift-like symmetry is due to the matrix derivative of the noncommutative geometric gauge theory, and this gives rise to a mass term for the vector field without introducing the Higgs field. This construction becomes possible by using a constant one form even matrix for the matrix derivative, for which only constant zero form odd matrices have been used so far. The fermionic action in this formalism is also constructed and discussed. ",New Type of Vector Gauge Theory from Noncommutative Geometry
"  Recent studies show that two low-energy Van Hove singularities (VHSs) seen as two pronounced peaks in the density of states (DOS) could be induced in twisted graphene bilayer. Here, we report angle dependent VHSs of slightly twisted graphene bilayer studied by scanning tunneling microscopy and spectroscopy. We show that energy difference of the two VHSs follows \DeltaEvhs ~ \hbar{\nu}F\DeltaK between 1.0^{\circ} and 3.0^{\circ} (here {\nu}F ~ 1.1\times106 m/s is the Fermi velocity of monolayer graphene, \DeltaK = 2Ksin(\theta/2) is the shift between the corresponding Dirac points of the twisted graphene bilayer). This result indicates that the rotation angle between graphene sheets not results in significant reduction of the Fermi velocity, which quite differs from that predicted by band structure calculations. However, around a twisted angle \theta ~ 1.3^{\circ}, the observed \DeltaEvhs ~ 0.11 eV is much less than the expected value \hbar{\nu}F\DeltaK ~ 0.28 eV at 1.3^{\circ}. The origin of the reduction of \DeltaEvhs at 1.3^{\circ} is discussed. ",Angle Dependent Van Hove Singularities in Slightly Twisted Graphene   Bilayer
"  Conceptual climate models provide an approach to understanding climate processes through a mathematical analysis of an approximation to reality. Recently, these models have also provided interesting examples of nonsmooth dynamical systems. Here we discuss a conceptual model of glacial cycles consisting of a system of three ordinary differential equations defining a discontinuous vector field. We show that this system has a large periodic orbit crossing the discontinuity boundary. This orbit can be interpreted as an intrinsic cycling of the Earth's climate giving rise to alternating glaciations and deglaciations. ",Periodic Orbits for a Discontinuous Vector Field Arising from a   Conceptual Model of Glacial Cycles
"  We address a conflicting report on the value and uncertainty of the astrophysical cross section factor of the 12C(a,g) reaction extracted from existing data. In sharp contrast to previously reported ambiguities (by up to a factor 8), Schuermann et al. suggest an accuracy of 12%. We demonstrate that the so claimed ""rigorous data selection criteria"" used by Schuermann et al. relies on the s-factors extracted by Assuncao et al. But these results were shown in a later analysis (by this author) to have large error bars (considerably larger than claimed by Assuncao em et al.) which render these data not appropriate for a rigorous analysis. When their ""rigorous data selection"" is adjusted to remove the results of Assuncao et al. the astrophysical cross section factor cannot be extracted with 12% accuracy, or even close to it. Such data on the S_E2 values at low energies deviate by up to a factor two from their fit and exhibit a sharper slope rising toward low energies, leading to strong doubt on their extrapolated S_E2(300) value and the quoted small error bar. Contrary to their claim the small value of S_E1(300) ~10 keVb cannot be ruled out by current data including the most modern gamma-ray data. As previously observed by several authors current data reveal ambiguities in the value of S_E1(300) ~10 keVb or ~80 keVb, and the new ambiguity that was recently revealed (by this author) of S_E2(300) ~60 keVb or ~154 keVb, appear to be a more reasonable evaluation the status of current data. ","On the sensitivity of extracting the astrophysical cross section factor   of the 12C(a,g) reaction from existing data [Comment on Schuermann et al.   Phys. Lett. B711(2012)35]"
"  The successful discovery of X-ray, optical and radio afterglows of GRB has made possible the identification of host galaxies at cosmological distances. The energy release inferred in these outbursts place them among the most energetic and violent events in the Universe. They are thought to be the outcome of a cataclysmic stellar collapse or compact stellar merger, leading to a relativistically expanding fireball, in which particles are accelerated at shocks and produce nonthermal radiation. The substantial agreement between observations and the theoretical predictions of the fireball shock model provide confirmation of the basic aspects of this scenario. Among recent issues are the collimation of the outflow and its implications for the energetics, the production of prompt bright flashes at wavelenghts much longer than gamma-rays, the time structure of the afterglow, its dependence on the central engine or progenitor system behavior, and the role of the environment on the afterglow. ",Origin of Gamma Ray Bursters
"  A newly developed isochrone synthesis algorithm for the photometric evolution of galaxies is described. Two initial mass functions, IMFs, in particular, the recent IMF determined by Kroupa, Tout, and Gilmore, three photometric transformations, and a 1-Gyr-burst star formation rate, SFR, are used to compute the $B-V$ and $V-K$ color index evolution. Non-negligible differences are observed among model results.   In the framework of the galaxy count model by Col\'in, Schramm, and Peimbert a simple merging scenario is considered to account for the excess of galaxies observed in the blue band counts. The excess is explained by the number and luminosity evolution of a group of galaxies called interacting, I. It is assumed that the number of I galaxies increases as $(1+z)^{\eta}$ due to mergers. Moreover, it is proposed that their characteristic luminosity increases as $(1+z)^3$ due to starbursts driven by galaxy-galaxy collision and decreases as $(1+z)^{-\eta}$ due to the change in the size of the galaxies. Not much number evolution is needed to account for the excess; for example, a model with $\eta = 4.0$ predicts that about 17 \% of the galaxies at $z = 0.4$ are interacting. Number evolution models with a rather high value of $\eta$ fit better the data; in particular, the model with $\eta = 4.0$ predicts that about 13 \% of the galaxies have $z > 0.7$ in the $21.0 < m_{b_J} < 22.5$ interval, this contrasts with the upper bound of 5 \% obtained with the sample of 78 galaxies by Colless et al. The excess of high redshift galaxies can not be simply explained by changing reasonably the parameters of the luminosity function of I galaxies. This result could indicate that mergers are not the whole story. Our best-fit model produces the following values for the ",Number and Luminosity Evolution of Interacting Galaxies as a Natural   explanation for the Galaxy Counts
"  In the late 80s, a curious effect suggested by Aharanov, Albert and Vaidman opened up new vistas regarding quantum measurements on weakly coupled systems. There, a combination of a ""weak"" finite interaction together with a ""strong"" post-selection measurement leads to an anomalous effect, namely the mean value of a spin-1/2 particle in the $z-$direction lies outside the conventional spectrum of $\pm$1.   In this paper, we investigate the quantum control of the weak value amplification of a qubit system coupled to a meter, via a second non-interacting qubit, initially quantum correlated with the first one. Our results show that for weak measurements, the control can be remotely realized via the post-selected state of the second qubit or the degree of squeezing of the meter. Additionally, in a step towards the study of the quantum control of the amplification, we can easily manipulate the degree of quantum correlations between the initial correlated qubits. We find that the degree of Entanglement has no effect on the quantum control of the amplification. However, we have found a clear connection between the amplification and quantum discord like measurements as well as classical correlations between the qubits. Moreover, we generalize the analysis to two control qubits and we can conclude that the single control qubit scheme is more efficient. Lastly, we suggest an original application of the amplification control protocol on the enhancement of the quantum measurement accuracy, e.g. measuring the relative phase of the post-selected control qubit in a more precise way, as opposed to the no-amplification case ",The power of a control qubit in weak measurements
"  We discuss the anomalous Hall effect in a two-dimensional electron gas subject to a spatially varying magnetization. This topological Hall effect (THE) does not require any spin-orbit coupling, and arises solely from Berry phase acquired by an electron moving in a smoothly varying magnetization. We propose an experiment with a structure containing 2D electrons or holes of diluted magnetic semiconductor subject to the stray field of a lattice of magnetic nanocylinders. The striking behavior predicted for such a system (of which all relevant parameters are well known) allows to observe unambiguously the THE and to distinguish it from other mechanisms. ",Topological Hall effect and Berry phase in magnetic nanostructures
"  We present a design of a spin-flip Zeeman slower controlled by a fast feedback circuit for a sodium Bose-Einstein condensate apparatus. We also demonstrate how the efficiency of the slower strongly depends on its intrinsic parameters, and compare these observations with a few theoretical models. Our findings lead to a simple three-step procedure of designing an optimal Zeeman slower for neutral atoms, especially for those atomic species with high initial velocities, such as sodium and lithium atoms. ",Optimizing a spin-flip Zeeman slower
"  General stochastic Euler schemes for ordinary differential equations are studied. We give proofs on the consistency, the rate of convergence and the asymptotic normality of these procedures. ",Consistency and Asymptotic Normality of Stochastic Euler Schemes for   Ordinary Differential Equations
"  Millions of battery-powered sensors deployed for monitoring purposes in a multitude of scenarios, e.g., agriculture, smart cities, industry, etc., require energy-efficient solutions to prolong their lifetime. When these sensors observe a phenomenon distributed in space and evolving in time, it is expected that collected observations will be correlated in time and space. In this paper, we propose a Deep Reinforcement Learning (DRL) based scheduling mechanism capable of taking advantage of correlated information. We design our solution using the Deep Deterministic Policy Gradient (DDPG) algorithm. The proposed mechanism is capable of determining the frequency with which sensors should transmit their updates, to ensure accurate collection of observations, while simultaneously considering the energy available. To evaluate our scheduling mechanism, we use multiple datasets containing environmental observations obtained in multiple real deployments. The real observations enable us to model the environment with which the mechanism interacts as realistically as possible. We show that our solution can significantly extend the sensors' lifetime. We compare our mechanism to an idealized, all-knowing scheduler to demonstrate that its performance is near-optimal. Additionally, we highlight the unique feature of our design, energy-awareness, by displaying the impact of sensors' energy levels on the frequency of updates. ",Energy Aware Deep Reinforcement Learning Scheduling for Sensors   Correlated in Time and Space
"  The two-nucleon density distributions in states with isospin $T=0$, spin $S$=1 and projection $M_S$=0 and $\pm$1 are studied in $^2$H, $^{3,4}$He, $^{6,7}$Li and $^{16}$O. The equidensity surfaces for $M_S$=0 distributions are found to be toroidal in shape, while those of $M_S$=$\pm$1 have dumbbell shapes at large density. The dumbbell shapes are generated by rotating tori. The toroidal shapes indicate that the tensor correlations have near maximal strength at $r<2$ fm in all these nuclei. They provide new insights and simple explanations of the structure and electromagnetic form factors of the deuteron, the quasi-deuteron model, and the $dp$, $dd$ and $\alpha d$ $L$=2 ($D$-wave) components in $^3$He, $^4$He and $^6$Li. The toroidal distribution has a maximum-density diameter of $\sim$1 fm and a half-maximum density thickness of $\sim$0.9 fm. Many realistic models of nuclear forces predict these values, which are supported by the observed electromagnetic form factors of the deuteron, and also predicted by classical Skyrme effective Lagrangians, related to QCD in the limit of infinite colors. Due to the rather small size of this structure, it could have a revealing relation to certain aspects of QCD. ",Femtometer Toroidal Structures in Nuclei
"  We study the percolative properties of random interlacements on the product of G with the integer line Z, when G is a weighted graph satisfying certain sub-Gaussian estimates attached to the parameters alpha > 1, measuring the volume growth on G, and beta between 2 and alpha + 1, measuring the sub-diffusive nature of the random walk on G. We develop decoupling inequalities, which are a key tool in showing that the critical level u_* for the percolation of the vacant set of random interlacements is always finite in our set-up, and that it is positive when alpha \geq 1 + beta/2. We also obtain several stretched exponential controls both in the percolative and non-percolative phases of the model. Even in the case where G = Z^d, d \geq 2, several of these results are new. ",Decoupling inequalities and interlacement percolation on G x Z
"  Many advances of deep learning techniques originate from the efforts of addressing the image classification task on large-scale datasets. However, the construction of such clean datasets is costly and time-consuming since the Internet is overwhelmed by noisy images with inadequate and inaccurate tags. In this paper, we propose a Ubiquitous Reweighting Network (URNet) that learns an image classification model from large-scale noisy data. By observing the web data, we find that there are five key challenges, i.e., imbalanced class sizes, high intra-classes diversity and inter-class similarity, imprecise instances, insufficient representative instances, and ambiguous class labels. To alleviate these challenges, we assume that every training instance has the potential to contribute positively by alleviating the data bias and noise via reweighting the influence of each instance according to different class sizes, large instance clusters, its confidence, small instance bags and the labels. In this manner, the influence of bias and noise in the web data can be gradually alleviated, leading to the steadily improving performance of URNet. Experimental results in the WebVision 2018 challenge with 16 million noisy training images from 5000 classes show that our approach outperforms state-of-the-art models and ranks the first place in the image classification task. ",Learning from Large-scale Noisy Web Data with Ubiquitous Reweighting for   Image Classification
"  A general form of the Borel-Cantelli Lemma and its connection with the proof of Khintchine's Theorem on Diophantine approximation and the more general Khintchine-Groshev theorem are discussed. The torus geometry in the planar case allows a relatively direct proof of the planar Groshev theorem for the set of $\psi$-approximable points in the plane. The construction and use of Haudsorff measure and dimension are explained and the notion of ubiquity, which is effective in estimating the lower bound of the Hausdorff dimension for quite general lim sup sets, is described. An application is made to obtain the Hausdorff dimension of the set of approximable points in the plane when $\psi(q)=q^{-v}$, $v>0$, corresponding to the planar Jarnik-Besicovich theorem. ","Diophantine approximation, Khintchine's theorem, torus geometry and   Hausdorff dimension"
"  First Order Reversal Curves (FORCs) have been used for a number of years for the extraction of information from magnetization measurements. The results are most unambiguous for irreversible processes -- for a collection of Preisach hysterons, one gets a ""FORC distribution"" $\rho(H_{down},H_{up})$, the number of hysterons with given downward \& upward reversal fields. There have been many proposals for dealing with reversible behavior, usually involving inserting it somehow into the irreversible FORC distribution. Here we will try to do the opposite, to separate them into another function which we will call the (reversible) ""saturation field distribution"", which is identically zero for a completely irreversible system of hysterons, while the irreversible FORC distribution is identically zero for a reversible system. Thus in a system with both purely reversible and purely irreversible components, such as single-domain Stoner-Wohlfarth particles with hard or easy axis along the field, this approach cleanly separates them. For more complicated systems, as with conventional FORC distributions, it at least provides a ""signature"" making it possible to identify microscopic models that might give a particular pair of irreversible and reversible distributions. ",FORC+: A method for separating reversible from irreversible behavior   using first order reversal curves
"  The ATLAS experiment at the Large Hadron Collider has a broad physics programme ranging from precision measurements to direct searches for new particles and new interactions, requiring ever larger and ever more accurate datasets of simulated Monte Carlo events. Detector simulation with GEANT4 is accurate but requires significant CPU resources. Over the past decade, ATLAS has developed and utilized tools that replace the most CPU-intensive component of the simulation -- the calorimeter shower simulation -- with faster simulation methods. Here, AtlFast3, the next generation of high-accuracy fast simulation in ATLAS is introduced. AtlFast3 combines parameterized approaches with machine-learning techniques and is deployed to meet current and future computing challenges and simulation needs of the ATLAS experiment. With highly accurate performance and a new ability to model substructure within jets, AtlFast3 is designed to be used to simulate large numbers of events for a wide range of physics processes. ",AtlFast3: the next generation of fast simulation in ATLAS
"  Given the success of reinforcement learning (RL) in various domains, it is promising to explore the application of its methods to the development of intelligent and autonomous cyber agents. Enabling this development requires a representative RL training environment. To that end, this work presents CyGIL: an experimental testbed of an emulated RL training environment for network cyber operations. CyGIL uses a stateless environment architecture and incorporates the MITRE ATT&CK framework to establish a high fidelity training environment, while presenting a sufficiently abstracted interface to enable RL training. Its comprehensive action space and flexible game design allow the agent training to focus on particular advanced persistent threat (APT) profiles, and to incorporate a broad range of potential threats and vulnerabilities. By striking a balance between fidelity and simplicity, it aims to leverage state of the art RL algorithms for application to real-world cyber defence. ",CyGIL: A Cyber Gym for Training Autonomous Agents over Emulated Network   Systems
"  A new current induced spin-torque transfer effect has been observed in a single ferromagnetic layer without resorting to multilayers. At a specific current density of one polarity injected from a point contact, abrupt resistance changes due to current-induced spin wave excitations have been observed. The critical current at the onset of spin-wave excitations depends linearly on the external field applied perpendicular to the layer. The observed effect is due to current-driven heterogeneity in an otherwise uniform ferromagnetic layer. ",Current-induced spin-wave excitations in a single ferromagnetic layer
"  In this short note, we prove that a bi-invariant Riemannian metric on $\mathrm{Sp}(n)$ is uniquely determined by the spectrum of its Laplace-Beltrami operator within the class of left-invariant metrics on $\mathrm{Sp}(n)$. In other words, on any of these compact simple Lie groups, every left-invariant metric which is not right-invariant cannot be isospectral to a bi-invariant metric. The proof is elementary and uses a very strong spectral obstruction proved by Gordon, Schueth, and Sutton. ",Spectral uniqueness of bi-invariant metrics on symplectic groups
"  Making use of the energetics and equations of state of defective uranium dioxide that calculated with first-principles method, we demonstrate a possibility of constraining the formation energy of point defects by measuring the transition pressures of the corresponding pseudo-phase of defects. The mechanically stable range of fluorite structure of UO2, which dictates the maximum possible pressure of relevant pseudo-phase transitions, gives rise to defect formation energies that span a wide band and overlap with the existing experimental estimates. We reveal that the knowledge about pseudo-phase boundaries can not only provide important information of energetics that is helpful for reducing the scattering in current estimates, but also be valuable for guiding theoretical assessments, even to validate or disprove a theory. In order to take defect interactions into account and to extrapolate the physical quantities at finite stoichiometry deviations to that near the stoichiometry, we develop a general formalism to describe the thermodynamics of a defective system. We also show that it is possible to include interactions among defects in a simple expression of point defect model (PDM) by introducing an auxiliary constant mean-field. This generalization of the simple PDM leads to great versatility that allows one to study nonlinear effects of stoichiometry deviation on materials' behavior. It is a powerful tool to extract the defect energetics from finite defect concentrations to the dilute limit. Besides these, the full content of the theoretical formalism and some relevant and interesting issues, including reentrant pseudo-transition, multi-defect coexistence, charged defects, and possible consequence of instantaneous defective response in a quantum crystal, are explored and discussed. ",Theoretical assessment on the possibility of constraining point defect   energetics by pseudo-phase transition pressures
  The perturbative vacuum of type 0 string theory is unstable due to the existence of the closed string tachyon. This instability can be removed by S^1 compactification with twisted boundary condition for the tachyon field. We show that even in this situation unwrapped NS5-branes are unstable and decay to bubbles of nothing smoothly without tunneling any potential barrier. We discuss a relation between the closed string tachyon condensation and the instability of NS5-branes. ,Decay of type 0 NS5-branes to nothing
"  The increasing demand for commodities is leading to changes in land use worldwide. In the tropics, deforestation, which causes high carbon emissions and threatens biodiversity, is often linked to agricultural expansion. While the need for deforestation-free global supply chains is widely recognized, making progress in practice remains a challenge. Here, we propose an automated approach that aims to support conservation and sustainable land use planning decisions by mapping tropical landscapes at large scale and high spatial resolution following the High Carbon Stock (HCS) approach. A deep learning approach is developed that estimates canopy height for each 10 m Sentinel-2 pixel by learning from sparse GEDI LIDAR reference data, achieving an overall RMSE of 6.3 m. We show that these wall-to-wall maps of canopy top height are predictive for classifying HCS forests and degraded areas with an overall accuracy of 86 % and produce a first high carbon stock map for Indonesia, Malaysia, and the Philippines. ",High carbon stock mapping at large scale with optical satellite imagery   and spaceborne LIDAR
"  With the prevalence of machine learning in high-stakes applications, especially the ones regulated by anti-discrimination laws or societal norms, it is crucial to ensure that the predictive models do not propagate any existing bias or discrimination. Due to the ability of deep neural nets to learn rich representations, recent advances in algorithmic fairness have focused on learning fair representations with adversarial techniques to reduce bias in data while preserving utility simultaneously. In this paper, through the lens of information theory, we provide the first result that quantitatively characterizes the tradeoff between demographic parity and the joint utility across different population groups. Specifically, when the base rates differ between groups, we show that any method aiming to learn fair representations admits an information-theoretic lower bound on the joint error across these groups. To complement our negative results, we also prove that if the optimal decision functions across different groups are close, then learning fair representations leads to an alternative notion of fairness, known as the accuracy parity, which states that the error rates are close between groups. Finally, our theoretical findings are also confirmed empirically on real-world datasets. ",Inherent Tradeoffs in Learning Fair Representations
"  We present the design and a first performance evaluation of Thrill -- a prototype of a general purpose big data processing framework with a convenient data-flow style programming interface. Thrill is somewhat similar to Apache Spark and Apache Flink with at least two main differences. First, Thrill is based on C++ which enables performance advantages due to direct native code compilation, a more cache-friendly memory layout, and explicit memory management. In particular, Thrill uses template meta-programming to compile chains of subsequent local operations into a single binary routine without intermediate buffering and with minimal indirections. Second, Thrill uses arrays rather than multisets as its primary data structure which enables additional operations like sorting, prefix sums, window scans, or combining corresponding fields of several arrays (zipping). We compare Thrill with Apache Spark and Apache Flink using five kernels from the HiBench suite. Thrill is consistently faster and often several times faster than the other frameworks. At the same time, the source codes have a similar level of simplicity and abstraction ",Thrill: High-Performance Algorithmic Distributed Batch Data Processing   with C++
"  For the general Two-Higgs-Doublet model, we present conditions for having spontaneous CP violation, in terms of physical masses and couplings. These relations involve the charged-Higgs mass, its cubic couplings with neutral scalars and quartic coupling, and become particularly simple in the alignment limit. In the simplified model with softly broken $Z_2$ symmetry, some deviation from alignment is required for spontaneous CP violation to be present. ",Spontaneous CP violation in the 2HDM: physical conditions and the   alignment limit
"  Retaining premium players is key to the success of free-to-play games, but most of them do not start purchasing right after joining the game. By exploiting the exceptionally rich datasets recorded by modern video games--which provide information on the individual behavior of each and every player--survival analysis techniques can be used to predict what players are more likely to become paying (or even premium) users and when, both in terms of time and game level, the conversion will take place. Here we show that a traditional semi-parametric model (Cox regression), a random survival forest (RSF) technique and a method based on conditional inference survival ensembles all yield very promising results. However, the last approach has the advantage of being able to correct the inherent bias in RSF models by dividing the procedure into two steps: first selecting the best predictor to perform the splitting and then the best split point for that covariate. The proposed conditional inference survival ensembles method could be readily used in operational environments for early identification of premium players and the parts of the game that may prompt them to become paying users. Such knowledge would allow developers to induce their conversion and, more generally, to better understand the needs of their players and provide them with a personalized experience, thereby increasing their engagement and paving the way to higher monetization. ",From Non-Paying to Premium: Predicting User Conversion in Video Games   with Ensemble Learning
"  We study two different versions of the site-diluted Ising model in three dimensions with long-range spatially correlated disorder by Monte Carlo means. We use finite-size scaling techniques to compute the critical exponents of these systems, taking into account the strong scaling-corrections. We find a $\nu$ value that is compatible with the analytical predictions. ",Site-diluted three dimensional Ising Model with long-range correlated   disorder
"  We study the effects of time-varying environmental noise on nonequilibrium phase transitions in spreading and growth processes. Using the examples of the logistic evolution equation as well as the contact process, we show that such temporal disorder gives rise to a distinct type of critical points at which the effective noise amplitude diverges on long time scales. This leads to enormous density fluctuations characterized by an infinitely broad probability distribution at criticality. We develop a real-time renormalization-group theory that provides a general framework for the effects of temporal disorder on nonequilibrium processes. We also discuss how general this exotic critical behavior is, we illustrate the results by computer simulations, and we touch upon experimental applications of our theory. ",Infinite-noise criticality: Nonequilibrium phase transitions in   fluctuating environments
"  We explain the recent diphoton excesses around $750$ GeV by both ATLAS and CMS as a singlet scalar $\Phi$ which couples to SM gluon and neutral gauge bosons only through higher dimensional operators. A natural explanation is that $\Phi$ is a pseudo-Nambu-Goldstone boson (pNGB) which receives parity violation through anomaly if there exists a hidden strong dynamics. The singlet and other light pNGBs will decay into two SM gauge bosons and even serves as the meta-stable coloured states which can be probed in the future. By accurately measuring their relative decay and the total production rate in the future, we will learn the underlying strong dynamics parameter. The lightest baryon in this confining theory could serve as a viable dark matter candidate. ",A hidden confining world on the 750 GeV diphoton excess
  Parametric unfolding of a true distribution distorted due to finite resolution and limited efficiency for the registration of individual events is discussed. Details of the computational algorithm of the unfolding procedure are presented. ,Parametric unfolding. Method and restrictions
  We present a systematic study of spherically symmetric self-dual solutions of SU(2) Yang-Mills theory on Euclidean Schwarzschild space. All the previously known solutions are recovered and a new one-parameter family of instantons is obtained. The newly found solutions have continuous actions and interpolate between the classic Charap and Duff instantons. We examine the physical properties of this family and show that it consists of dyons of unit (magnetic and electric) charge. ,New self-dual solutions of SU(2) Yang-Mills theory in Euclidean   Schwarzschild space
"  In the present paper, we investigate the effect of plasmonic Au nanoparticles (NPs) decoration on the photocatalytic efficiency of MoS$_2$ nanosheets. The Au NPs are grown on the surface of chemically exfoliated MoS$_2$ nanosheets by chemical reduction method. Au-MoS$_2$ nanostructures (NSs) are characterized by X-ray diffractometer, Raman spectrometer, absorption spectrophotometer, and transmission electron microscopy. Exfoliated MoS$_2$ and Au-MoS$_2$ NSs are used to study the photocatalytic degradation of organic dyes methyl red (MR) and methylene blue (MB). Under UV-Visible light irradiation, pristine MoS$_2$ shows photo degradation efficiencies between 30% to 46.9% for MR and 23.3% to 44% for MB, with varying exposure times from 30 to 120 min, respectively. However, Au-MoS$_2$ NSs with maximum Au NPs concentration show enhanced degradation efficiency from 70.2 to 96.7% for MR, and from 65.2 to 94.3% for MB. The manifold enhancement of degradation efficiency for both the dyes with Au-MoS$_2$ NSs may be attributed to the presence of Au NPs acting as charge trapping sites in the NSs. We believe this study would have potential application in battling the ill-effects of environmental degradation, which poses a major threat to humans as well as biodiversity. ",Enhanced photocatalytic activity of plasmonic Au nanoparticles   incorporated MoS$_2$ nanosheets for degradation of organic dyes
"  We study charge pumping when a combination of static potentials and potentials oscillating with a time period T is applied in a one-dimensional system of non-interacting electrons. We consider both an infinite system using the Dirac equation in the continuum approximation, and a periodic ring with a finite number of sites using the tight-binding model. The infinite system is taken to be coupled to reservoirs on the two sides which are at the same chemical potential and temperature. We consider a model in which oscillating potentials help the electrons to access a transmission resonance produced by the static potentials, and show that non-adiabatic pumping violates the simple \sin \phi rule which is obeyed by adiabatic two-site pumping. For the ring, we do not introduce any reservoirs, and we present a method for calculating the current averaged over an infinite time using the time evolution operator U(T) assuming a purely Hamiltonian evolution. We analytically show that the averaged current is zero if the Hamiltonian is real and time reversal invariant. Numerical studies indicate another interesting result, namely, that the integrated current is zero for any time-dependence of the potential if it is applied to only one site. Finally we study the effects of pumping at two sites on a ring at resonant and non-resonant frequencies, and show that the pumped current has different dependences on the pumping amplitude in the two cases. ",Nonadiabatic charge pumping by oscillating potentials in one dimension:   results for infinite system and finite ring
"  We find quasinormal spectrum of the massive scalar field in the background of the Kerr black holes. We show that all found modes are damped under the quasinormal modes boundary conditions when $\mu M$ is not large, thereby implying stability of the massive scalar field. This complements the region of stability determined by the Beyer inequality for large masses of the field. We show that, similar to the case of a non-rotating black holes, the massive term of the scalar field does not contribute in the regime of high damping. Thereby, the high damping asymptotic should be the same as for the massless scalar field. ",Stability and quasinormal modes of the massive scalar field around Kerr   black holes
"  A popular measure for the success or citation inequalities of individual scientists have been the Hirsch index ($h$). If the number $n_c$ of citations are plotted against the number $n_p$ of papers (having those citations), then $h$ corresponds to the fixed point (where $n_c = h = n_p$) of the above-mentioned citation function. There have been theoretical as well as numerical studies suggesting $h\sim \sqrt{N_c} \sim \sqrt {N_p}$, for any author having $N_p = \Sigma n_p$ total papers and $N_c = \Sigma n_c$ total citations. With extensive data analysis here, we show that $h \sim \sqrt N_c /log N_c \sim \sqrt N_p /log N_p$. Our numerical study also shows that the $h$-index values for size distribution of avalanches in equal load-sharing fiber bundle models (of materials failure), consisting of $N$ fibers, also scale as $\sqrt N/ log N$. We however observe a notable discrepancy in the scaling relation of $h$ for the size distribution of clusters near the percolation point of square lattice (indicating that the scaling behavior depends on the dimension). We also show that if the number $N_s$ of the members of parliaments or national assemblies of different countries of the world are identified effectively as their Hirsch index $h$, then $N_s$ indeed scales with the population $N$ as $\sqrt N /log N$ for the respective countries and this observation may help comprehending the discrepancies with $\sqrt N$ relationship, reported in a very recent analysis. ","Scaling Behavior of the Hirsch Index for Paper Citations, Failure   Avalanches and Percolation Clusters"
"  We develop a dynamic version of the primal-dual method for optimization problems, and apply it to obtain the following results. (1) For the dynamic set-cover problem, we maintain an $O(f^2)$-approximately optimal solution in $O(f \cdot \log (m+n))$ amortized update time, where $f$ is the maximum ""frequency"" of an element, $n$ is the number of sets, and $m$ is the maximum number of elements in the universe at any point in time. (2) For the dynamic $b$-matching problem, we maintain an $O(1)$-approximately optimal solution in $O(\log^3 n)$ amortized update time, where $n$ is the number of nodes in the graph. ",Design of Dynamic Algorithms via Primal-Dual Method
"  Numerous non-standard dynamics are described by contact-like effective interactions that can manifest themselves in electron-positron collisions only through deviations of the observables (cross sections, asymmetries) from the Standard Model predictions. If such a deviation were observed, it would be important to identify the actual source among the possible non-standard interactions as many different new physics scenarios may lead to very similar experimental signatures. We study the possibility of uniquely identifying the indirect effects of s-channel sneutrino exchange, as predicted by supersymmetric theories with R-parity violation, against other new physics scenarios in high-energy e^+e^- annihilation into lepton pairs at the International Linear Collider. These competitive models are interactions based on gravity in large and in TeV-scale extra dimensions, anomalous gauge couplings, Z' vector bosons and compositeness-inspired four-fermion contact interactions. To evaluate the identification reach on sneutrino exchange, we use as basic observable a double polarization asymmetry, that is particularly suitable to directly test for such s-channel sneutrino exchange effects in the data analysis. The availability of both beams being polarized plays a crucial role in identifying the new physics scenario. ",Sneutrino Identification in Lepton Pair Production at ILC with Polarized   Beams
"  In this article, we study the heart of a cotorsion pairs on an exact category and a triangulated category in a unified meathod, by means of the notion of an extriangulated category. We prove that the heart is abelian, and construct a cohomological functor to the heart. If the extriangulated category has enough projectives, this functor gives an equivalence between the heart and the category of coherent functors over the coheart modulo projectives. We also show how an n-cluster tilting subcategory of an extriangulated category gives rise to a family of cotorsion pairs with equivalent hearts. ",Hearts of twin Cotorsion pairs on extriangulated categories
"  We discuss exclusive central diffractive production of $\pi^{+} \pi^{-}$ in proton-(anti)proton collisions at high energies. Based on a tensor pomeron model we present results of the purely diffractive dipion continuum, the scalar $f_{0}(500)$, $f_{0}(980)$ and tensor $f_{2}(1270)$ resonances decaying into the $\pi^{+} \pi^{-}$ pairs as well as the photoproduction mechanism ($\rho^{0}$, Drell-S\""oding). We discuss how two pomerons couple to the tensor meson $f_{2}(1270)$ and the interference effects of resonance and dipion continuum contributions. The theoretical results are compared with existing STAR, CDF, and CMS experimental data. Predictions for planned or being carried out experiments (ALICE, ATLAS) are presented. We find that the relative contribution of resonant $f_2(1270)$ and dipion continuum strongly depend on the cut on proton transverse momenta (or four-momentum transfer squared $t_{1,2}$) which may explain some controversial observations made by different ISR experiments in the past. The cuts may play then the role of a $\pi \pi$ resonance filter. ",Exclusive diffractive production of $\pi^+ \pi^-$ pairs within tensor   pomeron approach
"  The one-loop structure of the trace anomaly is investigated using different regularizations and renormalization schemes: dimensional, proper time and Pauli-Villars. The universality of this anomaly is analyzed from a very general perspective. The Euler and Weyl terms of the anomalous trace of the stress tensor are absolutely universal. The pure derivative $ \square R$-term is shown to be universal only if the regularization breaks conformal symmetry softly. If the breaking of conformal symmetry by the regularization method is hard the coefficient of this term might become arbitrary which points out the presence of an ambiguous $ \int\sqrt{-g} R^2$-term in the effective quantum action. These ambiguities arise in some prescriptions of dimensional and Pauli-Villars regularizations. We discuss the implications of these results for anomaly-induced inflationary scenarios and AdS/CFT correspondence. ",Universality and Ambiguities of the Conformal Anomaly
"  We review recent progress in the construction and classification of six-dimensional (1,0) superconformal models with non-abelian tensor fields. Here we solve the generalized Jacobi identities which are required for consistency of the non-abelian vector/tensor gauge system and we present a large class of explicit examples. ",New superconformal models in six dimensions: Gauge group and   representation structure
"  In this work we present VCube-PS, a topic-based Publish/Subscribe system built on the top of a virtual hypercube-like topology. Membership information and published messages are broadcast to subscribers (members) of a topic group over dynamically built spanning trees rooted at the publisher. For a given topic, the delivery of published messages respects the causal order. VCube-PS was implemented on the PeerSim simulator, and experiments are reported including a comparison with the traditional Publish/Subscribe approach that employs a single rooted static spanning-tree for message distribution. Results confirm the efficiency of VCube-PS in terms of scalability, latency, number and size of messages. ",VCube-PS: A Causal Broadcast Topic-based Publish/Subscribe System
"  Disease occurs due to aberrant expression of genes and modulation of the biological pathways along which they lie. Inference of activated gene pathways, using gene expression data during disease progression, is an important problem. In this work, we have developed a generalizable framework for the identification of interacting pathways while incorporating biological realism, using functional data analysis and manifold embedding techniques. Additionally, we have also developed a new method to query for the differential co-ordinated activity of any desired pathway during disease progression. The methods developed in this work can be generalized to any conditions of interest. ",Identification and Query of Activated Gene Pathways in Disease   Progression
"  Collaborative tagging has recently attracted the attention of both industry and academia due to the popularity of content-sharing systems such as CiteULike, del.icio.us, and Flickr. These systems give users the opportunity to add data items and to attach their own metadata (or tags) to stored data. The result is an effective content management tool for individual users. Recent studies, however, suggest that, as tagging communities grow, the added content and the metadata become harder to manage due to an ease in content diversity. Thus, mechanisms that cope with increase of diversity are fundamental to improve the scalability and usability of collaborative tagging systems. This paper analyzes whether usage patterns can be harnessed to improve navigability in a growing knowledge space. To this end, it presents a characterization of two collaborative tagging communities that target scientific literature: CiteULike and Bibsonomy. We explore three main directions: First, we analyze the tagging activity distribution across the user population. Second, we define new metrics for similarity in user interest and use these metrics to uncover the structure of the tagging communities we study. The structure we uncover suggests a clear segmentation of interests into a large number of individuals with unique preferences and a core set of users with interspersed interests. Finally, we offer preliminary results that demonstrate that the interest-based structure of the tagging community can be used to facilitate content usage as communities scale. ",Tracking User Attention in Collaborative Tagging Communities
"  Disjunctive Answer Set Programming is a powerful declarative programming paradigm with complexity beyond NP. Identifying classes of programs for which the consistency problem is in NP is of interest from the theoretical standpoint and can potentially lead to improvements in the design of answer set programming solvers. One of such classes consists of dual-normal programs, where the number of positive body atoms in proper rules is at most one. Unlike other classes of programs, dual-normal programs have received little attention so far. In this paper we study this class. We relate dual-normal programs to propositional theories and to normal programs by presenting several inter-translations. With the translation from dual-normal to normal programs at hand, we introduce the novel class of body-cycle free programs, which are in many respects dual to head-cycle free programs. We establish the expressive power of dual-normal programs in terms of SE- and UE-models, and compare them to normal programs. We also discuss the complexity of deciding whether dual-normal programs are strongly and uniformly equivalent. ",Dual-normal Logic Programs - the Forgotten Class
"  Recent progress in extremely correlated Fermi liquid theory (ECFL) and dynamical mean field theory (DMFT) enables us to compute in the $d \to \infty$ limit the resistivity of the $t-J$ model after setting $J\to0$. This is also the $U=\infty$ Hubbard model. We study three densities $n=.75,.8,.85$ that correspond to a range between the overdoped and optimally doped Mott insulating state. We delineate four distinct regimes characterized by different behaviors of the resistivity $\rho$. We find at the lowest $T$ a Gutzwiller Correlated Fermi Liquid regime with $\rho \propto T^2$ extending up to an effective Fermi temperature that is dramatically suppressed from the non-interacting value. This is followed by a Gutzwiller Correlated Strange Metal regime with $\rho \propto (T-T_0)$, i.e. a linear resistivity extrapolating back to $\rho=0$ at a positive $T_0$. At a higher $T$ scale, this crosses over into the Bad Metal regime with $\rho \propto (T+T_1)$ extrapolating back to a finite resistivity at $T=0$, and passing through the Ioffe-Regel-Mott value where the mean free path is a few lattice constants. This regime finally gives way to the High $T$ Metal regime, where we find $\rho \propto T$. The present work emphasizes the first two, where the availability of an analytical ECFL theory is of help in identifying the changes in related variables entering the resistivity formula that accompany the onset of linear resistivity, and the numerically exact DMFT helps to validate the results. We also examine thermodynamic variables such as the magnetic susceptibility, compressibility, heat capacity and entropy, and correlate changes in these with the change in resistivity. This exercise casts valuable light on the nature of charge and spin correlations in the strange metal regime, which has features in common with the physically relevant strange metal phase seen in strongly correlated matters. ",A Strange Metal from Gutzwiller correlations in infinite dimensions
"  We present a preliminary analysis of XMM-Newton observations of the oxygen-rich supernova remnant G292.0+1.8 (MSH 11-54). Although the spatial extent of the remnant is 8 arcmin the bright central bar is narrow (1'-2') resulting in RGS spectra of a high spectral quality. This allows us to spectroscopically identify a cool, Te = 0.3 keV, and underionized component, resolve details of the Fe-L complex, and resolve the forbidden and resonant lines of the O VII triplet. We are also able to constrain the kinematics of the remnant using Ne IX as observed in the second order spectrum, and O VIII in the first order spectrum. We do not find evidence for O VII line shifts or Doppler broadening (sigma_v < 731 km/s), but line broadening of the Ne X Ly-alpha line seems to be present, corresponding to sigma_v ~ 1500 km/s. ",High Resolution X-ray Spectroscopy of G292.0+1.8/MSH 11-54
"  We study star formation rate (SFR) indicators for Wide-field Infrared Survey Explorer (WISE) 22 \mu m selected, star-forming galaxies at 0.01 < z < 0.3 in the Sloan Digital Sky Survey. Using extinction-corrected H\alpha\ luminosities and total infrared luminosities as reference SFR estimates, we calibrate WISE mid-infrared (MIR) related SFR indicators. Both 12 and 22 \mu m monochromatic luminosities correlate well with the reference SFR estimates, but tend to underestimate SFRs of metal-poor galaxies (at lower than solar metallicity), consistent with previous studies. We mitigate this metallicity dependence using a linear combination of observed H\alpha\ and WISE MIR luminosities for SFR estimates. The combination provides robust SFR measurements as Kennicutt et al. (2009) applied to Spitzer data. However, we find that the coefficient a in L_H\alpha(obs) + a L_MIR increases with SFR, and show that a non-linear combination of observed H\alpha\ and MIR luminosities gives the best SFR estimates with small scatters and with little dependence on physical parameters. Such a combination of H\alpha\ and MIR luminosities for SFR estimates is first applied to WISE data. We provide several SFR recipes using WISE data applicable to galaxies with 0.1 <~ SFR (M_sun yr^-1) <~ 100. ",The Calibration of Star Formation Rate Indicators for WISE 22 Micron   Selected Galaxies in the SDSS
"  In the electroweak phase transition there arises the problem of baryon number washout by sphaleron transitions, which can be avoided if the phase transition is strongly enough first order. The minimal supersymmetric standard model has just two Higgs doublets H1 and H2, while the next to minimal model, NMSSM, has an additional singlet, N, this latter giving rise to the helpful feature that the Higgs potential contains a tree level trilinear field term. We use the tunneling criterion for the existence of a first order electroweak phase change. A quantitative statistical analysis indicates that with parameters of the NMSSM satisfying the experimental constraints a strong first order phase change occurs in about 50% of cases. ",Electroweak Baryogenesis in the Next to Minimal Supersymmetric Model
"  The relative acceleration between two nearby particles moving along accelerated trajectories is studied, which generalizes the geodesic deviation equation. The polarization content of the gravitational wave in Horndeski theory is investigated by examining the relative acceleration between two self-gravitating particles. It is found out that the longitudinal polarization exists no matter whether the scalar field is massive or not. It would be still very difficult to detect the enhanced longitudinal polarization with the interferometer, as the violation of the strong equivalence principle of mirrors used by interferometers is extremely small. However, the pulsar timing array is promised to relatively easily detect the effect of the violation as neutron stars have large self-energy. The advantage of using this method to test the violation of the strong equivalence principle is that neutron stars are not required to be present in the binary systems. ",Strong Equivalence Principle and Gravitational Wave Polarizations in   Horndeski Theory
"  In this paper we present a new verification theorem for optimal stopping problems for Hunt processes. The approach is based on the Fukushima-Dynkin formula, and its advantage is that it allows us to verify that a given function is the value function without using the viscosity solution argument. Our verification theorem works in any dimension. We illustrate our results with some examples of optimal stopping of reflected diffusions and absorbed diffusions. ",A new approach to optimal stopping for Hunt processes
"  This note concerns a one-line diagrammatic proof of the Cayley-Hamilton Theorem. We discuss the proof's implications regarding the ""core truth"" of the theorem, and provide a generalization. We review the notation of trace diagrams and exhibit explicit diagrammatic descriptions of the coefficients of the characteristic polynomial, which occur as the n+1 ""simplest"" trace diagrams. We close with a discussion of diagrammatic polarization related to the theorem. ",On A Diagrammatic Proof of the Cayley-Hamilton Theorem
"  Several recent electron spin resonance studies have observed a quintet multiexciton state during the singlet fission process. Here we provide a general theoretical explanation for the generation of this state by invoking a time-varying exchange coupling between pairs of triplet excitons, and subsequently solving the relevant time-varying spin Hamiltonian for a range of transition times. We simulate experimental ESR spectra and draw qualitative conclusions about the adiabatic/diabatic transition between triplet pair spin states. ",Fluctuating exchange interactions enable quintet multiexciton formation   in singlet fission
"  In this work, a physical and geometrical optics based single-frequency imaging scheme is proposed for personal screening systems using multiple reconfigurable reflectarrays. This scheme is able to not only reconstruct profiles of potential threat objects on human body, but also identify their materials in terms of their complex relative permittivities. Both simulation and experiment are carried out to detect dielectric objects at a microwave frequency of 24.16 GHz. The object profiles and complex relative permittivities are obtained with both high accuracy and computational efficiency, which show great potentials for security imaging where inspection of human body for threat materials, such as narcotics, explosives, and other types of contraband, is very common. ",Single-Frequency Imaging and Material Characterization using   Reconfigurable Reflectarrays
"  Configuring a storage system to better serve an application is a challenging task complicated by a multidimensional, discrete configuration space and the high cost of space exploration (e.g., by running the application with different storage configurations). To enable selecting the best configuration in a reasonable time, we design an end-to-end performance prediction mechanism that estimates the turn-around time of an application using storage system under a given configuration. This approach focuses on a generic object-based storage system design, supports exploring the impact of optimizations targeting workflow applications (e.g., various data placement schemes) in addition to other, more traditional, configuration knobs (e.g., stripe size or replication level), and models the system operation at data-chunk and control message level.   This paper presents our experience to date with designing and using this prediction mechanism. We evaluate this mechanism using micro- as well as synthetic benchmarks mimicking real workflow applications, and a real application.. A preliminary evaluation shows that we are on a good track to meet our objectives: it can scale to model a workflow application run on an entire cluster while offering an over 200x speedup factor (normalized by resource) compared to running the actual application, and can achieve, in the limited number of scenarios we study, a prediction accuracy that enables identifying the best storage system configuration. ",Predicting Intermediate Storage Performance for Workflow Applications
  Presenting a general phase approach to stochastic processes we analyze in particular the Fokker-Planck equation for the noisy Burgers equation and discuss the time dependent and stationary probability distributions. In one dimension we derive the long-time skew distribution approaching the symmetric stationary Gaussian distribution. In the short time regime we discuss heuristically the nonlinear soliton contributions and derive an expression for the distribution in accordance with the directed polymer-replica model and asymmetric exclusion model results. ,Canonical phase space approach to the noisy Burgers equation
"  We study certain exclusive decays of high spin mesons into mesons in models of large N_c Yang-Mills with few flavors at strong coupling using string theory. The rate of the process is calculated by studying the splitting of a macroscopic string on the relevant dual gravity backgrounds. In the leading channel for the decay of heavy quarkonium into two open-heavy quark states, one of the two produced mesons has much larger spin than the other. In this channel the decay rate is only power-like suppressed with the mass of the produced quark-anti quark pair. We also reconsider decays of high spin mesons made up of light quarks, confirming the linear dependence of the rate on the mass of the decaying meson. As a bonus of our computation, we provide a formula for the splitting rate of a macroscopic string lying on a Dp-brane in flat space. ",New predictions on meson decays from string splitting
"  Fine-tuning pre-trained language models (PTLMs), such as BERT and its better variant RoBERTa, has been a common practice for advancing performance in natural language understanding (NLU) tasks. Recent advance in representation learning shows that isotropic (i.e., unit-variance and uncorrelated) embeddings can significantly improve performance on downstream tasks with faster convergence and better generalization. The isotropy of the pre-trained embeddings in PTLMs, however, is relatively under-explored. In this paper, we analyze the isotropy of the pre-trained [CLS] embeddings of PTLMs with straightforward visualization, and point out two major issues: high variance in their standard deviation, and high correlation between different dimensions. We also propose a new network regularization method, isotropic batch normalization (IsoBN) to address the issues, towards learning more isotropic representations in fine-tuning by dynamically penalizing dominating principal components. This simple yet effective fine-tuning method yields about 1.0 absolute increment on the average of seven NLU tasks. ",IsoBN: Fine-Tuning BERT with Isotropic Batch Normalization
"  Using polynomial evaluation, we give some useful criteria to answer questions about divisibility of polynomials. This allows us to develop interesting results concerning the prime elements in the domain of coefficients. In particular, it is possible to prove that under certain conditions, the domain of coefficients must have infinitely many prime elements. We give alternative characterizations for D-rings and present various examples. ",Some Divisibility Properties in Ring of Polynomials over a Unique   Factorization Domain
"  After short historical overview we describe the difficulties with application of standard QFT methods in quantum gravity (QG). The incompatibility of QG with the use of classical continuous space-time required conceptually new approach. We present briefly three proposals: loop quantum gravity (LQG), the field-theoretic framework on noncommutative space-time and QG models formulated on discretized (triangularized) space-time. We evaluate these models as realizing expected important properties of QG: background independence, consistent quantum diffeomorphisms, noncommutative or discrete structure of space-time at very short distances, finite/renormalizable QG corrections. We only briefly outline an important issue of embedding QG into larger geometric and dynamical frameworks (e.g. supergravity, (super)strings, p-branes, M-theory), with the aim to achieve full unification of all fundamental interactions. ",Quantum Gravity models - brief conceptual summary
"  We study the well-known Label Cover problem under the additional requirement that problem instances have large girth. We show that if the girth is some $k$, the problem is roughly $2^{\log^{1-\epsilon} n/k}$ hard to approximate for all constant $\epsilon > 0$. A similar theorem was claimed by Elkin and Peleg [ICALP 2000], but their proof was later found to have a fundamental error. We use the new proof to show inapproximability for the basic $k$-spanner problem, which is both the simplest problem in graph spanners and one of the few for which super-logarithmic hardness was not known. Assuming $NP \not\subseteq BPTIME(2^{polylog(n)})$, we show that for every $k \geq 3$ and every constant $\epsilon > 0$ it is hard to approximate the basic $k$-spanner problem within a factor better than $2^{(\log^{1-\epsilon} n) / k}$ (for large enough $n$). A similar hardness for basic $k$-spanner was claimed by Elkin and Peleg [ICALP 2000], but the error in their analysis of Label Cover made this proof fail as well. Thus for the problem of Label Cover with large girth we give the first non-trivial lower bound. For the basic $k$-spanner problem we improve the previous best lower bound of $\Omega(\log n)/k$ by Kortsarz [Algorithmica 1998]. Our main technique is subsampling the edges of 2-query PCPs, which allows us to reduce the degree of a PCP to be essentially equal to the soundness desired. This turns out to be enough to essentially guarantee large girth. ",Label Cover instances with large girth and the hardness of approximating   basic k-spanner
"  We find a continuum of extinction rates for solutions $u(y,\tau)\ge 0$ of the fast diffusion equation $u_\tau=\Delta u^m$ in a subrange of exponents $m\in (0,1)$. The equation is posed in $\ren$ for times up to the extinction time $T>0$. The rates take the form $\|u(\cdot,\tau)\|_\infty\sim (T-\tau)^\theta$ \ for a whole interval of $\theta>0$. These extinction rates depend explicitly on the spatial decay rates of initial data. ",A Continuum of Extinction Rates for the Fast Diffusion Equation
"  In this paper, we study quantum Sp(N) antiferromagnetic (AF) Heisenberg models in two dimensions (2D) by using the Schwinger-boson representation and the path-integral methods. An effective field theory, which is an extension of CP^{N-1} model in (2+1)D, is derived and its phase structure is studied by the 1/N-expansion. We introduce a spatial anisotropy in the exchange couplings and show that the effective coupling constant in the CP^{N-1} model is an increasing function of the anisotropy. For the SU(N) AF Heisenberg model, which is a specific case of the Sp(N) model, we found that phase transition from the ordered ""N\'eel state"" to paramagnetic phase takes place as the anisotropy is increased. In the vicinity of the SU(N) symmetric point, this phase structure is retained. However as a parameter that controls explicit breaking of the SU(N) symmetry is increased, a new phase, which is similar to the spiral-spin phase with a nematic order in frustrated SU(2) spin systems, appears. It is shown that at that phase transition point, a local SU(2) gauge symmetry with composite SU(2) gauge field appears in the low-energy sector. It is another example of symmetry-enhancement phenomenon at low energies. We also introduce a lattice gauge-theoretical model, which is a counterpart of the effective field theory, and study its phase structure by means of the Monte-Carlo simulations. ",Effective field theory for Sp(N) antiferromagnets and its phase   structure
"  Scientists have used many different classification methods to solve the problem of music classification. But the efficiency of each classification is different. In this paper, we propose two compared methods on the task of music style classification. More specifically, feature extraction for representing timbral texture, rhythmic content and pitch content are proposed. Comparative evaluations on performances of two classifiers were conducted for music classification with different styles. The result shows that XGB is better suited for small datasets than BPNN ",Music Style Classification with Compared Methods in XGB and BPNN
"  This article is devoted to obtaining an equation for the Abraham force in a continuous non-conducting medium and methods of its measurement. The equation for the Abraham force is obtained from the Minkowski tensor. The Abraham force appears when the vectors D and E, H and B are non-collinear. From the equation for the Abraham force it follows that it is a vortex force, and its divergence is equal to zero. It shows the existence of the Abraham electric force and the magnetic Abraham's force. Various measurement methods of the Abraham force, which follow from its equation, are given. ",Equation for the Abraham force in non-conducting medium and methods for   its measurement
"  The notion of epsilon multiplicity was originally defined by Ulrich and Validashti as a limsup and they used it to detect integral dependence of modules. It is important to know if it can be realized as a limit. In this article we show that the relative epsilon multiplicity of reduced Noetherian graded algebras over an excellent local ring exists as a limit. An important special case of a result of Cutkosky concerning epsilon multiplicity, is obtained as a corollary of our main theorem. We also develop the notion of mixed epsilon multiplicity for monomial ideals. ",Epsilon multiplicity for Noetherian graded algebras
"  The aim of this paper, is to define a bivariate exponentiated generalized linear exponential distribution based on Marshall-Olkin shock model. Statistical and reliability properties of this distribution are discussed. This includes quantiles, moments, stress-strength reliability, joint reliability function, joint reversed (hazard) rates functions and joint mean waiting time function. Moreover, the hazard rate, the availability and the mean residual lifetime functions for a parallel system, are established. One data set is analyzed, and it is observed that, the proposed distribution provides a better fit than Marshall-Olkin bivariate exponential, bivariate generalized exponential and bivariate generalized linear failure rate distributions. Simulation studies are presented to estimate both the relative absolute bias, and the relative mean square error for the distribution parameters based on complete data. ",Bivariate Exponentiated Generalized Linear Exponential Distribution with   Applications in Reliability Analysis
"  We study the effective approximation for a nonlocal stochastic Schrodinger equation with a rapidly oscillating, periodically time-dependent potential. We use the natural diffusive scaling of heterogeneous system and study the limit behaviour as the scaling parameter tends to 0. This is motivated by data assimilations with non-Gaussian uncertainties. The nonlocal operator in this stochastic partial differential equation is the generator of a non-Gaussian Levy-type process (i.e., a class of anomalous diffusion processes), with non-integrable jump kernel. With help of a two-scale convergence technique, we establish effective approximation for this nonlocal stochastic partial differential equation. More precisely, we show that a nonlocal stochastic Schrodinger equation has a nonlocal effective equation. We show that it approximates the orginal stochastic Schr\""{o}dinger equation weakly in a Sobolev-type space and strongly in $L^2$ space. In particular, this effective approximattion holds when the nonlocal operator is the fractional Laplacian. ","Effective Approximation for a Nonlocal Stochastic Schr\""{o}dinger   Equation with Oscillating Potential"
"  We analyse the non-linear propagation and dissipation of axisymmetric waves in accretion discs using the ZEUS-2D hydrodynamics code. The waves are numerically resolved in the vertical and radial directions. Both vertically isothermal and thermally stratified accretion discs are considered. The waves are generated by means of resonant forcing and several forms of forcing are considered. Compressional motions are taken to be locally adiabatic ($\gamma = 5/3$). Prior to non-linear dissipation, the numerical results are in excellent agreement with the linear theory of wave channelling in predicting the types of modes that are excited, the energy flux by carried by each mode, and the vertical wave energy distribution as a function of radius. In all cases, waves are excited that propagate on both sides of the resonance (inwards and outwards). For vertically isothermal discs, non-linear dissipation occurs primarily through shocks that result from the classical steepening of acoustic waves. For discs that are substantially thermally stratified, wave channelling is the primary mechanism for shock generation. Wave channelling boosts the Mach number of the wave by vertically confining the wave to a small cool region at the base of the disc atmosphere. In general, outwardly propagating waves with Mach numbers near resonance ${\cal M}_{\rm r} \ga 0.01$ undergo shocks within a distance of order the resonance radius. ","The Excitation, Propagation and Dissipation of Waves in Accretion Discs:   The Non-linear Axisymmetric Case"
"  We consider the question of deriving initial conditions for scalar fields in driving both an early and late quintessence phase. The dark energy field presents an unresolved uniformity problem. Further difficulties with initial conditions for assisted, kinetic and phantom inflation are presented. We review the use of the canonical measure and find the negative conclusions of Gibbons and Hawking can be allayed by means of a reasonable quantum cosmological input. We remark upon some attempts at incorporating inflationary schemes into cyclic and bouncing models. ",On initial conditions for inflationary and bouncing cosmologies
"  An inexact accelerated stochastic Alternating Direction Method of Multipliers (AS-ADMM) scheme is developed for solving structured separable convex optimization problems with linear constraints. The objective function is the sum of a possibly nonsmooth convex function and a smooth function which is an average of many component convex functions. Problems having this structure often arise in machine learning and data mining applications. AS-ADMM combines the ideas of both ADMM and the stochastic gradient methods using variance reduction techniques. One of the ADMM subproblems employs a linearization technique while a similar linearization could be introduced for the other subproblem. For a specified choice of the algorithm parameters, it is shown that the objective error and the constraint violation are $\mathcal{O}(1/k)$ relative to the number of outer iterations $k$. Under a strong convexity assumption, the expected iterate error converges to zero linearly. A linearized variant of AS-ADMM and incremental sampling strategies are also discussed. Numerical experiments with both stochastic and deterministic ADMM algorithms show that AS-ADMM can be particularly effective for structured optimization arising in big data applications. ",An Inexact Accelerated Stochastic ADMM for Separable Convex Optimization
  We develop the theory of central ideals on commutative rings. We introduce and study the central seminormalization of a ring in another one. This seminormalization is related to the theory of regulous functions on real algebraic varieties. We provide a construction of the central seminormalization by a decomposition theorem in elementary central gluings. The existence of a central seminormalization is established in the affine case and for real schemes. ,Central Algebraic Geometry and Seminormality
"  Using the first law of binary black-hole mechanics, we compute the binding energy E and total angular momentum J of two non-spinning compact objects moving on circular orbits with frequency Omega, at leading order beyond the test-particle approximation. By minimizing E(Omega) we recover the exact frequency shift of the Schwarzschild innermost stable circular orbit induced by the conservative piece of the gravitational self-force. Comparing our results for the coordinate invariant relation E(J) to those recently obtained from numerical simulations of comparable-mass non-spinning black-hole binaries, we find a remarkably good agreement, even in the strong-field regime. Our findings confirm that the domain of validity of perturbative calculations may extend well beyond the extreme mass-ratio limit. ",Gravitational Self-Force Correction to the Binding Energy of Compact   Binary Systems
"  We study the energy levels of H$_2$ molecules in a superstrong magnetic field ($B\go 10^{12}$ G), typically found on the surfaces of neutron stars. The interatomic interaction potentials are calculated by a Hartree-Fock method with multi-configurations assuming electrons are in the ground Landau state. Both the aligned configurations and arbitrary orientations of the molecular axis with respect to the magnetic field axis are considered. Different types of molecular excitations are then studied: electronic excitations, aligned (along the magnetic axis) vibrational excitations, transverse vibrational excitations (a constrained rotation of the molecular axis around the magnetic field line). Similar results for the molecular ion H$_2^+$ are also obtained and compared with previous variational calculations. Both numerical results and analytical fitting formulae are given for a wide range of field strengths. In contrast to the zero-field case, it is found that the transverse vibrational excitation energies can be larger than the aligned vibration excitation, and they both can be comparable or larger than the electronic excitations. For $B\go B_{crit}=4.23\times 10^{13}$ G, the Landau energy of proton is appreciable and there is some controversy regarding the dissociation energy of H$_2$. We show that H$_2$ is bound even for $B>>B_{crit}$ and that neither proton has a Landau excitation in the ground molecular state. ",Hydrogen Molecules In Superstrong Magnetic Field: II. Excitation Levels
"  The learned weights of a neural network are often considered devoid of scrutable internal structure. To discern structure in these weights, we introduce a measurable notion of modularity for multi-layer perceptrons (MLPs), and investigate the modular structure of MLPs trained on datasets of small images. Our notion of modularity comes from the graph clustering literature: a ""module"" is a set of neurons with strong internal connectivity but weak external connectivity. We find that training and weight pruning produces MLPs that are more modular than randomly initialized ones, and often significantly more modular than random MLPs with the same (sparse) distribution of weights. Interestingly, they are much more modular when trained with dropout. We also present exploratory analyses of the importance of different modules for performance and how modules depend on each other. Understanding the modular structure of neural networks, when such structure exists, will hopefully render their inner workings more interpretable to engineers. Note that this paper has been superceded by ""Clusterability in Neural Networks"", arxiv:2103.03386! ",Pruned Neural Networks are Surprisingly Modular
"  In this paper, we present various systems submitted by our team problemConquero for SemEval-2020 Shared Task 12 Multilingual Offensive Language Identification in Social Media. We participated in all the three sub-tasks of OffensEval-2020, and our final submissions during the evaluation phase included transformer-based approaches and a soft label-based approach. BERT based fine-tuned models were submitted for each language of sub-task A (offensive tweet identification). RoBERTa based fine-tuned model for sub-task B (automatic categorization of offense types) was submitted. We submitted two models for sub-task C (offense target identification), one using soft labels and the other using BERT based fine-tuned model. Our ranks for sub-task A were Greek-19 out of 37, Turkish-22 out of 46, Danish-26 out of 39, Arabic-39 out of 53, and English-20 out of 85. We achieved a rank of 28 out of 43 for sub-task B. Our best rank for sub-task C was 20 out of 39 using BERT based fine-tuned model. ",problemConquero at SemEval-2020 Task 12: Transformer and Soft   label-based approaches
"  We consider an exactly tractable model of the Kramers type for the voltage-dependent gating dynamics of single ion channels. It is assumed that the gating dynamics is caused by the thermally activated transitions in a bistable potential. Moreover, the closed state of the channel is highly degenerate and embraces the whole manifold of closed substates. Opening of the ion channel is energetically prohibited from most of the closed substates and requires a special conformation where the voltage sensor can move along an activation pathway and trigger the transition into the open conformation. When the corresponding activation barrier towards the channel's opening is removed by the applied voltage, the statistics of non-conducting time intervals become strongly influenced by the conformational diffusion. For the corresponding supra-threshold voltages, our model explains the origin of the power law distribution of the closed time intervals. The exponential-linear dependence of the opening rate on voltage, often used as an experimental fit, is also reproduced by our model. ",The role of conformational diffusion in ion channel gating
"  Deep Neural Networks (DNNs) have become increasingly popular in computer vision, natural language processing, and other areas. However, training and fine-tuning a deep learning model is computationally intensive and time-consuming. We propose a new method to improve the performance of nearly every model including pre-trained models. The proposed method uses an ensemble approach where the networks in the ensemble are constructed by reassigning model parameter values based on the probabilistic distribution of these parameters, calculated towards the end of the training process. For pre-trained models, this approach results in an additional training step (usually less than one epoch). We perform a variety of analysis using the MNIST dataset and validate the approach with a number of DNN models using pre-trained models on the ImageNet dataset. ",Make (Nearly) Every Neural Network Better: Generating Neural Network   Ensembles by Weight Parameter Resampling
"  Given a set C in R^d, let p(C) be the probability that a random d-dimensional unimodular lattice, chosen according to Haar measure on SL(d,Z)\SL(d,R), is disjoint from C\{0}. For special convex sets C we prove bounds on p(C) which are sharp up to a scaling of C by a constant. We also prove bounds on a variant of p(C) where the probability is conditioned on the random lattice containing a fixed given point p. Our bounds have applications, among other things, to the asymptotic properties of the collision kernel of the periodic Lorentz gas in the Boltzmann-Grad limit, in arbitrary dimension d. ",On the probability of a random lattice avoiding a large convex set
"  This paper was motivated by the problem of how to make robots fuse and transfer their experience so that they can effectively use prior knowledge and quickly adapt to new environments. To address the problem, we present a learning architecture for navigation in cloud robotic systems: Lifelong Federated Reinforcement Learning (LFRL). In the work, We propose a knowledge fusion algorithm for upgrading a shared model deployed on the cloud. Then, effective transfer learning methods in LFRL are introduced. LFRL is consistent with human cognitive science and fits well in cloud robotic systems. Experiments show that LFRL greatly improves the efficiency of reinforcement learning for robot navigation. The cloud robotic system deployment also shows that LFRL is capable of fusing prior knowledge. In addition, we release a cloud robotic navigation-learning website based on LFRL. ",Lifelong Federated Reinforcement Learning: A Learning Architecture for   Navigation in Cloud Robotic Systems
"  We prove a structure theorem for the multibrot sets, which are the higher degree analogues of the Mandelbrot set, and give a complete picture of the landing behavior of the rational parameter rays and the bifurcation phenomenon. Our proof is inspired by previous works of Schleicher and Milnor on the combinatorics of the Mandelbrot set; in particular, we make essential use of combinatorial tools such as orbit portraits and kneading sequences. However, we avoid the standard global counting arguments in our proof and replace them by local analytic arguments to show that the parabolic and the Misiurewicz parameters are landing points of rational parameter rays. ",Rational Parameter Rays of The Multibrot Sets
"  This volume contains the proceedings of the Combined 23nd International Workshop on Expressiveness in Concurrency and the 13th Workshop on Structural Operational Semantics (EXPRESS/SOS 2016) which was held on 22 August 2016 in Qu\'ebec City, Canada, as an affiliated workshop of CONCUR 2016, the 27th International Conference on Concurrency Theory. The EXPRESS workshops aim at bringing together researchers interested in the expressiveness of various formal systems and semantic notions, particularly in the field of concurrency. Their focus has traditionally been on the comparison between programming concepts (such as concurrent, functional, imperative, logic and object-oriented programming) and between mathematical models of computation (such as process algebras, Petri nets, event structures, modal logics, and rewrite systems) on the basis of their relative expressive power. The EXPRESS workshop series has run successfully since 1994 and over the years this focus has become broadly construed. The SOS workshops aim at being a forum for researchers, students and practitioners interested in new developments, and directions for future investigation, in the field of structural operational semantics. One of the specific goals of the SOS workshop series is to establish synergies between the concurrency and programming language communities working on the theory and practice of SOS. Since 2012, the EXPRESS and SOS communities have organized an annual combined EXPRESS/SOS workshop on the expressiveness of mathematical models of computation and the formal semantics of systems and programming concepts. ",Proceedings Combined 23rd International Workshop on Expressiveness in   Concurrency and 13th Workshop on Structural Operational Semantics
"  We present a complete analysis of the cosmological constraints on decaying dark matter. Previous analyses have used the cosmic microwave background and Type Ia supernova. We have updated them with the latest data as well as extended the analysis with the inclusion of Lyman-$\alpha$ forest, large scale structure and weak lensing observations. Astrophysical constraints are not considered in the present paper. The bounds on the lifetime of decaying dark matter are dominated by either the late-time integrated Sachs-Wolfe effect for the scenario with weak reionization, or CMB polarization observations when there is significant reionization. For the respective scenarios, the lifetimes for decaying dark matter are $\Gamma^{-1} \gtrsim 100$ Gyr and $ (f \Gamma) ^{-1} \gtrsim 5.3 \times 10^8$ Gyr (at 95.4% confidence level), where the phenomenological parameter $f$ is the fraction of the decay energy deposited in baryonic gas. This allows us to constrain particle physics models with dark matter candidates through investigation of dark matter decays into Standard Model particles via effective operators. For decaying dark matter of $\sim 100$ GeV mass, we found that the size of the coupling constant in the effective dimension-4 operators responsible for dark matter decay has to generically be $ \lesssim 10^{-22}$. We have also explored the implications of our analysis for representative models in theories of gauge-mediated supersymmetry breaking, minimal supergravity and little Higgs. ",Cosmological Constraints on Decaying Dark Matter
"  Learning with rejection (LWR) allows development of machine learning systems with the ability to discard low confidence decisions generated by a prediction model. That is, just like human experts, LWR allows machine models to abstain from generating a prediction when reliability of the prediction is expected to be low. Several frameworks for this learning with rejection have been proposed in the literature. However, most of them work for classification problems only and regression with rejection has not been studied in much detail. In this work, we present a neural framework for LWR based on a generalized meta-loss function that involves simultaneous training of two neural network models: a predictor model for generating predictions and a rejecter model for deciding whether the prediction should be accepted or rejected. The proposed framework can be used for classification as well as regression and other related machine learning tasks. We have demonstrated the applicability and effectiveness of the method on synthetically generated data as well as benchmark datasets from UCI machine learning repository for both classification and regression problems. Despite being simpler in implementation, the proposed scheme for learning with rejection has shown to perform at par or better than previously proposed methods. Furthermore, we have applied the method to the problem of hurricane intensity prediction from satellite imagery. Significant improvement in performance as compared to conventional supervised methods shows the effectiveness of the proposed scheme in real-world regression problems. ",Generalized Learning with Rejection for Classification and Regression   Problems
"  Models of nonequilibrium quantum transport underpin all modern electronic devices, from the largest scales to the smallest. Past simplifications such as coarse graining and bulk self-averaging served well to understand electronic materials. Such particular notions become inapplicable at mesoscopic dimensions, edging towards the truly quantum regime. Nevertheless a unifying thread continues to run through transport physics, animating the design of small-scale electronic technology: microscopic conservation and nonequilibrium dissipation. These fundamentals are inherent in quantum transport and gain even greater and more explicit experimental meaning in the passage to atomic-sized devices. We review their genesis, their theoretical context, and their governing role in the electronic response of meso- and nanoscopic systems. ",Nonequilibrium mesoscopic transport: a genealogy
"  The aim of this work is to provide an upper bound on the eigenvalues counting function $N(\mathbb{R}^n,-\Delta+V,e)$ of a Sch\""odinger operator $-\Delta +V$ on $\mathbb{R}^n$ corresponding to a potential $V\in L^{\frac{n}{2}+\varepsilon}(\mathbb{R}^n,dx)$, in terms of the sum of the eigenvalues counting function of the Dirichlet integral $\mathcal{D}$ with Dirichlet boundary conditions on the subpotential domain $\{V< e\}$, endowed with weighted Lebesgue measure $(V-e)_-\cdot dx$ and the eigenvalues counting function of the absorption-to-reflection operator on the equipotential surface $\{V=e\}$. ","On the eigenvalue counting function for Schr\""odinger operator: some   upper bounds"
"  Autonomous Underwater Vehicles (AUVs) are becoming increasingly important for different types of industrial applications. The generally high cost of (AUVs) restricts the access to them and therefore advances in research and technological development. However, recent advances have led to lower cost commercially available Remotely Operated Vehicles (ROVs), which present a platform that can be enhanced to enable a high degree of autonomy, similar to that of a high-end (AUV). In this article, we present how a low-cost commercial-off-the-shelf (ROV) can be used as a foundation for developing versatile and affordable (AUVs). We introduce the required hardware modifications to obtain a system capable of autonomous operations as well as the necessary software modules. Additionally, we present a set of use cases exhibiting the versatility of the developed platform for intervention and mapping tasks. ",From market-ready ROVs to low-cost AUVs
"  We introduce the electronic polarization originally defined in one-dimensional lattice systems to characterize two-dimensional topological insulators. The main idea is to use spiral boundary conditions which sweep all lattice sites in one-dimensional order. We find that the sign of the polarization changes at topological transition points of the two-dimensional Wilson-Dirac model (the lattice version of the Bernevig-Hughes-Zhang model) in the same way as in one-dimensional systems. Thus the polarization plays the role of ""order parameter"" to characterize the topological insulating state and enables us to study topological phases in different dimensions in a unified way. ",Characterization of topological insulators based on the electronic   polarization with spiral boundary conditions
"  We show that Odd Cycle Transversal and Vertex Multiway Cut admit deterministic polynomial kernels when restricted to planar graphs and parameterized by the solution size. This answers a question of Saurabh. On the way to these results, we provide an efficient sparsification routine in the flavor of the sparsification routine used for the Steiner Tree problem in planar graphs (FOCS 2014). It differs from the previous work because it preserves the existence of low-cost subgraphs that are not necessarily Steiner trees in the original plane graph, but structures that turn into (supergraphs of) Steiner trees after adding all edges between pairs of vertices that lie on a common face. We also show connections between Vertex Multiway Cut and the Vertex Planarization problem, where the existence of a polynomial kernel remains an important open problem. ",A deterministic polynomial kernel for Odd Cycle Transversal and Vertex   Multiway Cut in planar graphs
"  Simulating sample correlation matrices is important in many areas of statistics. Approaches such as generating Gaussian data and finding their sample correlation matrix or generating random uniform $[-1,1]$ deviates as pairwise correlations both have drawbacks. We develop an algorithm for adding noise, in a highly controlled manner, to general correlation matrices. In many instances, our method yields results which are superior to those obtained by simply simulating Gaussian data. Moreover, we demonstrate how our general algorithm can be tailored to a number of different correlation models. Using our results with a few different applications, we show that simulating correlation matrices can help assess statistical methodology. ",A method for generating realistic correlation matrices
"  Atoms in spatially dependent light fields are attracted to local intensity maxima or minima depending on the sign of the frequency difference between the light and the atomic resonance. For light fields confined in open high-Q optical resonators the backaction of the atoms onto the light field generates dissipative dynamic opto-mechanical potentials, which can be used to cool and trap the atoms. Extending the conventional case of high field seekers to the regime of blue atom-field detuning, where the particles are low field seeking, we show that inherent nonlinear atom field dynamics still can be tailored to cool and trap near zero field intensity. Studying field intensity, particle localization and kinetic energy for cavity driving or pumping the particle from the side, we identify optimal parameter regimes, where sub-Doppler cooling comes with trapping and minimal atomic saturation. ",Optomechanical cooling and self-trapping of low field seeking point-like   particles
"  We study uncertainty principles for function classes on the torus. The classes are defined in terms of spectral subspaces of the energy or the momentum, respectively. In our main theorems, the support of the Fourier transform of the considered functions is allowed to be supported in a (finite number of) parallelepipeds. The estimates we obtain do not depend on the size of the torus and the position of the parallelepipeds, but only on their size and number, and the density and scale of the observability set. Our results are on the one hand closely related to unique continuation for linear combinations of eigenfunctions (aka spectral inequalities) which can be obtained by Carleman estimates, on the other hand to observability estimates for the time-dependent Schroedinger and for the heat equation, and finally to the Logvinenko & Sereda theorem. In fact, they are based on the methods developed by Kovrijkine to refine and generalize the results of Logvinenko & Sereda and Kacnel'son. Furthermore, relying on completely different techniques associated with the time-dependent Schroedinger equation, we prove a companion theorem where the energy of the considered functions is allowed to be in a spectral subspace of a Schroedinger operator. ",Scale-free unique continuation estimates and Logvinenko-Sereda Theorems   on the torus
"  In this paper, we revisit the computation of particle number fluctuations and the R\'{e}nyi entanglement entropy of a two-dimensional Fermi gas using multi-dimensional bosonization. In particular, we compute these quantities for a circular Fermi surface and a circular entangling surface. Both quantities display a logarithmic violation of the area law, and the R\'{e}nyi entropy agrees with the Widom conjecture. Lastly, we compute the symmetry-resolved entanglement entropy for the two-dimensional circular Fermi surface and find that, while the total entanglement entropy scales as $R\log R$, the symmetry-resolved entanglement scales as $\sqrt{R\log R}$, where $R$ is the radius of the subregion of our interest. ","Particle Number Fluctuations, R\'{e}nyi and Symmetry-resolved   Entanglement Entropy in Two-dimensional Fermi Gas from Multi-dimensional   Bosonization"
"  We study the decay of a Higgs-like scalar Yukawa coupled to massless fermions in post-inflationary cosmology, combining a non-perturbative method with an adiabatic expansion. The renormalized survival probability $\mathcal{P}_\Phi(t)$ of a (quasi) particle ``born'' at time $t_b$ and decaying at rest in the comoving frame, $\mathcal{P}_\Phi(t) = \Big[\frac{t}{t_b}\Big]^{-\frac{Y^2}{8\pi^2}}~ e^{ \frac{Y^2}{4\pi^2}\,\big(t/t_b\big)^{1/4} } \,e^{-\Gamma_0\,(t-t_b)}~ \mathcal{P}_\Phi(t_b) $, with $\Gamma_0$ the decay rate at rest in Minkowski space-time. For an ultrarelativistic particle we find $\mathcal{P}_\Phi(t) = e^{-\frac{2}{3}\Gamma_0\,t_{nr}\,(t/t_{nr})^{3/2}}~ \mathcal{P}_\Phi(t_b)$ before it becomes non-relativistic at a time $t_{nr}$ as a consequence of the cosmological redshift. For $t\gg t_{nr}$ we find $\mathcal{P}_\Phi(t) = \Big[\frac{t}{t_{nr}}\Big]^{-\frac{Y^2}{8\pi^2}}~ e^{ \frac{Y^2}{4\pi^2}\,\big(t/t_{nr}\big)^{1/4} }~\Big[\frac{t}{t_{nr}}\Big]^{\Gamma_0 t_{nr}/2} \,e^{-\Gamma_0\,(t-t_{nr})}~ \mathcal{P}_\Phi(t_{nr})$. The extra power is a consequence of the memory on the past history of the decay process. We compare these results to an S-matrix inspired phenomenological Minkowski-like decay law modified by an instantaneous Lorentz factor to account for cosmological redshift. Such phenomenological description \emph{under estimates the lifetime of the particle}. For very long lived, very weakly coupled particles, we obtain an \emph{upper bound} for the survival probability as a function of redshift $z$ valid throughout the expansion history $\mathcal{P}_\Phi(z) \gtrsim e^{-\frac{\Gamma_0}{H_0}\,\Upsilon(z,z_b)}\,\mathcal{P}_\Phi(z_b)$, where $\Upsilon(z,z_b)$ only depends on cosmological parameters and $t_{nr}$. ",Cosmological decay of Higgs-like scalars into a fermion channel
"  We present [Ci] and [Cii] observations of a linear edge region in the Taurus molecular cloud, and model this region as a cylindrically symmetric PDR exposed to a low-intensity UV radiation field. The sharp, long profile of the linear edge makes it an ideal case to test PDR models and determine cloud parameters. We compare observations of the [C i], 3P1 -> 3P0 (492 GHz), [C i] 3P2 -> 3P1 (809 GHz), and [Cii] 2P3/2 -> 2P1/2 (1900 GHz) transitions, as well as the lowest rotational transitions of 12CO and 13CO, with line intensities produced by the RATRAN radiative transfer code from the results of the Meudon PDR code. We constrain the density structure of the cloud by fitting a cylindrical density function to visual extinction data. We study the effects of variation of the FUV field, 12C/13C isotopic abundance ratio, sulfur depletion, cosmic ray ionization rate, and inclination of the filament relative to the sky-plane on the chemical network of the PDR model and resulting line emission. We also consider the role of suprathermal chemistry and density inhomogeneities. We find good agreement between the model and observations, and that the integrated line intensities can be explained by a PDR model with an external FUV field of 0.05 G0, a low ratio of 12C to 13C ~ 43, a highly depleted sulfur abundance (by a factor of at least 50), a cosmic ray ionization rate (3 - 6) x 10-17 s^-1, and without significant effects from inclination, clumping or suprathermal chemistry. ","Photon-Dominated Region Modeling of the [C I],[C II], and CO Line   Emission from a Boundary in the Taurus Molecular Cloud"
"  In arXiv:0710.5653v1 M. Znojil claims that he has found and corrected an error in my paper: [Phys. Lett. B \textbf{650}, 208 (2007), arXiv:0706.1872v2] and that it is possible to escape its main conclusion, namely that the unitarity of the time-evolution and observability of the Hamiltonian imply time-independence of the metric operator. In this note I give a very short calculation showing that the analysis given by M. Znojil also leads to the same conclusion as of my above-mentioned paper. This is actually a reconfirmation of the validity of the results of the latter paper. ",Comment on ``Time-dependent quasi-Hermitian Hamiltonians and the unitary   quantum evolution''
"  A configuration of a graph is an assignment of one of two states, on or off, to each vertex of it. A regular move at a vertex changes the states of the neighbors of that vertex. A valid move is a regular move at an on vertex. The following result is proved in this note: given any starting configuration $x$ of a tree, if there is a sequence of regular moves which brings $x$ to another configuration in which there are $\ell$ on vertices then there must exist a sequence of valid moves which takes $x$ to a configuration with at most $\ell +2$ on vertices. We provide example to show that the upper bound $\ell +2$ is sharp. Some relevant results and conjectures are also reported. ",Difference between minimum light numbers of sigma-game and lit-only   sigma-game
  Quantum phase transitions in the Hubbard model on the honeycomb lattice are investigated in the variational cluster approximation. The critical interaction for the paramagnetic to antiferromagnetic phase transition is found to be in remarkable agreement with a recent large-scale quantum Monte Carlo simulation. Calculated staggered magnetization increases continuously with $U$ and thus we find the phase transition is of a second order. We also find that the semimetal-insulator transition occurs at infinitesimally small interaction and thus a paramagnetic insulating state appears in a wide interaction range. A crossover behavior of electrons from itinerant to localized character found in the calculated single-particle excitation spectra and short-range spin correlation functions indicates that an effective spin model for the paramagnetic insulating phase is far from a simple Heisenberg model with a nearest-neighbor exchange interaction. ,Quantum phase transitions in the honeycomb-lattice Hubbard model
"  This thesis is submitted in the partial fulfillment of the requirements for the degree of Doctor of Philosophy at the University of Oslo. It represents work that has been carried out between 2015 and 2018, under the supervision of Pr. Atle Jensen, Dr. Graig Sutherland, and Dr. Kai H. Christensen, in collaboration with Pr. Aleksey Marchenko and Pr. Brian Ward. The work presented was carried at the University of Oslo and the University Center in Svalbard. Financial support for the work was provided by the Norwegian Research Council under the Petromaks 2 scheme, through the project WOICE (Experiments on Waves in Oil and Ice), NFR Grant number 233901.   The thesis consists of an introduction, and a selection of 7 publications. The introduction presents the scientific context in which the work was undertaken, the methodology used, the results obtained, as well as some personal thoughts about unsuccessful directions encountered during the project and possible future work. I certify that this dissertation is mine and that the results presented are the result of the work of our research group, to which I brought significant contribution. ",An investigation into the interaction between waves and ice
"  Recently some pessimism has been expressed about our lack of progress in understanding quasars over the 50+ year since their discovery. It is worthwhile to look back at some of the progress that has been made - but still lies under the radar - perhaps because few people are working on optical/UV spectroscopy in this field. Great advances in understanding quasar phenomenology have emerged using eigenvector techniques. The 4D eigenvector 1 context provides a surrogate H-R Diagram for quasars with a source main sequence driven by Eddington ratio convolved with line-of-sight orientation. Appreciating the striking differences between quasars at opposite ends of the main sequence (so-called population A and B sources) opens the door towards a unified model of quasar physics, geometry and kinematics. We present a review of some of the progress that has been made over the past 15 years, and point out unsolved issues. ",Quasars in the 4D Eigenvector 1 Context: A stroll down memory lane
"  In this note we show that if a projective manifold admits a K\""ahler metric with negative holomorphic sectional curvature then the canonical bundle of the manifold is ample. This confirms a conjecture of the second author. ",Negative Holomorphic curvature and positive canonical bundle
"  This paper introduces several fundamental concepts in information theory from the perspective of their origins in engineering. Understanding such concepts is important in neuroscience for two reasons. Simply applying formulae from information theory without understanding the assumptions behind their definitions can lead to erroneous results and conclusions. Furthermore, this century will see a convergence of information theory and neuroscience; information theory will expand its foundations to incorporate more comprehensively biological processes thereby helping reveal how neuronal networks achieve their remarkable information processing abilities. ",An Introductory Review of Information Theory in the Context of   Computational Neuroscience
"  Let $M_n$ be a simple triangulation of the sphere $S^2$, drawn uniformly at random from all such triangulations with n vertices. Endow $M_n$ with the uniform probability measure on its vertices. After rescaling graph distance on $V(M_n)$ by $(3/(4n))^{1/4}$, the resulting random measured metric space converges in distribution, in the Gromov-Hausdorff-Prokhorov sense, to the Brownian map. In proving the preceding fact, we introduce a labelling function for the vertices of $M_n$. Under this labelling, distances to a distinguished point are essentially given by vertex labels, with an error given by the winding number of an associated closed loop in the map. We establish similar results for simple quadrangulations. ",The scaling limit of random simple triangulations and random simple   quadrangulations
"  Material irradiation experiment is dangerous and complex, thus it requires those with a vast advanced expertise to process the images and data manually. In this paper, we propose a generative adversarial model based on prior knowledge and attention mechanism to achieve the generation of irradiated material images (data-to-image model), and a prediction model for corresponding industrial performance (image-to-data model). With the proposed models, researchers can skip the dangerous and complex irradiation experiments and obtain the irradiation images and industrial performance parameters directly by inputing some experimental parameters only. We also introduce a new dataset ISMD which contains 22000 irradiated images with 22,143 sets of corresponding parameters. Our model achieved high quality results by compared with several baseline models. The evaluation and detailed analysis are also performed. ",Generative Model for Material Experiments Based on Prior Knowledge and   Attention Mechanism
"  We derive an equation of motion for the the dynamics of a ferromagnetic domain wall driven by an external magnetic field through a disordered medium and we study the associated depinning transition. The long-range dipolar interactions set the upper critical dimension to be $d_c=3$, so we suggest that mean-field exponents describe the Barkhausen effect for three-dimensional soft ferromagnetic materials. We analyze the scaling of the Barkhausen jumps as a function of the field driving rate and the intensity of the demagnetizing field, and find results in quantitative agreement with experiments on crystalline and amorphous soft ferromagnetic alloys. ",Dynamics of a ferromagnetic domain wall and the Barkhausen effect
"  In understanding the quantum physics of a black hole, nonperturbative aspects of gravity play important roles. In particular, huge gauge redundancies of a gravitational theory at the nonperturbative level, which are much larger than the standard diffeomorphism and relate even spaces with different topologies, allow us to take different descriptions of a system. While the physical conclusions are the same in any description, the same physics may manifest itself in vastly different forms in descriptions based on different gauge choices.   In this paper, we explore the relation between two such descriptions, which we refer to as the global gauge and unitary gauge constructions. The former is based on the global spacetime of general relativity, in which understanding unitarity requires the inclusion of subtle nonperturbative effects of gravity. The latter is based on a distant view of the black hole, in which unitarity is manifest but the existence of interior spacetime is obscured. These two descriptions are complementary. In this paper, we initiate the study of learning aspects of one construction through the analysis of the other.   We find that the existence of near empty interior spacetime manifest in the global gauge construction is related to the maximally chaotic, fast scrambling, and universal dynamics of the horizon in the unitary gauge construction. We use the complementarity of the gauge choices to understand the ensemble nature of the gravitational path integral in global spacetime in terms of coarse graining and thermality in a single unitary theory that does not involve any ensemble nature at the fundamental level. We also discuss how the interior degrees of freedom are related with those in the exterior in the two constructions. This relation emerges most naturally as entanglement wedge reconstruction and the effective theory of the interior in the respective constructions. ",Ensemble from Coarse Graining: Reconstructing the Interior of an   Evaporating Black Hole
"  We demonstrate an adaptive sampling approach for computing the probability of a rare event for a set of three-dimensional airplane geometries under various flight conditions. We develop a fully automated method to generate parameterized airplanes geometries and create volumetric mesh for viscous CFD solution. With the automatic geometry and meshing, we perform the adaptive sampling procedure to compute the probability of the rare event. We show that the computational cost of our adaptive sampling approach is hundreds of times lower than a brute-force Monte Carlo method. ","Aerodynamic Risk Assessment using Parametric, Three-Dimensional   Unstructured, High-Fidelity CFD and Adaptive Sampling"
"  We present theoretical and empirical results demonstrating the usefulness of voting rules for participatory democracies. We first give algorithms which efficiently elicit \epsilon-approximations to two prominent voting rules: the Borda rule and the Condorcet winner. This result circumvents previous prohibitive lower bounds and is surprisingly strong: even if the number of ideas is as large as the number of participants, each participant will only have to make a logarithmic number of comparisons, an exponential improvement over the linear number of comparisons previously needed. We demonstrate the approach in an experiment in Finland's recent off-road traffic law reform, observing that the total number of comparisons needed to achieve a fixed \epsilon approximation is linear in the number of ideas and that the constant is not large.   Finally, we note a few other experimental observations which support the use of voting rules for aggregation. First, we observe that rating, one of the common alternatives to ranking, manifested effects of bias in our data. Second, we show that very few of the topics lacked a Condorcet winner, one of the prominent negative results in voting. Finally, we show data hinting at a potential future direction: the use of partial rankings as opposed to pairwise comparisons to further decrease the elicitation time. ",Crowdsourcing for Participatory Democracies: Efficient Elicitation of   Social Choice Functions
"  The SNS linac accelerates an average beam current of 2 mA to an energy of 968 MeV. The linac is pulsed at 60 Hz with an H- beam pulse of 1 ms. The first 185 Mev of the linac uses normal conducting cavities, and the remaining length of the linac uses superconducting cavities. The linac operates at 402.5 MHz up to 87 MeV and then changes to 805 MHz for the remainder. This paper gives an overview of the Linac RF system. The overview includes a description and configuration of the high power RF components, the HV converter/modulator, and the RF controls. Issues and tradeoffs in the RF system will be discussed, especially with regards to the use of pulsed superconducting cavities. ",The Spallation Neutron Source (SNS) Linac RF System
"  It has been proved that the distribution of the point where the Smart Kinetic Walk (SKW) exits a domain converges in distribution to harmonic measure on the hexagonal lattice. For other lattices, it is believed that this result still holds, and there is good numerical evidence to support this conjecture. Here we examine the effect of the symmetry and asymmetry of the transition probability on each step of the SKW on the square lattice and test if the exit distribution converges in distribution to harmonic measure as well. From our simulations, the limiting exit distribution of the SKW with a non-uniform but symmetric transition probability as the lattice spacing goes to zero is the harmonic measure. This result does not hold for asymmetric transition probability. We are also interested in the difference between the SKW with symmetric transition probability exit distribution and harmonic measure. Our simulations provide strong support for a explicit conjecture about this first order difference. The explicit formula for the conjecture will be given below. ",The Exit Distribution for Smart Kinetic Walk with Symmetric and   Asymmetric Transition Probability
"  We investigate the problem of enhancement of mutual information by encoding classical data into entangled input states of arbitrary length and show that while there is a threshold memory or correlation parameter beyond which entangled states outperform the separable states, resulting in a higher mutual information, this memory threshold increases toward unity as the length of the string increases. These observations imply that encoding classical data into entangled states may not enhance the classical capacity of quantum channels. ",Entanglement and optimal strings of qubits for memory channels
"  We present an exploratory lattice QCD investigation of the differences between the valence quark structure of pion and its radial excitation $\pi(1300)$ in a fixed finite volume using the leading-twist factorization approach. We present evidences that the first pion excitation in our lattice computation is a single particle state that is likely to be the finite volume realization of $\pi(1300)$. An analysis with reasonable priors result in better estimates of the excited state PDF and the moments, wherein we find evidence that the radial excitation of pion correlates with an almost two-fold increase in the momentum fraction of valence quarks. This proof-of-principle work establishes the viability of future lattice computations incorporating larger operator basis that can resolve the structural changes accompanying hadronic excitation. ",Towards studying the structural differences between the pion and its   radial excitation
"  A social behavior analysis is used to study how a group of people interacts with another group. The analysis helps to understand how social behavior leads to its consequences such as what business decision is made after a businessmen's meeting. In this paper, we focus on visual human motion analysis which is one important component of social behavior analysis. Human motion analysis in visual surveillance usually tracks the motion of an individual or a group of people, yet social behavior is usually neglected. This paper first delivers a literature survey of visual surveillance, with emphasis on aspects of human motion analysis and social behavior. Second, it offers a perspective for social behavior analysis in an intelligent visual human monitoring system. Third, a social interaction is induced by a social behavior between two persons, one person and one group, or two groups, hence three general scenarios of social interactions are outlined for future theoretical development. The proposed human monitoring system enables the generation of valuable quantified information of social interactions. It provides an objective approach to evaluate performance of a human organization such as a company or a school. Finally, it can raise the awareness of researchers to further explore the field of social behavior analysis. ",Social Behavior Analysis in Visual Human Monitoring System : A Survey   and Perspective
  We examine analytically the ghost propagator Dyson-Schwinger Equation (DSE) in the deep IR regime and prove that a finite ghost dressing function at vanishing momentum is an alternative solution (solution II) to the usually assumed divergent one (solution I). We furthermore find that the Slavnov-Taylor identities discriminate between these two classes of solutions and strongly support the solution II. The latter turns out to be also preferred by lattice simulations within numerical uncertainties. ,On the IR behaviour of the Landau-gauge ghost propagator
  This contains a new version of the so-called non-commutative Gauss algorithm for polycyclic groups. Its results allow to read off the order and the index of a subgroup in an (possibly infinite) polycyclic group. ,Computing the order and the index of a subgroup in a polycyclic group
"  We analyze the magnetic mode structure of axially-magnetized, finite-length, nanoscopic cylinders in a regime where the exchange interaction dominates, along with simulations of the mode frequencies of the ferrimagnet yttrium iron garnet. For the bulk modes we find that the frequencies can be represented by an expression given by Herring and Kittel by using wavevector components obtained by fitting the mode patterns emerging from these simulations. In addition to the axial, radial, and azimuthal modes that are present in an infinite cylinder, we find localized ""cap modes"" that are ""trapped"" at the top and bottom cylinder faces by the inhomogeneous dipole field emerging from the ends. Semi-quantitative explanations are given for some of the modes in terms of a one-dimensional Schrodinger equation which is valid in the exchange dominant case. The assignment of the azimuthal mode number is carefully discussed and the frequency splitting of a few pairs of nearly degenerate modes is determined through the beat pattern emerging from them. ",Ferromagnetic resonance modes in the exchange dominated limit in   cylinders of finite length
"  We generalize the Clausius (in)equality to overdamped mesoscopic and macroscopic diffusions in the presence of nonconservative forces. In contrast to previous frameworks, we use a decomposition scheme for heat which is based on an exact variant of the Minimum Entropy Production Principle as obtained from dynamical fluctuation theory. This new extended heat theorem holds true for arbitrary driving and does not require assumptions of local or close to equilibrium. The argument remains exactly intact for diffusing fields where the fields correspond to macroscopic profiles of interacting particles under hydrodynamic fluctuations. We also show that the change of Shannon entropy is related to the antisymmetric part under a modified time-reversal of the time-integrated entropy flux. ",A nonequilibrium extension of the Clausius heat theorem
"  In the context of using norms for controlling multi-agent systems, a vitally important question that has not yet been addressed in the literature is the development of mechanisms for monitoring norm compliance under partial action observability. This paper proposes the reconstruction of unobserved actions to tackle this problem. In particular, we formalise the problem of reconstructing unobserved actions, and propose an information model and algorithms for monitoring norms under partial action observability using two different processes for reconstructing unobserved actions. Our evaluation shows that reconstructing unobserved actions increases significantly the number of norm violations and fulfilments detected. ",Norm Monitoring under Partial Action Observability
"  Optimized reviewer assignment can effectively utilize limited intellectual resources and significantly assure review quality in various scenarios such as paper selection in conference or journal, proposal selection in funding agencies and so on. However, little research on reviewer assignment of software peer review has been found. In this study, an optimization approach is proposed based on students' preference matrix and the model of asymmetric traveling salesman problem (ATSP). Due to the most critical role of rule matrix in this approach, we conduct a questionnaire to obtain students' preference matrices and convert them to rule matrices. With the help of software ILOG CPLEX, the approach is accomplished by controlling the exit criterion of ATSP model. The comparative study shows that the assignment strategies with both reviewers' preference matrix and authors' preference matrix get better performance than the random assignment. Especially, it is found that the performance is just a little better than that of random assignment when the reviewers' and authors' preference matrices are merged. In other words, the majority of students have a strong wish of harmonious development even though high-level students are not willing to do that. ",Solving reviewer assignment problem in software peer review: An approach   based on preference matrix and asymmetric TSP model
"  A mean-field density-functional model for three-phase equilibria in fluids (or other soft condensed matter) with two spatially varying densities is analyzed analytically and numerically. The interfacial tension between any two out of three thermodynamically coexisting phases is found to be captured by a surprisingly simple analytic expression that has a geometric interpretation in the space of the two densities. The analytic expression is based on arguments involving symmetries and invariances. It is supported by numerical computations of high precision and it agrees with earlier conjectures obtained for special cases in the same model. An application is presented to three-phase equilibria in the vicinity of a tricritical point. Using the interfacial tension expression and employing the field variables compatible with tricritical point scaling, the expected mean-field critical exponent is derived for the vanishing of the critical interfacial tension as a function of the deviation of the noncritical interfacial tension from its limiting value, upon approach to a critical endpoint in the phase diagram. The analytic results are again confirmed by numerical computations of high precision. ",Three-phase equilibria in density-functional theory: interfacial   tensions
"  As elderly population grows, social and health care begin to face validation challenges, in-home monitoring is becoming a focus for professionals in the field. Governments urgently need to improve the quality of healthcare services at lower costs while ensuring the comfort and independence of the elderly. This work presents an in-home monitoring approach based on off-the-shelf WiFi, which is low-costs, non-wearable and makes all-round daily healthcare information available to caregivers. The proposed approach can capture fine-grained human pose figures even through a wall and track detailed respiration status simultaneously by off-the-shelf WiFi devices. Based on them, behavioral data, physiological data and the derived information (e.g., abnormal events and underlying diseases), of the elderly could be seen by caregivers directly. We design a series of signal processing methods and a neural network to capture human pose figures and extract respiration status curves from WiFi Channel State Information (CSI). Extensive experiments are conducted and according to the results, off-the-shelf WiFi devices are capable of capturing fine-grained human pose figures, similar to cameras, even through a wall and track accurate respiration status, thus demonstrating the effectiveness and feasibility of our approach for in-home monitoring. ",When Healthcare Meets Off-the-Shelf WiFi: A Non-Wearable and Low-Costs   Approach for In-Home Monitoring
"  Quantum random number generators are becoming mandatory in a demanding technology world of high performing learning algorithms and security guidelines. Our implementation based on principles of quantum mechanics enable us to achieve the required randomness. We have generated high-quality quantum random numbers from a weak coherent source at telecommunication wavelength. The entropy is based on time of arrival of quantum states within a predefined time interval. The detection of photons by the InGaAs single-photon detectors and high precision time measurement of 5 ps enables us to generate 16 random bits per arrival time which is the highest reported to date. We have presented the theoretical analysis and experimental verification of the random number generation methodology. The method eliminates the requirement of any randomness extractor to be applied thereby, leveraging the principles of quantum physics to generate random numbers. The output data rate is on an average of 2.4 Mbps. The raw quantum random numbers are compared with NIST prescribed Blum-Blum-Shub pseudo random number generator and an in-house built hardware random number generator from FPGA, on the ENT and NIST Platform. ",Unpredictable and Uniform RNG based on time of arrival using InGaAs   Detectors
"  The Higgs Triplet Model (HTM) is one of important examples for extended Higgs sectors, because tiny neutrino masses can be simply explained. Unlike the canonical type-I seesaw model, a scale of new particles can be taken as $\mathcal{O}(100)$ GeV keeping an enough amount of production cross section for direct searches at collider experiments. In the HTM, there appear doubly-charged Higgs bosons $H^{\pm\pm}$, and detection of them is a key to probe the model. The decay property of $H^{\pm\pm}$ depends on the magnitude of the vacuum expectation value of the triplet field $v_\Delta$. When $v_\Delta$ is smaller than about 1 MeV, $H^{\pm\pm}$ can mainly decay into the same-sign dilepton, and the lower mass limit for $H^{\pm\pm}$ had been taken to be about 400 GeV at the LHC. On the other hand, if $v_\Delta$ is larger than about 1 MeV, $H^{\pm\pm}$ can mainly decay into the same-sign diboson. In this case, the mass bound cannot be applied, so that the scenario based on light $H^{\pm\pm}$ is still possible. In this talk, we discuss the phenomenology of the same-sign diboson decay scenario of $H^{\pm\pm}$. First, we review the mass bound from the current collider experiments given in Ref. \cite{KYY}. We then discuss the strategy for detection of $H^{\pm\pm}$ at the ILC. ",Doubly-charged Higgs bosons in the diboson decay scenario at the ILC
"  String theories with two dimensional space-time target spaces are characterized by the existence of a ``ground ring'' of operators of spin $(0,0)$. By understanding this ring, one can understand the symmetries of the theory and illuminate the relation of the critical string theory to matrix models. The symmetry groups that arise are, roughly, the area preserving diffeomorphisms of a two dimensional phase space that preserve the fermi surface (of the matrix model) and the volume preserving diffeomorphisms of a three dimensional cone. The three dimensions in question are the matrix eigenvalue, its canonical momentum, and the time of the matrix model. ",Ground Ring Of Two Dimensional String Theory
"  Evolution of quantum states of array of quantum dots is analyzed by means of numerical solution of the von Neumann equation. For two qubit system with dipole-dipole interaction and common phonon bath the evolution of the symmetric state $\frac{\uparrow\downarrow+\downarrow\uparrow}{\sqrt{2}}$ leads to the mixture of the triplet states, leaving the singlet decoupled. For three qubit system ($D_{1/2}^{\otimes3}=D_{3/2}+2D_{1/2}$) with common phonon bath we observed similar effects within the quartet state $D_{3/2}$ if all qubits were symmetrically connected. ",Symmetry and decoherence-free subspaces in quantum neural networks
"  Analog quantum simulation is widely considered a step on the path to fault tolerant quantum computation. If based on current noisy hardware, the accuracy of an analog simulator will degrade after just a few time steps, especially when simulating complex systems that are likely to exhibit quantum chaos. Here we describe a small, highly accurate quantum simulator and its use to run high fidelity simulations of three different model Hamiltonians for $>100$ time steps. While not scalable to exponentially large Hilbert spaces, this platform provides the accuracy and programmability required for systematic exploration of the interplay between dynamics, imperfections, and accuracy in quantum simulation. ","Small, Highly Accurate Quantum Processor for Intermediate-Depth Quantum   Simulations"
"  In this paper, we extend the gravitational bending of light studies in Kottler metrics to comprise nonlinear electrodynamics within the framework of Einstein - power - Maxwell theory. We show that the closest approach distance and the gravitational bending of light are affected from the presence of charge for particular values of the power parameter $k$, which is defined by means of energy conditions. It is shown that the bending angle of light is stronger in the case of a strong electric field, which is the case for $k=1.2$. ",Effect of power-law Maxwell field to the gravitational lensing
"  We demonstrate spin-accumulation signals controlled by the gate voltage in a metal-oxide-semiconductor field effect transistor structure with a Si channel and a CoFe/$n^{+}$-Si contact at room temperature. Under the application of a back-gate voltage, we clearly observe the three-terminal Hanle-effect signal, i.e., spin-accumulation signal. The magnitude of the spin-accumulation signals can be reduced with increasing the gate voltage. We consider that the gate controlled spin signals are attributed to the change in the carrier density in the Si channel beneath the CoFe/$n^{+}$-Si contact. This study is not only a technological jump for Si-based spintronic applications with gate structures but also reliable evidence for the spin injection into the semiconducting Si channel at room temperature. ",Electric-field control of spin accumulation signals in silicon at room   temperature
"  We present an analysis of user conversations in on-line social media and their evolution over time. We propose a dynamic model that accurately predicts the growth dynamics and structural properties of conversation threads. The model successfully reconciles the differing observations that have been reported in existing studies. By separating artificial factors from user behaviors, we show that there are actually underlying rules in common for on-line conversations in different social media websites. Results of our model are supported by empirical measurements throughout a number of different social media websites. ",From User Comments to On-line Conversations
"  Silver chloride is a material that has been investigated and used for many decades. Of particular interest are its optical properties, but only few fundamental theoretical studies exist. We present first-principles results for the optical properties of AgCl, obtained using time-dependent density functional theory and many-body perturbation theory. We show that optical properties exhibit strong excitonic effects, which are correctly captured only by solving the Bethe-Salpeter equation starting from quasiparticle self-consistent GW results. Numerical simulations are made feasible by using a model screening for the electron-hole interaction in a way that avoids the calculation of the static dielectric constant. A thorough analysis permits us to discuss localization in bright and dark excitons of silver chloride. ",First-principles study of excitons in the optical spectra of silver   chloride
"  We report on a novel phase transition at $T$ = 0.9 K in the Ce-based filled-skutterudite compound CeOs$_{4}$Sb$_{12}$ via measurements of the nuclear-spin lattice relaxation rate $1/T_{1}$ and nuclear quadrupole resonance (NQR) spectrum of Sb nuclei. The temperature ($T$) dependence of $1/T_1$ behaves as if approaching closely an antiferromagnetic (AFM) quantum critical point (QCP), following the relation $1/T_{1}\propto T/(T-T_{\rm N})^{1/2}$ with $T_{\rm N} = 0.06$ K in the range of $T=1.3-25$ K. The onset of either the spin-density-wave (SDW) or charge-density-wave (CDW) order at $T_{\rm 0} = 0.9$ K, that is, of the first order, is evidenced by a broadening of the NQR spectrum and a marked reduction in $1/T_1$ just below $T_{\rm 0}$. The $f$-electron-derived correlated band realized in CeOs$_{4}$Sb$_{12}$ is demonstrated to give rise to the novel phase transition on the verge of AFM QCP. ",Novel Phase Transition Near the Quantum Critical Point in the   Filled-Skutterudite Compound CeOs4Sb12: an Sb-NQR Study
"  We formulate a correspondence between SU(2) monopole chains and ``spectral data'', consisting of curves in $\mathbb{CP}^1\times\mathbb{CP}^1$ equipped with parabolic line bundles. This is the analogue for monopole chains of Donaldson's association of monopoles with rational maps. The construction is based on the Nahm transform, which relates monopole chains to Higgs bundles on the cylinder. As an application, we classify charge $k$ monopole chains which are invariant under actions of $\mathbb{Z}_{2k}$. We present images of these symmetric monopole chains that were constructed using a numerical Nahm transform. ",Parabolic Higgs bundles and cyclic monopole chains
"  We present a photometric study of UGC 4599, a low-luminosity galaxy superficially resembling Hoag's Object in that on sky survey images it appears to be a complete ring surrounding a roundish core. The nature of the outer ring of Hoag-type galaxies is still debated and may be related either to slow secular evolution or to environmental processes, such as galaxy-galaxy interactions. we show that in UGC 4599 (a) the nearly round central body follows well an r^1/4 light profile almost all the way to the centre, (b) the isophotes are strongly twisted with a sharp 45 deg transition at a radius of r~6 arcsec, (c) the blue ring seems to have reached near-equilibrium configuration with the central body, (d) the ring is actually composed of a one-and-a-half turn spiral feature, and (e) one side of the spiral shows conspicuous star formation in the form of at least nine HII regions, revealed by their H_alpha emission. Based on the photometric data, together with HI information from the literature, we characterize UGC 4599 as an elliptical-like object surrounded by a luminous ring and a massive, extremely extended HI disc. Given its observed properties, we rule out UGC 4599 as representing a late phase in barred early-type galaxies evolution. We discuss the origin of UGC 4599 and conclude that this galaxy could be the result of a major interaction between two gas-rich spiral galaxies that took place at least 5 Gyr ago. However, deep optical imaging and a detailed stellar population analysis are required to determine whether the large gas reservoir could have been accreted directly from the intergalactic medium onto a pre-existing elliptical galaxy in the early Universe. A detailed kinematical study will shed light on the exact nature of the central body and the ring of UGC 4599. ",UGC 4599: A Photometric Study of the Nearest Hoag-Type Ring Galaxy
"  Context. Diffusive shock acceleration (DSA) is the most promising mechanism to accelerate Galactic cosmic rays (CRs) in the shocks of supernova remnants (SNRs). The turbulence upstream is supposedly generated by the CRs, but this process is not well understood. The dominant mechanism may depend on the evolutionary state of the shock and can be studied via the CRs escaping upstream into the interstellar medium (ISM). Aims. Previous observations of the $\gamma$-Cygni SNR showed a difference in morphology between GeV and TeV energies. Since this SNR has the right age and is at the evolutionary stage for a significant fraction of CRs to escape, we aim to understand $\gamma$-ray emission in the vicinity of the $\gamma$-Cygni SNR. Methods. We observed the region of the $\gamma$-Cygni SNR with the MAGIC Imaging Atmospheric Cherenkov telescopes between May 2015 and September 2017 recording 87 h of good-quality data. Additionally we analysed Fermi-LAT data to study the energy dependence of the morphology as well as the energy spectrum in the GeV to TeV range. The energy spectra and morphology were compared against theoretical predictions, which include a detailed derivation of the CR escape process and their $\gamma$-ray generation. Results. The MAGIC and Fermi-LAT data allowed us to identify three emission regions, which can be associated with the SNR and dominate at different energies. Our hadronic emission model accounts well for the morphology and energy spectrum of all source components. It constrains the time-dependence of the maximum energy of the CRs at the shock, the time-dependence of the level of turbulence, and the diffusion coefficient immediately outside the SNR shock. While in agreement with the standard picture of DSA, the time-dependence of the maximum energy was found to be steeper than predicted and the level of turbulence was found to change over the lifetime of the SNR. ",Study of the GeV to TeV morphology of the $\gamma$-Cygni SNR (G78.2+2.1)   with MAGIC and Fermi-LAT
"  We aim to ascertain the physical parameters of a propagating wave over the solar disk detected by the Interface Region Imaging Spectrograph (IRIS). Using imaging data from the IRIS and the Solar Dynamic Observatory (SDO), we tracked bright spots to determine the parameters of a propagating transverse wave in active region (AR) loops triggered by activation of a filament. Deriving the Doppler velocity of Si IV line from spectral observations of IRIS, we have determined the rotating directions of active region loops which are relevant to the wave. On 2015 December 19, a filament was located on the polarity inversion line of the NOAA AR 12470. The filament was activated and then caused a C 1.1 two-ribbon flare. Between the flare ribbons, two rotation motions of a set of bright loops were observed to appear in turn with opposite directions. Following the end of the second rotation, a propagating wave and an associated transverse oscillation were detected in these bright loops. In 1400 A channel, there was bright material flowing along the loops in a wave-like manner, with a period of ~128 s and a mean amplitude of ~880 km. For the transverse oscillation, we tracked a given loop and determine the transverse positions of the tracking loop in a limited longitudinal range. In both of 1400 A and 171 A channels, approximately four periods are distinguished during the transverse oscillation. The mean period of the oscillation is estimated as ~143 s and the displacement amplitude as between ~1370 km and ~690 km. We interpret these oscillations as a propagating kink wave and obtain its speed of ~1400 km s-1. Our observations reveal that a flare associated with filament activation could trigger a kink propagating wave in active region loops over the solar disk. ","Propagating wave in active region-loops, located over the solar disk   observed by the Interface Region Imaging Spectrograph"
"  We carry out a general analysis of tree level flavor changing neutral currents in the context of 331 models, considering arbitrary quark and gauge boson mixing matrices. The results are applied to definite textures of quark mass matrices, and differences between various 331 scenarios are pointed out. ",Flavor changing neutral currents in 331 models
"  Firstly, a new state feedback model reference adaptive control approach is developed for uncertain systems with gain scheduled reference models in a multi-input multi-output (MIMO) setting. Specifically, adaptive state feedback for output tracking control problem of MIMO nonlinear systems is studied and gain scheduled reference model system is used for generating desired state trajectories. Using convex optimization tools, a common Lyapunov matrix is computed for multiple linearizations near equilibrium and non-equilibrium points of the nonlinear closed loop gain scheduled reference system. This approach guarantees stability of the closed-loop gain scheduled system. Adaptive state feedback control scheme is then developed, and its stability is proven. The resulting closed-loop system is shown to have bounded solutions with bounded tracking error, with the proposed stable gain scheduled reference model. Secondly, the developed control approach is improved for systems with constraints on the control inputs. The resulting closed-loop system is shown to have bounded solutions with bounded tracking error. Sufficient conditions for ultimate boundedness of the closed-loop system are derived. A semi-global stability result is proved with respect to the level of saturation for open-loop unstable plants while the stability result is shown to be global for open-loop stable plants. Thirdly, a decentralized adaptive state feedback control architecture is developed and its stability is proved. Specifically, the resulting closed-loop system is shown to have bounded solutions with bounded tracking error for all the subsystems with the proposed stable gain scheduled reference model. Simulation results are presented for each control architecture. ",Model Reference Adaptive Control of Systems with Gain Scheduled   Reference Models
"  Sub-arcsecond lensing statistics depend sensitively on the inner mass profiles of low-mass objects and the faint-end slopes of the Schechter luminosity function and the Press-Schechter mass function. By requiring the luminosity and mass functions to give consistent predictions for the distribution of image separation below 1'', we show that dark matter halos with masses below 10^12 M_sun cannot have a single type of profile, be it the singular isothermal sphere (SIS) or the shallower ``universal'' dark matter profile. Instead, consistent results are achieved if we allow a fraction of the halos at a given mass to be luminous with the SIS profile, and the rest be dark with an inner logarithmic slope shallower than -1.5 to compensate for the steeper faint-end slope of the mass function compared with the luminosity function. We quantify how rapidly the SIS fraction must decrease with decreasing halo mass, thereby providing a statistical measure for the effectiveness of feedback processes on the baryon content in low-mass halos. ",Schechter vs. Schechter: Sub-Arcsecond Gravitational Lensing and Inner   Halo Profiles
"  We study event horizons of non-axisymmetric black holes and show how features found in axisymmetric studies of colliding black holes and of toroidal black holes are non-generic and how new features emerge. Most of the details of black hole formation and black hole merger are known only in the axisymmetric case, in which numerical evolution has successfully produced dynamical space-times. The work that is presented here uses a new approach to construct the geometry of the event horizon, not by locating it in a given spacetime, but by direct construction. In the axisymmetric case, our method produces the familiar pair-of-pants structure found in previous numerical simulations of black hole mergers, as well as event horizons that go through a toroidal epoch as discovered in the collapse of rotating matter. The main purpose of this paper is to show how new - substantially different - features emerge in the non-axisymmetric case. In particular, we show how black holes generically go through a toroidal phase before they become spherical, and how this fits together with the merger of black holes. ",The Asymmetric Merger of Black Holes
"  It is demonstrated that Breit and negative-energy state contributions reduce the 2.5 sigma deviation [S.C. Bennett and C.E. Wieman, Phys. Rev. Lett. 82, 2484 (1999)] in the value of the weak charge of 133Cs from the Standard Model prediction to 1.7sigma. The corrections are obtained in the relativistic many-body perturbation theory by combining all-order Coulomb and second-order Breit contributions. The corrections to parity-nonconserving amplitudes amount to 0.6% in 133Cs and 1.1% in 223Fr. The relevant magnetic-dipole hyperfine structure constants are modified at the level of 0.3% in Cs, and 0.6% in Fr. Electric-dipole matrix elements are affected at 0.1% level in Cs and a few 0.1% in Fr. ",Role of negative-energy states and Breit interaction in calculation of   atomic parity-nonconserving amplitudes
"  Bridgeland stability manifolds of Calabi-Yau categories are of noticeable interest both in mathematics and in physics. By looking at some of the known example, a pattern clearly emerges and gives a fairly precise description of how they look like. In particular, they all seem to have missing loci, which tend to correspond to degenerate stability conditions vanishing on spherical objects. Describing such missing strata is also interesting from a mirror-symmetric perspective, as they conjecturally parametrize interesting types of degenerations of complex structures. All the naive attempts at constructing modular partial compactifications show how elusive and subtle the problem in fact is: ideally, the missing strata would correspond to stability manifolds of quotient triangulated categories, but establishing such correspondence on geometric level and viewing stability conditions on quotients of the original triangulated category as suitable degenerations of stability conditions is not straightforward. In this paper, we will present a method to construct such partial compactifications if some additional hypoteses are satisfied, by realizing our space of interest as a suitable metric completion of the stability manifold. ",A local compactification of the Bridgeland stability manifold
"  An integrity-based path planning strategy for autonomous ground vehicle (AGV) navigation in urban environments is developed. The vehicle is assumed to navigate by utilizing cellular long-term evolution (LTE) signals in addition to Global Positioning System (GPS) signals. Given a desired destination, an optimal path is calculated, which minimizes a cost function that considers both the horizontal protection level (HPL) and travel distance. The constraints are that (i) the ratio of nodes with faulty signals to the total nodes be lower than a maximum allowable ratio and (ii) the HPLs along each candidate path be lower than the horizontal alert limit (HAL). To predict the faults and HPL before the vehicle is driven, GPS and LTE pseudoranges along the candidate paths are generated utilizing a commercial ray-tracing software and three-dimensional (3D) terrain and building maps. Simulated pseudoranges inform the path planning algorithm about potential biases due to reflections from buildings in urban environments. Simulation results are presented showing that the optimal path produced by the proposed path planning strategy has the minimum average HPL among the candidate paths. ",Integrity-Based Path Planning Strategy for Urban Autonomous Vehicular   Navigation Using GPS and Cellular Signals
  Large ballistic magnetoresistance (BMR) has been measured in Ni single-atom conductors electrodeposited between microfabricated thin films. These measurements irrefutably eliminate any magnetostriction related artifacts in the BMR effect. ,Ballistic magnetoresistance in nickel single-atom conductors
"  In this report, future performance demands of batteries for various vehicular applications are modeled. Vehicles ranging in size from electric bikes to heavy trucks are assessed using driving cycle data which allows key performance parameters such as desired range (km), specific energy of the battery (Wh/Kg), cycle life requirement and expected price per unit capacity (Euro/kWh) to be calculated. These projected performance requirements are compared with the outputs for three existing Li-ion batteries (namely (a) Kokam based high specific energy source (b) A123 based high power energy source and (c) Winston low cost system). The theoretical, current state of the art and projected performance parameters for 'beyond Li-ion' technologies (Li-S and Li-O2) are also compared to the modeled battery performance demands. The analysis indicates that current battery technologies are unlikely to meet future requirements in terms of required specific energies and will likely be too costly. In comparison, fully realized beyond Li-ion alternatives may deliver the required specific energy for the full range of vehicles examined. However, scale-up of these systems is a daunting challenge and their successful implementation will depend on improvements in terms of cycle life, electrode and electrolyte stability, rate performance and development of practical battery architectures. ","Comparing the suitability of Lithium ion, Lithium Sulfur and Lithium air   batteries for current and future vehicular applications"
"  The nuclear symmetry energy coefficient (including the coefficient $a_{\rm sym}^{(4)}$ of $I^{4}$ term) of finite nuclei is extracted by using the differences of available experimental binding energies of isobaric nuclei. It is found that the extracted symmetry energy coefficient $a^{*}_{\rm sym}(A,I)$ decreases with increasing of isospin asymmetry $I$, which is mainly caused by Wigner correction, since $e^{*}_{\rm sym}$ is the summation of the traditional symmetry energy $e_{\rm sym}$ and the Wigner energy $e_{\rm W}$. We obtain the optimal values $J=30.25\pm0.10$ MeV, $a_{\rm ss}=56.18\pm1.25$ MeV, $a_{\rm sym}^{(4)}=8.33\pm1.21$ MeV and the Wigner parameter $x=2.38\pm0.12$ through the polynomial fit to 2240 measured binding energies for nuclei with $20 \leq A \leq 261$ with an rms deviation of 23.42 keV. We also find that the volume symmetry coefficient $J\simeq 30$ MeV is insensitive to the value $x$, whereas the surface symmetry coefficient $a_{\rm ss}$ and the coefficient $a_{\rm sym}^{(4)}$ are very sensitive to the value of $x$ in the range $1\leq x\leq 4$. The contribution of $a_{\rm sym}^{(4)}$ term increases rapidly with increasing of isospin asymmetry $I$. For very neutron-rich nuclei, the contribution of $a_{\rm sym}^{(4)}$ term will play an important role. ",Effect of Wigner energy on the symmetry energy coefficient in nuclei
  We establish certain conditions which imply that a map $f:X\to Y$ of topological spaces is null homotopic when the induced integral cohomology homomorphism is trivial; one of them is: $H^*(X)$ and $\pi_*(Y)$ have no torsion and $H^*(Y)$ is polynomial. ,On the homotopy classification of maps
"  We formulate the recently proposed ghost-free theory of multiple interacting vielbeins in terms of their corresponding metrics. This is achieved by reintroducing all local Lorentz invariances broken by the multivielbein interaction potential which, in turn, allows us to explicitly separate the gauge degrees of freedom in the vielbeins from the components of the metrics by an appropriate gauge choice. We argue that the gauge choice does not spoil the no-ghost proof of the multivielbein theory, hence the multimetric theory is ghost-free. We further show the on-shell equivalence of the metric and vielbein descriptions, first in general and thereafter in two illustrative examples. ",Metric Formulation of Ghost-Free Multivielbein Theory
"  Every (1 polarization) cylindrical wave solution of vacuum general relativity is completely determined by a corresponding axisymmetric solution to the free scalar wave equation on an auxilliary 2+1 dimensional flat spacetime. The physical metric at radius R is determined by the energy, $\gamma (R)$, of the scalar field in a box (in the flat spacetime) of radius R. In a recent work, among other important results, Ashtekar and Pierri have introduced a strategy to study the quantum geometry in this system, through a regularized quantum counterpart of $\gamma (R)$. We show that this regularized object is a densely defined symmetric operator, thereby correcting an error in their proof of this result. We argue that it admits a self adjoint extension and show that the operator, unlike its classical counterpart, is not positive. ",On the metric operator for quantum cylindrical waves
"  Let $f\colon S\to B$ be a non-isotrivial fibred surface. We prove that the genus $g$, the rank $u_f$ of the unitary summand of the Hodge bundle $f_*\omega_f$ and the Clifford index $c_f$ satisfy the inequality $u_f \leq g - c_f$. Moreover, we prove that if the general fibre is a plane curve of degree $\geq 5$ then the stronger bound $u_f \leq g - c_f-1$ holds. In particular, this provides a strengthening of the bounds of \cite{BGN} and of \cite{FNP}. The strongholds of our arguments are the deformation techniques developed by the first author in \cite{Rigid} and by the third author and Pirola in \cite{PT}, which display here naturally their power and depht. ",On the rank of the flat unitary summand of the Hodge bundle
"  The aim of this note is to discuss in more detail the Pohozaev-type identities that have been recently obtained by the author, Paul Laurain and Tristan Rivi\`ere in the framework of half-harmonic maps defined either on $R$ or on the sphere $S^1$ with values into a closed manifold $N^n\subset R^m$. Weak half-harmonic maps are critical points of the following nonlocal energy $$\int_{R}|(-\Delta)^{1/4}u|^2 dx~~\mbox{or}~~\int_{S^1}|(-\Delta)^{1/4}u|^2\ d\theta.$$   If $u$ is a sufficiently smooth critical point of the above energy then it satisfies the following equation of stationarity $$\frac{du}{dx}\cdot (-\Delta)^{1/2} u=0~~\mbox{a.e in $R$}~~\mbox{or}~~\frac{\partial u}{\partial \theta}\cdot (-\Delta)^{1/2} u=0~~\mbox{a.e in $S^1$.}$$   By using the invariance of the equation of stationarity in $S^1$ with respect to the trace of the M\""obius transformations of the $2$ dimensional disk we derive a countable family of relations involving the Fourier coefficients of weak half-harmonic maps $u\colon S^1\to N^n.$ In the same spirit we also provide as many Pohozaev-type identities in $2$-D for stationary harmonic maps as conformal vector fields in $R^2$ generated by holomorphic functions. ",Some Remarks on Pohozaev-Type Identities
"  Determinant representations of form factors are used to represent the spontaneous magnetization of the Heisenberg XXZ chain (Delta >1) on the finite lattice as the ratio of two determinants. In the thermodynamic limit (the lattice of infinite length), the Baxter formula is reproduced in the framework of Algebraic Bethe Ansatz. It is shown that the finite size corrections to the Baxter formula are exponentially small. ",Spontaneous magnetization of the XXZ Heisenberg spin-1/2 chain
"  The estimate of a Multiperiod probability of default applied to residential mortgages can be obtained using the mean of the observed default, so called the Mean of ratios estimator, or aggregating the default and the issued mortgages and computing the ratio of their sum, that is the Ratio of means. This work studies the statistical properties of the two estimators with the result that the Ratio of means has a lower statistical uncertainty. The application on a private residential mortgage portfolio leads to a lower probability of default on the overall portfolio by eleven basis points. ",Mean of Ratios or Ratio of Means: statistical uncertainty applied to   estimate Multiperiod Probability of Defaul
"  The nonzero strange quark mass effect in different types of single flavor color superconductivity and the phase diagram in a magnetic field are studied. We have obtained simple analytical forms of the quasi-particle energies for an arbitrary mass and explored the mass correction to the pressure and the transition temperature. It is found that the mass reduces the pressure and transition temperature of strange quarks, but it doesn't change the ranking $P_n<P_{\rm A}<P_{\rm polar}<P_{\rm planar}<P_{\rm CSL}$ of the pressure for the four canonical single flavor phases. The phase diagram with magnetic field and temperature for a system of three flavors is obtained for two different values of the strange quark mass. The changes from the one obtained previously under the approximation of massless strange quarks are examined. ",Mass Effect in Single Flavor Color Superconductivity
"  The electrical resistivity of Fermi liquids (FLs) displays a quadratic temperature ($T$) dependence because of electron-electron (e-e) scattering. For such collisions to decay the charge current, there are two known mechanisms: inter-band scattering (identified by Baber) and Umklapp events. However, dilute metallic strontium titanate (STO) was found to display $T^2$ resistivity in absence of either of these two mechanisms. The presence of soft phonons and their possible role as scattering centers raised the suspicion that $T$-square resistivity in STO is not due to e-e scattering. Here, we present the case of Bi$_2$O$_2$Se, a layered semiconductor with hard phonons, which becomes a dilute metal with a small single-component Fermi surface upon doping. It displays $T$-square resistivity well below the degeneracy temperature where neither Umklapp nor interband scattering is conceivable. We observe a universal scaling between the prefactor of $T^2$ resistivity and the Fermi energy, which is an extension of the Kadowaki-Woods plot to dilute metals. Our results imply the absence of a satisfactory theoretical basis for the ubiquity of e-e driven $T$-square resistivity in Fermi liquids. ",T-square resistivity without Umklapp scattering in dilute metallic   Bi$_2$O$_2$Se
"  A set of key properties for an ideal dissipation scheme in gyrokinetic simulations is proposed, and implementation of a model collision operator satisfying these properties is described. This operator is based on the exact linearized test-particle collision operator, with approximations to the field-particle terms that preserve conservation laws and an H-Theorem. It includes energy diffusion, pitch-angle scattering, and finite Larmor radius effects corresponding to classical (real-space) diffusion. The numerical implementation in the continuum gyrokinetic code GS2 is fully implicit and guarantees exact satisfaction of conservation properties. Numerical results are presented showing that the correct physics is captured over the entire range of collisionalities, from the collisionless to the strongly collisional regimes, without recourse to artificial dissipation. ",Linearized model Fokker-Planck collision operators for gyrokinetic   simulations. II. Numerical implementation and tests
"  The problem of estimating single- and multi-dimensional integrals, with or without end-point singularities, is prevalent in all fields of scientific research, and in particular in physics. Although tanh-sinh quadrature is known to handle most of these cases excellently, its use is not widely spread among physicists. Moreover, while most calculations are limited by the use of finite-precision floating-point arithmetic, similar considerations for tanh-sinh quadrature are mostly lacking in literature, where infinite-precision floating-point numbers are often assumed. Also little information is available on the application of tanh-sinh quadrature to multiple integration.   We have investigated the risks and limitations associated with limited-precision floating-point numbers when using tanh-sinh quadrature for both single and multiple integration, while obtaining excellent convergence rates. In addition, this paper provides recommendations for a straightforward implementation using limited-precision floating-point numbers and for avoiding numerical instabilities. ",Tanh-sinh quadrature for single and multiple integration using   floating-point arithmetic
"  We consider the problem of short- and medium-term electricity load forecasting by using past loads and daily weather forecast information. Conventionally, many researchers have directly applied regression analysis. However, interpreting the effect of weather on these loads is difficult with the existing methods. In this study, we build a statistical model that resolves this interpretation issue. A varying coefficient model with basis expansion is used to capture the nonlinear structure of the weather effect. This approach results in an interpretable model when the regression coefficients are nonnegative. To estimate the nonnegative regression coefficients, we employ nonnegative least squares. Three real data analyses show the practicality of our proposed statistical modeling. Two of them demonstrate good forecast accuracy and interpretability of our proposed method. In the third example, we investigate the effect of COVID-19 on electricity loads. The interpretation would help make strategies for energy-saving interventions and demand response. ",Interpretable modeling for short- and medium-term electricity load   forecasting
"  We verify the existence of radially symmetric first-order solitons in a gauged $CP(2)$ scenario in which the dynamics of the Abelian gauge field is controlled by the Maxwell-Chern-Simons action. We implement the standard Bogomol'nyi-Prasad-Sommerfield (BPS) formalism, from which we obtain a well-defined lower bound for the corresponding energy (i.e. the Bogomol'nyi bound) and the first-order equations saturating it. We solve these first-order equations numerically by means of the finite-difference scheme, therefore obtaining regular solutions of the effective model, their energy being quantized according the winding number rotulating the final configurations, as expected. We depict the numerical solutions, whilst commenting on the main properties they engender. ",Topological first-order solitons in a gauged $CP(2)$ model with the   Maxwell-Chern-Simons action
"  The cooperative control applied to vehicles allows the optimization of traffic on the roads. There are many aspects to consider in the case of the operation of autonomous vehicles on highways since there are different external parameters that can be involved in the analysis of a network. In this paper, we present the design and simulation of adaptive control for a platoon with heterogeneous vehicles, taking into account that not all vehicles can communicate their control input, and in turn include structured nonlinear uncertainty input parameters. ",Adaptive Control for Unknown Heterogeneous Vehicles Synchronization with   Unstructured Uncertainty
"  The days that precede Valentine's Day are characterized by extensive gift shopping activities all across the globe. In China, where much shopping takes place online, there has been an explosive growth in e-commerce sales during Valentine's Day over the recent years. This exploratory study investigates the extent to which each product category and each shopper group can exhibit romantic love within China's e-market throughout the 2 weeks leading up to 2019 Valentine's Day. Massive data from Alibaba, the biggest e-commerce retailer worldwide, are utilized to formulate an innovative romance index (RI) to quantitatively measure e-romantic values for products and shoppers. On this basis, millions of shoppers, along with their millions of products purchased around Valentine's Day, are analyzed as a case study to demonstrate their love consumption and romantic gift-giving. The results of the analysis are then illustrated to help understand Chinese e-romance based on the perspectives of different product categories and shopper groups. This empirical information visualization also contributes to improving the segmentation, targeting, and positioning of China's e-market for Valentine's Day. ",Chinese E-Romance: Analyzing and Visualizing 7.92 Million Alibaba   Valentine's Day Purchases
"  The Euler-Heisenberg effective action in a self-dual background is remarkably simple at two-loop. This simplicity is due to the inter-relationship between self-duality, helicity and supersymmetry. Applications include two-loop helicity amplitudes, beta-functions and nonperturbative effects. The two-loop Euler-Heisenberg effective Lagrangian for QED in a self-dual background field is naturally expressed in terms of one-loop quantities. This mirrors similar behavior recently found in two-loop amplitudes in N=4 SUSY Yang-Mills theory. ","Self-duality, Helicity and Higher-loop Euler-Heisenberg Effective   Actions"
"  We use cosmography to present constraints on the kinematics of the Universe without postulating any underlying theoretical model a priori. To this end, we use a Markov Chain Monte Carlo analysis to perform comparisons to the supernova Ia union 2 compilation, combined with the Hubble Space Telescope measurements of the Hubble constant, and the Hubble parameter datasets. The cosmographic approach to our analysis is revisited and extended for new notions of redshift presented as alternatives to the redshift z. Furthermore, we introduce a new set of fitting parameters describing the kinematical evolution of the Universe in terms of the equation of state of the Universe and derivatives of the total pressure. Our results are consistent with the \Lambda CDM model, although alternative models, with nearly constant pressure and no cosmological constant, match the results accurately as well. ",Constraints from Cosmography in various parameterizations
"  The cytoskeleton is an inhomogeneous network of semi-flexible filaments, which are involved in a wide variety of active biological processes. Although the cytoskeletal filaments can be very stiff and embedded in a dense and cross-linked network, it has been shown that, in cells, they typically exhibit significant bending on all length scales. In this work we propose a model of a semi-flexible filament deformed by different types of cross-linkers for which one can compute and investigate the bending spectrum. Our model allows to couple the evolution of the deformation of the semi-flexible polymer with the stochastic dynamics of linkers which exert transversal forces onto the filament. We observe a $q^{-2}$ dependence of the bending spectrum for some biologically relevant parameters and in a certain range of wavenumbers $q$. However, generically, the spatially localized forcing and the non-thermal dynamics both introduce deviations from the thermal-like $q^{-2}$ spectrum. ",Non-equilibrium fluctuations of a semi-flexible filament driven by   active cross-linkers
"  Protoplanetary disks are dynamic objects, within which dust grains and gas are expected to be redistributed over large distances. Evidence for this redistribution is seen both in other protoplanetary disks and in our own Solar System, with high-temperature materials thought to originate close to the central star found in the cold, outer regions of the disks. While models have shown this redistribution is possible through a variety of mechanisms, these models have generally ignored the possible growth of solids via grain-grain collisions that would occur during transit. Here we investigate the interplay of coagulation and radial and vertical transport of solids in protoplanetary disks, considering cases where growth is limited by bouncing or by fragmentation. We find that in all cases, growth effectively limits the ability for materials to be carried outward or preserved at large distances from the star. This is due to solids being incorporated into large aggregates which drift inwards rapidly under the effects of gas drag. We discuss the implications for mixing in protoplanetary disks, and how the preservation of high temperature materials in outer disks may require structures or outward flow patterns to avoid them being lost via radial drift. ",Tracking Dust Grains During Transport and Growth in Protoplanetary Disks
"  By proceeding from a simple non-polarized formalism, we consider in detail the polarization procedure as applied to the generating equations of the quantum antibracket algebra, in terms of the parametrized generating operator. ",Quantum antibrackets: polarization and parametrization
"  The time-dependent version of nuclear density functional theory, using functionals derived from Skyrme interactions, is able to approximately describe nuclear dynamics. We present time-dependent results of calculations of dipole resonances, concentrating on excitations of valence neutrons against a proton plus neutron core in the neutron-rich doubly-magic $^{132}$Sn nucleus, and results of collision dynamics, highlighting potential routes to ternary fusion, with the example of a collision of $^{48}$Ca+$^{48}$Ca+$^{208}$Pb resulting in a compound nucleus of element 120 stable against immiedate fission ",Resonances and Reactions from Mean-Field Dynamics
"  By controlling synaptic and neural correlations, deep learning has achieved empirical successes in improving classification performances. How synaptic correlations affect neural correlations to produce disentangled hidden representations remains elusive. Here we propose a simplified model of dimension reduction, taking into account pairwise correlations among synapses, to reveal the mechanism underlying how the synaptic correlations affect dimension reduction. Our theory determines the synaptic-correlation scaling form requiring only mathematical self-consistency, for both binary and continuous synapses. The theory also predicts that weakly-correlated synapses encourage dimension reduction compared to their orthogonal counterparts. In addition, these synapses slow down the decorrelation process along the network depth. These two computational roles are explained by the proposed mean-field equation. The theoretical predictions are in excellent agreement with numerical simulations, and the key features are also captured by a deep learning with Hebbian rules. ",Weakly-correlated synapses promote dimension reduction in deep neural   networks
"  In this paper, we investigate additive properties of generalized Drazin inverse for linear operators in Banach spaces. Under new polynomial conditions on generalized Drazin invertible operators a and b, we prove their sum has generalized Drazin inverse and give explicit representations of the generalized inverse $(a+b)^d$. ",Additive properties of G-Drazin inverse of linear operators
"  We prove that the separable and local approximations of the discontinuity-inducing zero-range interaction in one-dimensional quantum mechanics are equivalent. We further show that the interaction allows the perturbative treatment through the coupling renormalization.   Keywords: one-dimensional system, generalized contact interaction, renormalization, perturbative expansion. PACS Nos: 3.65.-w, 11.10.Gh, 31.15.Md ",Equivalence of Local and Separable Realizations of the   Discontinuity-Inducing Contact Interaction and Its Perturbative   Renormalizability
  We propose an exact formula for the energy radiated by an accelerating quark in N=2 superconformal theories in four dimensions. This formula reproduces the known Bremsstrahlung function for N=4 theories and provides a prediction for all the perturbative and instanton corrections in N=2 theories. We perform a perturbative check of our proposal up to three loops. ,The Exact Bremsstrahlung Function in N=2 Superconformal Field Theories
"  SZ clusters surveys like Planck, the South Pole Telescope, and the Atacama Cosmology Telescope, will soon be publishing several hundred SZ-selected systems. The key ingredient required to transport the mass calibration from current X-ray selected cluster samples to these SZ systems is the Ysz--Yx scaling relation. We constrain the amplitude, slope, and scatter of the Ysz--Yx scaling relation using SZ data from Planck, and X-ray data from Chandra. We find a best fit amplitude of \ln (D_A^2\Ysz/CY_X) = -0.202 \pm 0.024 at the pivot point CY_X=8\times 10^{-5} Mpc^2. This corresponds to a Ysz/Yx-ratio of 0.82\pm 0.024, in good agreement with X-ray expectations after including the effects of gas clumping. The slope of the relation is \alpha=0.916\pm 0.032, consistent with unity at \approx 2.3\sigma. We are unable to detect intrinsic scatter, and find no evidence that the scaling relation depends on cluster dynamical state. ",The Ysz--Yx Scaling Relation as Determined from Planck and Chandra
"  Coded caching utilizes proper file subpacketization and coded delivery to make full use of the multicast opportunities in content delivery, to alleviate file transfer load in massive content delivery scenarios. Most existing work considers deterministic environments. An important practical topic is to characterize the impact of the uncertainty from user inactivity on coded caching. We consider a one server cache-enabled network under homogeneous file and network settings in presence of user inactivity. Unlike random or probabilistic caching studied in the literature, deterministic coded caching is considered, with the objective to minimize the worst-case backhaul load by optimizing the file subpacketization and the caching strategy. First, a coded caching method is used, where each file is split into the same type of fragments labeled using sets with fixed cardinality, and the optimality of the selected cardinality is proved. Optimal file subpacketization by splitting the file into multiple types of fragments labeled with multiple cardinalities is then discussed. We show that the closed-form optimum turns out to be given by a fixed cardinality -- optimizing for user inactivity only affects file delivery, cache placement is not affected. A decentralized version is also discussed and analyzed, where each user fills its storage independently at random without centralized coordination, and user inactivity is taken into account in file delivery. Simulation results show that the optimization based centralized coded caching scheme provides performance comparable to the ideal scenario assuming full knowledge of user inactivity in the placement phase, while decentralized caching performs slightly worse against user inactivity. ",Fundamental Rate-Memory Tradeoff for Coded Caching in Presence of User   Inactivity
"  Sterile neutrinos in the electronvolt mass range are hinted at by a number of terrestrial neutrino experiments. However, such neutrinos are highly incompatible with data from the Cosmic Microwave Background and large scale structure. This paper discusses how charging sterile neutrinos under a new pseudoscalar interaction can reconcile eV sterile neutrinos with terrestrial neutrino data. We show that this model can reconcile eV sterile neutrinos in cosmology, providing a fit to all available data which is way better than the standard $\Lambda$CDM model with one additional fully thermalized sterile neutrino. In particular it also prefers a value of the Hubble parameter much closer to the locally measured value. ",Sterile neutrinos with pseudoscalar self-interactions and cosmology
"  We present total and final-state resolved charge transfer (CT) rate coefficients for low-charge Ge, Se, Br, Kr, Rb, and Xe ions reacting with neutral hydrogen over the temperature range 10^2--10^6 K. Each of these elements has been detected in ionized astrophysical nebulae, particularly planetary nebulae. CT rate coefficients are a key ingredient for the ionization equilibrium solutions needed to determine total elemental abundances from those of the observed ions. A multi-channel Landau Zener approach was used to compute rate coefficients for projectile ions with charges q=2-5, and for singly-charged ions the Demkov approximation was utilized. Our results for five-times ionized species are lower limits, due to the incompleteness of level energies in the NIST database. In addition, we computed rate coefficients for charge transfer ionization reactions between the neutral species of the above six elements and ionized hydrogen. The resulting total and state-resolved CT rate coefficients are tabulated and available at the CDS. In tandem with our concurrent investigations of other important atomic processes in photoionized nebulae, this work will enable robust investigations of neutron-capture element abundances and nucleosynthesis via nebular spectroscopy. ","Atomic data for neutron-capture elements III. Charge transfer rate   coefficients for low-charge ions of Ge, Se, Br, Kr, Rb, and Xe"
"  Many young extra-galactic clusters have a measured velocity dispersion that is too high for the mass derived from their age and total luminosity, which has led to the suggestion that they are not in virial equilibrium. Most of these clusters are confined to a narrow age range centred around 10 Myr because of observational constraints. At this age the cluster light is dominated by luminous evolved stars, such as red supergiants, with initial masses of ~13-22 Msun for which (primordial) binarity is high. In this study we investigate to what extent the observed excess velocity dispersion is the result of the orbital motions of binaries. We demonstrate that estimates for the dynamical mass of young star clusters, derived from the observed velocity dispersion, exceed the photometric mass by up-to a factor of 10 and are consistent with a constant offset in the square of the velocity dispersion. This can be reproduced by models of virialised star clusters hosting a massive star population of which ~25 is in binaries, with typical mass ratios of ~0.6 and periods of ~1000 days. We conclude that binaries play a pivotal role in deriving the dynamical masses of young (~10 Myr) moderately massive and compact (<1e5 Msun; > 1 pc) star clusters. ",On the velocity dispersion of young star clusters: super-virial or   binaries?
"  We present a finite-dimensional and smooth formulation of string structures on spin bundles. It uses trivializations of the Chern-Simons 2-gerbe associated to this bundle. Our formulation is particularly suitable to deal with string connections: it enables us to prove that every string structure admits a string connection and that the possible choices form an affine space. Further we discover a new relation between string connections, 3-forms on the base manifold, and degree three differential cohomology. We also discuss in detail the relation between our formulation of string connections and the original version of Stolz and Teichner. ",String Connections and Chern-Simons Theory
"  The packing of charged micron-sized particles was investigated using discrete element simulations based on adhesive contact dynamic model. The formation process and the final obtained structures of ballistic packings are studied to show the effect of interparticle Coulomb force. It was found that increasing the charge on particles causes a remarkable decrease of the packing volume fraction \phi and the average coordination number Z, indicating a looser and chainlike structure. Force-scaling analysis shows that the long-range Coulomb interaction changes packing structures through its influence on particle inertia before they are bonded into the force networks. Once contact networks are formed, the expansion effect caused by repulsive Coulomb forces are dominated by short-range adhesion. Based on abundant results from simulations, a dimensionless adhesion parameter Ad* , which combines the effects of the particle inertia, the short-range adhesion and the long-range Coulomb interaction, is proposed and successfully scales the packing results for micron-sized particles within the latestly derived adhesive loose packing (ALP) regime. The structural properties of our packings follow well the recent theoretical prediction which is described by an ensemble approach based on a coarse-grained volume function, indicating some kind of universality in the low packing density regime of the phase diagram regardless of adhesion or particle charge. Based on the comprehensive consideration of the complicated inter-particle interactions, our findings provide insight into the roles of short-range adhesion and repulsive Coulomb force during packing formation and should be useful for further design of packings. ",Effect of long-range repulsive Coulomb interactions on packing structure   of adhesive particles
"  With a self-similar magnetohydrodynamic (MHD) model of an exploding progenitor star and an outgoing rebound shock and with the thermal bremsstrahlung as the major radiation mechanism in X-ray bands, we reproduce the early X-ray light curve observed for the recent event of XRO 080109/SN 2008D association. The X-ray light curve consists of a fast rise, as the shock travels into the ""visible layer"" in the stellar envelope, and a subsequent power-law decay, as the plasma cools in a self-similar evolution. The observed spectral softening is naturally expected in our rebound MHD shock scenario. We propose to attribute the ""non-thermal spectrum"" observed to be a superposition of different thermal spectra produced at different layers of the stellar envelope. ",Rebound Shock Breakouts of Exploding Massive Stars: A MHD Void Model
"  Dialogue systems in the form of chatbots and personal assistants are being increasingly integrated into people's lives. These dialogue systems often have the ability to adopt an anthropomorphic persona, mimicking a societal demographic to appear more approachable and trustworthy to users. However, the adoption of a persona can result in the adoption of biases. We define persona biases as harmful differences in text (e.g., varying levels of offensiveness or affirmations of biased statements) generated from adopting different demographic personas. In this paper, we present the first large-scale study on persona biases in dialogue systems and conduct analyses on personas of different social classes, sexual orientations, races, and genders. Furthermore, we introduce an open-source framework, UnitPersonaBias, a tool to explore and aggregate subtle persona biases in dialogue systems. In our studies of the Blender and DialoGPT dialogue systems, we show that the choice of personas can affect the degree of harms in generated responses. Additionally, adopting personas of more diverse, historically marginalized demographics appears to decrease harmful responses the most. ",Revealing Persona Biases in Dialogue Systems
"  By using pairs of nontrivial rational solutions of congruent number equation $$ C_N:\;\;y^2=x^3-N^2x, $$ constructed are pairs of rational right (Pythagorean) triangles with one common side and the other sides equal to the sum and difference of the squares of the same rational numbers. The parametrizations are found for following Diophantine systems: \begin{align*} (p^2\pm q^2)^2-a^2 & =\square_{1,2}\,, \\[0.2cm] c^2-(p^2\pm q^2)^2 & =\square_{1,2}\,, \\[0.2cm] a^2+(p^2\pm q^2)^2 & =\square_{1,2}\,, \\[0.2cm] (p^2\pm q^2)^2-a^2 & =(r^2\pm s^2)^2. \end{align*} ",Diophantine Equations and Congruent Number Equation Solutions
"  For Erd\H{o}s-R\'enyi random graphs with average degree $\gamma$, and uniformly random $\gamma$-regular graph on $n$ vertices, we prove that with high probability the size of both the Max-Cut and maximum bisection are $n\Big(\frac{\gamma}{4} + {{\sf P}}_* \sqrt{\frac{\gamma}{4}} + o(\sqrt{\gamma})\Big) + o(n)$ while the size of the minimum bisection is $n\Big(\frac{\gamma}{4}-{{\sf P}}_*\sqrt{\frac{\gamma}{4}} + o(\sqrt{\gamma})\Big) + o(n)$. Our derivation relates the free energy of the anti-ferromagnetic Ising model on such graphs to that of the Sherrington-Kirkpatrick model, with ${{\sf P}}_* \approx 0.7632$ standing for the ground state energy of the latter, expressed analytically via Parisi's formula. ",Extremal Cuts of Sparse Random Graphs
"  Magnetic reconnection, a fundamentally important process in many aspects of astrophysics, is believed to be initiated by the tearing instability of an electric current sheet, a region where magnetic field abruptly changes direction and electric currents build up. Recent studies have suggested that the amount of magnetic shear in these structures is a critical parameter for the switch-on nature of magnetic reconnection in the solar atmosphere, at fluid spatial scales much larger than kinetic scales. We present results of simulations of reconnection in 3D current sheets with conditions appropriate to the solar corona. Using high-fidelity simulations, we follow the evolution of the linear and non-linear 3D tearing instability, leading to reconnection. We find that, depending on the parameter space, magnetic shear can play a vital role in the onset of significant energy release and heating via non-linear tearing. Two regimes in our study exist, dependent on whether the current sheet is longer or shorter than the wavelength of the fastest growing parallel mode (in the corresponding infinite system), thus determining whether sub-harmonics are present in the actual system. In one regime, where the fastest growing parallel mode has sub-harmonics, the non-linear interaction of these sub-harmonics and the coalescence of 3D plasmoids dominates the non-linear evolution, with magnetic shear playing only a weak role in the amount of energy released. In the second regime, where the fastest growing parallel mode has no-sub-harmonics, then only strongly sheared current sheets, where oblique mode are strong enough to compete with the dominant parallel mode, show any significant energy release. We expect both regimes to exist on the Sun, and so our results have important consequences for the the question of reconnection onset in different solar physics applications. ",The Onset of 3D Magnetic Reconnection and Heating in the Solar Corona
"  We present a method to accurately predict the Helmholtz harmonic free energies of molecular crystals in high-throughput settings. This is achieved by devising a computationally efficient framework that employs a Gaussian Process Regression model based on local atomic environments. The cost to train the model with ab initio potentials is reduced by starting the optimisation of the framework parameters, as well as the training and validation sets, with an empirical potential. This is then transferred to train the model based on density-functional theory potentials, including dispersion-corrections. We benchmarked our framework on a set of 444 hydrocarbon crystal structures, comprising 38 polymorphs, and 406 crystal structures either measured in different conditions or derived from them. Superior performance and high prediction accuracy, with mean absolute deviation below 0.04 kJ/mol/atom at 300 K is achieved by training on as little as 60 crystal structures. Furthermore, we demonstrate the predictive efficiency and accuracy of the developed framework by successfully calculating the thermal lattice expansion of aromatic hydrocarbon crystals within the quasi-harmonic approximation, and predict how lattice expansion affects the polymorph stability ranking. ",Efficient Gaussian Process Regression for prediction of molecular   crystals harmonic free energies
"  Geologic shear fractures such as faults and slip surfaces involve marked friction along the discontinuities as they are subjected to significant confining pressures. This friction plays a critical role in the growth of these shear fractures, as revealed by the fracture mechanics theory of Palmer and Rice decades ago. In this paper, we develop a novel phase-field model of shear fracture in pressure-sensitive geomaterials, honoring the role of friction in the fracture propagation mechanism. Building on a recently proposed phase-field method for frictional interfaces, we formulate a set of governing equations for different contact conditions (or lack thereof) in which frictional energy dissipation emerges in the crack driving force during slip. We then derive the degradation function and the threshold fracture energy of the phase-field model such that the stress-strain behavior is insensitive to the length parameter for phase-field regularization. This derivation procedure extends a methodology used in recent phase-field models of cohesive tensile fracture to shear fracture in frictional materials in which peak and residual strengths coexist and evolve by confining pressure. The resulting phase-field formulation is demonstrably consistent with the theory of Palmer and Rice. Numerical examples showcase that the proposed phase-field model is a physically sound and numerically efficient method for simulating shear fracture processes in geologic materials, such as faulting and slip surface growth. ",A phase-field model of frictional shear fracture in geologic materials
"  When a user requests a web page from a web archive, the user will typically either get an HTTP 200 if the page is available, or an HTTP 404 if the web page has not been archived. This is because web archives are typically accessed by URI lookup, and the response is binary: the archive either has the page or it does not, and the user will not know of other archived web pages that exist and are potentially similar to the requested web page. In this paper, we propose augmenting these binary responses with a model for selecting and ranking recommended web pages in a Web archive. This is to enhance both HTTP 404 responses and HTTP 200 responses by surfacing web pages in the archive that the user may not know existed. First, we check if the URI is already classified in DMOZ or Wikipedia. If the requested URI is not found, we use ML to classify the URI using DMOZ as our ontology and collect candidate URIs to recommended to the user. Next, we filter the candidates based on if they are present in the archive. Finally, we rank candidates based on several features, such as archival quality, web page popularity, temporal similarity, and URI similarity. We calculated the F1 score for different methods of classifying the requested web page at the first level. We found that using all-grams from the URI after removing numerals and the TLD produced the best result with F1=0.59. For second-level classification, the micro-average F1=0.30. We found that 44.89% of the correctly classified URIs contained at least one word that exists in a dictionary and 50.07% of the correctly classified URIs contained long strings in the domain. In comparison with the URIs from our Wayback access logs, only 5.39% of those URIs contained only words from a dictionary, and 26.74% contained at least one word from a dictionary. These percentages are low and may affect the ability for the requested URI to be correctly classified. ","Making Recommendations from Web Archives for ""Lost"" Web Pages"
"  In this paper we provide a geometric description of the possible poles of the Igusa local zeta function associated to an analytic mapping and a locally constant function, in terms of a log-principalizaton of an ideal naturally attached to the mapping. Typically our new method provides a much shorter list of possible poles compared with the previous methods. We determine the largest real part of the poles of the Igusa zeta function, and then as a corollary, we obtain an asymptotic estimation for the number of solutions of an arbitrary system of polynomial congruences in terms of the log-canonical threshold of the subscheme given by the ideal attached to the mapping. We associate to an analytic mapping a Newton polyhedron and a new notion of non-degeneracy with respect to it. By constructing a log-principalization, we give an explicit list for the possible poles of the Igusa zeta function associated to a non-degenerate mapping. ","Zeta Functions for Analytic Mappings, Log-principalization of Ideals,   and Newton Polyhedra"
"  ALICE is the CERN LHC experiment optimised for the study of the strongly interacting matter produced in heavy-ion collisions and devoted to the characterisation of the quark-gluon plasma. To achieve the physics program for LHC Run 3, a major upgrade of the experimental apparatus is ongoing. A key element of the upgrade is the substitution of the Inner Tracking System (ITS) with a completely new silicon-based detector (ITS 2) whose features will allow the reconstruction of rare physics channels not accessible with the previous layout. The enabling technology for such a performance boost is the adoption of custom-designed CMOS Monolithic Active Pixel Sensor as detecting elements. In this proceedings, an overview of the adopted technologies as well as the status of the detector commissioning will be given. ",ALICE ITS Upgrade for LHC Run 3: Commissioning in the Laboratory
"  Self-organized V-N co-doped TiO2 nanotube arrays (TNAs) with various doping amount were synthesized by anodizing in association with hydrothermal treatment. Impacts of V-N co-doping on the morphologies, phase structures, and photoelectrochemical properties of the TNAs films were thoroughly investigated. The co-doped TiO2 photocatalysts show remarkably enhanced photocatalytic activity for the CO2 photoreduction to methane under ultraviolet illumination. The mechanism of the enhanced photocatalytic activity is discussed in detail. ",Self-organized vanadium and nitrogen co-doped titania nanotube arrays   with enhanced photocatalytic reduction of CO2 into CH4
"  Estimation of intrinsic images still remains a challenging task due to weaknesses of ground-truth datasets, which either are too small or present non-realistic issues. On the other hand, end-to-end deep learning architectures start to achieve interesting results that we believe could be improved if important physical hints were not ignored. In this work, we present a twofold framework: (a) a flexible generation of images overcoming some classical dataset problems such as larger size jointly with coherent lighting appearance; and (b) a flexible architecture tying physical properties through intrinsic losses. Our proposal is versatile, presents low computation time, and achieves state-of-the-art results. ",Deep intrinsic decomposition trained on surreal scenes yet with   realistic light effects
"  We investigate a nonlinear localization microscopy method based on Rabi oscillations of single emitters. We demonstrate the fundamental working principle of this new technique using a cryogenic far-field experiment in which subwavelength features smaller than $\lambda$/10 are obtained. Using Monte Carlo simulations, we show the superior localization accuracy of this method under realistic conditions and a potential for higher acquisition speed or a lower number of required photons as compared to conventional linear schemes. The method can be adapted to other emitters than molecules and allows for the localization of several emitters at different distances to a single measurement pixel. ",Coherent Nonlinear Single Molecule Microscopy
  The hydrodynamic expansion rate of quark gluon plasma (QGP) is evaluated and compared with the scattering rate of quarks and gluons within the system. Partonic scattering rates evaluated within the ambit of perturbative Quantum Choromodynamics (pQCD) are found to be smaller than the expansion rate evaluated with ideal equation of state (EoS) for the QGP. This indicate that during the space-time evolution the system remains out of equilibrium. Enhancement of pQCD cross sections and a more realistic EoS keep the partons closer to the equilibrium. ,Equilibration in Quark Gluon Plasma
"  A search for pair production of doubly-charged Higgs bosons in the process p pbar to H++H-- to mu+mu+mu-mu- is performed with the D0 Run II detector at the Fermilab Tevatron. The analysis is based on a sample of inclusive di-muon data collected at an energy of sqrt{s}=1.96 TeV, corresponding to an integrated luminosity of 113 pb-1. In the absence of a signal, 95 % confidence level mass limits of M(H++L)>118.4 GeV/c2 and M(H++R)>98.2 GeV/c2 are set for left-handed and right-handed doubly-charged Higgs bosons, respectively, assuming 100% branching into muon pairs. ",Search for Doubly-charged Higgs Boson Pair Production in the Decay to   mu+mu+mu-mu- in p pbar Collisions at s**1/2=1.96 TeV
"  We report an improved measurement of the neutrino mixing angle $\theta_{13}$ from the Daya Bay Reactor Neutrino Experiment. We exclude a zero value for $\sin^22\theta_{13}$ with a significance of 7.7 standard deviations. Electron antineutrinos from six reactors of 2.9 GW$_{\rm th}$ were detected in six antineutrino detectors deployed in two near (flux-weighted baselines of 470 m and 576 m) and one far (1648 m) underground experimental halls. Using 139 days of data, 28909 (205308) electron antineutrino candidates were detected at the far hall (near halls). The ratio of the observed to the expected number of antineutrinos assuming no oscillations at the far hall is $0.944\pm 0.007({\rm stat.}) \pm 0.003({\rm syst.})$. An analysis of the relative rates in six detectors finds $\sin^22\theta_{13}=0.089\pm 0.010({\rm stat.})\pm0.005({\rm syst.})$ in a three-neutrino framework. ",Improved Measurement of Electron Antineutrino Disappearance at Daya Bay
"  Identification of every single genome present in a microbial sample is an important and challenging task with crucial applications. It is challenging because there are typically millions of cells in a microbial sample, the vast majority of which elude cultivation. The most accurate method to date is exhaustive single cell sequencing using multiple displacement amplification, which is simply intractable for a large number of cells. However, there is hope for breaking this barrier as the number of different cell types with distinct genome sequences is usually much smaller than the number of cells.   Here, we present a novel divide and conquer method to sequence and de novo assemble all distinct genomes present in a microbial sample with a sequencing cost and computational complexity proportional to the number of genome types, rather than the number of cells. The method is implemented in a tool called Squeezambler. We evaluated Squeezambler on simulated data. The proposed divide and conquer method successfully reduces the cost of sequencing in comparison with the naive exhaustive approach.   Availability: Squeezambler and datasets are available under http://compbio.cs.wayne.edu/software/squeezambler/. ",Distilled Single Cell Genome Sequencing and De Novo Assembly for Sparse   Microbial Communities
"  We consider compact Hankel operators realized in $ \ell^2(\mathbb Z_+)$ as infinite matrices $\Gamma$ with matrix elements $h(j+k)$. Roughly speaking, we show that if $h(j)\sim (b_{1}+ (-1)^j b_{-1}) j^{-1}(\log j)^{-\alpha}$ as $j\to \infty$ for some $\alpha>0$, then the eigenvalues of $\Gamma$ satisfy $\lambda_{n}^{\pm} (\Gamma)\sim c^{\pm} n^{-\alpha}$ as $n\to \infty$. The asymptotic coefficients $c^{\pm}$ are explicitly expressed in terms of the asymptotic coefficients $b_{1} $ and $b_{-1}$. Similar results are obtained for Hankel operators $\mathbf \Gamma$ realized in $ L^2(\mathbb R_+)$ as integral operators with kernels $\mathbf h(t+s)$. In this case the asymptotics of eigenvalues $\lambda_{n}^{\pm} (\mathbf \Gamma)$ are determined by the behaviour of $\mathbf h(t)$ as $t\to 0$ and as $t\to \infty$. ",Asymptotic behaviour of eigenvalues of Hankel operators
"  We prove that the Kodaira dimension of the moduli space M_{23} of curves of genus 23 is at least 2. We also present some evidence for the hypothesis that the Kodaira dimension of the moduli space is actually equal to 2. Note that for g > 23 the moduli space is of general type, while for g\leq 22, Harris and Morrison conjectured that M_g is uniruled. The result on M_{23} is obtained by investigating the relative position of three explicit multicanonical divisors which are of Brill-Noether type. ",The Geometry of the Moduli Space of Curves of Genus 23
"  In this paper, diffusion in polymer solutions undergoing evaporation of solvent is modeled as a coupled heat and mass transfer problem with moving boundary condition within the framework of nonequilibrium thermodynamics. The proposed governing equations derived from the fundamental equation of classical thermodynamics using the local equilibrium hypothesis display more complex connection between heat and non-convective mass fluxes than what has been presented in the previous research works. Numerical computations, performed using an explicit finite difference scheme, indicate that the model is able to capture the effect of thermal diffusion in polymer solutions. This effect manifests itself as an increase in local concentration of solvent near warm substrates during solution casting process. ",Diffusion in Evaporating Polymer Solutions: A Model in the Dissipative   Formalism of Nonequilibrium Thermodynamics
"  In this (second) part of the work we present the results of numerical and qualitative analysis, based on a new model of the Archimedean-type interaction between dark matter and dark energy. The Archimedean-type force is linear in the four-gradient of the dark energy pressure and plays a role of self-regulator of the energy redistribution in a cosmic dark fluid. Because of the Archimedean-type interaction the cosmological evolution is shown to have a multistage character. Depending on the choice of the values of the model guiding parameters,the Universe's expansion is shown to be perpetually accelerated, periodic or quasiperiodic with finite number of deceleration/acceleration epochs. We distinguished the models, which can be definitely characterized by the inflation in the early Universe, by the late-time accelerated expansion and nonsingular behavior in intermediate epochs, and classified them with respect to a number of transition points. Transition points appear, when the acceleration parameter changes the sign, providing the natural partition of the Universe's history into epochs of accelerated and decelerated expansion. The strategy and results of numerical calculations are advocated by the qualitative analysis of the instantaneous phase portraits of the dynamic system associated with the key equation for the dark energy pressure evolution. ",Archimedean-type force in a cosmic dark fluid: II. Qualitative and   numerical study of a multistage Universe expansion
  We present a review of the phonon thermal conductivity of segmented nanowires focusing on theoretical results for Si and Si/Ge structures with the constant and periodically modulated cross-sections. We describe the use of the face-centered cubic cell and Born-von Karman models of the lattice vibrations for calculating the phonon energy spectra in the segmented nanowires. Modification of the phonon spectrum in such nanostructures results in strong reduction of the phonon thermal conductivity and suppression of heat transfer due to a trapping of phonon modes in nanowire segments. Possible practical applications of segmented nanowires in thermoelectric energy generation are also discussed. ,Thermal Conductivity of Segmented Nanowires
"  Using a family of modified Weibull distributions, encompassing both sub-exponentials and super-exponentials, to parameterize the marginal distributions of asset returns and their natural multivariate generalizations, we give exact formulas for the tails and for the moments and cumulants of the distribution of returns of a portfolio make of arbitrary compositions of these assets. Using combinatorial and hypergeometric functions, we are in particular able to extend previous results to the case where the exponents of the Weibull distributions are different from asset to asset and in the presence of dependence between assets. We treat in details the problem of risk minimization using two different measures of risks (cumulants and value-at-risk) for a portfolio made of two assets and compare the theoretical predictions with direct empirical data. While good agreement is found, the remaining discrepancy between theory and data stems from the deviations from the Weibull parameterization for small returns. Our extended formulas enable us to determine analytically the conditions under which it is possible to ``have your cake and eat it too'', i.e., to construct a portfolio with both larger return and smaller ``large risks''. ",General framework for a portfolio theory with non-Gaussian risks and   non-linear correlations
"  We study the basic Galois connection induced by the ""satisfaction"" relation between external operations $A^n\rightarrow B$ defined on a set $A$ and valued in a possibly different set $B$ on the one hand, and ordered pairs $(R,S)$ of relations $R\subseteq A^m$ and $S\subseteq B^m$, called relational constraints, on the other hand. We decompose the closure maps associated with this Galois connection, in terms of closure operators corresponding to simple closure conditions describing the corresponding Galois closed sets of functions and constraints. We consider further Galois correspondences by restricting the sets of primal and dual objects to fixed arities. We describe the restricted Galois closure systems by means of parametrized analogues of the simpler closure conditions, and present factorizations of the corresponding Galois closure maps, similar to those provided in the unrestricted case. ",On Galois Connections between External Operations and Relational   Constraints: Arity Restrictions and Operator Decompositions
"  The article presents a brief review of the Brazilian legislation that impacts indigenous communities' digital privacy rights through governmental data collection. Furthermore, the article aims to discuss the need to collect sensitive data from indigenous communities without the participation of the same communities in developing the features for the data collection. The article argues that the digitalization of indigenous communities' information follows a colonial paradigm, harming entire indigenous communities and worsening their already precarious situation.   --   O artigo apresenta uma breve revis\~ao da legisla\c{c}\~ao brasileira que impacta os direitos de privacidade digital das comunidades ind\'igenas por meio da coleta de dados governamentais. Al\'em disso, o artigo visa discutir a necessidade de coletar dados sens\'iveis de comunidades ind\'igenas sem a participa\c{c}\~ao das mesmas comunidades no desenvolvimento dos recursos para a coleta de dados. O artigo argumenta que a digitaliza\c{c}\~ao das informa\c{c}\~oes das comunidades ind\'igenas segue um paradigma colonial, prejudicando comunidades ind\'igenas inteiras e agravando sua situa\c{c}\~ao j\'a prec\'aria. ",Privacidade digital como direito do cidadao: o caso dos grupos indigenas   do Brasil
  We complete the proof of bosonization of noninteracting nonrelativistic fermions in one space dimension by deriving the bosonized action using $W_\infty$ coherent states in the fermion path-integral. This action was earlier derived by us using the method of coadjoint orbits. We also discuss the classical limit of the bosonized theory and indicate the precise nature of the truncation of the full theory that leads to the collective field theory. ,$W_\infty$ coherent states and path-integral derivation of bosonization   of non-relativistic fermions in one dimension
"  The connection zeta function of a finite abstract simplicial complex G is defined as zeta_L(s)=sum_x 1/lambda_x^s, where lambda_x are the eigenvalues of the connection Laplacian L defined by L(x,y)=1 if x and y intersect and 0 else. (I) As a consequence of the spectral formula chi(G)=sum_x (-1)^dim(x) = p(G)-n(G), where p(G) is the number of positive eigenvalues and n(G) is the number of negative eigenvalues of L, both the Euler characteristic chi(G)=zeta(0)-2 i zeta'(0)/pi as well as determinant det(L)=e^zeta'(0)/pi can be written in terms of zeta. (II) As a consequence of the generalized Cauchy-Binet formula for the coefficients of the characteristic polynomials of a product of matrices we show that for every one-dimensional simplicial complex G, the functional equation zeta(s)=zeta(-s) holds, where zeta(s) is the Zeta function of the positive definite squared connection operator L^2 of G. Equivalently, the spectrum sigma of the integer matrix L^2 for a 1-dimensional complex always satisfies the symmetry sigma = 1/sigma and the characteristic polynomial of L^2 is palindromic. The functional equation extends to products of one-dimensional complexes. (III) Explicit expressions for the spectrum of circular connection Laplacian lead to an explicit entire zeta function in the Barycentric limit. The situation is simpler than in the Hodge Laplacian H=D^2 case where no functional equation was available. In the connection Laplacian case, the limiting zeta function is a generalized hypergeometric function which for an integer s is given by an elliptic integral over the real elliptic curve w^2=(1+z)(1-z)(z^2-4z-1), which has the analytic involutive symmetry (z,w) to (1/z,w/z^2). ",An Elementary Dyadic Riemann Hypothesis
"  Non-thermalized dark matter is a cosmologically valid alternative to the paradigm of weakly interacting massive particles. For dark matter belonging to a $Z_2$-odd sector that contains in addition a thermalized mediator particle, dark matter production proceeds in general via both the freeze-in and superWIMP mechanism. We highlight their interplay and emphasize the connection to long-lived particles at colliders. For the explicit example of a colored t-channel mediator model we map out the entire accessible parameter space, cornered by bounds from the LHC, big bang nucleosynthesis and Lyman-alpha forest observations, respectively. We discuss prospects for the HL- and HE-LHC. ",Interplay of super-WIMP and freeze-in production of dark matter
"  The longstanding goals of federated learning (FL) require rigorous privacy guarantees and low communication overhead while holding a relatively high model accuracy. However, simultaneously achieving all the goals is extremely challenging. In this paper, we propose a novel framework called hierarchical federated learning (H-FL) to tackle this challenge. Considering the degradation of the model performance due to the statistic heterogeneity of the training data, we devise a runtime distribution reconstruction strategy, which reallocates the clients appropriately and utilizes mediators to rearrange the local training of the clients. In addition, we design a compression-correction mechanism incorporated into H-FL to reduce the communication overhead while not sacrificing the model performance. To further provide privacy guarantees, we introduce differential privacy while performing local training, which injects moderate amount of noise into only part of the complete model. Experimental results show that our H-FL framework achieves the state-of-art performance on different datasets for the real-world image recognition tasks. ",H-FL: A Hierarchical Communication-Efficient and Privacy-Protected   Architecture for Federated Learning
"  We study the efficiency of synchronization in ensembles of identical coupled stochastic oscillator systems. By deriving a chemical Langevin equation, we measure the rate at which the systems synchronize. The rate at which the difference in the Hilbert phases of the systems evolve provides a suitable order parameter, and a 2--dimensional recurrence plot further facilitates the analysis of stochastic synchrony. We find that a global mean--field coupling effects the most rapid approach to global synchrony, and that when the number of ""information carrying"" molecular species increases, the rate of synchrony increases. The Langevin analysis is complemented by numerical simulations. ",Synchronization efficiency in coupled stochastic oscillators: The role   of connection topology
"  Recent observations with the Atacama Large Millimeter/submillimeter Array (ALMA) detected far-infrared emission lines such as the [OIII] 88 \mu m line from galaxies at $z \sim 7 - 9$. Far-infrared lines can be used to probe the structure and kinematics of such high-redshift galaxies as well as to accurately determine their spectroscopic redshifts. We use a cosmological simulation of galaxy formation to study the physical properties of [OIII] 88 \mu m emitters. In a comoving volume of 50 $h^{-1}$ Mpc on a side, we locate 34 galaxies with stellar masses greater than $10^8\ {\rm M_\odot}$ at $z = 9$, and more than 270 such galaxies at $z = 7$. We calculate the [OIII] 88 \mu m luminosities ($L_{\rm OIII}$) by combining a physical model of HII regions with emission line calculations using the photoionization code CLOUDY. We show that the resulting $L_{\rm OIII}$, for a given star formation rate, is slightly higher than predicted from the empirical relation for local galaxies, and is consistent with recent observations of galaxies at redshifts 7 - 9. Bright [OIII] emitters with $L_{\rm OIII} > 10^8 {\rm L_\odot}$ have stellar masses greater than $10^9\ {\rm M_\odot}$, star formation rates higher than $3\ {\rm M_\odot\ yr}^{-1}$, and the typical metallicity is $\sim 0.1\ {\rm Z_\odot}$. The galaxies are hosted by dark matter halos with masses greater than $10^{10.5}\ {\rm M_\odot}$. Massive galaxies show characteristic structure where the [OIII] emitting gas largely overlaps with young stars, but the emission peak is separated from the main stellar population, suggesting the stochastic and localized nature of star formation in the first galaxies. We propose to use the [OIII] 5007 \AA\ line, to be detected by James Webb Space Telescope (JWST), to study the properties of galaxies whose [OIII] 88 \mu m line emission has been already detected with ALMA. ",The distribution and physical properties of high-redshift [OIII]   emitters in a cosmological hydrodynamics simulation
"  This paper studies constrained information projections on Banach spaces with respect to a Gaussian reference measure. Specifically our interest lies in characterizing projections of the reference measure, with respect to the KL-divergence, onto sets of measures corresponding to changes in the mean (or {\it shift measures}). As our main result, we give a portmanteau theorem that characterizes the relationship among several different formulations of this problem. In the general setting of Gaussian measures on a Banach space, we show that this information projection problem is equivalent to minimization of a certain Onsager-Machlup (OM) function with respect to an associated stochastic process. We then construct several reformulations in the more specific setting of classical Wiener space. First, we show that KL-weighted optimization over shift measures can also be expressed in terms of an OM function for an associated stochastic process that we are able to characterize. Next, we show how to encode the feasible set of shift measures through an explicit functional constraint by constructing an appropriate penalty function. Finally, we express our information projection problem as a calculus of variations problem, which suggests a solution procedure via the Euler-Lagrange equation. We work out the details of these reformulations for several specific examples. ",Information Projection on Banach spaces with Applications to State   Independent KL-Weighted Optimal Control
"  We present a spectral analysis of the e+e- annihilation emission from the Galactic Centre region based on the first year of measurements made with the spectrometer SPI of the INTEGRAL mission. We have found that the annihilation spectrum can be modelled by the sum of a narrow and a broad 511 keV line plus an ortho-Ps continuum. The broad line is detected with a flux of (0.35+/-0.11)e-3 s-1 cm-2. The measured width of 5.4+/-1.2 keV FWHM is in agreement with the expected broadening of 511 keV photons emitted in the annihilation of Ps that are formed by the charge exchange process of slowing down positrons with H atoms. The flux of the narrow line is (0.72+/-0.12)e-3 s-1 cm-2 and its width is 1.3+/-0.4 keV FWHM. The measured ortho-Ps continuum flux yields a fraction of Ps of (96.7+/-2.2)%. To derive in what phase of the interstellar medium positrons annihilate, we have fitted annihilation models calculated for each phase to the data. We have found that 49(+2,-23)% of the annihilation emission comes from the warm neutral phase and 51(+3,-2)% from the warm ionized phase. While we may not exclude that less than 23% of the emission might come from cold gas, we have constrained the fraction of annihilation emission from molecular clouds and hot gas to be less than 8% and 0.5%, respectively. We have compared our knowledge of the interstellar medium in the bulge and the propagation of positrons with our results and found that they are in good agreement if the sources are diffusively distributed and if the initial kinetic energy of positrons is lower than a few MeV. Despite its large filling factor, the lack of annihilation emission from the hot gas is due to its low density, which allows positrons to escape this phase. ",Spectral analysis of the Galactic e+e- annihilation emission
"  We investigate the global cold dust properties of 85 nearby (z < 0.5) QSOs, chosen from the Palomar-Green sample of optically luminous quasars. We determine their infrared spectral energy distributions and estimate their rest-frame luminosities by combining Herschel data from 70 to 500 microns with near-infrared and mid-infrared measurements from the Two Micron All Sky Survey (2MASS) and the Wide-Field Infrared Survey Explorer (WISE). In most sources the far-infrared (FIR) emission can be attributed to thermally heated dust. Single temperature modified black body fits to the FIR photometry give an average dust temperature for the sample of 33~K, with a standard deviation of 8~K, and an average dust mass of 7E6 Solar Masses with a standard deviation of 9E6 Solar Masses. Estimates of star-formation that are based on the FIR continuum emission correlate with those based on the 11.3 microns PAH feature, however, the star-formation rates estimated from the FIR continuum are higher than those estimated from the 11.3 microns PAH emission. We attribute this result to a variety of factors including the possible destruction of the PAHs and that, in some sources, a fraction of the FIR originates from dust heated by the active galactic nucleus and by old stars. ",Herschel Survey of the Palomar-Green QSOs at Low Redshift
"  In this paper we prove that if f is a planar K-quasiconformal map and 0<t<2, t' = 2t/(2K-Kt+t), then f transforms sets of finite (t')-Hausdorff measure into sets of finite t-Hausdorff measure. We also prove the following more quantitative statement: If E is a planar set, then H^t(E) \leq C(K) H^{t'}(f(E))^{t/(t'K)}, where H^s stands for the s-Hausdorff measure. ",Quasiconformal distortion of Hausdorff measures
"  We present recursive multiport schemes for implementing quantum Fourier transforms and the inversion step in Grover's algorithm on an integrated linear optics device. In particular, each scheme shows how to execute a quantum operation on $2d$ modes using a pair of circuits for the same operation on $d$ modes. The circuits operate on path-encoded qudits and realize $d$-dimensional unitary transformations on these states using linear optical networks with $O\left(d^2\right)$ optical elements. To evaluate the schemes against realistic errors, we ran simulations of proof-of-principle experiments using a simple fabrication model of silicon-based photonic integrated devices that employ directional couplers and thermo-optic modulators for beam splitters and phase shifters, respectively. We find that high-fidelity performance is achievable with our multiport circuits for $2$-qubit and $3$-qubit quantum Fourier transforms, and for quantum search on four-item and eight-item databases. ",Recursive multiport schemes for implementing quantum algorithms with   photonic integrated circuits
"  This paper investigates task-oriented communication for multi-device cooperative edge inference, where a group of distributed low-end edge devices transmit the extracted features of local samples to a powerful edge server for inference. While cooperative edge inference can overcome the limited sensing capability of a single device, it substantially increases the communication overhead and may incur excessive latency. To enable low-latency cooperative inference, we propose a learning-based communication scheme that optimizes local feature extraction and distributed feature encoding in a task-oriented manner, i.e., to remove data redundancy and transmit information that is essential for the downstream inference task rather than reconstructing the data samples at the edge server. Specifically, we leverage an information bottleneck (IB) principle to extract the task-relevant feature at each edge device and adopt a distributed information bottleneck (DIB) framework to formalize a single-letter characterization of the optimal rate-relevance tradeoff for distributed feature encoding. To admit flexible control of the communication overhead, we extend the DIB framework to a distributed deterministic information bottleneck (DDIB) objective that explicitly incorporates the representational costs of the encoded features. As the IB-based objectives are computationally prohibitive for high-dimensional data, we adopt variational approximations to make the optimization problems tractable. To compensate the potential performance loss due to the variational approximations, we also develop a selective retransmission (SR) mechanism to identify the redundancy in the encoded features of multiple edge devices to attain additional communication overhead reduction. Extensive experiments evidence that the proposed task-oriented communication scheme achieves a better rate-relevance tradeoff than baseline methods. ",Task-Oriented Communication for Multi-Device Cooperative Edge Inference
"  We study hydrodynamic phonon heat transport in two-dimensional (2D) materials. Starting from the Peierls-Boltzmann equation within the Callaway model, we derive a 2D Guyer-Krumhansl-like equation describing non-local hydrodynamic phonon transport, taking into account the quadratic dispersion of flexural phonons. In additional to Poiseuille flow, second sound propagation, the equation predicts heat current vortices and negative nonlocal thermal conductance in 2D materials, common in classical fluid but scarcely considered in phonon transport. Our results also illustrate the universal transport behavior of hydrodynamics, independent on the type of quasi-particles and their microscopic interactions. ",Nonlocal hydrodynamic phonon transport in two-dimensional materials
"  The paper deals with classical problem for cracks dislocated in a certain very specific porous elastic material, described by a Cowin-Nunziato model. We propose a method based upon a reducing of stress concentration problem for cracks to some integral equations. By applying Fourier integral transforms the problem is reduced to some integral equations. For the plane-strain problem we operate with a direct numerical treatment of a hypersingular integral equation. In the axially symmetric case, for the penny-shaped crack, the problem is reduced to a regular Fredholm integral equation of the second kind. In the both cases we study stress-concentration factor, and investigate its behavior versus porosity of the material. More in particular the stress concentration factor in the medium with voids is always higher, under the same conditions, than in the classical elastic medium made of material of the skeleton. Further, as can be seen, the influence of the porosity becomes more significant for larger cracks; that is also quite natural from a physical point of view. ",On stress analysis for cracks in elastic materials with voids
"  Let K be an algebraic number field, O_K the ring of integers of K, and f : X --> Spec(O_K) an arithmetic surface. Let (E, h) be a rank r Hermitian vector bundle on X such that $E$ is semistable on the geometric generic fiber of f. In this paper, we will prove an arithmetic analogy of Bogomolov-Gieseker's inequality: c_2(E, h) - (r-1)/(2r) c_1(E, h)^2 >= 0. ",Inequality of Bogomolov-Gieseker's type on arithmetic surfaces
"  To date, most analysis of WLANs has been focused on their operation under saturation condition. This work is an attempt to understand the fundamental performance of WLANs under unsaturated condition. In particular, we are interested in the delay performance when collisions of packets are resolved by an exponential backoff mechanism. Using a multiple-vacation queueing model, we derive an explicit expression for packet delay distribution, from which necessary conditions for finite mean delay and delay jitter are established. It is found that under some circumstances, mean delay and delay jitter may approach infinity even when the traffic load is way below the saturation throughput. Saturation throughput is therefore not a sound measure of WLAN capacity when the underlying applications are delay sensitive. To bridge the gap, we define safe-bounded-mean-delay (SBMD) throughput and safe-bounded-delay-jitter (SBDJ) throughput that reflect the actual network capacity users can enjoy when they require bounded mean delay and delay jitter, respectively. The analytical model in this paper is general enough to cover both single-packet reception (SPR) and multi-packet reception (MPR) WLANs, as well as carrier-sensing and non-carrier-sensing networks. We show that the SBMD and SBDJ throughputs scale super-linearly with the MPR capability of a network. Together with our earlier work that proves super-linear throughput scaling under saturation condition, our results here complete the demonstration of MPR as a powerful capacity-enhancement technique for both delay-sensitive and delay-tolerant applications. ",Delay Analysis for Wireless Local Area Networks with Multipacket   Reception under Finite Load
"  The first excited $J^\pi=0^+$ state of $^{12}$C, the so-called Hoyle state, plays an essential role in a triple-$\alpha$ ($^4$He) reaction, which is a main contributor to the synthesis of $^{12}$C in a burning star. We investigate the Coulomb screening effects on the energy shift of the Hoyle state in a thermal plasma environment using precise three-$\alpha$ model calculations. The Coulomb screening effect between $\alpha$ clusters are taken into account within the Debye-H\""uckel approximation. To generalize our study, we utilize two standard $\alpha$-cluster models, which treat the Pauli principle between the $\alpha$ particles differently. We find that the energy shifts do not depend on these models and follow a simple estimation in the zero-size limit of the Hoyle state when the Coulomb screening length is as large as a value typical of such a plasma consisting of electrons and $\alpha$ particles. ",Coulomb screening effect on the Hoyle state energy in thermal plasmas
"  We extend the matrix decomposition method(MDM) in classifying the $2\times N\times N$ truly entangled states to $2\times M\times N$ system under the condition of stochastic local operations and classical communication. It is found that the MDM is quite practical and convenient in operation for the asymmetrical tripartite states, and an explicit example of the classification of $2\times 6\times 7$ quantum system is presented. ",Classification of the Entangled States $2 \times M \times N$
"  A large deviation technique is applied to the mean-field phi4-model, providing an exact expression for the configurational entropy s(v,m) as a function of the potential energy v and the magnetization m. Although a continuous phase transition occurs at some critical energy v_c, the entropy is found to be a real analytic function in both arguments, and it is only the maximization over m which gives rise to a nonanalyticity in s(v)=sup_m s(v,m). This mechanism of nonanalyticity-generation by maximization over one variable of a real analytic function is restricted to systems with long-range interactions and has--for continuous phase transitions--the generic occurrence of classical critical exponents as an immediate consequence. Furthermore, this mechanism can provide an explanation why, contradictory to the so-called topological hypothesis, the phase transition in the mean-field phi4-model need not be accompanied by a topology change in the family of constant-energy submanifolds. ","The mean-field phi4-model: entropy, analyticity, and configuration space   topology"
"  The ground state configurations of the one--dimensional Falicov--Kimball model are studied exactly with numerical calculations revealing unexpected effects for small interaction strength. In neutral systems we observe molecular formation, phase separation and changes in the conducting properties; while in non--neutral systems the phase diagram exhibits Farey tree order (Aubry sequence) and a devil's staircase structure. Conjectures are presented for the boundary of the segregated domain and the general structure of the ground states. ",Molecule Formation and the Farey Tree in the One-Dimensional   Falicov-Kimball Model
"  Power flow refers to the injection of power on the lines of an electrical grid, so that all the injections at the nodes form a consistent flow within the network. Optimality, in this setting, is usually intended as the minimization of the cost of generating power. Current can either be direct or alternating: while the former yields approximate linear programming formulations, the latter yields formulations of a much more interesting sort: namely, nonconvex nonlinear programs in complex numbers. In this technical survey, we derive formulation variants and relaxations of the alternating current optimal power flow problem. ",Mathematical Programming formulations for the Alternating Current   Optimal Power Flow problem
"  The local SUSY symmetry of the loop dynamics of QCD is found. The remarkable thing is, there is no einbein-gravitino on this theory, which makes it a 1D topological supergravity, or locally SUSY quantum mechanics. Using this symmetry, we derive the large $N_c$ loop equation in momentum superloop space. Introducing as before the position operator $\X{\mu}$ we argue that the superloop equation is equivalent to invariance of correlation functions of products of these operators with respect to certain quadrilinear transformation. The applications to meson and glueball sectors as well as the chiral symmetry breaking are discussed. The 1D field theory with Quark propagating around the loop in superspace is constructed. ",Hidden Symmetries of Large N QCD
  We present a progress report for studies on maxima related to offspring in branching processes. We summarize and discuss the findings on the subject that appeared in the last ten years. Some of the results are refined and illustrated with new examples. ,Revisiting Offspring Maxima in Branching Processes
"  Accurate diagnosis of Autism Spectrum Disorder (ASD) followed by effective rehabilitation is essential for the management of this disorder. Artificial intelligence (AI) techniques can aid physicians to apply automatic diagnosis and rehabilitation procedures. AI techniques comprise traditional machine learning (ML) approaches and deep learning (DL) techniques. Conventional ML methods employ various feature extraction and classification techniques, but in DL, the process of feature extraction and classification is accomplished intelligently and integrally. DL methods for diagnosis of ASD have been focused on neuroimaging-based approaches. Neuroimaging techniques are non-invasive disease markers potentially useful for ASD diagnosis. Structural and functional neuroimaging techniques provide physicians substantial information about the structure (anatomy and structural connectivity) and function (activity and functional connectivity) of the brain. Due to the intricate structure and function of the brain, proposing optimum procedures for ASD diagnosis with neuroimaging data without exploiting powerful AI techniques like DL may be challenging. In this paper, studies conducted with the aid of DL networks to distinguish ASD are investigated. Rehabilitation tools provided for supporting ASD patients utilizing DL networks are also assessed. Finally, we will present important challenges in the automated detection and rehabilitation of ASD and propose some future works. ",Deep Learning for Neuroimaging-based Diagnosis and Rehabilitation of   Autism Spectrum Disorder: A Review
"  Pions in external magnetic field are investigated in the frame of a Pauli-Villars regularized Nambu--Jona-Lasinio model. The meson propagators in terms of quark bubbles in Ritus and Schwinger schemes are analytically derived, and pion masses are numerically calculated in the Ritus scheme. For neutral and charged pions at finite temperature, there exist respectively one and three mass jumps at the corresponding Mott transition points, due to the discrete energy levels of the two constituent quarks in magnetic field. ",Pions in magnetic field at finite temperature
"  We construct minimal electronic models for a newly discovered superconductor LaO$_{1-x}$F$_x$BiS$_2$ ($T_c=$ 10.6K) possessing BiS$_2$ layers based on first principles band calculation. First, we obtain a model consisting of two Bi $6p$ and two S $3p$ orbitals, which give nearly electron-hole symmetric bands. Further focusing on the bands that intersect the Fermi level, we obtain a model with two $p$ orbitals. The two bands (per BiS$_2$ layer) have quasi-one-dimensional character with a double minimum dispersion, which gives good nesting of the Fermi surface. At around $x\sim 0.5$ the topology of the Fermi surface changes, so that the density of states at the Fermi level becomes large. Possible pairing states are discussed. ",Minimal electronic models for superconducting BiS$_2$ layers
"  We performed a series of high-pressure synchrotron X-ray diffraction (XRD) and resistance measurements on the Weyl semimetal NbAs. The crystal structure remains stable up to 26 GPa according to the powder XRD data. The resistance of NbAs single crystal increases monotonically with pressure at low temperature. Up to 20 GPa, no superconducting transition is observed down to 0.3 K. These results show that the Weyl semimetal phase is robust in NbAs, and applying pressure is not a good way to get a topological superconductor from a Weyl semimetal. ",High-pressure study of the Weyl semimetal NbAs
"  Gaussian mixture models (GMM) and support vector machines (SVM) are introduced to classify faults in a population of cylindrical shells. The proposed procedures are tested on a population of 20 cylindrical shells and their performance is compared to the procedure, which uses multi-layer perceptrons (MLP). The modal properties extracted from vibration data are used to train the GMM, SVM and MLP. It is observed that the GMM produces 98%, SVM produces 94% classification accuracy while the MLP produces 88% classification rates. ","Fault Classification in Cylinders Using Multilayer Perceptrons, Support   Vector Machines and Guassian Mixture Models"
"  We consider the solid-solid interactions in the two body problem. The relative equilibria have been previously studied analytically and general motions were numerically analyzed using some expansion of the gravitational potential up to the second order, but only when there are no direct interactions between the orientation of the bodies. Here we expand the potential up to the fourth order and we show that the secular problem obtained after averaging over fast angles, as for the precession model of Boue and Laskar [Boue, G., Laskar, J., 2006. Icarus 185, 312-330], is integrable, but not trivially. We describe the general features of the motions and we provide explicit analytical approximations for the solutions. We demonstrate that the general solution of the secular system can be decomposed as a uniform precession around the total angular momentum and a periodic symmetric orbit in the precessing frame. More generally, we show that for a general n-body system of rigid bodies in gravitational interaction, the regular quasiperiodic solutions can be decomposed into a uniform precession around the total angular momentum, and a quasiperiodic motion with one frequency less in the precessing frame. ",Solid-solid interaction in the two body problem
  A new method to determine the CO-to-H$_2$ conversion factor $X_{\rm CO}$ using absorption of diffuse X-ray emission by local molecular clouds was developed. It was applied to the Ophiucus (G353+17) and Corona Australis (G359-18) clouds using CO-line and soft X-ray archival data. We obtained a value $X_{\rm CO} =1.85 \pm 0.45 \times 10^{20} {\rm H_2 cm^{-2}/(K~ km~ s^{-1})}$ as the average of least-$chi^2$ fitting results for R4 (0.7 keV) and R5 (0.8 keV) bands.   Full resolution pdf available at http://www.ioa.s.u-tokyo.ac.jp/~sofue/htdocs/2016Xco/ ,CO-to-H_2 Conversion Factor of Molecular Clouds using X-Ray Shadows
"  A graph $G = (V,E)$ is a double-threshold graph if there exist a vertex-weight function $w \colon V \to \mathbb{R}$ and two real numbers $\mathtt{lb}, \mathtt{ub} \in \mathbb{R}$ such that $uv \in E$ if and only if $\mathtt{lb} \le \mathtt{w}(u) + \mathtt{w}(v) \le \mathtt{ub}$. In the literature, those graphs are studied as the pairwise compatibility graphs that have stars as their underlying trees. We give a new characterization of double-threshold graphs, which gives connections to bipartite permutation graphs. Using the new characterization, we present a linear-time algorithm for recognizing double-threshold graphs. Prior to our work, the fastest known algorithm by Xiao and Nagamochi [COCOON 2018] ran in $O(n^6)$ time, where $n$ is the number of vertices. ",Linear-Time Recognition of Double-Threshold Graphs
"  Randomized ensemble double Q-learning (REDQ) has recently achieved state-of-the-art sample efficiency on continuous-action reinforcement learning benchmarks. This superior sample efficiency is possible by using a large Q-function ensemble. However, REDQ is much less computationally efficient than non-ensemble counterparts such as Soft Actor-Critic (SAC). To make REDQ more computationally efficient, we propose a method of improving computational efficiency called Dr.Q, which is a variant of REDQ that uses a small ensemble of dropout Q-functions. Our dropout Q-functions are simple Q-functions equipped with dropout connection and layer normalization. Despite its simplicity of implementation, our experimental results indicate that Dr.Q is doubly (sample and computationally) efficient. It achieved comparable sample efficiency with REDQ and much better computational efficiency than REDQ and comparable computational efficiency with that of SAC. ",Dropout Q-Functions for Doubly Efficient Reinforcement Learning
"  We use high resolution direct numerical simulations to study the anisotropic contents of a turbulent, statistically homogeneous flow with random transitions among multiple energy containing states. We decompose the velocity correlation functions on different sectors of the three dimensional group of rotations, SO(3), using a high-precision quadrature. Scaling properties of anisotropic components of longitudinal and transverse velocity fluctuations are accurately measured at changing Reynolds numbers. We show that independently of the anisotropic content of the energy containing eddies, small-scale turbulent fluctuations recover isotropy and universality faster than previously reported in experimental and numerical studies. The discrepancies are ascribed to the presence of highly anisotropic contributions that have either been neglected or measured with less accuracy in the foregoing works. Furthermore, the anomalous anisotropic scaling exponents are devoid of any sign of saturation with increasing order. Our study paves the way to systematically assess persistence of anisotropy in high Reynolds number flows. ",Multiscale anisotropic fluctuations in sheared turbulence with multiple   states
"  We have found analytical self-dual solutions within the generalized Yang-Mills-Higgs model introduced in Phys. Rev. D 86, 085034 (2012). Such solutions are magnetic monopoles satisfying Bogomol'nyi-Prasad-Sommerfield (BPS) equations and usual finite energy boundary conditions. Moreover, the new solutions are classified in two different types according to their capability of recovering (or not) the usual 't Hooft--Polyakov monopole. Finally, we compare the profiles of the solutions we found with the standard ones, from which we comment about the main features exhibited by the new configurations. ",Analytical self-dual solutions in a nonstandard Yang-Mills-Higgs   scenario
  The golden ratio and Fibonacci numbers are found to occur in various aspects of nature. We discuss the occurrence of this ratio in an interesting physical problem concerning center of masses in two dimensions. The result is shown to be independent of the particular shape of the object. The approach taken extends naturally to higher dimensions. This leads to ratios similar to the golden ratio and generalization of the Fibonacci sequence. The hierarchy of these ratios with dimension and the limit as the dimension tends to infinity is discussed using the physical problem. ,"Balancing on the edge, the golden ratio, the Fibonacci sequence and   their generalization"
"  We study the dynamics of an active Brownian particle with a nonlinear friction function located in a spatial cubic potential. For strong but finite damping, the escape rate of the particle over the spatial potential barrier shows a nonmonotonic dependence on the noise intensity. We relate this behavior to the fact that the active particle escapes from a limit cycle rather than from a fixed point and that a certain amount of noise can stabilize the sojourn of the particle on this limit cycle. ",Escape rate of an active Brownian particle over a potential barrier
"  We extract the Bjorken integral Gamma^{p-n}_1 in the range 0.17 < Q^2 < 1.10 GeV^2 from inclusive scattering of polarized electrons by polarized protons, deuterons and 3He, for the region in which the integral is dominated by nucleon resonances. These data bridge the domains of the hadronic and partonic descriptions of the nucleon. In combination with earlier measurements at higher Q^2, we extract the non-singlet twist-4 matrix element f_2. ",Experimental determination of the evolution of the Bjorken integral at   low Q^2
"  The problem of $\textit{visual metamerism}$ is defined as finding a family of perceptually indistinguishable, yet physically different images. In this paper, we propose our NeuroFovea metamer model, a foveated generative model that is based on a mixture of peripheral representations and style transfer forward-pass algorithms. Our gradient-descent free model is parametrized by a foveated VGG19 encoder-decoder which allows us to encode images in high dimensional space and interpolate between the content and texture information with adaptive instance normalization anywhere in the visual field. Our contributions include: 1) A framework for computing metamers that resembles a noisy communication system via a foveated feed-forward encoder-decoder network -- We observe that metamerism arises as a byproduct of noisy perturbations that partially lie in the perceptual null space; 2) A perceptual optimization scheme as a solution to the hyperparametric nature of our metamer model that requires tuning of the image-texture tradeoff coefficients everywhere in the visual field which are a consequence of internal noise; 3) An ABX psychophysical evaluation of our metamers where we also find that the rate of growth of the receptive fields in our model match V1 for reference metamers and V2 between synthesized samples. Our model also renders metamers at roughly a second, presenting a $\times1000$ speed-up compared to the previous work, which allows for tractable data-driven metamer experiments. ",Towards Metamerism via Foveated Style Transfer
"  The critical behaviour of a non-local scalar field theory is studied. This theory has a non-local kinetic term which involves a real power 1-2\alpha of the Laplacian. The interaction term is the usual local \phi^{4} interaction. The lowest order Feynman diagrams corresponding to coupling constant renormalization, mass renormalization and field renormalization are computed. Particular features appearing in the renormalization of these non-local theory that differ from the case of local theories are studied. The previous calculations lead to the perturbative computation of the coupling constant beta function and critical exponents \nu and \eta. In four dimensions for \alpha<0 this beta function presents asymptotic freedom in the UV. This is remarcable since no non-abelian vector fields are included. However this comes at the expense of loosing reflection positivity. ",Critical behaviour of a non-local \phi^{4} field theory and asymptotic   freedom
"  We introduce a technique using nonbacktracking random walk for estimating the spectral radius of simple random walk. This technique relates the density of nontrivial cycles in simple random walk to that in nonbacktracking random walk. We apply this to infinite Ramanujan graphs, which are regular graphs whose spectral radius equals that of the tree of the same degree. Kesten showed that the only infinite Ramanujan graphs that are Cayley graphs are trees. This result was extended to unimodular random rooted regular graphs by Ab\'{e}rt, Glasner and Vir\'{a}g. We show that an analogous result holds for all regular graphs: the frequency of times spent by simple random walk in a nontrivial cycle is a.s. 0 on every infinite Ramanujan graph. We also give quantitative versions of that result, which we apply to answer another question of Ab\'{e}rt, Glasner and Vir\'{a}g, showing that on an infinite Ramanujan graph, the probability that simple random walk encounters a short cycle tends to 0 a.s. as the time tends to infinity. ",Cycle density in infinite Ramanujan graphs
"  For $\gamma \in (0,2)$, $U\subset \mathbb C$, and an instance $h$ of the Gaussian free field (GFF) on $U$, the $\gamma$-Liouville quantum gravity (LQG) surface associated with $(U,h)$ is formally described by the Riemannian metric tensor $e^{\gamma h} (dx^2 + dy^2)$ on $U$. Previous work by the authors showed that one can define a canonical metric (distance function) $D_h$ on $U$ associated with a $\gamma$-LQG surface. We show that this metric is conformally covariant in the sense that it respects the coordinate change formula for $\gamma$-LQG surfaces. That is, if $U,\widetilde{U}$ are domains, $\phi \colon U \to \widetilde{U}$ is a conformal transformation, $Q=2/\gamma+\gamma/2$, and $\widetilde h = h\circ\phi^{-1} + Q\log|(\phi^{-1})'|$, then $D_h(z,w) = D_{\widetilde{h}}(\phi(z),\phi(w))$ for all $z,w \in U$. This proves that $D_h$ is intrinsic to the quantum surface structure of $(U,h)$, i.e., it does not depend on the particular choice of parameterization. ","Conformal covariance of the Liouville quantum gravity metric for $\gamma   \in (0,2)$"
"  The possibility of the emergence of some kind of long-range ordering (LRO) due to the increase of multiplicity of the local degrees of freedom (spin value $S$) is studied in an Ising antiferromagnet on a kagome lattice (IAKL) by Monte Carlo simulation. In particular, the critical exponent of the spin correlation function, obtained from a finite-size scaling analysis, is evaluated for various values of $S$, including $S=\infty$, with the goal to determine whether there exists some threshold value of the spin $S_C$ above which the system would show true or quasi-LRO, similar to a related model on a triangular lattice (IATL). It is found that, unlike in the IATL case, the IAKL model remains disordered for any spin value and any finite temperature. ",Absence of long-range order in a general spin-$S$ kagome lattice Ising   antiferromagnet
"  A greedy algorithm called Bayesian multiple matching pursuit (BMMP) is proposed to estimate a sparse signal vector and its support given $m$ linear measurements. Unlike the maximum a posteriori (MAP) support detection, which was proposed by Lee to estimate the support by selecting an index with the maximum likelihood ratio of the correlation given by a normalized version of the orthogonal matching pursuit (OMP), the proposed method uses the correlation given by the matching pursuit proposed by Davies and Eldar. BMMP exploits the diversity gain to estimate the support by considering multiple support candidates, each of which is obtained by iteratively selecting an index set with a size different for each candidate. In particular, BMMP considers an extended support estimate whose maximal size is $m$ in the process to obtain each of the support candidates. It is observed that BMMP outperforms other state-of-the-art methods and approaches the ideal limit of the signal sparsity in our simulation setting. ",Bayesian Approach with Extended Support Estimation for Sparse Regression
"  In this paper, we discuss the application of quasi-Monte Carlo methods to the Heston model. We base our algorithms on the Broadie-Kaya algorithm, an exact simulation scheme for the Heston model. As the joint transition densities are not available in closed-form, the Linear Transformation method due to Imai and Tan, a popular and widely applicable method to improve the effectiveness of quasi-Monte Carlo methods, cannot be employed in the context of path-dependent options when the underlying price process follows the Heston model. Consequently, we tailor quasi-Monte Carlo methods directly to the Heston model. The contributions of the paper are threefold: We firstly show how to apply quasi-Monte Carlo methods in the context of the Heston model and the SVJ model, secondly that quasi-Monte Carlo methods improve on Monte Carlo methods, and thirdly how to improve the effectiveness of quasi-Monte Carlo methods by using bridge constructions tailored to the Heston and SVJ models. Finally, we provide some extensions for computing greeks, barrier options, multidimensional and multi-asset pricing, and the 3/2 model. ",Quasi-Monte Carlo methods for the Heston model
  The AXSIS project (Attosecond X-ray Science: Imaging and Spectroscopy) aims to develop a THz-driven compact X-ray source for applications e.g. in chemistry and biology by using ultrafast coherent diffraction imaging and spectroscopy. The key components of AXSIS are the THz-driven electron gun and THz-driven dielectric loaded linear accelerator as well as an inverse Compton scattering scheme for the X-rays production. This paper is focused on the prototype of the THz-driven electron gun which is capable of accelerating electrons up to tens of keV. Such a gun was manufactured and tested at the test-stand at DESY. Due to variations in gun fabrication and generation of THz-fields the gun is not exactly operated at design parameters. Extended simulations have been performed to understand the experimentally observed performance of the gun. A detailed comparison between simulations and experimental measurements is presented in this paper. ,Performance analysis of the prototype THz-driven electron gun for the   AXSIS project
"  In this paper, we prove the Gan-Gross-Prasad conjecture and the Ichino-Ikeda conjecture for unitary groups $U_n\times U_{n+1}$ in all the endoscopic cases. Our main technical innovation is the computation of the contributions of certain cuspidal data, called $*$-generic, to the Jacquet-Rallis trace formula for linear groups. We offer two different computations of these contributions: one, based on truncation, is expressed in terms of regularized Rankin-Selberg periods of Eisenstein series and Flicker-Rallis intertwining periods. The other, built upon Zeta integrals, is expressed in terms of functionals on the Whittaker model. A direct proof of the equality between the two expressions is also given. Finally several useful auxiliary results about the spectral expansion of the Jacquet-Rallis trace formula are provided. ",The global Gan-Gross-Prasad conjecture for unitary groups: the   endoscopic case
"  In this note some generalization of the Chern character is discussed from the chromatic point of view. We construct a multiplicative G_{n+1}-equivariant natural transformation \Theta from some height (n+1) cohomology theory E^*(-) to the height n cohomology theory K^*(-)\hat{\otimes}_F L, where K^*(-) is essentially the n-th Morava K-theory. As a corollary, it is shown that the G_n-module K^*(X) can be recovered from the G_{n+1}-module E^*(X). We also construct a lift of \Theta to a natural transformation between characteristic zero cohomology theories. ",Equivariance of generalized Chern characters
"  We study the optimal setup for observation of the CP asymmetry in neutrino factory experiments --- the baseline length, the muon energy and the analysis method. First, we point out that the statistical quantity which has been used in previous works doesn't represent the CP asymmetry. Then we propose the more suitable quantity, $\equiv \chi^{2}_{2} $, which is sensitive to the CP asymmetry. We investigate the behavior of $ \chi^{2}_{2} $ with ambiguities of the theoretical parameters. The fake CP asymmetry due to the matter effect increases with the baseline length and hence the error in the estimation of the fake CP asymmetry grows with the baseline length due to the ambiguities of the theoretical parameters. Namely, we lose the sensitivity to the genuine CP-violation effect in longer baseline. ",Ambiguities of theoretical parameters and CP/T violation in neutrino   factories
"  In this paper a discussion of kinematics and physics of the Broad Line Region (BLR) is given. The possible physical conditions in the BLR and problems in determination of the physical parameters (electron temperature and density) are considered. Moreover, one analyses the geometry of the BLR and the probability that (at least) a fraction of the radiation in the Broad Emission Lines (BELs) originates from a relativistic accretion disk. ",The Broad Line Region of AGN: Kinematics and Physics
"  GaN is a wide-bandgap semiconductor used in high-efficiency LEDs and solar cells. The solid is produced industrially at high chemical purities by deposition from a vapour phase, and oxygen may be included at this stage. Oxidation represents a potential path for tuning its properties without introducing more exotic elements or extreme processing conditions. In this work, ab initio computational methods are used to examine the energy potentials and electronic properties of different extents of oxidation in GaN. Solid-state vibrational properties of Ga, GaN, Ga2O3 and a single substitutional oxygen defect have been studied using the harmonic approximation with supercells. A thermodynamic model is outlined which combines the results of ab initio calculations with data from experimental literature. This model allows free energies to be predicted for arbitrary reaction conditions within a wide process envelope. It is shown that complete oxidation is favourable for all industrially-relevant conditions, while the formation of defects can be opposed by the use of high temperatures and a high N2:O2 ratio. ",Oxidation of GaN: An ab initio thermodynamic approach
"  The Container Relocation Problem (CRP) is concerned with finding a sequence of moves of containers that minimizes the number of relocations needed to retrieve all containers, while respecting a given order of retrieval. However, the assumption of knowing the full retrieval order of containers is particularly unrealistic in real operations. This paper studies the stochastic CRP (SCRP), which relaxes this assumption. A new multi-stage stochastic model, called the batch model, is introduced, motivated, and compared with an existing model (the online model). The two main contributions are an optimal algorithm called Pruning-Best-First-Search (PBFS) and a randomized approximate algorithm called PBFS-Approximate with a bounded average error. Both algorithms, applicable in the batch and online models, are based on a new family of lower bounds for which we show some theoretical properties. Moreover, we introduce two new heuristics outperforming the best existing heuristics. Algorithms, bounds and heuristics are tested in an extensive computational section. Finally, based on strong computational evidence, we conjecture the optimality of the ""Leveling"" heuristic in a special ""no information"" case, where at any retrieval stage, any of the remaining containers is equally likely to be retrieved next. ",The Stochastic Container Relocation Problem
"  The underlying mathematical structures of gauge theories are known to be geometrical in nature and the local and global features of this geometry have been studied for a long time in mathematics under the name of fibre bundles. It is now understood that the global properties of gauge theories can have a profound influence on physics. For example, instantons and monopoles are both consequences of properties of geometry in the large, and the former can lead to, e.g., CP-violation, while the latter can lead to such remarkable results as the creation of fermions out of bosons. Some familiarity with global differential geometry and fibre bundles seems therefore very desirable to a physicist who works with gauge theories. One of the purposes of the present work is to introduce the physicist to these disciplines using simple examples. ",Gauge Theories and Fibre Bundles - Applications to Particle Dynamics
"  Let $\{B_\beta (x), x \in \mathbb{S}^N\}$ be a fractional Brownian motion on the $N$-dimensional unit sphere $\mathbb{S}^N$ with Hurst index $\beta$. We study the excursion probability $\mathbb{P}\{\sup_{x\in T} B_\beta(x) > u \}$ and obtain the asymptotics as $u\to \infty$, where $T$ can be the entire sphere $\mathbb{S}^N$ or a geodesic disc on $\mathbb{S}^N$. ",Extremes of Spherical Fractional Brownian Motion
"  Despite the absence of experimental evidence, weak scale supersymmetry remains one of the best motivated and studied Standard Model extensions. This report summarises recent ATLAS results on inclusive searches for supersymmetric squarks and gluinos, including third generation squarks produced in the decay of gluinos. Results are presented for both R-parity conserving and R-parity violating scenarios, with final states containing jets with and without missing transverse momentum, light leptons, taus or photons. ",Inclusive searches for squarks and gluinos with the ATLAS detector
"  In this paper we describe the physical processes that lead to the generation of Giant Electro- Magnetic Pulses (GEMP) on powerful laser facilities. Our study is based on experimental mea- surements of both the charging of a solid target irradiated by an ultra-short, ultra-intense laser and the detection of the electromagnetic emission in the GHz domain. An unambiguous correlation between the neutralisation current in the target holder and the electromagnetic emission shows that the source of the GEMP is the remaining positive charge inside the target after the escape of fast electrons accelerated by the ultra-intense laser. A simple model for calculating this charge in the thick target case is presented. From this model and knowing the geometry of the target holder, it becomes possible to estimate the intensity and the dominant frequencies of the GEMP on any facility. ",Physics of Giant ElectroMagnetic Pulse generation in short pulse laser   experiments
"  A novel order parameter $\Phi$ for spin glasses is defined based on topological criteria and with a clear physical interpretation. $\Phi$ is first investigated for well known magnetic systems and then applied to the Edwards-Anderson $\pm J$ model on a square lattice, comparing its properties with the usual $q$ order parameter. Finite size scaling procedures are performed. Results and analyses based on $\Phi$ confirm a zero temperature phase transition and allow to identify the low temperature phase. The advantages of $\Phi$ are brought out and its physical meaning is established. ",Novel order parameter to describe the critical behavior of Ising spin   glass models
"  W prove a dimension-free estimate for the $L^2(\mathbb{R}^d)$ norm of the maximal truncated Riesz transform in terms of the $L^2(\mathbb{R}^d)$ norm of the Riesz transform. Consequently, the vector of maximal truncated Riesz transforms has a dimension-free estimate on $L^2(\mathbb{R}^d)$. We also show that the maximal function of the vector of truncated Riesz transforms has a dimension-free estimate on all $L^p(\mathbb{R}^d)$ spaces, $1<p<\infty.$ ",A dimension-free estimate on $L^2$ for the maximal Riesz transform in   terms of the Riesz transform
"  For all integers $n \geq k \geq 1$, define $H(n,k) := \sum 1 / (i_1 \cdots i_k)$, where the sum is extended over all positive integers $i_1 < \cdots < i_k \leq n$. These quantities are closely related to the Stirling numbers of the first kind by the identity $H(n,k) = s(n + 1, k + 1) / n!$. Motivated by the works of Erd\H{o}s-Niven and Chen-Tang, we study the $p$-adic valuation of $H(n,k)$. In particular, for any prime number $p$, integer $k \geq 2$, and $x \geq (k-1)p$, we prove that $\nu_p(H(n,k)) < -(k - 1)(\log_p(n/(k - 1)) - 1)$ for all positive integers $n \in [(k-1)p, x]$ whose base $p$ representations start with the base $p$ representation of $k - 1$, but at most $3x^{0.835}$ exceptions. We also generalize a result of Lengyel by giving a description of $\nu_2(H(n,2))$ in terms of an infinite binary sequence. ",On the p-adic valuation of Stirling numbers of the first kind
"  We calculate the R\'enyi entropy of a positive integer order $M$ for a reduced density matrix of a single-level quantum dot connected to left and right leads. We exploit a $2 \times 2$ modified Keldysh Green function matrix obtained by the discrete Fourier transform of a $2 M \times 2M$ multi-contour Keldysh Green function matrix. A moment generating function of self-information is deduced from the analytic continuation of $M$ to the complex plane. We calculate the probability distribution of self-information and find that, within the Hartree approximation, the on-site Coulomb interaction affects rare events and modifies a bound of the probability distribution. A simple equality, from which an upper bound of the average, i.e., the entanglement entropy, would be inferred, is presented. For noninteracting electrons, the entanglement entropy is expressed with current cumulants of the full-counting statistics of electron transport. ",Full counting statistics of information content in the presence of   Coulomb interaction
"  The single spike is a rigidly rotating classical string configuration closely related to the giant magnon. We calculate bosonic and fermionic modes of this solution, from which we see that it is not supersymmetric. It can be viewed as an excitation above a hoop of string wound around the equator, in the same sense that the magnon is an excitation above an orbiting point particle. We find the operator which plays the role of the Hamiltonian for this sector, which compared to the magnon's E-J has the angular momentum replaced by a winding charge. The single spike solution is unstable, and we use the modes to attempt a semi-classical computation of its lifetime. ",Vibrating giant spikes and the large-winding sector
"  Liouville (super)integrability of a Hamiltonian system of differential equations is based on the existence of globally well-defined constants of the motion, while Lie point symmetries provide a local approach to conserved integrals. Therefore, it seems natural to investigate in which sense Lie point symmetries can be used to provide information concerning the superintegrability of a given Hamiltonian system. The two-dimensional oscillator and the central force problem are used as benchmark examples to show that the relationship between standard Lie point symmetries and superintegrability is neither straightforward nor universal. In general, it turns out that superintegrability is not related to either the size or the structure of the algebra of variational dynamical symmetries. Nevertheless, all of the first integrals for a given Hamiltonian system can be obtained through an extension of the standard point symmetry method, which is applied to a superintegrable nonlinear oscillator describing the motion of a particle on a space with non-constant curvature and spherical symmetry. ",Global versus local superintegrability of nonlinear oscillators
  We investigate exchange current contributions to elastic electron-deuteron scattering using exactly Poincar\'e invariant quantum mechanics with a null-plane kinematic symmetry. Our model exchange current is motivated by one-pion-exchange physics. Exact current conservation and current covariance are satisfied by using this current to compute a linearly independent set of current matrix elements. The remaining current matrix elements are generated from the independent matrix elements using the covariance and current conservation constraints. The presence of the exchange current increases the sensitivity to the choice of independent current matrix elements. Two choices of independent matrix elements that have distinct motivations lead to a good description of all of the elastic scattering observables for momentum transfers below 8 (GeV)$^2$. ,Exchange current contributions in null-plane quantum models of elastic   electron deuteron scattering
"  In the study of nonlinear evolutions, the method of adiabatic approximation is an essential tool to reduce an infinite dimensional dynamical system to a simpler, possibly finite dimensional one.In this paper, we formulate a generic scheme of adiabatic approximation that is valid foran abstract dissipative, conservative or dispersive evolution under mild regularity assumptions.The key prerequisite for the scheme is the existence of what we call approximate solitons. These are some low energy but not necessarily stationary configurations, which we use to approximate nearby evolutions with systematically minimized errors.   The main result is analogous to nonlinear stability: Given an initial configuration sufficiently close to the manifold of approximate solitons, the evolution generated by the former stays close to this manifold. Moreover, the full evolution reduces in a suitable sense to an evolution on the moduli space of the approximate solitons. Both assertions hold in a long but possibly finite interval, determined by the type of evolution and the properties of the approximate solitons. We present some applications to phase field theory. ",A generic framework of adiabatic approximation for evolutions with   focusing nonlinearity
"  We investigate the evolutionary prisoner's dilemma game in structured populations by introducing dimers, which are defined as that two players in each dimer always hold a same strategy. We find that influences of dimers on cooperation depend on the type of dimers and the population structure. For those dimers in which players interact with each other, the cooperation level increases with the number of dimers though the cooperation improvement level depends on the type of network structures. On the other hand, the dimers, in which there are not mutual interactions, will not do any good to the cooperation level in a single community, but interestingly, will improve the cooperation level in a population with two communities. We explore the relationship between dimers and self-interactions and find that the effects of dimers are similar to that of self-interactions. Also, we find that the dimers, which are established over two communities in a multi-community network, act as one type of interaction through which information between communities is communicated by the requirement that two players in a dimer hold a same strategy. ",Effects of dimers on cooperation in the spatial prisoner's dilemma game
"  To every partition $n=n_1+n_2+\cdots+n_s$ one can associate a vertex operator realization of the Lie algebras $a_{\infty}$ and $\hat{gl}_n$. Using this construction we obtain reductions of the $s$--component KP hierarchy, reductions which are related to these partitions. In this way we obtain matrix KdV type equations. We show that the following two constraints on a KP $\tau$--function are equivalent (1) $\tau$ is a $\tau$--function of the $[n_1,n_2,\ldots,n_s]$--th reduced KP hierarchy which satisfies string equation, $L_{-1}\tau=0$, (2) $\tau$ satisfies the vacuum constraints of the $W_{1+\infty}$ algebra. Talk given at the V International Conference on Mathematical Physics, String Theory and Quantum Gravity at Alushta, June 10-20 1994 ","The $[n_1,n_2,\ldots,n_s]$--th reduced KP hierarchy and $W_{1+\infty}$   constraints"
"  We present the results from the first ensemble prediction model for major solar flares (M and X classes). The primary aim of this investigation is to explore the construction of an ensemble for an initial prototyping of this new concept. Using the probabilistic forecasts from three models hosted at the Community Coordinated Modeling Center (NASA-GSFC) and the NOAA forecasts, we developed an ensemble forecast by linearly combining the flaring probabilities from all four methods. Performance-based combination weights were calculated using a Monte-Carlo-type algorithm that applies a decision threshold $P_{th}$ to the combined probabilities and maximizing the Heidke Skill Score (HSS). Using the data for 13 recent solar active regions between years 2012 - 2014, we found that linear combination methods can improve the overall probabilistic prediction and improve the categorical prediction for certain values of decision thresholds. Combination weights vary with the applied threshold and none of the tested individual forecasting models seem to provide more accurate predictions than the others for all values of $P_{th}$. According to the maximum values of HSS, a performance-based weights calculated by averaging over the sample, performed similarly to a equally weighted model. The values $P_{th}$ for which the ensemble forecast performs the best are 25 \% for M-class flares and 15 \% for X-class flares. When the human-adjusted probabilities from NOAA are excluded from the ensemble, the ensemble performance in terms of the Heidke score, is reduced. ",Ensemble Forecasting of Major Solar Flares -- First Results
"  We theoretically investigate the local density of states (LDOS) probed by a STM tip of ferromagnetic metals hosting a single adatom and a subsurface impurity. We model the system via the two-impurity Anderson Hamiltonian. By using the equation of motion with the relevant Green functions, we derive analytical expressions for the LDOS of two host types: a surface and a quantum wire. The LDOS reveals Friedel-like oscillations and Fano interference as a function of the STM tip position. These oscillations strongly depend on the host dimension. Interestingly, we find that the spin-dependent Fermi wave numbers of the hosts give rise to spin-polarized quantum beats in the LDOS. While the LDOS for the metallic surface shows a damped beating pattern, it exhibits an opposite behavior in the quantum wire. Due to this absence of damping, the wire operates as a spatially resolved spin filter with a high efficiency. ",Dimensionality effects in the LDOS of ferromagnetic hosts probed via   STM: spin-polarized quantum beats and spin filtering
"  Given a nilpotent Lie algebra $L$ of dimension $\le 6$ on an arbitrary field of characteristic $\neq 2$, we show a direct method which allows us to detect the capability of $L$ via computations on the size of its nonabelian exterior square $L \wedge L$. For dimensions higher than $ 6$, we show a result of general nature, based on the evidences of the low dimensional case, focusing on generalized Heisenberg algebras. Indeed we detect the capability of $L \wedge L$ via the size of the Schur multiplier $M(L/Z^\wedge(L))$ of $L/Z^\wedge(L)$, where $Z^\wedge(L)$ denotes the exterior center of $L$. ",Capability of nilpotent Lie algebras of small dimension
"  In the weak field regime, gravitational waves can be considered as being made up of collisionless, relativistic tensor modes that travel along null geodesics of the perturbed background metric. We work in this geometric optics picture to calculate the anisotropies in gravitational wave backgrounds resulting from astrophysical and cosmological sources. Our formalism yields expressions for the angular power spectrum of the anisotropies. We show how the anisotropies are sourced by intrinsic, Doppler, Sachs-Wolfe, and Integrated Sachs-Wolfe terms in analogy with Cosmic Microwave Background photons. ",Anisotropies of Gravitational Wave Backgrounds: A Line Of Sight Approach
"  Classical rate theories often fail in cases where the observable(s) or order parameter(s) used are poor reaction coordinates or the observed signal is deteriorated by noise, such that no clear separation between reactants and products is possible. Here, we present a general spectral two-state rate theory for ergodic dynamical systems in thermal equilibrium that explicitly takes into account how the system is observed. The theory allows the systematic estimation errors made by standard rate theories to be understood and quantified. We also elucidate the connection of spectral rate theory with the popular Markov state modeling (MSM) approach for molecular simulation studies. An optimal rate estimator is formulated that gives robust and unbiased results even for poor reaction coordinates and can be applied to both computer simulations and single-molecule experiments. No definition of a dividing surface is required. Another result of the theory is a model-free definition of the reaction coordinate quality (RCQ). The RCQ can be bounded from below by the directly computable observation quality (OQ), thus providing a measure allowing the RCQ to be optimized by tuning the experimental setup. Additionally, the respective partial probability distributions can be obtained for the reactant and product states along the observed order parameter, even when these strongly overlap. The effects of both filtering (averaging) and uncorrelated noise are also examined. The approach is demonstrated on numerical examples and experimental single-molecule force probe data of the p5ab RNA hairpin and the apo-myoglobin protein at low pH, here focusing on the case of two-state kinetics. ",Spectral rate theory for projected two-state kinetics
"  We study the topological $G_2$ and $Spin(7)$ strings at 1-loop. We define new double complexes for supersymmetric NSNS backgrounds of string theory using generalised geometry. The 1-loop partition function then has a target-space interpretation as a particular alternating product of determinants of Laplacians, which we have dubbed the analytic torsion. In the case without flux where these backgrounds have special holonomy, we reproduce the worldsheet calculation of the $G_2$ string and give a new prediction for the $Spin(7)$ string. We also comment on connections with topological strings on Calabi-Yau and K3 backgrounds. ",Topological G$_{2}$ and Spin(7) strings at 1-loop from double complexes
  We investigate the $J_1$-$J_2$ Heisenberg model on the triangular lattice with an additional scalar chirality term and show that a chiral spin liquid is stabilized in a sizeable region of the phase diagram. This topological phase is situated in between a coplanar $120^\circ$ N\'{e}el ordered and a non-coplanar tetrahedrally ordered phase. Furthermore we discuss the nature of the spin-disordered intermediate phase in the $J_1$-$J_2$ model. We compare the groundstates from Exact Diagonalization with a Dirac spin liquid wavefunction and propose a scenario where this wavefunction describes the quantum critical point between the $120^\circ$ magnetically ordered phase and a putative $\mathbb{Z}_2$ spin liquid. ,Chiral Spin Liquid and Quantum Criticality in Extended $S=1/2$   Heisenberg Models on the Triangular Lattice
"  The potentials between two B-mesons are computed in the heavy-quark limit using quenched lattice QCD at $m_\pi\sim 400~{\rm MeV}$. Non-zero central potentials are clearly evident in all four spin-isospin channels, (I,s_l) = (0,0) , (0,1) , (1,0) , (1,1), where s_l is the total spin of the light degrees of freedom. At short distance, we find repulsion in the $I\ne s_l$ channels and attraction in the I=s_l channels. Linear combinations of these potentials that have well-defined spin and isospin in the t-channel are found, in three of the four cases, to have substantially smaller uncertainties than the potentials defined with the s-channel (I,s_l), and allow quenching artifacts from single hairpin exchange to be isolated. The BB*\pi coupling extracted from the long-distance behavior of the finite-volume t-channel potential is found to be consistent with quenched calculations of the matrix element of the isovector axial-current. The tensor potentials in both of the s_l = 1 channels are found to be consistent with zero within calculational uncertainties. ",BB Potentials in Quenched Lattice QCD
"  Wind topographically forced by hills and sand dunes accelerates on the upwind (stoss) slopes and reduces on the downwind (lee) slopes. This secondary wind regime, however, possesses a subtle effect, reported here for the first time from field measurements of near-surface wind velocity over a low dune: the wind velocity close to the surface reaches its maximum upwind of the crest. Our field-measured data show that this upwind phase shift of velocity with respect to topography is found to be in quantitative agreement with the prediction of hydrodynamical linear analysis for turbulent flows with first order closures. This effect, together with sand transport spatial relaxation, is at the origin of the mechanisms of dune initiation, instability and growth. ",Field evidence for the upwind velocity shift at the crest of low dunes
"  The reductions of a square complex matrix A to its canonical forms under transformations of similarity, congruence, or *congruence are unstable operations: these canonical forms and reduction transformations depend discontinuously on the entries of A. We survey results about their behavior under perturbations of A and about normal forms of all matrices A+E in a neighborhood of A with respect to similarity, congruence, or *congruence. These normal forms are called miniversal deformations of A; they are not uniquely determined by A+E, but they are simple and depend continuously on the entries of E. ",An informal introduction to perturbations of matrices determined up to   similarity or congruence
"  This paper establishes the continuity of the path delay operators for dynamic network loading (DNL) problems based on the Lighthill-Whitham-Richards model, which explicitly capture vehicle spillback. The DNL describes and predicts the spatial-temporal evolution of traffic flow and congestion on a network that is consistent with established route and departure time choices of travelers. The LWR-based DNL model is first formulated as a system of partial differential algebraic equations (PDAEs). We then investigate the continuous dependence of merge and diverge junction models with respect to their initial/boundary conditions, which leads to the continuity of the path delay operator through the wave-front tracking methodology and the generalized tangent vector technique. As part of our analysis leading up to the main continuity result, we also provide an estimation of the minimum network supply without resort to any numerical computation. In particular, it is shown that gridlock can never occur in a finite time horizon in the DNL model. ",Continuity of the path delay operator for dynamic network loading with   spillback
"  Audio source separation is usually achieved by estimating the short-time Fourier transform (STFT) magnitude of each source, and then applying a spectrogram inversion algorithm to retrieve time-domain signals. In particular, the multiple input spectrogram inversion (MISI) algorithm has been exploited successfully in several recent works. However, this algorithm suffers from two drawbacks, which we address in this paper. First, it has originally been introduced in a heuristic fashion: we propose here a rigorous optimization framework in which MISI is derived, thus proving the convergence of this algorithm. Besides, while MISI operates offline, we propose here an online version of MISI called oMISI, which is suitable for low-latency source separation, an important requirement for e.g., hearing aids applications. oMISI also allows one to use alternative phase initialization schemes exploiting the temporal structure of audio signals. Experiments conducted on a speech separation task show that oMISI performs as well as its offline counterpart, thus demonstrating its potential for real-time source separation. ",Online Spectrogram Inversion for Low-Latency Audio Source Separation
  In the paper we consider the point measure that corresponds to Arratia flow. The central limit theorem of the multiple integrals with respect to this measure was obtained. ,Gaussian structure in coalescing stochastic flows
"  Finding the common subsequences of $L$ multiple strings has many applications in the area of bioinformatics, computational linguistics, and information retrieval. A well-known result states that finding a Longest Common Subsequence (LCS) for $L$ strings is NP-hard, e.g., the computational complexity is exponential in $L$. In this paper, we develop a randomized algorithm, referred to as {\em Random-MCS}, for finding a random instance of Maximal Common Subsequence ($MCS$) of multiple strings. A common subsequence is {\em maximal} if inserting any character into the subsequence no longer yields a common subsequence. A special case of MCS is LCS where the length is the longest. We show the complexity of our algorithm is linear in $L$, and therefore is suitable for large $L$. Furthermore, we study the occurrence probability for a single instance of MCS and demonstrate via both theoretical and experimental studies that the longest subsequence from multiple runs of {\em Random-MCS} often yields a solution to $LCS$. ",A Fast Randomized Algorithm for Finding the Maximal Common Subsequences
"  This paper studies real-world road networks from an algorithmic perspective, focusing on empirical studies that yield useful properties of road networks that can be exploited in the design of fast algorithms that deal with geographic data. Unlike previous approaches, our study is not based on the assumption that road networks are planar graphs. Indeed, based on the a number of experiments we have performed on the road networks of the 50 United States and District of Columbia, we provide strong empirical evidence that road networks are quite non-planar. Our approach therefore instead is directed at finding algorithmically-motivated properties of road networks as non-planar geometric graphs, focusing on alternative properties of road networks that can still lead to efficient algorithms for such problems as shortest paths and Voronoi diagrams. In particular, we study road networks as multiscale-dispersed graphs, which is a concept we formalize in terms of disk neighborhood systems. This approach allows us to develop fast algorithms for road networks without making any additional assumptions about the distribution of edge weights. In fact, our algorithms can allow for non-metric weights. ",Studying Geometric Graph Properties of Road Networks Through an   Algorithmic Lens
"  Most of the statistical tests currently used to detect differentially expressed genes are based on asymptotic results, and perform poorly for low expression tags. Another problem is the common use of a single canonical cutoff for the significance level (p-value) of all the tags, without taking into consideration the type II error and the highly variable character of the sample size of the tags.   This work reports the development of two significance tests for the comparison of digital expression profiles, based on frequentist and Bayesian points of view, respectively. Both tests are exact, and do not use any asymptotic considerations, thus producing more correct results for low frequency tags than the chi-square test. The frequentist test uses a tag-customized critical level which minimizes a linear combination of type I and type II errors. A comparison of the Bayesian and the frequentist tests revealed that they are linked by a Beta distribution function. These tests can be used alone or in conjunction, and represent an improvement over the currently available methods for comparing digital profiles. ",Significance tests for comparing digital gene expression profiles
"  The formation of the projectile spectator and the fragmentation processes in 107,124Sn + 120Sn collisions at 600 MeV/nucleon are studied with the isospin-dependent quantum molecular dynamics (IQMD) model. The minimum spanning tree algorithm and the ratio of parallel to transverse kinetic quantities are applied to identify the equilibrated projectile spectator during the dynamical evolution. The influence of secondary decay on fragmentation observables is investigated by performing calculations with and without the statistical code GEMINI. The validity of the theoretical approach is examined by comparing the calculated product yields and correlations with the experimental results of the ALADIN Collaboration for the studied reactions. ","Dynamical properties and secondary decay effects of projectile   fragmentation in 107,124Sn + 120Sn collisions at 600 MeV/nucleon"
"  We investigate the distribution of relative velocities between small heavy particles of different sizes in turbulence by analysing a statistical model for bidisperse turbulent suspensions, containing particles with two different Stokes numbers. This number, ${\rm St}$, is a measure of particle inertia which in turn depends on particle size. When the Stokes numbers are similar, the distribution exhibits power-law tails, just as in the case of equal ${\rm St}$. The power-law exponent is a non-analytic function of the mean Stokes number $\overline{\rm St}$, so that the exponent cannot be calculated in perturbation theory around the advective limit. When the Stokes-number difference is larger, the power law disappears, but the tails of the distribution still dominate the relative-velocity moments, if $\overline{\rm St}$ is large enough. ",Relative velocities in bidisperse turbulent suspensions
"  We give a brief summary of the Dyson-Schwinger and Bethe-Salpeter approach to hadron spectroscopy and report on recent progress in determining resonance properties in this framework. We exemplify the extraction of resonances using a scalar model, where we solve the scattering equation for the four-point scattering amplitude and extract the pole locations on the second Riemann sheet as well as the phase shifts. ",Towards resonance properties in the Dyson-Schwinger approach
"  The SLIM experiment was an array of 427 m^2 of nuclear track detectors, exposed at a high altitude laboratory (Chacaltaya, Bolivia, 5230 m a.s.l.), for ~4.22 years. SLIM was sensitive to downgoing intermediate mass magnetic monopoles with masses in the range 10^5 to 10^12 GeV. The analysis of the full detector gives a flux upper limit of 1.3x10^{-15} 1/(cm^2*s*sr) (90% C.L.) for downgoing fast intermediate magnetic monopoles. ",Magnetic Monopole Search with the SLIM Experiment
"  The endpoint distribution and dynamics of semiflexible fibers is studied by numerical simulation. A brief overview is given over the analytical theory of flexible and semiflexible polymers. In particular, a closed expression is given for the relaxation spectrum of wormlike chains, which determines polymer diffusion and rheology. Next a simulation model for wormlike chains with full hydrodynamic interaction is described, and relations for the bending and torsion modulus are given. Two methods are introduced to include torsion stiffness into the model. The model is validated by simulating single chains in a heat bath, and comparing the endpoint distribution of the chains with established Monte Carlo results. It is concluded that torsion stiffness leads to a slightly shorter effective persistence length for a given bending stiffness. To further validate the simulation model, polymer diffusion is studied for fixed persistence length and varying polymer length N. The diffusion constant shows crossover from Rouse to reptation behaviour. The terminal relaxation time obtained from the monomer displacement is consistent with the theory of wormlike chains. The probability for chain crossing has also been studied. This probability is so low that it does not influence the present results. ",Mesoscale simulation of semiflexible chains. I. Endpoint distribution   and chain dynamics
"  Recently, researchers utilize Knowledge Graph (KG) as side information in recommendation system to address cold start and sparsity issue and improve the recommendation performance. Existing KG-aware recommendation model use the feature of neighboring entities and structural information to update the embedding of currently located entity. Although the fruitful information is beneficial to the following task, the cost of exploring the entire graph is massive and impractical. In order to reduce the computational cost and maintain the pattern of extracting features, KG-aware recommendation model usually utilize fixed-size and random set of neighbors rather than complete information in KG. Nonetheless, there are two critical issues in these approaches: First of all, fixed-size and randomly selected neighbors restrict the view of graph. In addition, as the order of graph feature increases, the growth of parameter dimensionality of the model may lead the training process hard to converge. To solve the aforementioned limitations, we propose GraphSW, a strategy based on stage-wise training framework which would only access to a subset of the entities in KG in every stage. During the following stages, the learned embedding from previous stages is provided to the network in the next stage and the model can learn the information gradually from the KG. We apply stage-wise training on two SOTA recommendation models, RippleNet and Knowledge Graph Convolutional Networks (KGCN). Moreover, we evaluate the performance on six real world datasets, Last.FM 2011, Book-Crossing,movie, LFM-1b 2015, Amazon-book and Yelp 2018. The result of our experiments shows that proposed strategy can help both models to collect more information from the KG and improve the performance. Furthermore, it is observed that GraphSW can assist KGCN to converge effectively in high-order graph feature. ",GraphSW: a training protocol based on stage-wise training for GNN-based   Recommender Model
  We present an analysis of the diffuse ultraviolet (UV) emission near the Taurus Molecular Cloud based on observations made by the Galaxy Evolution Explorer (GALEX). We used a Monte Carlo dust scattering model to show that about half of the scattered flux originates in the molecular cloud with 25% arising in the foreground and 25% behind the cloud. The best-fit albedo of the dust grains is 0.3 but the geometry is such that we could not constrain the phase function asymmetry factor (g). ,Dust Scattering from the Taurus Molecular Cloud
  We develop a microscopic theory describing the peak in the temperature dependence of the non-local resistance of three-terminal NSN devices. This peak emerges at sufficiently high temperatures as a result of a competition between quasiparticle/charge imbalance and subgap (Andreev) contributions to the conductance matrix. Both the height and the shape of this peak demonstrate the power law dependence on the superconductor thickness $L$ in contrast to the zero-temperature non-local resistance which decays (roughly) exponentially with increasing $L$. A similar behavior was observed in recent experiments. ,Non-local electron transport and cross-resistance peak in NSN   heterostructures
"  We define closed model category structures on different categories connected to the world of operad algebras over the category C(k) of (unbounded) complexes of k-modules: on the category of operads, on the category of algebras over a fixed operad, on the category of modules over a fixed operad algebra. In Sections 2 - 6 we define the necessary structures and provide some standard comparison results. In Section 7 we define cotangent complex. In Section 8 we define a canonical structure of homotopy Lie algebra on the tangent complex. ",Homological algebra of homotopy algebras
"  We consider a variant of the planted clique problem where we are allowed unbounded computational time but can only investigate a small part of the graph by adaptive edge queries. We determine (up to logarithmic factors) the number of queries necessary both for detecting the presence of a planted clique and for finding the planted clique.   Specifically, let $G \sim G(n,1/2,k)$ be a random graph on $n$ vertices with a planted clique of size $k$. We show that no algorithm that makes at most $q = o(n^2 / k^2 + n)$ adaptive queries to the adjacency matrix of $G$ is likely to find the planted clique. On the other hand, when $k \geq (2+\epsilon) \log_2 n$ there exists a simple algorithm (with unbounded computational power) that finds the planted clique with high probability by making $q = O( (n^2 / k^2) \log^2 n + n \log n)$ adaptive queries. For detection, the additive $n$ term is not necessary: the number of queries needed to detect the presence of a planted clique is $n^2 / k^2$ (up to logarithmic factors). ",Finding a planted clique by adaptive probing
"  Low dimensional magnetism has been powerfully boosted as a promising candidate for numerous applications. The stability of the long-range magnetic order is directly dependent on the electronic structure and the relative strength of the competing magnetic exchange constants. Here, we report a comparative pressure-dependent theoretical and experimental study of the electronic structure and exchange interactions of two-dimensional ferromagnets CrBr3 and Cr2Ge2Te6 . While CrBr3 is found to be a Mott-Hubbard-like insulator, Cr2Ge2Te6 shows a charge-transfer character due to the broader character of the Te 5p bands at the Fermi level. This different electronic behaviour is responsible of the robust insulating state of CrBr3 , in which the magnetic exchange constants evolve monotonically with pressure, and the proximity to a metal-insulator transition predicted for Cr2Ge2Te6 , which causes a non-monotonic evolution of its magnetic ordering temperature. We provide a microscopic understanding for the pressure evolution of the magnetic properties of the two systems. ",Electronic structure and magnetic exchange interactions of Cr-based van   der Waals ferromagnets. A comparative study between CrBr3 and Cr2Ge2Te6
"  In our previous paper [math.NT/0408050], we established a correspondence between vector-valued holomorphic Siegel modular forms and cohomology with local coefficients for local symmetric spaces $X$ attached to real orthogonal groups of type $(p,q)$. This correspondence is realized using theta functions associated to explicitly constructed ""special"" Schwartz forms. Furthermore, the theta functions give rise to generating series of certain ""special cycles"" in $X$ with coefficients.   In this paper, we study the boundary behaviour of these theta functions in the non-compact case and show that the theta functions extend to the Borel-Sere compactification $\bar{X}$ of $X$. However, for the $\Q$-split case for signature $(p,p)$, we have to construct and consider a slightly larger compactification, the ""big"" Borel-Serre compactification. The restriction to each face of $\bar{X}$ is again a theta series as in [math.NT/0408050], now for a smaller orthogonal group and a larger coefficient system.   As application we establish the cohomological nonvanishing of the special (co)cycles when passing to an appropriate finite cover of $X$. In particular, the (co)homology groups in question do not vanish. ",Boundary behavior of special cohomology classes arising from the Weil   representation
"  New polarization potentials have been determined based on: 1) the latest photo-neutron cross section evaluation and a missing factor of two in previous work, and 2) the mass dependency of the symmetry energy, $a_{sym}(A)$. The magnitude of the first one is 35\% stronger than the currently accepted polarization potential. The second one opens up the possibility for a parameter-free polarization potential. Both polarization potentials are essentially the same for heavy nuclei. The polarization effect on quadrupole collectivity is more substantial than previously assumed for light nuclei. Particular cases are discussed where long-standing discrepancies between high-precision Coulomb-excitation and lifetime measurements still remain. A solution to the long-standing discrepancy between $B(E2; 0^+_1\rightarrow 2^+_1)$ values determined in $^{18}$O by several Coulomb-excitation studies and a high-precision lifetime measurement is provided in favor of the latter. Polarization effects in light nuclei also influence the determination of spectroscopic quadrupole moments in Coulomb-excitation measurements. The hindrance of polarizability observed in the photo-neutron cross section for single-closed shell nuclei is calculated to have a negligible effect on quadrupole collectivity, within the existing experimental uncertainties. ",Nuclear polarization effects in Coulomb excitation studies
"  In this chapter, the regulation of Unmanned Aerial Vehicle (UAV) communication network is investigated in the presence of dynamic changes in the UAV lineup and user distribution. We target an optimal UAV control policy which is capable of identifying the upcoming change in the UAV lineup (quit or join-in) or user distribution, and proactively relocating the UAVs ahead of the change rather than passively dispatching the UAVs after the change. Specifically, a deep reinforcement learning (DRL)-based UAV control framework is developed to maximize the accumulated user satisfaction (US) score for a given time horizon which is able to handle the change in both the UAV lineup and user distribution. The framework accommodates the changed dimension of the state-action space before and after the UAV lineup change by deliberate state transition design. In addition, to handle the continuous state and action space, deep deterministic policy gradient (DDPG) algorithm, which is an actor-critic based DRL, is exploited. Furthermore, to promote the learning exploration around the timing of the change, the original DDPG is adapted into an asynchronous parallel computing (APC) structure which leads to a better training performance in both the critic and actor networks. Finally, extensive simulations are conducted to validate the convergence of the proposed learning approach, and demonstrate its capability in jointly handling the dynamics in UAV lineup and user distribution as well as its superiority over a passive reaction method. ",Responsive Regulation of Dynamic UAV Communication Networks Based on   Deep Reinforcement Learning
"  In terms of spin-charge separated variables, the Minkowski space Yang-Mills BPST instanton describes a locally conformally flat doubly-wrapped cigar manifold that can be viewed as a Euclidean quantum black hole. An ensemble of instantons then corresponds to a ``spacetime foam'' that creates a locally conformally flat spacetime from ``nothing'' as a quantum fluctuation. ",Yang-Mills instanton as a quantum black hole
"  The birefringent fermions possess a spectrum with two distinct Fermi velocities. Here based on the lattice model, we use the mean-field method to investigate the interaction-induced phase transitions of the birefringent fermions. We consider both the short-range nearest-neighbor (NN) and next-nearest-neighbor (NNN) repulsive interactions and calculate the phase diagrams under different conditions. We find that the NN interactions can induce the asymmetric charge density wave order, while the NNN interactions can drive the asymmetric quantum anomalous Hall order (AQAH) in the large limit of anisotropy in the hopping integrals, \beta\rightarrow 1. The AQAH order is characterized by the unequal loop currents connecting the NNN sites and by the appearance of a gap between the two conduction (valence) bands. Such asymmetric fermionic orders can be attributed to the specific lattice geometry of the birefringent fermions. The implications of our results for experiments are also discussed. ",Emergence of asymmetric fermionic order in interacting birefringent   fermions
"  Recently-developed variational perturbation expansions converge exponentially fast for positive coupling constants. They do not, however, possess the correct left-hand cut in the complex coupling constant plane, implying a wrong large-order behavior of their Taylor expansion coefficients. We correct this deficiency and present a method of resumming divergent series with their proper large-order behavior. For a given set of expansion coefficients, knowledge of the large-order behavior considerably improves the quality of the approximation. ",Variational Resummation of Divergent Series with known Large-Order   Behavior
"  The low-energy sector of QCD with $N_f = 2\!+\!1$ dynamical quark flavors at non-vanishing chemical potential and temperature is studied with a non-perturbative functional renormalization group method. The analysis is performed in different truncations in order to explore fluctuation-induced modifications of the quark-meson correlations as well as quark and meson propagators on the chiral phase transition of QCD. Depending on the chosen truncation significant quantitative implications on the phase transition are found. In the chirally symmetric phase, the quark flavor composition of the pseudoscalar $(\eta,\eta^{\prime})$-meson complex turns out to be drastically sensitive to fluctuation-induced modifications in the presence of the axial $U(1)_A$ anomaly. This has important phenomenological consequences for the assignment of chiral partners to these mesons. ",Fluctuation-induced modifications of the phase structure in (2+1)-flavor   QCD
"  The camera's focal plane array (FPA) fill factor is one of the parameters for digital cameras, though it is not widely known and usually not reported in specs sheets. The fill factor of an imaging sensor is defined as the ratio of a pixel's light sensitive area to its total theoretical area. It is generally believed that the lower fill factor may reduce the accuracy of photogrammetric measurements. But nevertheless, there are no studies addressing the effect of the imaging sensor's fill factor on digital image correlation (DIC) measurement accuracy. We report on research aiming to quantify the effect of fill factor on DIC measurements accuracy in terms of displacement error and strain error. We use rigid-body-translation experiments then numerically modify the recorded images to synthesize three different types of images with 1/4 of the original resolution. Each type of the synthesized images has different value of the fill factor; namely 100%, 50% and 25%. By performing DIC analysis with the same parameters on the three different types of synthesized images, the effect of fill factor on measurement accuracy may be realized. Our results show that the FPA's fill factor can have a significant effect on the accuracy of DIC measurements. This effect is clearly dependent on the type and characteristics of the speckle pattern. The fill factor has a clear effect on measurement error for low contrast speckle patterns and for high contrast speckle patterns (black dots on white background) with small dot size (3 pixels dot diameter). However, when the dot size is large enough (about 7 pixels dot diameter), the fill factor has very minor effect on measurement error. ",Effect of Camera's Focal Plane Array Fill Factor on Digital Image   Correlation Measurement Accuracy
"  Prediction models are often employed in estimating parameters of optimization models. Despite the fact that in an end-to-end view, the real goal is to achieve good optimization performance, the prediction performance is measured on its own. While it is usually believed that good prediction performance in estimating the parameters will result in good subsequent optimization performance, formal theoretical guarantees on this are notably lacking. In this paper, we explore conditions that allow us to explicitly describe how the prediction performance governs the optimization performance. Our weaker condition allows for an asymptotic convergence result, while our stronger condition allows for exact quantification of the optimization performance in terms of the prediction performance. In general, verification of these conditions is a non-trivial task. Nevertheless, we show that our weaker condition is equivalent to the well-known Fisher consistency concept from the learning theory literature. This then allows us to easily check our weaker condition for several loss functions. We also establish that the squared error loss function satisfies our stronger condition. Consequently, we derive the exact theoretical relationship between prediction performance measured with the squared loss, as well as a class of symmetric loss functions, and the subsequent optimization performance. In a computational study on portfolio optimization, fractional knapsack and multiclass classification problems, we compare the optimization performance of using of several prediction loss functions (some that are Fisher consistent and some that are not) and demonstrate that lack of consistency of the loss function can indeed have a detrimental effect on performance. ",Risk Guarantees for End-to-End Prediction and Optimization Processes
"  In order to enable Micro-Aerial Vehicles (MAVs) to assist in complex, unknown, unstructured environments, they must be able to navigate with guaranteed safety, even when faced with a cluttered environment they have no prior knowledge of. While trajectory optimization-based local planners have been shown to perform well in these cases, prior work either does not address how to deal with local minima in the optimization problem, or solves it by using an optimistic global planner.   We present a conservative trajectory optimization-based local planner, coupled with a local exploration strategy that selects intermediate goals. We perform extensive simulations to show that this system performs better than the standard approach of using an optimistic global planner, and also outperforms doing a single exploration step when the local planner is stuck. The method is validated through experiments in a variety of highly cluttered environments including a dense forest. These experiments show the complete system running in real time fully onboard an MAV, mapping and replanning at 4 Hz. ",Safe Local Exploration for Replanning in Cluttered Unknown Environments   for Micro-Aerial Vehicles
"  Experimental evidences and theoretical motivations lead to consider the curved space-time relativity based on the de Sitter group $SO_0(1,4)$ or $Sp(2,2)$ as an appealing substitute to the flat space-time Poincare relativity. Quantum elementary systems are then associated to unitary irreducible representations of that simple Lie group. At the lowest limit of the discrete series lies a remarkable family of scalar representations involving Krein structures and related undecomposable representation cohomology which deserves to be thoroughly studied in view of quantization of the corresponding carrier fields. The purpose of this note is to present the mathematical material needed to examine the problem and to indicate possible extensions of an exemplary case, namely the so-called de Sitterian massless minimally coupled field, i.e. a scalar field in de Sitter space-time which does not couple to the Ricci curvature. ",Krein Spaces in de Sitter Quantum Theories
"  Semantic composition functions have been playing a pivotal role in neural representation learning of text sequences. In spite of their success, most existing models suffer from the underfitting problem: they use the same shared compositional function on all the positions in the sequence, thereby lacking expressive power due to incapacity to capture the richness of compositionality. Besides, the composition functions of different tasks are independent and learned from scratch. In this paper, we propose a new sharing scheme of composition function across multiple tasks. Specifically, we use a shared meta-network to capture the meta-knowledge of semantic composition and generate the parameters of the task-specific semantic composition models. We conduct extensive experiments on two types of tasks, text classification and sequence tagging, which demonstrate the benefits of our approach. Besides, we show that the shared meta-knowledge learned by our proposed model can be regarded as off-the-shelf knowledge and easily transferred to new tasks. ",Meta Multi-Task Learning for Sequence Modeling
"  We derive the mass function of condensations (clumps) which were formed through a turbulent cascade over a range of spatial scales $L\le20$ pc during early, predominantly turbulent evolution of a molecular cloud. The approach rests upon the assumption of a statistical clump mass-density relationship $n\propto m^x$ with a scale dependence of the exponent $x$ obtained from equipartition relations between various forms of energy of clumps. The derived clump mass function (ClMF) could be represented by series of 2 or 3 power laws, depending on the chosen equipartition relation, the velocity scaling index and the type of turbulent forcing. The high-mass ClMF exhibits an average slope $\Gamma\simeq-1$, typical for fractal clouds, whereas its intermediate-mass part is shallower or flattened, in agreement with some observational studies. ",Clump mass function at an early stage of molecular cloud evolution: I. A   statistical approach
"  We present a simple primary colour editing method for consumer product images. We show that by using colour correction and colour blending, we can automate the pain-staking colour editing task and save time for consumer colour preference researchers. To improve the colour harmony between the primary colour and its complementary colours, our algorithm also tunes the other colours in the image. Preliminary experiment has shown some promising results compared with a state-of-the-art method and human editing. ",Simple Primary Colour Editing for Consumer Product Images
"  A DJ mix is a sequence of music tracks concatenated seamlessly, typically rendered for audiences in a live setting by a DJ on stage. As a DJ mix is produced in a studio or the live version is recorded for music streaming services, computational methods to analyze DJ mixes, for example, extracting track information or understanding DJ techniques, have drawn research interests. Many of previous works are, however, limited to identifying individual tracks in a mix or segmenting it, and the sizes of the datasets are usually small. In this paper, we provide an in-depth analysis of DJ music by aligning a mix to its original music tracks. We set up the subsequence alignment such that the audio features are less sensitive to the tempo or key change of the original track in a mix. This approach provides temporally tight mix-to-track matching from which we can obtain cue-points, transition length, mix segmentation, and musical changes in DJ performance. Using 1,557 mixes from 1001Tracklists including 13,728 tracks and 20,765 transitions, we conduct the proposed analysis and show a wide range of statistics, which may elucidate the creative process of DJ music making. ",A Computational Analysis of Real-World DJ Mixes using Mix-To-Track   Subsequence Alignment
  We study toroidal orbifold models with topologically invariant terms in the path integral formalism and give physical interpretations of the terms from an operator formalism point of view. We briefly discuss a possibility of a new class of modular invariant orbifold models. ,Topological Terms in String Theory on Orbifolds
"  It is expected that the implementation of minimal length in quantum models leads to a consequent lowering of Planck's scale. In this paper, using the quantum model with minimal length of Kempf et al \cite{kempf0}, we examine the effect of the minimal length on the Casimir force between parallel plates. ",Casimir Effect in the Presence of Minimal Lengths
  In this paper we study a one-dimensional random motion by having a general Erlang distribution for the sojourn times of the switching process and we obtain solution of the four order hyperbolic PDE for 2-Erlang case. ,The Distribution of Random Evolution in Erlang Semi-Marov Media
"  A commonly used theoretical definition of superfluidity in the ground state of a Bose gas is based on the response of the system to an imposed velocity field or, equivalently, to twisted boundary conditions in a box. We are able to carry out this program in the case of a dilute interacting Bose gas in a trap. We prove that a gas with repulsive interactions is 100% superfluid in the dilute limit in which the Gross-Pitaevskii equation is exact. This is the first example in an experimentally realistic continuum model in which superfluidity is rigorously verified. ",Superfluidity in Dilute Trapped Bose Gases
"  Deep inelastic charged--current reactions have been studied in $e^+p$ and $e^-p$ collisions at a center of mass energy of about $300\,\gev$ in the kinematic region $Q^2\greater200\,\gev^2$ and $x\greater0.006$ using the ZEUS detector at HERA. The integrated cross sections for $Q^2\greater200\,\gev^2$ are found to be $\sigep=30.3\,{}^{+5.5}_{\mns4.2}\,{}^{+1.6}_{\mns2.6}\,{\rm pb}$ and $\sigem=54.7\,{}^{+15.9}_{\mns\chax 9.8}\,{}^{+2.8}_{\mns3.4}\,{\rm pb}$. Differential cross sections have been measured as functions of the variables $x$, $y$ and $Q^2$. From the measured differential cross sections $d\sigma/dQ^2$, the $W$ boson mass is determined to be $M_W=79\,{}^{+8} _{-7}{}^{+4}_{-4}\,\gev$. Measured jet rates and transverse energy profiles agree with model predictions. A search for charged--current interactions with a large rapidity gap yielded one candidate event, corresponding to a cross section of $\sigep(Q^2\greater200\,\gev^2;\eta_{\rm max}<2.5)=0.8\,{}_{-0.7}^ {+1.8}\,\pm0.1\,{\rm pb}$. ",Study of Charged-Current ep Interactions at Q2 > 200 GeV2 with the ZEUS   Detector at HERA
"  In 1962 Charles Hartshorne published a modal logic proof formalizing Anselm of Canterbury's ontological argument for the necessary existence of God. This article presents Kurt G\""odel's notes on this proof which have now been discovered in his Nachlass among other theological material, and discusses possible influences on the development of G\""odel's own ontological proof. To complete the picture, strong connections between Anselm of Canterbury's and G\""odel's conceptions of God and his positive properties are pointed out. ","Kurt G\""odel's reception of Charles Hartshorne's ontological proof"
"  Filliman duality expresses (the characteristic measure of) a convex polytope P containing the origin as an alternating sum of simplices that share supporting hyperplanes with P. The terms in the alternating sum are given by a triangulation of the polar body P^o. The duality can lead to useful formulas for the volume of P. A limiting case called Lawrence's algorithm can be used to compute the Fourier transform of P.   In this note we extend Filliman duality to an involution on the space of polytopal measures on a finite-dimensional vector space, excluding polytopes that have a supporting hyperplane coplanar with the origin. As a special case, if P is a convex polytope containing the origin, any realization of P^o as a linear combination of simplices leads to a dual realization of P. ",A generalization of Filliman duality
"  We analyze the entanglement properties of the asymptotic steady state after a quench from free to hard-core bosons in one dimension. The R\'enyi and von Neumann entanglement entropies are found to be extensive, and the latter coincides with the thermodynamic entropy of the Generalized Gibbs Ensemble (GGE). Computing the spectrum of the two-point function, we provide exact analytical results both for the leading extensive parts and the subleading terms for the entropies as well as for the cumulants of the particle number fluctuations. We also compare the extensive part of the entanglement entropy with the thermodynamic ones, showing that the GGE entropy equal the entanglement one and it is the double of the diagonal entropy. ",Stationary entanglement entropies following an interaction quench in 1D   Bose gas
"  In many discharges at ASDEX Upgrade fast particle losses can be observed due to Alfv\'enic gap modes, Reversed Shear Alfv\'en Eigenmodes or core-localized Beta Alfv\'en Eigenmodes. For the first time, simulations of experimental conditions in the ASDEX Upgrade fusion device are performed for different plasma equilibria (particularly for different, also non-monotonic q profiles). The numerical tool is the extended version of the HAGIS code [Pinches'98, Br\""udgam PhD Thesis, 2010], which also computes the particle motion in the vacuum region between vessel wall in addition to the internal plasma volume. For this work, a consistent fast particle distribution function was implemented to represent the strongly anisotropic fast particle population as generated by ICRH minority heating. Furthermore, HAGIS was extended to use more realistic eigenfunctions, calculated by the gyrokinetic eigenvalue solver LIGKA [Lauber'07]. The main aim of these simulations is to allow fast ion loss measurements to be interpreted with a theoretical basis. Fast particle losses are modeled and directly compared with experimental measurements [Garc\'ia-Mu\~noz'10]. The phase space distribution and the mode-correlation signature of the fast particle losses allows them to be characterized as prompt, resonant or diffusive (non-resonant). The experimental findings are reproduced numerically. It is found that a large number of diffuse losses occur in the lower energy range (at around 1/3 of the birth energy) particularly in multiple mode scenarios (with different mode frequencies), due to a phase space overlap of resonances leading to a so-called domino [Berk'95] transport process. In inverted q profile equilibria, the combination of radially extended global modes and large particle orbits leads to losses with energies down to 1/10th of the birth energy. ",Multi-mode Alfv\'enic Fast Particle Transport and Losses: Numerical vs.   Experimental Observation
"  Exact RG equations are discussed with emphasis on the role of the anomalous dimension $\eta$. For the Polchinski equation this may be introduced as a free parameter reflecting the freedom of such equations up to contributions which vanish in the functional integral. The exact value of $\eta$ is only determined by the requirement that there should exist a well defined non trivial limit at a IR fixed point. The determination of $\eta$ is related to the existence of an exact marginal operator, for which an explicit form is given. The results are extended to the exact Wetterich RG equation for the one particle irreducible action $\Gamma$ by a Legendre transformation. An alternative derivation of the derivative expansion is described. An application to $\N=2$ supersymmetric theories in three dimensions is described where if an IR fixed point exists then $\eta$ is not small. ",Remarks on Exact RG Equations
"  The contour argument was introduced by Peierls for two dimensional Ising model. Peierls benefited from the particular symmetries of the Ising model. For non-symmetric models the argument was developed by Pirogov and Sinai. It is very general and rather difficult. Intuitively clear that the Peierls argument does work for any symmetric model. But contours defined in Pirogov-Sinai theory do not work if one wants to use Peierls argument for more general symmetric models. We give a new definition of contour which allows relatively easier prove the main result of the Pirogov-Sinai theory for symmetric models. Namely, our contours allow us to apply the classical Peierls argument (with contour removal operation). ",Pirogov-Sinai Theory With New Contours for Symmetric Models
"  In recognition-based action interaction, robots' responses to human actions are often pre-designed according to recognized categories and thus stiff. In this paper, we specify a new Interactive Action Translation (IAT) task which aims to learn end-to-end action interaction from unlabeled interactive pairs, removing explicit action recognition. To enable learning on small-scale data, we propose a Paired-Embedding (PE) method for effective and reliable data augmentation. Specifically, our method first utilizes paired relationships to cluster individual actions in an embedding space. Then two actions originally paired can be replaced with other actions in their respective neighborhood, assembling into new pairs. An Act2Act network based on conditional GAN follows to learn from augmented data. Besides, IAT-test and IAT-train scores are specifically proposed for evaluating methods on our task. Experimental results on two datasets show impressive effects and broad application prospects of our method. ",Learning End-to-End Action Interaction by Paired-Embedding Data   Augmentation
"  Digital Twin is an emerging technology at the forefront of Industry 4.0, with the ultimate goal of combining the physical space and the virtual space. To date, the Digital Twin concept has been applied in many engineering fields, providing useful insights in the areas of engineering design, manufacturing, automation, and construction industry. While the nexus of various technologies opens up new opportunities with Digital Twin, the technology requires a framework to integrate the different technologies, such as the Building Information Model used in the Building and Construction industry. In this work, an Information Fusion framework is proposed to seamlessly fuse heterogeneous components in a Digital Twin framework from the variety of technologies involved. This study aims to augment Digital Twin in buildings with the use of AI and 3D reconstruction empowered by unmanned aviation vehicles. We proposed a drone-based Digital Twin augmentation framework with reusable and customisable components. A proof of concept is also developed, and extensive evaluation is conducted for 3D reconstruction and applications of AI for defect detection. ",Drone-based AI and 3D Reconstruction for Digital Twin Augmentation
"  Most exoplanets detected so far have atmospheric T significantly higher than 300K. Often close to their star, they receive an intense UV photons flux that triggers important photodissociation processes. The T dependency of VUV absorption cross sections are poorly known, leading to an undefined uncertainty in atmospheric models. Similarly, data measured at low T similar to that of the high atmosphere of Mars, Venus, and Titan are often lacking. Our aim is to quantify the T dependency of the abs. cross section of important molecules in planetary atmospheres. We want to provide both high-resolution data at T prevailing in these media and a simple parameterization of the absorption in order to simplify its use in photochemical models. This study focuses on carbon dioxide. We performed experimental measurements of CO$_2$ absorption cross section with synchrotron radiation for the wavelength range (115--200nm). For longer wavelengths (195--230nm), we used a deuterium lamp and a 1.5m Jobin-Yvon spectrometer. We used these data in our 1D thermo-photochemical model in order to study their impact on the predicted atmospheric compositions. The cross section of CO$_2$ increases with T. It can be separated in two parts: a continuum and a fine structure superimposed on the continuum. The variation of the continuum of absorption can be represented by the sum of three gaussian functions. Using data at high T in thermo-photochemical models modifies significantly the abundance and the photodissociation rates of many species, in addition to CO$_2$, such as methane and ammonia. These deviations have an impact on synthetic transmission spectra, leading to variations of up to 5 ppm. We present a full set of HR ($\Delta \lambda$=0.03nm) absorption cross sections of CO$_2$ from 115 to 230nm for T ranging from 150 to 800K. ",VUV-absorption cross section of carbon dioxide from 150 to 800 K and   applications to warm exoplanetary atmospheres
"  In the present thesis I studied the phenomenology arising from a class of string models called sequestered compactifications, which were born with the aim of getting low-energy SUSY from strings. This is not an easy task if combined with cosmological constraints, since the mechanism of moduli stabilization fixes both the scale of supersymmetric particles and the scale of moduli, which tend to be of the same order. However, if on the one hand supersymmetric particles with TeV mass are desired in order to address the hierarchy problem, on the other hand the cosmological moduli problem requires the moduli to be heavier than 100 TeV. The specific setup of sequestered compactifications makes this hierarchy achievable, at least in principle: as in these models the visible sector is located on a stack of D3-branes at singularities, a physical separation between the visible degrees of freedom and the SUSY-breaking sources takes place. Such decoupling translates into a hierarchy between the scale of SUSY-breaking and the spectrum of supersymmetric particles. Moreover, it is interesting to notice that moduli are the four-dimensional manifestation of the existence of extra-dimensions, and then their presence is a common feature of all string compactifications. Since they are gravitationally coupled, they could decay late in the history of the universe, affecting in a significant way its cosmological evolution. Possible deviations of the cosmological observables from the values predicted by the standard Hot Big Bang Theory constitute an interesting alternative for the discovery of BSM physics, which is complementary to the particle physics search. For this reason in addition to SUSY-breaking in sequestered models, I also studied several cosmological scenarios arising from them, such as production of non-thermal dark matter and dark radiation, reheating from moduli decay and inflation. ",Sequestered String Models: Supersymmetry Breaking and Cosmological   Applications
"  For the weakly coupled heterotic string (WCHS) there is a well-known factor of twenty conflict between the minimum string coupling unification scale, Lambda_H ~5x10^(17) GeV, and the projected MSSM unification scale, Lambda_U ~ 2.5x10^(16) GeV, assuming an intermediate scale desert (ISD). Renormalization effects of intermediate scale MSSM-charged exotics (ISME) (endemic to quasi-realistic string models) can resolve this issue, pushing the MSSM scale up to the string scale. However, for a generic string model, this implies that the projected Lambda_U unification under ISD is accidental. If the true unification scale is 5.0x10^(17) GeV, is it possible that illusionary unification at 2.5x10^(17) GeV in the ISD scenario is not accidental? If it is not, then under what conditions would the assumption of ISME in a WCHS model imply apparent unification at Lambda_U when ISD is falsely assumed? Geidt's ""optical unification"" suggests that Lambda_U is not accidental, by offering a mechanism whereby a generic MSSM scale Lambda_U < Lambda_H is guaranteed. A WCHS model was constructed that offers the possibility of optical unification, depending on the availability of anomaly-cancelling flat directions meeting certain requirements. This paper reports on the systematic investigation of the optical unification properties of the set of stringent flat directions of this model. Stringent flat directions can be guaranteed to be F-flat to all finite order (or to at least a given finite order consistent with electroweak scale supersymmetry breaking) and can be viewed as the likely roots of more general flat directions. Analysis of the phenomenology of stringent flat directions gives an indication of the remaining optical unification phenomenology that must be garnered by flat directions developed from them. ",Stringent Phenomenological Investigation into Heterotic String Optical   Unification
"  In this work, we present three experiences developed with 3D printing technology for teaching in Optics. These activities were planned, designed, and implemented to go deeper into knowledge about light polarization, reflection and refraction phenomena, and colour perception. The planning methodology is also detailed, in particular, the design and description of the activity. Experimental guides, 3D models and assembly manuals are available in a free and freely accessible web space. In summary, we demonstrate that the 3D printing can be used as a technological, inclusive and pedagogical resource for teaching. This methodology can be extended and adapted to other disciplines, as well as applied locally in educational institutions. ",Desarrollo de experiencias para la ense\~nanza y difusion de la Optica   con impresion 3D
  In this paper we show an application of the Minimum Spanning Tree (MST) clustering method to the high-energy gamma-ray sky observed at energies higher than 10 GeV in 6.3 years by the Fermi-Large Area Telescope. We report the detection of 19 new high-energy gamma-ray clusters with good selection parameters whose centroid coordinates were found matching the positions of known BL Lac objects in the 5th Edition of the Roma-BZCAT catalogue. A brief summary of the properties of these sources is presented. ,Application of the MST clustering to the high energy gamma-ray sky. I -   New possible detection of high-energy gamma-ray emission associated with BL   Lac objects
"  NGC 253 is a nearby spiral galaxy that is currently undergoing a nuclear burst of star formation in a 100 pc diameter region. We present spatially resolved 8--13 micron low-resolution spectra at four positions along the ridge of 8--13 micron emission. We find that the relative strengths of the ionic, dust emission features, and dust continuum emission vary with position in the galaxy but can be accounted for everywhere without recourse to extinction by silicates. The brightest mid-infrared peak (which is displaced from the nucleus) has elevated levels of both continuum and 11.1--12.9 micron `plateau' emission, indicative of dust heated within a photo-dissociation region. Spectra obtained over the course of 3 yr at the position of the brightest mid-infrared peak show no significant time variation. ",8-13 micron spectroscopy of NGC 253: a spatially resolved starburst
"  We study the mathematical structure of covariant phase observables. Such an observable can alternatively be expressed as a phase matrix, as a sequence of unit vectors, as a sequence of phase states, or as an equivalent class of covariant trace-preserving operations. Covariant generalized operator measures are defined by structure matrices which form a W*-algebra with phase matrices as its subset. The properties of the Radon-Nikodym derivatives of phase probability measures are studied. ",On the structure of covariant phase observables
"  Designing well-connected graphs is a fundamental problem that frequently arises in various contexts across science and engineering. The weighted number of spanning trees, as a connectivity measure, emerges in numerous problems and plays a key role in, e.g., network reliability under random edge failure, estimation over networks and D-optimal experimental designs. This paper tackles the open problem of designing graphs with the maximum weighted number of spanning trees under various constraints. We reveal several new structures, such as the log-submodularity of the weighted number of spanning trees in connected graphs. We then exploit these structures and design a pair of efficient approximation algorithms with performance guarantees and near-optimality certificates. Our results can be readily applied to a wide verity of applications involving graph synthesis and graph sparsification scenarios. ",Maximizing the Weighted Number of Spanning Trees: Near-$t$-Optimal   Graphs
"  In the paper, we consider the large time behavior of solutions to the convection-diffusion equation u_t - Delta u + nabla cdot f(u) = 0 in R^n times [0,infinity), where f(u) ~ u^q as u --> 0. Under the assumption that q >= 1+1/(n+beta) and the initial condition u_0 satisfies: u_0 in L^1(R^n), integral_{R^n} u_0(x) dx = 0, and |e^{t Delta}u_0|_{L^1(R^n)} <= Ct^{-beta/2} for fixed beta in (0,1), all t>0, and a constant C, we show that the L^1-norm of the solution to the convection-diffusion equation decays with the rate t^{-beta/2} as t --> infinity. Moreover, we prove that, for small initial conditions, the exponent q^* = 1+1/(n+beta) is critical in the following sense. For q > q^* the large time behavior in L^p(R^n), 1 <= p <= infinity, of solutions is described by self-similar solutions to the linear heat equation. For q = q^*, we prove that the convection-diffusion equation with f(u) = u|u|^{q^*-1} has a family of self-similar solutions which play an important role in the large time asymptotics of general solutions. ",On zero mass solutions of viscous conservation laws
"  Automatic processing of 3D Point Cloud data for object detection, tracking and segmentation is the latest trending research in the field of AI and Data Science, which is specifically aimed at solving different challenges of autonomous driving cars and getting real time performance. However, the amount of data that is being produced in the form of 3D point cloud (with LiDAR) is very huge, due to which the researchers are now on the way inventing new data compression algorithms to handle huge volumes of data thus generated. However, compression on one hand has an advantage in overcoming space requirements, but on the other hand, its processing gets expensive due to the decompression, which indents additional computing resources. Therefore, it would be novel to think of developing algorithms that can operate/analyse directly with the compressed data without involving the stages of decompression and recompression (required as many times, the compressed data needs to be operated or analyzed). This research field is termed as Compressed Domain Processing. In this paper, we will quickly review few of the recent state-of-the-art developments in the area of LiDAR generated 3D point cloud data compression, and highlight the future challenges of compressed domain processing of 3D point cloud data. ",A Quick Review on Recent Trends in 3D Point Cloud Data Compression   Techniques and the Challenges of Direct Processing in 3D Compressed Domain
  This paper describes a method for accelerating large scale Artificial Neural Networks (ANN) training using multi-GPUs by reducing the forward and backward passes to matrix multiplication. We propose an out-of-core multi-GPU matrix multiplication and integrate the algorithm with the ANN training. The experiments demonstrate that our matrix multiplication algorithm achieves linear speedup on multiple inhomogeneous GPUs. The full paper of this project can be found at [1]. ,Large Scale Artificial Neural Network Training Using Multi-GPUs
"  We present a new version of Peregrine, the tool for the analysis and parameterized verification of population protocols introduced in [Blondin et al., CAV'2018]. Population protocols are a model of computation, intensely studied by the distributed computing community, in which mobile anonymous agents interact stochastically to perform a task.   Peregrine 2.0 features a novel verification engine based on the construction of stage graphs. Stage graphs are proof certificates, introduced in [Blondin et al., CAV'2020], that are typically succinct and can be independently checked. Moreover, unlike the techniques of Peregrine 1.0, the stage graph methodology can verify protocols whose executions never terminate, a class including recent fast majority protocols. Peregrine 2.0 also features a novel proof visualization component that allows the user to interactively explore the stage graph generated for a given protocol. ",Peregrine 2.0: Explaining Correctness of Population Protocols through   Stage Graphs
"  Internet browsers use security protocols to protect sensitive messages. An inductive analysis of TLS (a descendant of SSL 3.0) has been performed using the theorem prover Isabelle. Proofs are based on higher-order logic and make no assumptions concerning beliefs or finiteness. All the obvious security goals can be proved; session resumption appears to be secure even if old session keys have been compromised. The proofs suggest minor changes to simplify the analysis. TLS, even at an abstract level, is much more complicated than most protocols that researchers have verified. Session keys are negotiated rather than distributed, and the protocol has many optional parts. Nevertheless, the resources needed to verify TLS are modest: six man-weeks of effort and three minutes of processor time. ",Inductive Analysis of the Internet Protocol TLS
"  This paper considers the problem of approximating a Boolean function $f$ using another Boolean function from a specified class. Two classes of approximating functions are considered: $k$-juntas, and linear Boolean functions. The $n$ input bits of the function are assumed to be independently drawn from a distribution that may be biased. The quality of approximation is measured by the mismatch probability between $f$ and the approximating function $g$. For each class, the optimal approximation and the associated mismatch probability is characterized in terms of the biased Fourier expansion of $f$. The technique used to analyze the mismatch probability also yields an expression for the noise sensitivity of $f$ in terms of the biased Fourier coefficients, under a general i.i.d. input perturbation model. ",Boolean Functions with Biased Inputs: Approximation and Noise   Sensitivity
"  We report the electric transport study of the three-dimensional topological insulator TlBiSe$_2$. We applied a newly developed analysis procedure and precisely determined two-carrier transport properties. Magnetotransport properties revealed a multicarrier conduction of high- and low-mobility electrons in the bulk, which was in qualitative agreement with angle-resolved photoemission results~[K. Kuroda $et~al.$, Phys. Rev. Lett. $\bm{105}$, 146801 (2010)]. The temperature dependence of the Hall mobility was explained well with the conventional Bloch-Gr{\""u}neisen formula and yielded the Debye temperature $\varTheta_{\rm{D}}=113 \pm 14$~K. The results indicate that the scattering of bulk electrons is dominated by acoustic phonons. ",Precise determination of two-carrier transport properties in the   topological insulator TlBiSe$_2$
"  It is shown that the known notion of selective coideal can be extended to a family $\mathcal{H}$ of subsets of $\mathcal{R}$, where $(\mathcal{R},\leq,r)$ is a topological Ramsey space in the sense of Todorcevic (see \cite{todo}). Then it is proven that, if $\mathcal{H}$ selective, the $\mathcal{H}$-Ramsey and $\mathcal{H}$-Baire subsets of $\mathcal{R}$ are equivalent. This extends the results of Farah in \cite{farah} for semiselective coideals of $\mathbb{N}$. Also, it is proven that the family of ${\cal H}$--Ramsey subsets of ${\cal R}$ is closed under the Souslin operation. ",Local Ramsey theory. An abstract approach
"  Deformed relativistic kinematics have been considered as a way to capture residual effects of quantum gravity. It has been shown that they can be understood geometrically in terms of a curved momentum space on a flat spacetime. In this article we present a systematic analysis under which conditions and how deformed relativistic kinematics, encoded in a momentum space metric on flat spacetime, can be lifted to curved spacetimes in terms of a self-consistent cotangent bundle geometry, which leads to purely geometric, geodesic motion of freely falling point particles. We find that momentum space metrics can be consistently lifted to curved spacetimes if they either lead to a dispersion relation which is homogeneous in the momenta, or, if they satisfy a specific symmetry constraint. The latter is relevant for the momentum space metrics encoding the most studied deformed relativistic kinematics. For these, the constraint can only be satisfied in a momentum space basis in which the momentum space metric is invariant under linear local Lorentz transformations. We discuss how this result can be interpreted and the consequences of relaxing some conditions and principles of the construction from which we started. ",Deformed relativistic kinematics on curved spacetime -- a geometric   approach
"  Wireless communication applications has acquired a vastly increasing range over the past decade. This rapidly increasing demand implies limitations on utilizing wireless resources. One of the most important resources in wireless communication is frequency spectrum. This thesis provides different solutions towards increasing the spectral efficiency. The first solution provided in this thesis is to use a more accurate optimization metric: maximal acheivable rate (compared to traditional metric: ergodic capacity) to optimize training data size in wireless communication. Training data symbols are previously known symbols to the receiver inserted in data packets which are used by receiver to acquire channel state information (CSI). Optimizing training data size with respect to our proposed tight optimization metric, we could achieve higher rates especially for short packet and ultra reliable applications. Our second proposed solution to increase spectral efficiency is to design a multifunction communication and sensing platform utilizing a special training sequence design. We proposed a platform where two training sequences are designed, one for the base-station and the other for the user. By designing these two training sequence such that they are uncorrelated to each other, the base station will be able to distinguish between the two training sequence. Having one of the sequences especially designed for radar purposes (by designing it such that it has an impulse-like autocorrelation), the system will be able to sense the environment, transmit and receive the communication data simultaneously. ",Efficient Use of Spectral Resources in Wireless Communication Using   Training Data Optimization
"  We consider a version of the stationary phase method in one dimension of A. Erd\'elyi, allowing the phase to have stationary points of non-integer order and the amplitude to have integrable singularities. After having completed the original proof and improved the error estimate in the case of regular amplitude, we consider a modification of the method by replacing the smooth cut-off function employed in the source by a characteristic function, leading to more precise remainder estimates. We exploit this refinement to study the time-asymptotic behaviour of the solution of the free Schr\""odinger equation on the line, where the Fourier transform of the initial data is compactly supported and has a singularity. We obtain asymptotic expansions with respect to time in certain space-time cones as well as uniform and optimal estimates in curved regions which are asymptotically larger than any space-time cone. These results show the influence of the frequency band and of the singularity on the propagation and on the decay of the wave packets. ","Lossless error estimates for the stationary phase method with   applications to propagation features for the Schr\""odinger equation"
"  We have recently proposed quantized gossip algorithms which solve the consensus and averaging problems on directed graphs with the least restrictive connectivity requirements. In this paper we study the convergence time of these algorithms. To this end, we investigate the shrinking time of the smallest interval that contains all states for the consensus algorithm, and the decay time of a suitable Lyapunov function for the averaging algorithm. The investigation leads us to characterizing the convergence time by the hitting time in certain special Markov chains. We simplify the structures of state transition by considering the special case of complete graphs, where every edge can be activated with an equal probability, and derive polynomial upper bounds on convergence time. ",Convergence Time Analysis of Quantized Gossip Consensus on Digraphs
"  The isomorph theory provides an explanation for the so-called power law density scaling which has been observed in many molecular and polymeric glass formers, both experimentally and in simulations. Power law density scaling (relaxation times and transport coefficients being functions of $\rho^{\gamma_S}/T$, where $\rho$ is density, $T$ is temperature, and $\gamma_S$ is a material specific scaling exponent) is an approximation to a more general scaling predicted by the isomorph theory. Furthermore, the isomorph theory provides an explanation for Rosenfeld scaling (relaxation times and transport coefficients being functions of excess entropy) which has been observed in simulations of both molecular and polymeric systems. Doing molecular dynamics simulations of flexible Lennard-Jones chains (LJC) with rigid bonds, we here provide the first detailed test of the isomorph theory applied to flexible chain molecules. We confirm the existence of isomorphs, which are curves in the phase diagram along which the dynamics is invariant in the appropriate reduced units. This holds not only for the relaxation times but also for the full time dependence of the dynamics, including chain specific dynamics such as the end-to-end vector autocorrelation function and the relaxation of the Rouse modes. As predicted by the isomorph theory, jumps between different state points on the same isomorph happen instantaneously without any slow relaxation. Since the LJC is a simple coarse-grained model for alkanes and polymers, our results provide a possible explanation for why power-law density scaling is observed experimentally in alkanes and many polymeric systems. The theory provides an independent method of determining the scaling exponent, which is usually treated as a empirical scaling parameter. ",Scaling of the dynamics of flexible Lennard-Jones chains
"  Photoacoustic Computed Tomography (PACT) is a major configuration of photoacoustic imaging, a hybrid noninvasive modality for both functional and molecular imaging. PACT has rapidly gained importance in the field of biomedical imaging due to superior performance as compared to conventional optical imaging counterparts. However, the overall cost of developing a PACT system is one of the challenges towards clinical translation of this novel technique. The cost of a typical commercial PACT system originates from optical source, ultrasound detector, and data acquisition unit. With growing applications of photoacoustic imaging, there is a tremendous demand towards reducing its cost. In this review article, we have discussed various approaches to reduce the overall cost of a PACT system, and provided a cost estimation to build a low-cost PACT system. ",Review of Cost Reduction Methods in Photoacoustic Computed Tomography
"  We study the rapidity window dependences of higher order cumulants of conserved charges observed in relativistic heavy ion collisions. The time evolution and the rapidity window dependence of the non-Gaussian fluctuations are described by the diffusion master equation. Analytic formulas for the time evolution of cumulants in a rapidity window are obtained for arbitrary initial conditions. We discuss that the rapidity window dependences of the non-Gaussian cumulants have characteristic structures reflecting the non-equilibrium property of fluctuations, which can be observed in relativistic heavy ion collisions with the present detectors. It is argued that various information on the thermal and transport properties of the hot medium can be revealed experimentally by the study of the rapidity window dependences, especially by the combined use, of the higher order cumulants. Formulas of higher order cumulants for a probability distribution composed of sub-probabilities, which are useful for various studies of non-Gaussian cumulants, are also presented. ",Rapidity window dependences of higher order cumulants and diffusion   master equation
"  We report single-shot readout of a superconducting flux qubit by using a flux-driven Josephson parametric amplifier (JPA). After optimizing the readout power, gain of the JPA and timing of the data acquisition, we observe the Rabi oscillations with a contrast of 74% which is mainly limited by the bandwidth of the JPA and the energy relaxation of the qubit. The observation of quantum jumps between the qubit eigenstates under continuous monitoring indicates the nondestructiveness of the readout scheme. ",Single-shot readout of a superconducting flux qubit with a flux-driven   Josephson parametric amplifier
"  Consider a rowwise independent triangular array of gamma random variables with varying parameters. Under several different conditions on the shape parameter, we show that the sequence of row-maximums converges weakly after linear or power transformation. Depending on the parameter combinations, we obtain both Gumbel and non-Gumbel limits.   The weak limits for maximum of the coordinates of certain Dirichlet vectors of increasing dimension are also obtained using the gamma representation. ",Maxima of Dirichlet and triangular arrays of gamma variables
"  Metagenomics is the study of environments through genetic sampling of their microbiota. Metagenomic studies produce large datasets that are estimated to grow at a faster rate than the available computational capacity. A key step in the study of metagenome data is sequence similarity searching which is computationally intensive over large datasets. Tools such as BLAST require large dedicated computing infrastructure to perform such analysis and may not be available to every researcher.   In this paper, we propose a novel approach called ScalLoPS that performs searching on protein sequence datasets using LSH (Locality-Sensitive Hashing) that is implemented using the MapReduce distributed framework. ScalLoPS is designed to scale across computing resources sourced from cloud computing providers. We present the design and implementation of ScalLoPS followed by evaluation with datasets derived from both traditional as well as metagenomic studies. Our experiments show that with this method approximates the quality of BLAST results while improving the scalability of protein sequence search. ",Scalable Protein Sequence Similarity Search using Locality-Sensitive   Hashing and MapReduce
"  An extension of the Asakura-Oosawa-Vrij model of hard sphere colloids and non-adsorbing polymers, that takes polymer non-ideality into account through a repulsive stepfunction pair potential between polymers, is studied with grand canonical Monte Carlo simulations and density functional theory. Simulation results validate previous theoretical findings for the shift of the bulk fluid demixing binodal upon increasing strength of polymer-polymer repulsion, promoting the tendency to mix. For increasing strength of the polymer-polymer repulsion, simulation and theory consistently predict the interfacial tension of the free colloidal liquid-gas interface to decrease significantly for fixed colloid density difference in the coexisting phases, and to increase for fixed polymer reservoir packing fraction. ",Simulation and theory of fluid demixing and interfacial tension of   mixtures of colloids and non-ideal polymers
"  A method is proposed to identify and localize the cause of network collapse with augmented power flow analysis for a grid model with insufficient resources. Owing to heavy network loading, insufficient generation, component failures and unavoidable disturbances, power grid models can sometimes fail to converge to a feasible solution for a steady-state power flow study. For applications such as system expansion planning, it is desirable to locate the system buses that are contributing to network infeasibilities to facilitate corrective actions. This paper proposes a novel LASSO-inspired regularization of the power flow matrix that enforces sparsity to localize and quantify infeasibilities in the network. One of the examples demonstrates how the proposed method is capable of localizing a source of blackout to a single dominant bus on an 80k+ bus eastern interconnection model. ",A LASSO-Inspired Approach for Localizing Power System Infeasibility
"  A natural extension of a right-continuous integer-valued random walk is one which can jump to the right by one or two units. First passage times above a given fixed level then admit a tractable Laplace transform (probability generating function). Explicit expressions for the probabilities that the respective overshoots are either $0$ or $1$, according as the random walk crosses a given level for the first time either continuously or not, also obtain. An interesting non-obvious observation, which follows from the analysis, is that any such (non-degenerate) random walk will, eventually in $n\in \mathbb{N}\cup \{0\}$, always be more likely to pass over the level $n$ for the first time with overshoot zero, rather than one. Some applications are considered. ",A note on the times of first passage for `nearly right-continuous'   random walks
"  The famous Fisher-KPP reaction diffusion model combines linear diffusion with the typical Fisher-KPP reaction term, and appears in a number of relevant applications. It is remarkable as a mathematical model since, in the case of linear diffusion, it possesses a family of travelling waves that describe the asymptotic behaviour of a wide class solutions $0\leq u(x,t)\leq 1$ of the problem posed in the real line. The existence of propagation wave with finite speed has been confirmed in the cases of ""slow"" and ""pseudo-linear"" doubly nonlinear diffusion too, see arXiv:1601.05718. We investigate here the corresponding theory with ""fast"" doubly nonlinear diffusion and we find that general solutions show a non-TW asymptotic behaviour, and exponential propagation in space for large times. Finally, we prove precise bounds for the level sets of general solutions, even when we work in with spacial dimension $N \geq 1$. In particular, we show that location of the level sets is approximately linear for large times, when we take spatial logarithmic scale, finding a strong departure from the linear case, in which appears the famous Bramson logarithmic correction. ","The Fisher-KPP problem with doubly nonlinear ""fast"" diffusion"
"  We describe our efforts to study dwarf galaxies with active nuclei, whose black holes, with masses < 10^6 M_sun, provide the best current observational constraints on the mass distribution of primordial seed black holes. Although these low-mass galaxies do not necessarily contain classical bulges, Barth, Greene, & Ho (2005) show that their stellar velocity dispersions and black hole masses obey the same relation as more massive systems. In order to characterize the properties of the dwarf hosts without the glare of the active nucleus, we have compiled a complementary sample of narrow-line active galaxies with low-mass hosts. The host galaxy properties, both their structures and stellar populations, are consistent with the general properties of low-mass, blue galaxies from Sloan. The black holes in these galaxies are probably radiating close to their Eddington limits, suggesting we may have found Type 2 analogues of narrow-line Seyfert 1 galaxies. ",The Smallest AGN Host Galaxies
"  Spatial coherence resonance in a spatially extended system that is locally modeled by Hodgkin-Huxley (HH) neurons is studied in this paper. We focus on the ability of additive temporally and spatially uncorrelated Gaussian noise to extract a particular spatial frequency of excitatory waves in the medium, whereby examining also the impact of diffusive and small-world network topology determining the interactions amongst coupled HH neurons. We show that there exists an intermediate noise intensity that is able to extract a characteristic spatial frequency of the system in a resonant manner provided the latter is diffusively coupled, thus indicating the existence of spatial coherence resonance. However, as the diffusive topology of the medium is relaxed via the introduction of shortcut links introducing small-world properties amongst coupled HH neurons, the ability of additive Gaussian noise to evoke ordered excitatory waves deteriorates rather spectacularly, leading to the decoherence of the spatial dynamics and with it related absence of spatial coherence resonance. In particular, already a minute fraction of shortcut links suffices to substantially disrupt coherent pattern formation in the examined system. ",Spatial coherence resonance on diffusive and small-world networks of   Hodgkin-Huxley neurons
  The Friedrichs model with one discrete state coupled to more than one continuum is studied. The exact eigenstates for the full Hamiltonian can be solved explicitly. The discrete state is found to generate more than one virtual state pole or more than one pair of resonance poles in different Riemann sheets in different situations. The form factors could also generate new states on different sheets. All these states can appear in the generalized completeness relation. ,On Friedrichs Model with Two Continuum States
"  The structure of the reported excitation spectra of the light unflavored baryons is described in terms of multi-spin valued Lorentz group representations of the so called Rarita-Schwinger (RS) type (K/2, K/2)* [(1/ 2,0)+ (0,1/2)] with K=1,3, and 5. We first motivate legitimacy of such pattern as fundamental fields as they emerge in the decomposition of triple fermion constructs into Lorentz representations. We then study the baryon realization of RS fields as composite systems by means of the quark version of the U(4) symmetric diatomic rovibron model. In using the U(4)/ O(4)/ O(3)/ O(2) reduction chain, we are able to reproduce quantum numbers and mass splittings of the above resonance assemblies. We present the essentials of the four dimensional angular momentum algebra and construct electromagnetic tensor operators. The predictive power of the model is illustrated by ratios of reduced probabilities concerning electric de-excitations of various resonances to the nucleon. ",Baryons in O(4) and Vibron Model
"  Observations of fluorescent iron lines from accreting black holes provide one of the best tests of strong field gravity available to date, and the only current observational tool to probe black hole spacetime. However, the two most widely used models for spectral fitting (diskline, laor) are over a decade old and have significant limitations. We present a new code for calculating these effects which will be incorporated within the XSPEC package ",Accurate Modelling of Relativistic Iron Lines from Accretion Discs
"  We present a systematic search for parallax microlensing events among a total of 512 microlensing candidates in the OGLE II database for the 1997-1999 seasons. We fit each microlensing candidate with both the standard microlensing model and also a parallax model that accounts for the Earth's motion around the Sun. We then search for the parallax signature by comparing the chi^2 of the standard and parallax models. For the events which show a significant improvement, we further use the `duration' of the event and the signal-to-noise ratio as criteria to separate true parallax events from other noisy microlensing events. We have discovered one convincing new candidate, sc33_4505, and seven other marginal cases. The convincing candidate (sc33_4505) is caused by a slow-moving, and likely low-mass, object, similar to other known parallax events. We found that irregular sampling and gaps between observing seasons hamper the recovery of parallax events. We have also searched for long-duration events that do not show parallax signatures. The lack of parallax effects in a microlensing event puts a lower-limit on the Einstein radius projected onto the observer plane, which in turn imposes a lower limit on the lens mass divided by the relative lens-source parallax. Most of the constraints are however quite weak. ",Parallax Microlensing Events in the OGLE II Database Toward the Galactic   Bulge
"  In this paper we define and characterize cointegrated continuous-time linear state-space models. A main result is that a cointegrated continuous-time linear state-space model can be represented as a sum of a L\'evy process and a stationary linear state-space model. Moreover, we prove that the class of cointegrated multivariate L\'evy-driven autoregressive moving-average (MCARMA) processes, the continuous-time analogues of the classical vector ARMA processes, is equivalent to the class of cointegrated continuous-time linear state space models. Necessary and sufficient conditions for MCARMA processes to be cointegrated are given as well extending the results of Comte for MCAR processes. The conditions depend on the autoregressive polynomial. Finally, we investigate cointegrated continuous-time linear state-space models observed on a discrete time-grid and derive an error correction form for this model. The error correction form is based on an infinite linear filter in contrast to the finite linear filter for VAR models. ",Cointegrated Continuous-time Linear State Space and MCARMA Models
"  The Galactic calibration of the period-luminosity (PL) relation for classical Cepheids is examined using trigonometric, open cluster, and pulsation parallaxes, which help establish independent versions of the relationship. The calibration is important for the continued use of classical Cepheids in constraining cosmological models (by refining estimates for H_0), for defining zero-points for the SNe Ia and population II (Type II Cepheids/RR Lyrae variables) distance scales, for clarifying properties of the Milky Way's spiral structure, and for characterizing dust extinction affecting Cepheids in the Milky Way and other galaxies. Described is a program to extend and refine the Galactic Cepheid PL relation by obtaining UBVRIJHKs photometry and spectra for stars in open clusters suspected of hosting classical Cepheids, using the the facilities of the OAMM, DAO, AAVSO, and ARO. ",The Galactic Calibration of the Cepheid Period-Luminosity Relation and   its Implications for the Universal Distance Scale
"  A key problem in statistical modeling is model selection, how to choose a model at an appropriate level of complexity. This problem appears in many settings, most prominently in choosing the number ofclusters in mixture models or the number of factors in factor analysis. In this tutorial we describe Bayesian nonparametric methods, a class of methods that side-steps this issue by allowing the data to determine the complexity of the model. This tutorial is a high-level introduction to Bayesian nonparametric methods and contains several examples of their application. ",A Tutorial on Bayesian Nonparametric Models
"  We consider time evolution of Turing patterns in an extended system governed by an equation of the Swift-Hohenberg type, where due to an external periodic parameter modulation long-wave and short-wave patterns with length scales related as 1:3 emerge in succession. We show theoretically and demonstrate numerically that the spatial phases of the patterns, being observed stroboscopically, are governed by an expanding circle map, so that the corresponding chaos of Turing patterns is hyperbolic, associated with a strange attractor of the Smale-Williams solenoid type. This chaos is shown to be robust with respect to variations of parameters and boundary conditions. ",Hyperbolic Chaos of Turing Patterns
  We investigate laser-induced acoustic wave propagation through smooth and roughened titanium-coated glass substrates. Acoustic waves are generated in a controlled manner via the laser spallation technique. Surface displacements are measured during stress wave loading by alignment of a Michelson-type interferometer. A reflective coverslip panel facilitates capture of surface displacements during loading of as-received smooth and roughened specimens. Through interferometric experiments we extract the substrate stress profile at each laser fluence (energy per area). The shape and amplitude of the substrate stress profile is analyzed at each laser fluence. Peak substrate stress is averaged and compared between smooth specimens with reflective panel and rough specimens with reflective panel. The reflective panel is necessary because the surface roughness of the rough specimens precludes in situ interferometry. Through these experiments we determine that the surface roughness employed has no significant effect on substrate stress propagation and smooth substrates are an appropriate surrogate to determine stress wave loading amplitude of roughened surfaces less than 1.2 {\mu}m average roughness (Ra). No significant difference was observed when comparing the average peak amplitude and loading slope in the stress wave profile for the smooth and rough configurations at each fluence. ,Laser-induced stress wave propagation through smooth and rough   substrates
"  Suppose that $m$ senders want to transmit classical information to $n$ receivers with zero probability of error using a noisy multipartite communication channel. The senders are allowed to exchange classical, but not quantum, messages among themselves, and the same holds for the receivers. If the channel is classical, a single use can transmit information if and only if multiple uses can. In sharp contrast, we exhibit, for each $m$ and $n$ with $m\ge 2$ or $n\ge 2$, a quantum channel of which a single use is not able to transmit information yet two uses can. This latter property requires and is enabled by quantum entanglement. ",Entanglement between Two Uses of a Noisy Multipartite Quantum Channel   Enables Perfect Transmission of Classical Information
"  Quantum light sources are characterized by their distinctive statistical distribution of photons. For example, single photons and correlated photon pairs exhibit antibunching and reduced variance in the number distribution that is impossible with classical light. Most common realizations of quantum light sources have relied on spontaneous parametric processes such as down-conversion (SPDC) and four-wave mixing (SFWM). These processes are mediated by vacuum fluctuations of the electromagnetic field. Therefore, by manipulating the electromagnetic mode structure, for example, using nanophotonic systems, one can engineer the spectrum of generated photons. However, such manipulations are susceptible to fabrication disorders which are ubiquitous in nanophotonic systems and lead to device-to-device variations in the spectrum of generated photons. Here, we demonstrate topologically robust mode engineering of the electromagnetic vacuum fluctuations and implement a nanophotonic quantum light source where the spectrum of generated photons is robust against fabrication disorders. Specifically, we use the topological edge states to achieve an enhanced and robust generation of correlated photon pairs using SFWM and show that they outperform their topologically-trivial counterparts. We demonstrate the non-classical nature of our source using conditional antibunching of photons which confirms that we have realized a robust source of heralded single photons. Such topological effects, which are unique to bosonic systems, could pave the way for the development of robust quantum photonic devices. ",A topological source of quantum light
"  It is well known that deep neural networks (DNNs) are vulnerable to adversarial attacks, which are implemented by adding crafted perturbations onto benign examples. Min-max robust optimization based adversarial training can provide a notion of security against adversarial attacks. However, adversarial robustness requires a significantly larger capacity of the network than that for the natural training with only benign examples. This paper proposes a framework of concurrent adversarial training and weight pruning that enables model compression while still preserving the adversarial robustness and essentially tackles the dilemma of adversarial training. Furthermore, this work studies two hypotheses about weight pruning in the conventional setting and finds that weight pruning is essential for reducing the network model size in the adversarial setting, training a small model from scratch even with inherited initialization from the large model cannot achieve both adversarial robustness and high standard accuracy. Code is available at https://github.com/yeshaokai/Robustness-Aware-Pruning-ADMM. ","Adversarial Robustness vs Model Compression, or Both?"
"  In a joint experimental and theoretical study, we investigate the isostructural collapse from the ambient pressure tetragonal phase to a collapsed tetragonal phase for non-superconducting metallic SrFe2As2 and SrFe_1.8Ru_0.2As_2. The crystallographic details have been studied using X-ray powder diffraction up to 20 GPa pressure in a diamond anvil cell. The structural phase transition occurs at 10 GPa and 9 GPa for SrFe2As2 and SrFe_1.8Ru_0.2As_2, respectively. The changes in the unit cell dimensions are highly anisotropic with a continuous decrease of the c lattice parameter with pressure, while the a-axis length increases until the transition to a collapsed tetragonal phase and then continues to decrease. Across the phase transition, we observe a volume reduction of 5% and 4% for SrFe2As2 and SrFe_1.8Ru_0.2As_2, respectively. We are able to discern that Ru substitution on the Fe-site acts like `chemical pressure' to the system. Density-functional theory-based calculations of the electronic structure and electron localizability indicator are consistent with the experimental observations. Detailed analysis of the electronic structure in k-space and real space reveals As 4pz interlayer bond formation as the driving force of the c/a collapse with a change in the As-As bond length of about 0.35ang. ","Symmetry preserving lattice collapse in tetragonal SrFe_(2-x)Ru_xAs_2 (x   = 0, 0.2) -- a combined experimental and theoretical study"
"  A vector bundle on a smooth projective variety, if it is generically generated by global sections, yields a rational map to a Grassmannian, called Kodaira map. We investigate the asymptotic behaviour of the Kodaira maps for the symmetric powers of a vector bundle, and we show that these maps stabilize to a map dominating all of them, as it happens for a line bundle via the Iitka fibration. Through this Iitaka-type construction, applied to the cotangent bundle, we give a new characterization of Abelian varieties. ",Iitaka fibrations for vector bundles
"  The paper investigates localized deformation patterns resulting from the onset of instabilities in lattice structures. The study is motivated by previous observations on discrete hexagonal lattices, where the onset of non-uniform, quasi-static deformation patterns was associated with the loss of convexity of the interaction potential, and where a variety of localized deformations were found depending on loading configuration, lattice parameters and boundary conditions. These observations are here conducted on other lattice structures, with the goal of identifying models of reduced complexity that are able to provide insight into the key parameters that govern the onset of instability-induced localization. To this end, we first consider a two-dimensional square lattice consisting of point masses connected by in-plane axial springs and vertical ground springs. Results illustrate that depending on the choice of spring constants and their relative values, the lattice exhibits in-plane or out-of plane instabilities leading to folding and unfolding. This model is further simplified by considering the one-dimensional case of a spring-mass chain sitting on an elastic foundation. A bifurcation analysis of this lattice identifies the stable and unstable branches and illustrates its hysteretic and loading path-dependent behaviors. Finally, the lattice is further reduced to a minimal four mass model which undergoes a folding/unfolding process qualitatively similar to the same process in the central part of a longer chain, helping our understanding of localization in more complex systems. In contrast to the widespread assumption that localization is induced by defects or imperfections in a structure, this work illustrates that such phenomena can arise in perfect lattices as a consequence of the mode-shapes at the bifurcation points. ",A study of deformation localization in nonlinear elastic lattices
"  The Near-Earth Asteroid Thermal Model (NEATM, Harris, 1998) has proven to be a reliable simple thermal model for radiometric diameter determination. However NEATM assumes zero thermal emission on the night side of an asteroid. We investigate how this assumption affects the best-fit beaming parameter, overestimates the effective diameter and underestimates the albedo at large phase angles, by testing NEATM on thermal IR fluxes generated from simulated asteroid surfaces with different thermal inertia. We compare NEATM to radar diameters and find that NEATM overestimates the diameter when the beaming parameter is fitted to multi-wavelength observations and underestimates the diameter when the default beaming parameter is used. The Night Emission Simulated Thermal Model (NESTM) is introduced. NESTM models the night side temperature as an iso-latitudinal fraction (f) of the maximum day side temperature (Maximum temperature calculated for NEATM with beaming parameter = 1). A range of f is found for different thermal parameters, which depend on the thermal inertia. NESTM diameters are compared with NEATM and radar diameters, and it is shown that NESTM may reduce the systematic bias in overestimating diameters. It is suggested that a version of the NESTM which assumes the thermal inertia = 200 S.I. units is adopted as a default model when the solar phase angle is greater than 45 degrees. ",Investigation of Systematic Bias in Radiometric Diameter Determination   of Near-Earth Asteroids: the Night Emission Simulated Thermal Model (NESTM)
"  Given a measurable space (X, M) there is a (Galois) connection between sub-sigma-algebras of M and equivalence relations on X. On the other hand equivalence relations on X are closely related to congruences on stochastic relations. In recent work, Doberkat has examined lattice properties of posets of congruences on a stochastic relation and motivated a domain-theoretic investigation of these ordered sets. Here we show that the posets of sub-sigma-algebras of a measurable space do not enjoy desired domain-theoretic properties and that our counterexamples can be applied to the set of smooth equivalence relations on an analytic space, thus giving a rather unsatisfactory answer to Doberkat's question. ",A domain-theoretic investigation of posets of sub-sigma-algebras   (extended abstract)
"  Some time ago, Atiyah showed that there exists a natural identification between the k-instantons of a Yang-Mills theory with gauge group $G$ and the holomorphic maps from $CP_1$ to $\Omega G$. Since then, Nair and Mazur, have associated the $\Theta $ vacua structure in QCD with self-intersecting Riemann surfaces immersed in four dimensions. From here they concluded that these 2D surfaces correspond to the non-perturbative phase of QCD and carry the topological information of the $\Theta$ vacua. In this paper we would like to elaborate on this point by making use of Atiyah's identification. We will argue that an effective description of QCD may be more like a $WZW$ model coupled to the induced metric of an immersion of a 2-D Riemann surface in $R^4$. We make some further comments on the relationship between the coadjoint orbits of the Kac-Moody group on $G$ and instantons with axial symmetry and monopole charge. ",QCD Instantons and 2D Surfaces
  We study two ions confined in a Penning trap. We show that electronically highly excited states exist in which an electron is delocalized among the two ions forming a giant molecule of several micrometer size. At energies close to the top of the Coulomb barrier these molecular states can be regarded as superpositions of Rydberg states of individual ions. We illuminate the possibility to observe coherent charge transfer between the ions. Beyond a critical principal quantum number the electron can coherently tunnel through the Coulomb barrier to an adjacent doubly charged ion. The tunneling occurs on timescales on which the dynamics of the nuclei can be considered frozen and radiative decay can be neglected. ,Trap assisted creation of giant molecules and Rydberg-mediated coherent   charge transfer in a Penning trap
"  We propose a novel approach, MUSE, to illustrate textual attributes visually via portrait generation. MUSE takes a set of attributes written in text, in addition to facial features extracted from a photo of the subject as input. We propose 11 attribute types to represent inspirations from a subject's profile, emotion, story, and environment. We propose a novel stacked neural network architecture by extending an image-to-image generative model to accept textual attributes. Experiments show that our approach significantly outperforms several state-of-the-art methods without using textual attributes, with Inception Score score increased by 6% and Fr\'echet Inception Distance (FID) score decreased by 11%, respectively. We also propose a new attribute reconstruction metric to evaluate whether the generated portraits preserve the subject's attributes. Experiments show that our approach can accurately illustrate 78% textual attributes, which also help MUSE capture the subject in a more creative and expressive way. ",MUSE: Textual Attributes Guided Portrait Painting Generation
"  We present the results of the calculation of the one-loop correction to the effective vertex for the quark-antiquark pair production in collisions of the virtual photon with the Reggeized gluon. This vertex is supposed then to be used for the calculation of the virtual photon impact factor, which is extremely important, for instance, for the description of the small $x$ deep inelastic scattering in the BFKL approach. ",Next-to-leading virtual photon - Reggeized gluon interaction
"  Network sampling is used around the world for surveys of vulnerable, hard-to-reach populations including people at risk for HIV, opioid misuse, and emerging epidemics. The sampling methods include tracing social links to add new people to the sample. Current estimates from these surveys are inaccurate, with large biases and mean squared errors and unreliable confidence intervals. New estimators are introduced here which eliminate almost all of the bias, have much lower mean squared error, and enable confidence intervals with good properties. The improvement is attained by avoiding unrealistic assumptions about the population network and the design, instead using the topology of the sample network data together with the sampling design actually used. In simulations using the real network of an at-risk population, the new estimates eliminate almost all the bias and have mean squared-errors that are 2 to 92 times lower than those of current estimators. The new estimators are effective with a wide variety of network designs including those with strongly restricted branching such as Respondent-Driven Sampling and freely branching designs such as Snowball Sampling. ",New estimates for network sampling
"  We revisit the game in which each of several players chooses a pattern and then a coin is flipped repeatedly until one of these patterns is generated. In particular, we demonstrate how to compute the probability of any one player winning this game, and find the distribution of the game's duration. Our presentation is an extension (and perhaps a simplification) of the results of Blom and Thornburn. ",Playing Several Patterns Against One Another
"  We revisit fuzzy neural network with a cornerstone notion of generalized hamming distance, which provides a novel and theoretically justified framework to re-interpret many useful neural network techniques in terms of fuzzy logic. In particular, we conjecture and empirically illustrate that, the celebrated batch normalization (BN) technique actually adapts the normalized bias such that it approximates the rightful bias induced by the generalized hamming distance. Once the due bias is enforced analytically, neither the optimization of bias terms nor the sophisticated batch normalization is needed. Also in the light of generalized hamming distance, the popular rectified linear units (ReLU) can be treated as setting a minimal hamming distance threshold between network inputs and weights. This thresholding scheme, on the one hand, can be improved by introducing double thresholding on both extremes of neuron outputs. On the other hand, ReLUs turn out to be non-essential and can be removed from networks trained for simple tasks like MNIST classification. The proposed generalized hamming network (GHN) as such not only lends itself to rigorous analysis and interpretation within the fuzzy logic theory but also demonstrates fast learning speed, well-controlled behaviour and state-of-the-art performances on a variety of learning tasks. ",Revisit Fuzzy Neural Network: Demystifying Batch Normalization and ReLU   with Generalized Hamming Network
  At low temperatures electron hopping in a three dimensional Coulomb glass produces fluctuations in the single particle density of states and hence in the resistivity. This results in a low frequency resisitivity noise spectrum which goes as (1/f)^(alpha) where alpha is very close to 1. This holds down to extremely low frequencies. ,1/f Noise in a Coulomb Glass
"  We report the discovery of PSR J1747-2958, a radio pulsar with period P = 98 ms and dispersion measure DM = 101 pc/cc, in a deep observation with the Parkes telescope of the axially-symmetric ""Mouse"" radio nebula (G359.23-0.82). Timing measurements of the newly discovered pulsar reveal a characteristic age Pdt/2dP = 25 kyr and spin-down luminosity dE/dt = 2.5e36 erg/s. The pulsar (timing) position is consistent with that of the Mouse's ""head"". The distance derived from the DM, ~2 kpc, is consistent with the Mouse's distance limit from HI absorption, < 5.5 kpc. Also, the X-ray energetics of the Mouse are compatible with being powered by the pulsar. Therefore we argue that PSR J1747-2958, moving at supersonic speed through the local interstellar medium, powers this unusual non-thermal nebula. The pulsar is a weak radio source, with period-averaged flux density at 1374 MHz of 0.25 mJy and luminosity ~1 mJy kpc^2. ",Heartbeat of the Mouse: a young radio pulsar associated with the   axisymmetric nebula G359.23-0.82
"  The Hirzebruch functional equation is \[   \sum_{i = 1}^{n} \prod_{j \ne i} { 1 \over f(z_j - z_i)} = c \] with constant $c$ and initial conditions $f(0)=0, f'(0)=1$. In this paper we find all solutions of the Hirzebruch functional equation for $n \leqslant 6$ in the class of meromorphic functions and in the class of series. Previously, such results were known only for $n \leqslant 4$.   The Todd function is the function determining the two-parametric Todd genus (i.e. the $\chi_{a,b}$-genus). It gives a solution to the Hirzebruch functional equation for any $n$. The elliptic function of level $N$ is the function determining the elliptic genus of level $N$. It gives a solution to the Hirzebruch functional equation for $n$ divisible by $N$.   A series corresponding to a meromorphic function $f$ with parameters in $U \subset \mathbb{C}^k$ is a series with parameters in the Zariski closure of $U$ in $\mathbb{C}^k$, such that for parameters in $U$ it coincides with the series expansion at zero of $f$. The main results are:   Any series solution of the Hirzebruch functional equation for $n = 5$ corresponds to the Todd function or to the elliptic function of level $5$.   Any series solution of the Hirzebruch functional equation for $n = 6$ corresponds to the Todd function or to the elliptic function of level $2$, $3$ or $6$.   This gives a complete classification of complex genera that are fiber multiplicative with respect to $\mathbb{C}P^{n-1}$ for $n \leqslant 6$. ",Hirzebruch Functional Equation: Classification of Solutions
"  Intermediate resolution spectroscopy of the white dwarf SDSSJ104341.53+085558.2 contains double-peaked emission lines of CaII8498,8542,8662 and identifies this object to be the second single white dwarf to be surrounded by a gaseous disc of metal-rich material, similar to the recently discovered SDSSJ1228+1040. A photospheric Magnesium abundance of 0.3 times the solar value, determined from the observed MgII4481 absorption line, implies that the white dwarf is accreting from the circumstellar material. The absence of Balmer emission lines and of photospheric HeI4471 absorption indicates that the accreted material is depleted in volatile elements and, by analogy with SDSS1228+1040, may be the result of the tidal disruption of an asteroid. Additional spectroscopy of the DAZ white dwarfs WD1337+705 and GD362 does not reveal CaII emission lines. GD362 is one of the few cool DAZ that display strong infrared flux excess, thought to be originating in a circumstellar dust disc, and its temperature is likely too low to sublimate sufficient amounts of disc material to generate detectable CaII emission. WD1337+705 is, as SDSS1228+1040 and SDSS1043+0855, moderately hot, but has the lowest Mg abundance of those three stars, suggesting a possible correlation between the photospheric Mg abundance and the equivalent width of the CaII emission triplet. Our inspection of 7360 white dwarfs from SDSS DR4 fails to unveil additional strong ""metal gas disc"" candidates, and implies that these objects are rather rare. ",SDSSJ104341.53+085558.2: A second white dwarf with a gaseous debris disc
"  Multi-view subspace clustering aims to discover the inherent structure by fusing multi-view complementary information. Most existing methods first extract multiple types of hand-crafted features and then learn a joint affinity matrix for clustering. The disadvantage lies in two aspects: 1) Multi-view relations are not embedded into feature learning. 2) The end-to-end learning manner of deep learning is not well used in multi-view clustering. To address the above issues, we propose a novel multi-view deep subspace clustering network (MvDSCN) by learning a multi-view self-representation matrix in an end-to-end manner. MvDSCN consists of two sub-networks, i.e., diversity network (Dnet) and universality network (Unet). A latent space is built upon deep convolutional auto-encoders and a self-representation matrix is learned in the latent space using a fully connected layer. Dnet learns view-specific self-representation matrices while Unet learns a common self-representation matrix for all views. To exploit the complementarity of multi-view representations, Hilbert Schmidt Independence Criterion (HSIC) is introduced as a diversity regularization, which can capture the non-linear and high-order inter-view relations. As different views share the same label space, the self-representation matrices of each view are aligned to the common one by a universality regularization. Experiments on both multi-feature and multi-modality learning validate the superiority of the proposed multi-view subspace clustering model. ",Multi-view Deep Subspace Clustering Networks
"  We examine swimmers comprising of two rigid spheres which oscillate periodically along their axis of symmetry, considering both when the oscillation is in phase and anti-phase, and study the effects of fluid viscoelasticity on their net motion. These swimmers both display reciprocal motion in a Newtonian fluid and hence no net swimming is achieved over one cycle. Conversely, we find that when the two spheres are of different sizes, the effect of viscoelasticity acts to propel the swimmers forward in the direction of the smaller sphere. Finally, we compare the motion of rigid spheres oscillating in viscoelastic fluids with elastic spheres in Newtonian fluids where we find similar results. ",Two-sphere swimmers in viscoelastic fluids
"  We develop a physical framework for interpreting high-resolution images of pre planetary nebule (""prePNe"") with pairs of candle shaped lobes. We use hydrodynamical models to infer the historical properties of the flows injected from the nucleus that shape the lobes into standard forms. First, we find a suitable set of parameters of a fast, collimated, tapered flow that is actively reshaped by an exterior slow AGB wind and that nicely fits the basic shape, kinematics, mass, and momenta of this class of prePNe. Next we vary the most influential parameters of this ""baseline"" model-such as density, speed, and geometry-to see how changes in the flow parameters affect the nebular observables after 900y. Several generic conlusions emerge, such as the injected flows that create the hollow candle-shaped lobes must be light, ""tapered"", and injected considerably faster than the lobe expansion speed. Multi-polar and starfish prePNe probably evolve from wide angle flows in which thin-shell instabilites corrugate their leading edges. We show how the common linear relationship of Doppler shift and position along the lobe is a robust outcome the interaction of tapered diverging streamlines with the lobes' curved walls. Finally we probe how magnetic fields affect the basline model by adding a toroidal field to the injected baseline flow. Examples of prePNe and PNe that may have been magnetically shaped are listed. We conclude that the light, field-free, tapered baseline flow model is an successful and universal pardigm for unravelling the histories of lobe formation in prePNe. ","Models of the Mass-Ejection Histories of pre Planetary Nebulae, III. The   Shaping of Lobes by post-AGB Winds"
"  We study the problem of extending partial isomorphisms for hypertournaments, which are relational structures generalizing tournaments. This is a generalized version of an old question of Herwig and Lascar. We show that the generalized problem has a negative answer, and we provide a positive answer in a special case. As a corollary, we show that the extension property holds for tournaments in case the partial isomorphisms have pairwise disjoint ranges and pairwise disjoint domains. ",The Hrushovski property for hypertournaments and profinite topologies
"  We use a large set of cosmological smoothed particle hydrodynamics (SPH) simulations to examine the effect of mass resolution and box size on synthetic Lya forest spectra at 2 \leq z \leq 5. The mass resolution requirements for the convergence of the mean Lya flux and flux power spectrum at z=5 are significantly stricter than at lower redshift. This is because transmission in the high redshift Lya forest is primarily due to underdense regions in the intergalactic medium (IGM), and these are less well resolved compared to the moderately overdense regions which dominate the Lya forest opacity at z~2-3. We further find that the gas density distribution in our simulations differs significantly from previous results in the literature at large overdensities (\Delta>10). We conclude that studies of the Lya forest at z=5 using SPH simulations require a gas particle mass of M_gas \leq 2x10^5 M_sol/h, which is >8 times the value required at z=2. A box size of at least 40 Mpc/h is preferable at all redshifts. ",Resolving the high redshift Lyman-alpha forest in smoothed particle   hydrodynamics simulations
"  Coherent-one-way (COW) quantum key distribution (QKD) held the promise of distributing secret keys over long distances with a simple experimental setup. Indeed, this scheme is currently used in commercial applications. Surprisingly, however, it has been recently shown that its secret key rate scales at most quadratically with the system's transmittance and, thus, it is not appropriate for long distance QKD transmission. Such pessimistic result was derived by employing a so-called zero-error attack, in which the eavesdropper does not introduce any error, but still the legitimate users of the system cannot distill a secure key. Here, we present a zero-error attack against COW-QKD that is essentially optimal, in the sense that no other attack can restrict further its maximum achievable distance in the absence of errors. This translates into an upper bound on its secret key rate that is more than an order of magnitude lower than previously known upper bounds. ",Zero-error attack against coherent-one-way quantum key distribution
"  This letter is a proof of concept for an improved transmission switching (TS) performance by moving the search space to load shed buses. Research from the past shows that changing transmission system topology changes the power flows and removes post contingency violations. Hence, TS can reduce the amount of load shed after an N-1 contingency. One of the major challenges is to find the best TS candidate in a suitable time. In this letter, the best TS candidate is determined by using a novel heuristic bi-level method based on linear sensitivity. The proposed bi-level method is easy to implement in the real world, guarantees removal of post contingency violations, and ranks the best TS candidates based on minimum load shedding possible. Moreover, the proposed method is computationally efficient since it does not involve mixed integer programming. The bi-level method is implemented by modifying the topology of transmission system after the N-1 contingency in the IEEE 39-bus test system and results show that TS with generation re-dispatch is the best solution for load shed recovery to prevent cascading failures. Moreover, the bi-level method performs even for the case when the existing methods in literature fail to completely remove post contingency violations. ",An Improved Transmission Switching Algorithm for Managing Post-(N-1)   Contingency Violations in Electricity Networks
"  Modelising the translation errors by suitable mathematical operators in the crystal basis model of the genetic code and requiring that codons prone to be misread encode the same amino-acid, the main features of the organisation in multiplets of the genetic code are described. ",Wigner-Eckart Theorem in the crystal and the organisation of the genetic   code
"  The Chebyshev or $\ell_{\infty}$ estimator is an unconventional alternative to the ordinary least squares in solving linear regressions. It is defined as the minimizer of the $\ell_{\infty}$ objective function \begin{align*}   \hat{\boldsymbol{\beta}} := \arg\min_{\boldsymbol{\beta}} \|\boldsymbol{Y} - \mathbf{X}\boldsymbol{\beta}\|_{\infty}. \end{align*} The asymptotic distribution of the Chebyshev estimator under fixed number of covariates were recently studied (Knight, 2020), yet finite sample guarantees and generalizations to high-dimensional settings remain open. In this paper, we develop non-asymptotic upper bounds on the estimation error $\|\hat{\boldsymbol{\beta}}-\boldsymbol{\beta}^*\|_2$ for a Chebyshev estimator $\hat{\boldsymbol{\beta}}$, in a regression setting with uniformly distributed noise $\varepsilon_i\sim U([-a,a])$ where $a$ is either known or unknown. With relatively mild assumptions on the (random) design matrix $\mathbf{X}$, we can bound the error rate by $\frac{C_p}{n}$ with high probability, for some constant $C_p$ depending on the dimension $p$ and the law of the design. Furthermore, we illustrate that there exist designs for which the Chebyshev estimator is (nearly) minimax optimal. In addition we show that ""Chebyshev's LASSO"" has advantages over the regular LASSO in high dimensional situations, provided that the noise is uniform. Specifically, we argue that it achieves a much faster rate of estimation under certain assumptions on the growth rate of the sparsity level and the ambient dimension with respect to the sample size. ",Non-Asymptotic Bounds for the $\ell_{\infty}$ Estimator in Linear   Regression with Uniform Noise
"  It is known that the capacity of parallel (multi-carrier) Gaussian point-to-point, multiple access and broadcast channels can be achieved by separate encoding for each subchannel (carrier) subject to a power allocation across carriers. In this paper we show that such a separation does not apply to parallel Gaussian interference channels in general. A counter-example is provided in the form of a 3 user interference channel where separate encoding can only achieve a sum capacity of $\log({SNR})+o(\log({SNR}))$ per carrier while the actual capacity, achieved only by joint-encoding across carriers, is $3/2\log({SNR}))+o(\log({SNR}))$ per carrier. As a byproduct of our analysis, we propose a class of multiple-access-outerbounds on the capacity of the 3 user interference channel. ",Multiple Access Outerbounds and the Inseparability of Parallel   Interference Channels
"  Ba0.6Sr0.4TiO3 and (Ba0.6Sr0.4)(Zr0.3Ti0.7)O3 thin films were deposited on La0.9Sr1.1NiO4 buffered SrTiO3 substrates. (Ba0.6Sr0.4)(Zr0.3Ti0.7)O3 film (2.77 nF) showed one order large capacitance compared to that of Ba0.6Sr0.4TiO3 film (270 pF) at 100 kHz. (Ba0.6Sr0.4)(Zr0.3Ti0.7)O3 film showed negative capacitance at f >3 MHz except for f=5.05 to 7.36 MHz, and 10.4 to 13.4 MHz, where it showed positive capacitance. Tunability of the Ba0.6Sr0.4TiO3 film (~15%) is much lower than that of the (Ba0.6Sr0.4)(Zr0.3Ti0.7)O3 film (30 to 65%, both normal and inverse). A significant change of the tunability was observed at frequencies f>500 kHz for the (Ba0.6Sr0.4)(Zr0.3Ti0.7)O3 film showing inverse tunability, this can be attributed to the negative capacitance effect, where current lags behind the voltage. (Ba0.6Sr0.4)(Zr0.3Ti0.7)O3 film (6.87x10-6 A/cm2) showing one order high leakage current density than BST film (1.32x10-7 A/cm2). Ba0.6Sr0.4TiO3 film showed large grain size (140 nm) and surface roughness (11.5 nm) and (Ba0.6Sr0.4)(Zr0.3Ti0.7)O3 film showed small grain size (80 nm) and roughness (2.3 nm). ",Frequency dependent negative capacitance of (Ba0.6Sr0.4)(ZrxTi1-x)O3   thin films grown on La0.9Sr1.1NiO4 buffered SrTiO3 substrate
"  As an effective way of metric learning, triplet loss has been widely used in many deep learning tasks, including face recognition and person-ReID, leading to many states of the arts. The main innovation of triplet loss is using feature map to replace softmax in the classification task. Inspired by this concept, we propose here a new adversarial modeling method by substituting the classification loss of discriminator with triplet loss. Theoretical proof based on IPM (Integral probability metric) demonstrates that such setting will help the generator converge to the given distribution theoretically under some conditions. Moreover, since triplet loss requires the generator to maximize distance within a class, we justify tripletGAN is also helpful to prevent mode collapse through both theory and experiment. ",TripletGAN: Training Generative Model with Triplet Loss
"  Due to the lack of two-dimensional silicon-based semiconductors and the fact that most of the components and devices are generated on single-crystal silicon or silicon-based substrates in modern industry, designing two-dimensional silicon-based semiconductors is highly desired. With the combination of a swarm structure search method and density functional theory in this work, a quaternary compound SiBCN with graphene-like structure is found and displays a wide direct band gap as expected. The band gap is of ~2.63 eV which is just between ~2.20 and ~3.39 eV of the highlighted semiconductors SiC and GaN. Notably, the further calculation reveals that SiBCN possesses high carrier mobility with ~5.14x10^3 and ~13.07x10^3 cm^2V^-1s^-1 for electron and hole, respectively. Furthermore, the ab initio molecular dynamics simulations also show that the graphene-like structure of SiBCN can be well kept even at an extremely high temperature of 2000 K. The present work tells that designing ulticomponent silicides may be a practicable way to search for new silicon-based low-dimensional semiconductors which can match well with the previous Si-based substrates. ",Graphene-like quaternary compound SiBCN: a new wide direct band gap   semiconductor predicted by a first-principles study
"  We discuss some striking properties of photons propagating in a cold axion condensate oscillating coherently in time with a frequency $1/m_a$. Three effects are discussed in this contribution: (a) due to the time dependence of the background, photons moving in the cold axion background have no definite energies and some momenta are not accessible to them. (b) we investigate the combined influence of a magnetic field and the cold axion background and propose a possible interferometric experiment to detect the latter. (c) if the axion condensate has a space dependence, the photon refraction index is modified in the medium, possibly leading to total reflection at the interface with the ordinary vacuum. ",Photon propagation in a cold axion condensate
"  Observations of gamma-ray bursts (GRBs) at Very High Energy (VHE) offer a unique opportunity to investigate particle acceleration processes, magnetic fields and radiation fields in these events. Very Long Baseline Interferometry (VLBI) observations have been proven to be a powerful tool providing unique information on the source size of the GRBs at mas scales, as well as their accurate positions and possible expansion speeds. This paper reports on the follow-up observations of GRB 190114C, the first ever GRB detected with high significance at TeV photon energies by the MAGIC telescope, conducted with the East Asia VLBI Network (EAVN) at 22 GHz on three epochs, corresponding to 6, 15 and 32 days after the burst. The derived maps do not show any significant source above 5 sigma. The inferred upper limits on the GRB 190114C flux density at 22 GHz are used here to constrain the allowable two-dimensional parameter space for the afterglow emission. We find that our limits are consistent with most afterglow parameter combinations proposed so far in the literature. This is the first effort for the EAVN to search and monitor a radio transient in the Target of Opportunity mode. In addition to the useful constraints on GRB 190114C radio emission, experience gained from these observations is very helpful for future routine operation of EAVN transient program. ",East Asia VLBI Network observations of the TeV Gamma-Ray Burst 190114C
"  We want to study the influence of the quantum vacuum on the light propagation. At first, by working in the standard linear quantum theory of the electromagnetic fields, it is shown that the electric permittivity and the magnetic permeability of the vacuum medium are changed; but, the resulting speed of light isn't modified. Then, taking into account nonlinear effects by considering the Euler-Heisenberg Lagrangian, the corresponding zero point (vacuum) energy and the resulting modification of the speed of light are found up to the first non-vanishing correction. ",Dispersive Property of the Quantum Vacuum and the Speed of Light
"  We present strong theoretical evidence that a Larkin-Ovchinnikov (LOFF/FFLO) pairing phase is favoured over the homogeneous superfluid and normal phases in three-dimensional unitary Fermi systems. Using a Density Functional Theory (DFT) based on the latest quantum Monte-Carlo calculations and experimental results, we show that this phase is competitive over a large region of the phase diagram. The oscillations in the number densities and pairing field have a substantial amplitude, and a period some 3 to 10 times the average interparticle separation. Within the DFT, the transition to a normal polarized Fermi liquid at large polarizations is smooth, while the transition to a fully-paired superfluid is abrupt. ",A Unitary Fermi Supersolid: The Larkin-Ovchinnikov Phase
"  Growing demand for fast charging and optimised battery designs is fuelling significant interest in electrochemical models of Li-ion batteries. However, estimating parameter values for these models remains a major challenge. In this paper, a structural identifiability analysis was applied to a pseudo-2D Li-ion electrochemical battery model that can be considered as a linearised and decoupled form of the benchmark Doyle-Fuller-Newman model. From an inspection of the impedance function, it was shown that this model is uniquely parametrised by 21 parameters, being combinations of the electrochemical parameters like the conductivities and diffusion coefficients. The well-posedness of the parameter estimation problem with these parameters was then established. This result could lead to more realistic predictions about the internal state of the battery by identifying the parameter set that can be uniquely identified from the data. ",Structural Identifiability of a Pseudo-2D Li-ion Battery Electrochemical   Model
"  We show that the magnetism of double perovskite AFe_{1/2}M_{1/2}O_3 systems may be described by the Heisenberg model on the simple cubic lattice, where only half of sites are occupied by localized magnetic moments. The nearest-neighbor interaction J_1 is more than 20 times the next-nearest neighbor interaction J_2, the third-nearest interaction along the space diagonal of the cube being negligible. We argue that the variety of magnetic properties observed in different systems is connected with the variety of chemical ordering in them. We analyze six possible types of the chemical ordering in 2x2x2 supercell, and argue that the probability to find them in a real compound does not correspond to a random occupation of lattice sites by magnetic ions. The exchange J_2 rather than J_1 define the magnetic energy scale of most double perovskite compounds that means the enhanced probability of 1:1 short range ordering. Two multiferroic compounds PbFe_{1/2}M_{1/2}O_3 (M=Nb, Ta) are exceptions. We show that the relatively high temperature of antiferromagnetic transition is compatible with a layered short-range chemical order, which was recently shown to be most stable for these two compounds [I. P. Raevski, {\em et al.}, Phys.\ Rev.\ B \textbf{85}, 224412 (2012)]. We show also that one of the types of ordering has ferrimagnetic ground state. The clusters with short-range order of this type may be responsible for a room-temperature superparamagnetism, and may form the cluster glass at low temperatures. ",Magnetic interactions in disordered perovskite PbFe_{1/2}Nb_{1/2}O_3 and   related compounds. Dominance of nearest-neighbor interaction
"  Claude Francis Milliet Dechales described the Coriolis effect in his 1674 Cursus seu Mundus Mathematicus. Dechales discussed and illustrated the deflection of both falling bodies and of projectiles launched toward the poles that should occur on a rotating Earth. Interestingly, this was done as an argument against the Earth's rotation, the deflections not having been observed at the time. Dechales's work follows on that of Giovanni Battista Riccioli, who had also described the effect in his Almagestum Novum of 1651. ",The Coriolis Effect Further Described in the Seventeenth Century
"  This article explores subspace clustering algorithms using CUR decompositions, and examines the effect of various hyperparameters in these algorithms on clustering performance on two real-world benchmark datasets, the Hopkins155 motion segmentation dataset and the Yale face dataset. Extensive experiments are done for a variety of sampling methods and oversampling parameters for these datasets, and some guidelines for parameter choices are given for practical applications. ",On Matrix Factorizations in Subspace Clustering
  The fuelling of plasmas by shallow frozen pellets with simultaneous mitigation of edge localised modes (ELM) by external magnetic perturbation is demonstrated on the MAST tokamak. Post-pellet particle loss is dominated by ELMs and inter-ELM gas fuelling. It is shown that the size of post-pellet ELMs can be controlled by external magnetic perturbations. Post-pellet ELMs remove particles from the large part of pellet deposition zone including the area with positive density gradient. The mechanism explaining this peculiarity of particle loss is suggested. ,Pellet fuelling with edge-localised modes controlled by external   magnetic perturbations in MAST
"  Determining the number of fluorescent entities that are coupled to a given molecule (DNA, protein, etc.) is a key point of numerous biological studies, especially those based on a single molecule approach. Reliable methods are important, in this context, not only to characterize the labeling process, but also to quantify interactions, for instance within molecular complexes. We combined Fluorescence Correlation Spectroscopy (FCS) and photobleaching experiments to measure the effective number of molecules and the molecular brightness as a function of the total fluorescence count rate on solutions of cDNA (containing a few percent of C bases labeled with Alexa Fluor 647). Here, photobleaching is used as a control parameter to vary the experimental outputs (brightness and number of molecules). Assuming a Poissonian distribution of the number of fluorescent labels per cDNA, the FCS-photobleaching data could be easily fit to yield the mean number of fluorescent labels per cDNA strand (@ 2). This number could not be determined solely on the basis of the cDNA brightness, because of both the statistical distribution of the number of fluorescent labels and their unknown brightness when incorporated in cDNA. The statistical distribution of the number of fluorophores labeling cDNA was confirmed by analyzing the photon count distribution (with the cumulant method), which showed clearly that the brightness of cDNA strands varies from one molecule to the other. ","Measuring, in solution, multiple-fluorophore labeling by combining   Fluorescence Correlation Spectroscopy and photobleaching"
"  In this paper, we study affine manifolds endowed with linear foliations. These are foliations defined by vector subspaces invariant by the linear holonomy. We show that an $n$-dimensional compact, complete, and oriented affine manifold endowed with a codimension $1$ linear foliation ${\cal F}$ is homeomophic to the $n$-dimensional torus if the leaves of ${\cal F}$ are simply connected. Let $(M,\nabla_M)$ be a $3$-dimensional compact affine manifold endowed with a codimension $1$ linear foliation. We prove that $(M,\nabla_M)$ has a finite cover which is homeomorphic to the total space of a bundle over the circle if its developing map is injective, and has a convex image. ",Linear foliations on affine manifolds
"  We show that the observational universe may emerge classically from a de Sitter background with low energy scale. We find, after calculating the curvature perturbation, that the resulting scenario is actually a style of the eternal inflation scenario, in which some regions will go through the slowly expanding Galilean genesis phase with the rapidly increasing energy density and become island universes, while other regions are still eternally inflating, which will make the room for more island universes to emerge. ",Galilean Islands in Eternally Inflating Background
"  The cubic nonlinear Schr\""odinger equation with repulsive nonlinearity and an elliptic function potential models a quasi-one-dimensional repulsive dilute gas Bose-Einstein condensate trapped in a standing light wave. New families of stationary solutions are presented. Some of these solutions have neither an analog in the linear Schr\""odinger equation nor in the integrable nonlinear Schr\""odinger equation. Their stability is examined using analytic and numerical methods. All trivial-phase stable solutions are deformations of the ground state of the linear Schr\""odinger equation. Our results show that a large number of condensed atoms is sufficient to form a stable, periodic condensate. Physically, this implies stability of states near the Thomas-Fermi limit. ",Stability of Repulsive Bose-Einstein Condensates in a Periodic Potential
"  Segmenting stroke lesions from T1-weighted MR images is of great value for large-scale stroke rehabilitation neuroimaging analyses. Nevertheless, there are great challenges with this task, such as large range of stroke lesion scales and the tissue intensity similarity. The famous encoder-decoder convolutional neural network, which although has made great achievements in medical image segmentation areas, may fail to address these challenges due to the insufficient uses of multi-scale features and context information. To address these challenges, this paper proposes a Cross-Level fusion and Context Inference Network (CLCI-Net) for the chronic stroke lesion segmentation from T1-weighted MR images. Specifically, a Cross-Level feature Fusion (CLF) strategy was developed to make full use of different scale features across different levels; Extending Atrous Spatial Pyramid Pooling (ASPP) with CLF, we have enriched multi-scale features to handle the different lesion sizes; In addition, convolutional long short-term memory (ConvLSTM) is employed to infer context information and thus capture fine structures to address the intensity similarity issue. The proposed approach was evaluated on an open-source dataset, the Anatomical Tracings of Lesions After Stroke (ATLAS) with the results showing that our network outperforms five state-of-the-art methods. We make our code and models available at https://github.com/YH0517/CLCI_Net. ",CLCI-Net: Cross-Level fusion and Context Inference Networks for Lesion   Segmentation of Chronic Stroke
"  Let $n; r; e; s$ be are positive integers and the prime p; the finite local principal ideals ring of parameters $p; n; r; e; s)$ $GR(p^n;r)[x]/(x^e - pu ; x^s),$ is defined by an invertible element u of the Galois ring $GR(p^n; r)$ of characteristic $p^n$ of order $p^{nr}.$ It is called Galois-Eisenstein ring of parameters $(p; n; r; e; s)$. A basic problem, which seems to be very difficult is to determine all non-isomorphism pure Galois-Eisenstein rings of parameters $(p; n; r; e; s).$ In this paper, this isomorphism problem for pure Galois-Eisenstein rings of parameters $(p; n; r; e; s)$ is investigated. ",Non isomorphic pure Galois-Eisenstein rings
"  Let $\u_{1\times n}$, $\X_{n\times n}$, and $\v_{n\times 1}$ be matrices of indeterminates, $\Adj \X$ be the classical adjoint of $\X$, and $H(n)$ be the ideal $I_1(\u\X)+I_1(\X\v)+I_1(\v\u-\Adj \X)$. Vasconcelos has conjectured that $H(n)$ is a perfect Gorenstein ideal of grade $2n$. In this paper, we obtain the minimal free resolution of $H(n)$; and thereby establish Vasconcelos' conjecture. ",Ideals associated to two sequences and a matrix
"  Dark matter candidates such as weakly-interacting massive particles are predicted to annihilate or decay into Standard Model particles leaving behind distinctive signatures in gamma rays, neutrinos, positrons, antiprotons, or even anti-nuclei. Indirect dark matter searches, and in particular those based on gamma-ray observations and cosmic ray measurements could detect such signatures. Here we review the strengths and limitations of this approach and look into the future of indirect dark matter searches. ",Indirect dark matter searches in Gamma- and Cosmic Rays
"  Various solar features can be seen on maps of the Sun in the mm and sub-mm wavelength range. The recently installed Atacama Large Millimeter/submillimeter Array (ALMA) is capable of observing the Sun in that wavelength range with an unprecedented spatial, temporal and spectral resolution. To interpret solar observations with ALMA the first important step is to compare ALMA maps with simultaneous images of the Sun recorded in other spectral ranges. First we identify different structures in the solar atmosphere seen in the optical, IR and EUV parts of the spectrum (quiet Sun (QS), active regions (AR), prominences on the disc, magnetic inversion lines (IL), coronal holes (CH) and coronal bright points (CBPs)) in a full disc solar ALMA image. The second aim is to measure the intensities (brightness temperatures) of those structures and compare them with the corresponding QS level. A full disc solar image at 1.21 mm obtained on December 18, 2015 during a CSV-EOC campaign with ALMA is calibrated and compared with full disc solar images from the same day in H\alpha, in He I 1083 nm core, and with SDO images (AIA at 170 nm, 30.4 nm, 21.1 nm, 19.3 nm, and 17.1 nm and HMI magnetogram). The brightness temperatures of various structures are determined by averaging over corresponding regions of interest in the ALMA image. Positions of the QS, ARs, prominences on the disc, ILs, CHs and CBPs are identified in the ALMA image. At 1.21 mm ARs appear as bright areas (but sunspots are dark), while prominences on the disc and CHs are not discernible from the QS background, although having slightly less intensity than surrounding QS regions. ILs appear as large, elongated dark structures and CBPs correspond to ALMA bright points. These results are in general agreement with sparse earlier measurements at similar wavelengths. The identification of CBPs represents the most important new result. ",First analysis of solar structures in 1.21 mm full-disc ALMA image of   the Sun
  We demonstrate that the EPR-Bohm probabilities can be easily obtained in the classical (but contextual) probabilistic framework by using the formula of interference of probabilities. From this point of view the EPR-Bell experiment is just an experiment on interference of probabilities. We analyse the time structure of contextuality in the EPR-Bohm experiment. The conclusion is that quantum mechanics does not contradict to a local realistic model in which probabilities are calculated as averages over conditionings/measurements for pairs of instances of time $t_1< t_2.$ If we restrict our consideration only to simultaneous measurements at the fixed instance of time $t$ we would get contradiction with Bell's theorem. One of implications of this fact might be the impossibility to define instances of {\it time with absolute precision} on the level of the contextual microscopic realistic model. ,"EPR-Bohm experiment, interference of probabilities, imprecision of time"
"  We acquired high resolution IR spectra of CI Tau, the host star of one of the few young planet candidates amenable to direct spectroscopic detection. We confirm the planet's existence with a direct detection of CO in the planet's atmosphere. We also calculate a mass of 11.6 M$_J$ based on the amplitude of its radial velocity variations. We estimate its flux contrast with its host star to get an absolute magnitude estimate for the planet of 8.17 in the K band. This magnitude implies the planet formed via a ""hot start"" formation mechanism. This makes CI Tau b the youngest confirmed exoplanet as well as the first exoplanet around a T Tauri star with a directly determined, model-independent, dynamical mass. ",CO Detected in CI Tau b: Hot Start Implied by Planet Mass and M$_K$
"  The spatial distribution of elemental abundances in the disc of our Galaxy gives insights both on its assembly process and subsequent evolution, and on the stellar nucleogenesis of the different elements. Gradients can be traced using several types of objects as, for instance, (young and old) stars, open clusters, HII regions, planetary nebulae. We aim at tracing the radial distributions of abundances of elements produced through different nucleosynthetic channels -the alpha-elements O, Mg, Si, Ca and Ti, and the iron-peak elements Fe, Cr, Ni and Sc - by using the Gaia-ESO idr4 results of open clusters and young field stars. From the UVES spectra of member stars, we determine the average composition of clusters with ages >0.1 Gyr. We derive statistical ages and distances of field stars. We trace the abundance gradients using the cluster and field populations and we compare them with a chemo-dynamical Galactic evolutionary model. Results. The adopted chemo-dynamical model, with the new generation of metallicity-dependent stellar yields for massive stars, is able to reproduce the observed spatial distributions of abundance ratios, in particular the abundance ratios of [O/Fe] and [Mg/Fe] in the inner disc (5 kpc<RGC <7 kpc), with their differences, that were usually poorly explained by chemical evolution models. Often, oxygen and magnesium are considered as equivalent in tracing alpha-element abundances and in deducing, e.g., the formation time-scales of different Galactic stellar populations. In addition, often [alpha/Fe] is computed combining several alpha-elements. Our results indicate, as expected, a complex and diverse nucleosynthesis of the various alpha-elements, in particular in the high metallicity regimes, pointing towards a different origin of these elements and highlighting the risk of considering them as a single class with common features. ",The Gaia-ESO Survey: radial distribution of abundances in the Galactic   disc from open clusters and young field stars
"  Thermal energy can be directly converted to electrical energy as a result of thermoelectric effects. Because this conversion realises clean energy technology, such as waste heat recovery and energy harvesting, substantial efforts have been made to search for thermoelectric materials. Under the belief that the material figure of merit $zT$ represents the energy conversion efficiencies of thermoelectric devices, various high peak-$zT$ materials have been explored for half a century. However, thermoelectric properties vary greatly with temperature $T$, so the single value $zT$ does not represent device efficiency accurately. Here we show that the efficiency of thermoelectric conversion is completely determined by \emph{three} parameters $Z_{\mathrm{gen}}$, $\tau$, and $\beta$, which we call the \emph{thermoelectric degrees of freedom}. The $Z_{\mathrm{gen}}$, which is an average of material properties, is a generalisation of the traditional figure of merit. The $\tau$ and $\beta$, which reflect the gradients of the material properties, are proportional to escaped heat caused by the Thomson effect and asymmetric Joule heat, respectively. Our finding proposes new directions for achieving high thermoelectric efficiency; increasing one of the thermoelectric degrees of freedom results in higher efficiency. For example, thermoelectric efficiency can be enhanced up to 176\% by tuning the thermoelectric degrees of freedom in segmented legs, compared to the best efficiency of single-material legs. ",Thermoelectric efficiency has three Degrees of Freedom
"  Reznikov et al. (Phys. Rev. Lett. 75, 3340 (1995)) have presented definitive observations of nonequilibrium noise in a quantum point contact. Especially puzzling is the ""anomalous"" peak structure of the excess noise measured at constant current; to date it remains unexplained. We show that their experiment directly reveals the deep link between conservation principles in the electron gas and its low-dimensional, mesoscopic behavior. Key to that connection are gauge invariance and the compressibility sum rule. These are central not only to the experiment of Reznikov et al. but to the very nature of all mesoscopic transport. ",Where is the Shot Noise of a Quantum Point Contact?
"  Uncertainty Quantification for nonlinear hyperbolic problems becomes a challenging task in the vicinity of shocks. Standard intrusive methods lead to oscillatory solutions and can result in non-hyperbolic moment systems. The intrusive polynomial moment (IPM) method guarantees hyperbolicity but comes at higher numerical costs. In this paper, we filter the gPC coefficients of the Stochastic Galerkin (SG) approximation, which allows a numerically cheap reduction of oscillations. The derived filter is based on Lasso regression which sets small gPC coefficients of high order to zero. We adaptively choose the filter strength to obtain a zero-valued highest order moment, which allows optimality of the corresponding optimization problem. The filtered SG method is tested for Burgers' and the Euler equations. Results show a reduction of oscillations at shocks, which leads to an improved approximation of expectation values and the variance compared to SG and IPM. ",Filtered Stochastic Galerkin Methods For Hyperbolic Equations
"  We report on ongoing work to gain insight into the astronomy knowledge and perspectives of pre-service teachers and middle school students in Norway. We carefully adapted and translated into Norwegian an existing instrument, the Introductory Astronomy Questionnaire (IAQ); we administered this adapted IAQ to (i) pre-service teachers at the largest teacher education institution in Norway, and (ii) students drawn from eight middle schools in Oslo, in both cases before and after astronomy instruction. Amongst our preliminary findings - based on an analysis of both free-response writing and multiple-choice responses - was that when prompted to provide responses to hypothetical students, the pre-service teachers exhibited a marked drop in pedagogical responses pre- to post-instruction, with corresponding shifts towards more authoritative responses. We also identified potentially serious issues relating to middle school students' conceptions of size and distances in the universe, with significant stratification along gender lines. ",Perspectives on astronomy: probing Norwegian pre-service teachers and   middle school students
"  We study excitation waves on a Newman-Watts small-world network model of coupled excitable elements. Depending on the global coupling strength, we find differing resilience to the added long-range links and different mechanisms of propagation failure. For high coupling strengths, we show agreement between the network and a reaction-diffusion model with additional mean-field term. Employing this approximation, we are able to estimate the critical density of long-range links for propagation failure. ",Effect of small-world topology on wave propagation on networks of   excitable elements
"  We present the X-ray afterglow catalog of BeppoSAX from the launch of the satellite to the end of the mission. Thirty-three X-ray afterglows were securely identified based on their fading behavior out of 39 observations. We have extracted the continuum parameters (decay index, spectral index, flux, absorption) for all available afterglows. We point out a possible correlation between the X-ray afterglow luminosity and the energy emitted during the prompt $\gamma$-ray event. We do not detect a significant jet signature within the afterglows, implying a lower limit on the beaming angle, neither a standard energy release when X-ray fluxes are corrected for beaming. Our data support the hypothesis that the burst should be surrounded by an interstellar medium rather than a wind environment, and that this environment should be dense. This may be explained by a termination shock located near the burst progenitor. We finally point out that some dark bursts may be explained by an intrinsic faintness of the event, while others may be strongly absorbed. ",The BeppoSAX catalog of GRB X-ray afterglow observations
  Recently the global variation of the Planck mass in the General Relativistic Einstein-Hilbert action was proposed as a self-tuning mechanism of the cosmological constant preventing vacuum energy from freely gravitating. We show that this global mechanism emerges for generic local scalar-tensor theories with additional coupling of the scalar field to the field strength of a three-form gauge field that turns the scalar field constant on the domain of the action. Evaluation of the resulting integral constraint equation over the observable Universe yields a self-consistent framework with General Relativistic field equations and arbitrary radiatively stable residual cosmological constant. We argue that the expectation value for this residual is in good agreement with the magnitude of the observed cosmic acceleration. ,A local self-tuning mechanism for the cosmological constant
"  We empirically verify that the market capitalisations of coins and tokens in the cryptocurrency universe follow power-law distributions with significantly different values, with the tail exponent falling between 0.5 and 0.7 for coins, and between 1.0 and 1.3 for tokens. We provide a rationale for this, based on a simple proportional growth with birth & death model previously employed to describe the size distribution of firms, cities, webpages, etc. We empirically validate the model and its main predictions, in terms of proportional growth (Gibrat's law) of the coins and tokens. Estimating the main parameters of the model, the theoretical predictions for the power-law exponents of coin and token distributions are in remarkable agreement with the empirical estimations, given the simplicity of the model. Our results clearly characterize coins as being ""entrenched incumbents"" and tokens as an ""explosive immature ecosystem"", largely due to massive and exuberant Initial Coin Offering activity in the token space. The theory predicts that the exponent for tokens should converge to 1 in the future, reflecting a more reasonable rate of new entrants associated with genuine technological innovations. ",Classification of cryptocurrency coins and tokens by the dynamics of   their market capitalisations
"  This is the content of a set of lectures given at the XIII Jorge Andre Swieca Summer School on Particles and Fields, held in Campos do Jordao, Brazil in January 2005. They intend to be a basic introduction to the topic of gauge/gravity duality in confining theories. We start by reviewing some key aspects of the low energy physics of non-Abelian gauge theories. Then, we present the basics of the AdS/CFT correspondence and its extension both to gauge theories in different spacetime dimensions with sixteen supercharges and to more realistic situations with less supersymmetry. We discuss the different options of interest: placing D-branes at singularities and wrapping D-branes in calibrated cycles of special holonomy manifolds. We finally present an outline of a number of non-perturbative phenomena in non-Abelian gauge theories as seen from supergravity. ",Gauge/String Duality in Confining Theories
"  Smart grid is an energy infrastructure that increases energy efficiency by using communication infrastructure, smart meters, smart appliances, automated control and networking, and more. This paper focuses on the Power Line Communication (PLC) aspect and technologies used in the smart grid. There are various challenges and advancements in the smart grid; this research discusses how PLC can improve smart grid performance. In order to provide applicable results, practical PLC system parameters and other required data was obtained from Florida Power and Light (FPL). Modeling of the PLC system with different types of digital modulations was conducted using MATLAB/Simulink software and Python. The benefits and design tradeoffs of Amplitude Shift Keying (ASK), Frequency Shift Keying (FSK), and Phase Shift Keying (PSK) are discussed. The modulation schemes are compared on the basis of their applicability to a practical PLC network by comparing the results of the simulations ",Modeling and Analysis of Power Line Communications for Application in   Smart Grid
"  By means of atomistic molecular dynamics simulations we investigate the behaviour of poly(N-isopropylacrylamide), PNIPAM, in water at temperatures below and above the lower critical solution temperature (LCST), including the undercooled regime. The transition between water soluble and insoluble states at the LCST is described as a cooperative process involving an intramolecular coil-to-globule transition preceding the aggregation of chains and the polymer precipitation. In this work we investigate the molecular origin of such cooperativity and the evolution of the hydration pattern in the undercooled polymer solution. The solution behaviour of an atactic 30-mer at high dilution is studied in the temperature interval from 243 to 323 K with a favourable comparison to available experimental data. In the PNIPAM water soluble states we detect a correlation between polymer segmental dynamics and diffusion motion of bound water, occurring with the same activation energy. Simulation results show that below the coil-to-globule transition temperature PNIPAM is surrounded by a network of hydrogen bonded water molecules and that the cooperativity arises from the structuring of water clusters in proximity to hydrophobic groups. Differently, the perturbation of the hydrogen bond pattern involving water and amide groups occurs above the transition temperature. Altogether these findings reveal that even above the LCST PNIPAM remains largely hydrated and that the coil-to-globule transition is related with a significant rearrangement of the solvent in proximity of the surface of the polymer. The comparison between the hydrogen bonding of water in the surrounding of PNIPAM isopropyl groups and in bulk displays a decreased structuring of solvent at the hydrophobic polymer-water interface across the transition temperature, as expected because of the topological extension along the chain of such interface. ",On the Molecular Origin of the Cooperative Coil-to-globule Transition of   Poly(N-isopropylacrylamide) in Water
"  We demonstrate the role of proximity effect in the thermal hysteresis of superconducting constrictions. From the analysis of successive thermal instabilities in the transport characteristics of micron-size superconducting quantum interference devices with a well-controlled geometry, we obtain a complete picture of the different thermal regimes. These determine whether the junctions are hysteretic or not. Below the superconductor critical temperature, the critical current switches from a classical weak-link behavior to one driven by the proximity effect. The associated small amplitude of the critical current makes it robust with respect to the heat generation by phase-slips, leading to a non-hysteretic behavior. ",Reversibility of Superconducting Nb Weak Links Driven by the Proximity   Effect in a Quantum Interference Device
"  The transition between low and high density phases is a typical feature of systems with social interactions. This contribution focuses on simple evacuation design of one room with one entrance and one exit; four passing-through experiments were organized and evaluated by means of automatic image processing. The phase of the system, determined by travel time and occupancy, is evaluated with respect to the inflow, a controlled boundary condition. Critical values of inflow and outflow were described with respect to the transition from low density to congested state. Moreover, microscopic analysis of travel time is provided. ",Experimental Study of Phase Transition in Pedestrian Flow
"  The paper reports on the first observation of doubly-magic Nickel-48 in an experimental at the SISSI/LISE3 facility of GANIL. Four Nickel-48 isotopes were identified. In addition, roughly 100 Nickel-49, 50 Iron-45, and 290 Chromium-42 isotopes were observed. This opens the possibility to search for two-proton emission from these nuclei. ",On the discovery of doubly-magic $^{48}$Ni
"  Motivated by previous studies in literature about the potential importance of relativistic corrections to galaxy cluster hydrostatic masses, we calculate the masses of 12 relaxed clusters (with Chandra X-ray data) using the Tolman-Oppenheimer-Volkov (TOV) equation of hydrostatic equilibrium and the ideal gas equation of state. Analytical formulae for gas density and temperature profiles for these clusters, previously derived by Vikhlinin et al (astro-ph/0507092) were used to obtain these masses. We compare the TOV-based masses with those obtained using the corresponding Newtonian equation of hydrostatic equilibrium. We find that the fractional relative difference between the two masses are negligible, corresponding to $\sim \mathcal{O}(10^{-5})$. ",Galaxy cluster hydrostatic masses using Tolman-Oppenheimer-Volkoff   equation
"  Provided the enhancement in the $p \bar{p}$ spectrum in radiative decay $J/\psi \to \gamma p \bar{p}$ observed by the BES collaboration is due to an existence of a $p \bar{p}$ molecular state, we calculate its binding energy and lifetime in the linear $\sigma$ model. We consider a possibility that the enhancement is due to a $p \bar p$ resonance which is in either S-wave or P-wave structure and compare our results with the data. ",Can the observed enhancement in the mass spectrum of p \bar p in J/\psi   \to \gamma p \bar p be interpreted by a possible p \bar p bound state
  We report on experimental tests of the trend of random laserlinewidth versus pumping power as predicted by an Haus master equation that is formally identical to the one-dimensional Gross- Pitaevskii equation in an harmonic potential. Experiments are done by employing picosecond pumped dispersions of Titaniumdioxide particles in dye-doped methanol. The derivation of the master equations is also detailed and shown to be in agreement with experiments analytically predicting the value of the threshold linewidth. ,Haus/Gross-Pitaevskii equation for random lasers
"  Development of models and dedicated numerical methods for dynamics in fractured rocks is an active research field, with research moving towards increasingly advanced process couplings and complex fracture networks. The inclusion of coupled processes in simulation models is challenged by the high aspect ratio of the fractures, the complex geometry of fracture networks and the crucial impact of processes that completely change characteristics on the fracture-rock interface. This paper provides a general discussion of design principles for introducing fractures in simulators, and defines a framework for integrated modeling, discretization and computer implementation. The framework is implemented in the simulation software PorePy, which can serve as a flexible prototyping tool or multiphysics problems in fractured rocks. Based on a representation of the fractures and their intersections as lower-dimensional objects, we discuss data structures for mixed-dimensional meshes, formulation of multiphysics problems and discretizations that utilize existing software. We further present the implementation of these concepts in the PorePy open-source software tool, which is aimed at coupled simulation of flow and transport in three-dimensional fractured reservoirs as well as deformation of fractures and the reservoir in general. We present validation by benchmarks for flow, poroelasticity and fracture deformation in fractured porous media. The flexibility of the framework is then illustrated by simulations of fully coupled flow and transport and of injection driven deformation of fractures. All results reported herein can be reproduced by openly available simulation scripts. ",PorePy: An Open-Source Software for Simulation of Multiphysics Processes   in Fractured Porous Media
"  Optical Feshbach resonance is capable of inducing spatially varying interactions in ultra-cold atoms. Its applications to pancake-shaped clouds of bosons and fermions enable one to study several fresh phenomena. We examine possibilities of inducing counter-intuitive structures such as creating a superfluid enclave inside a Mott insulator for bosons and a normal-gas core enclosed by a superfluid shell for fermions. We discuss feasible experimental setups and signatures of those interesting structures, which can be very different from common structures observed in experiments so far. While a superfluid enclave in a Mott insulator can be useful for constructing atomic devices for atomtronics, superconducting islands observed in scanning-tunneling microscopy of heavily underdoped high-temperature superconductors may be studied with cold Fermi gases with spatially varying attractions. ",Spatially varying interactions induced in atomic gases by optical   Feshbach resonance
"  The Kramers turnover problem, that is obtaining a uniform expression for the rate of escape of a particle over a barrier for any value of the external friction was solved in the eighties. Two formulations were given, one by Melnikov and Meshkov (MM) (J. Chem. Phys. 85, 1018 (1986)), which was based on a perturbation expansion for the motion of the particle in the presence of friction. The other, by Pollak, Grabert and Haenggi (PGH) (J. Chem. Phys. 91, 4073 (1989)), valid also for memory friction, was based on a perturbation expansion for the motion along the collective unstable normal mode of the particle. Both theories did not take into account the temperature dependence of the average energy loss to the bath. Increasing the bath temperature will reduce the average energy loss. In this paper, we analyse this effect, using a novel perturbation theory. We find that within the MM approach, the thermal energy gained from the bath diverges, the average energy gain becomes infinite, implying an essential failure of the theory. Within the PGH approach increasing the bath temperature reduces the average energy loss but only by a finite small amount, of the order of the inverse of the reduced barrier height. This then does not seriously affect the theory. Analysis and application for a cubic potential and Ohmic friction are presented. ",Improvements to Kramers Turnover Theory
"  This study proposes that the longstanding problems of quantum chromodynamics (QCD) as an SU(3)_C gauge theory, the confinement mechanism and \Theta vacuum, can be resolved by dynamical spontaneous symmetry breaking (DSSB) through the condensation of singlet gluons and quantum nucleardynamics (QND) as an SU(2)_N \times U(1)_Z gauge theory is produced. The confinement mechanism is the result of massive gluons and the Yukawa potential provides hadron formation. The evidences for the breaking of discrete symmetries (C, P, T, CP) during DSSB appear explicitly: baryons and mesons without their parity partners, the conservation of vector current and the partial conservation of the axial vector current, the baryon asymmetry \delta_B \simeq 10^{-10}, and the neutron electric dipole moment \Theta < 10^{-9}. ",Dynamical Spontaneous Symmetry Breaking in Quantum Chromodynamics
"  In the AdS/CFT correspondence, the entanglement entropy of subregions in the boundary CFT is conjectured to be dual to the area of a bulk extremal surface at leading order in $G_N$ in the holographic limit. Under this dictionary, distantly separated regions in the CFT vacuum state have zero mutual information at leading order, and only attain nonzero mutual information at this order when they lie close enough to develop significant classical and quantum correlations. Previously, the separation at which this phase transition occurs for equal-size ball-shaped regions centered at antipodal points on the boundary was known analytically only in $3$ spacetime dimensions. Inspired by recent explorations of general relativity at large-$d$, we compute the separation at which the phase transition occurs analytically in the limit of infinitely many spacetime dimensions, and find that distant regions cannot develop large correlations without collectively occupying the entire volume of the boundary theory. We interpret this result as illustrating the spatial decoupling of holographic correlations in the large-$d$ limit, and provide intuition for this phenomenon using results from quantum information literature. We also compute the phase transition separation numerically for a range of bulk spacetime dimensions from $4$ to $21$, where analytic results are intractable but numerical results provide insight into the dimension-dependence of holographic correlations. For bulk dimensions above $5$, our exact numerical results are well approximated analytically by working to next-to-leading order in the large-$d$ expansion. ",Large-$d$ phase transitions in holographic mutual information
"  This article studies the limiting behavior of a class of robust population covariance matrix estimators, originally due to Maronna in 1976, in the regime where both the number of available samples and the population size grow large. Using tools from random matrix theory, we prove that, for sample vectors made of independent entries having some moment conditions, the difference between the sample covariance matrix and (a scaled version of) such robust estimator tends to zero in spectral norm, almost surely. This result can be applied to various statistical methods arising from random matrix theory that can be made robust without altering their first order behavior. ",Robust Estimates of Covariance Matrices in the Large Dimensional Regime
"  To unravel the origin of the dielectric anomaly at the antiferromagnetic ordering of magnetoelectric Bi$_2$Fe$_4$O$_9$ we performed neutron powder diffraction measurements across the N$\acute{\rm e}$el temperature, $T_{\rm N}$. Both local structures and long-range symmetry are studied using the complementary analyses of atomic pair distribution function (PDF) and Rietveld methods at temperatures 300~K, 250~K, and 200~K. We present that PDF peaks which reflect local atomic arrangements exhibit a noticeable variation below $T_{\rm N}$ without long-range symmetry change. The implication of the PDF evolution is discussed in view of a local structural distortion at the onset of the antiferromagnetic ordering. ",Local structural distortion induced by antiferromagnetic ordering in   Bi$_2$Fe$_4$O$_9$ studied using neutron total scattering analysis
"  In our previous investigations, we have developed the renormalization group method to $p$-adic models on Cayley trees, this method is closely related to the investigation of $p$-adic dynamical systems associated with a given model. In this paper, we study chaotic behavior of the Potts-Bethe mapping. We point out that a similar kind of result is not known in the case of real numbers (with rigorous proofs). ",Chaotic behavior of the $P$-adic Potts-Bethe mapping
"  Recently, there has been a significant level of discussion of the correct treatment of Kelvin-Helmholtz instability in the astrophysical community. This discussion relies largely on how the KHI test is posed and analyzed. We pose a stringent test of the initial growth of the instability. The goal is to provide a rigorous methodology for verifying a code on two dimensional Kelvin-Helmholtz instability. We ran the problem in the Pencil Code, Athena, Enzo, NDSPHMHD, and Phurbas. A strict comparison, judgment, or ranking, between codes is beyond the scope of this work, though this work provides the mathematical framework needed for such a study. Nonetheless, how the test is posed circumvents the issues raised by tests starting from a sharp contact discontinuity yet it still shows the poor performance of Smoothed Particle Hydrodynamics. We then comment on the connection between this behavior to the underlying lack of zeroth-order consistency in Smoothed Particle Hydrodynamics interpolation. We comment on the tendency of some methods, particularly those with very low numerical diffusion, to produce secondary Kelvin-Helmholtz billows on similar tests. Though the lack of a fixed, physical diffusive scale in the Euler equations lies at the root of the issue, we suggest that in some methods an extra diffusion operator should be used to damp the growth of instabilities arising from grid noise. This statement applies particularly to moving-mesh tessellation codes, but also to fixed-grid Godunov schemes. ",A Well-Posed Kelvin-Helmholtz Instability Test and Comparison
"  Constraints on models which predict resonant top-quark pair production at the LHC are provided via a reinterpretation of the Standard Model (SM) particle level measurement of the top-anti-top invariant mass distribution, $m(t\bar{t})$. We make use of state-of-the-art Monte Carlo event simulation to perform a direct comparison with measurements of $m(t\bar{t})$ in the semi-leptonic channels, considering both the boosted and the resolved regime of the hadronic top decays. A simplified model to describe various scalar resonances decaying into top-quarks is considered, including CP-even and CP-odd, color-singlet and color-octet states, and the excluded regions in the respective parameter spaces are provided. ",Constraining scalar resonances with top-quark pair production at the LHC
"  Consider a complex simple Lie algebra g of rank n. Denote by \Pi a system of simple roots, by W the corresponding Weyl group, consider a reduced expression w = s_{\alpha_{1}} ... s_{\alpha_{t}} (each \alpha_{i} in \Pi) of some w \in W and call diagram any subset of {1, ..., t}. We denote by U_{q}^{w}(g) the ""quantum nilpotent"" algebra defined by J. C. Jantzen. We prove (theorem 5.3. 1) that the positive diagrams naturally associated with the positive subexpressions (of the reduced expression of w) in the sense of R. Marsh and K. Rietsch, coincide with the admissible diagrams constructed by G. Cauchon which describe the natural stratification of Spec(U_{q}^{w}(g)). If the Lie algebra g is of type A_{n} and w is choosen in order that U_{q}^{w}(g) is the quantum matrices algebra O_{q}(M_{p,m}(k)) with m = n-p+1 (see section 2.1), then the admissible diagrams are known (G. Cauchon) to be the Le - diagrams in the sense of A. Postnikov . In this particular case, the equality of Le - diagrams and positive subexpressions (of the reduced expression of w) have also been proved (with quite different methods) by A. Postnikov and by T. Lam and L. Williams. ",Admissible Diagrams in U_{q}^{w}(g) and Combinatoric Properties of Weyl   Groups
"  Accurate calibration of probabilistic predictive models learned is critical for many practical prediction and decision-making tasks. There are two main categories of methods for building calibrated classifiers. One approach is to develop methods for learning probabilistic models that are well-calibrated, ab initio. The other approach is to use some post-processing methods for transforming the output of a classifier to be well calibrated, as for example histogram binning, Platt scaling, and isotonic regression. One advantage of the post-processing approach is that it can be applied to any existing probabilistic classification model that was constructed using any machine-learning method.   In this paper, we first introduce two measures for evaluating how well a classifier is calibrated. We prove three theorems showing that using a simple histogram binning post-processing method, it is possible to make a classifier be well calibrated while retaining its discrimination capability. Also, by casting the histogram binning method as a density-based non-parametric binary classifier, we can extend it using two simple non-parametric density estimation methods. We demonstrate the performance of the proposed calibration methods on synthetic and real datasets. Experimental results show that the proposed methods either outperform or are comparable to existing calibration methods. ",Binary Classifier Calibration: Non-parametric approach
"  Motivated by studying stochastic systems with non-Gaussian L\'evy noise, spectral properties for a type of linear cocycles are considered. These linear cocycles have countable jump discontinuities in time. A multiplicative ergodic theorem is proved for such linear cocycles. Then, the result is illustrated for two linear stochastic systems with general L\'evy motions. ",A Multiplicative Ergodic Theorem for Discontinuous Random Dynamical   Systems and Applications
"  Beyond Earth-like planets, moons can be habitable, too. No exomoons have been securely detected, but they could be extremely abundant. Young Jovian planets can be as hot as late M stars, with effective temperatures of up to 2000 K. Transits of their moons might be detectable in their infrared photometric light curves if the planets are sufficiently separated ($\gtrsim10$ AU) from the stars to be directly imaged. The moons will be heated by radiation from their young planets and potentially by tidal friction. Although stellar illumination will be weak beyond 5 AU, these alternative energy sources could liquify surface water on exomoons for hundreds of Myr. A Mars-mass H$_2$O-rich moon around $\beta$ Pic b would have a transit depth of $1.5\times10^{-3}$, in reach of near-future technology. ",Transits of extrasolar moons around luminous giant planets
"  Porous nanowires (NWs) with tunable thermal conductance are examined as a candidate for thermoelectric (TE) devices with high efficiency (ZT). Thermal conductance of porous Si and Ge NWs is calculated using the complete phonon dispersion obtained from a modified valence force field (MVFF) model. The presence of holes in the wires break the crystal symmetry which leads to the reduction in ballistic thermal conductance ($\sigma_{l}$). $[100]$ Si and Ge NWs show similar percentage reduction in $\sigma_{l}$ for the same amount of porosity. A 4nm $\times$ 4nm Si (Ge) NW shows $\sim$ 30% (29%) reduction in $\sigma_{l}$ for a hole of radius 0.8nm. The model predicts an anisotropic reduction in $\sigma_{l}$ in SiNWs, with $[111]$ showing maximum reduction followed by $[100]$ and $[110]$ for a similar hole radius. The reduction in $\sigma_{l}$ is attributed to phonon localization and anisotropic mode reduction. ",Tuning lattice thermal conductance by porosity control in ultra-scaled   Si and Ge nanowires
"  I give a new proof, in scheme-theoretic language, of Tate's old result on genus-change over nonperfect fields in characteristic p>0. Namely, for normal geometrically integral curves, the difference between arithmetic and geometric genus over the algebraic closure is divisible by (p-1)/2. ",On genus-change in algebraic curves over nonperfect fields
  External errors of effective temperatures of stars for selected libraries are estimated from data intercomparisons. It is found that the obtained errors are mainly in a good correspondence with the published data. The results may be used to homogenize the effective temperatures by averaging the data (with the weights inversely proportional to the squared errors) from independent sources. ,Homogenized effective temperatures from stellar libraries
"  This paper addresses a multi-robot planning problem in partially unknown semantic environments. The environment is assumed to have known geometric structure (e.g., walls) and to be occupied by static labeled landmarks with uncertain positions and classes. This modeling approach gives rise to an uncertain semantic map generated by semantic SLAM algorithms. Our goal is to design control policies for robots equipped with noisy perception systems so that they can accomplish collaborative tasks captured by global temporal logic specifications. To account for environmental and perceptual uncertainty, we extend a fragment of Linear Temporal Logic (LTL), called co-safe LTL, by including perception-based atomic predicates allowing us to incorporate uncertainty-wise and probabilistic satisfaction requirements directly into the task specification. The perception-based LTL planning problem gives rise to an optimal control problem, solved by a novel sampling-based algorithm, that generates open-loop control policies that are updated online to adapt to a continuously learned semantic map. We provide extensive experiments to demonstrate the efficiency of the proposed planning architecture. ",Perception-Based Temporal Logic Planning in Uncertain Semantic Maps
"  The Wess-Zumino model on N=1/2 nonanticommutative superspace, which contains the dimension-6 term F^3, is shown to be renormalizable to all orders in perturbation theory, upon adding F and F^2 terms to the original Lagrangian. The renormalizability is possible, even with this higher-dimension operator, because the Lagrangian is not hermitian. Such deformed field theories arise naturally in string theory with a graviphoton background. ",N=1/2 Wess-Zumino model is renormalizable
"  Starting with a solvable Nevanlinna-Pick interpolation problem with the initial data coming from the symmetrized bidisk, this paper studies the corresponding uniqueness set, i.e., the largest set in the domain where all solutions to the problem coincide. It is shown that the uniqueness set coincides with an algebraic variety in the domain. The algebraic variety - canonically constructed from the interpolation data - is called the uniqueness variety. It was shown that the uniqueness variety contains a distinguished variety which by definition is the zero set of a two-variable polynomial that intersects the domain and exits through its distinguished boundary. A complete algebraic and geometric characterizations of distinguished varieties are obtained in this paper. ",Distinguished varieties and the Nevanlinna-Pick interpolation problem on   the symmetrized bidisk
"  We made a multi-wavelength study of young massive star clusters (YSCs) in the interacting galaxy ARP 24, using the optical and ultraviolet images from Hubble Space Telescope (HST), Sloan Digital Sky Survey, and Galaxy Evolution Explorer; the mid-infrared images from Spitzer Space Telescope; and the narrow-band Ha image and optical spectra from the NAOC 2.16m telescope. Based on the HST images, we found that the brightest infrared knot in ARP 24 is associated with a complex of five young massive star clusters, within a region of ~ 0.95"" radius (127pc) in size. The ages and masses of the star clusters in this complex and other regions were estimated using HST broadband photometries and the Starburst99 synthesis models. The star clusters in this complex are very young (within ages of ~ 3-5 Myr) and massive (masses of ~ 10^5 Msun). The ionization parameter and metallicity of the complex were estimated using the emission line ratios, and the star formation rates were calculated using monochromatic 24um, FUV, and Ha line luminosities. We speculate that ARP 24 may formed by a retrograde fly-by encounter indicated by its one-armed appearance and fan-like structure, and the formation of the YSCs in this galaxy is triggered by the interaction. The clusters in the YSC complex may formed in a single giant molecular cloud simultaneously. From the ultraviolet to mid-infrared spectral energy distributions, we found that the region of the YSC complex is relatively bluer in optical and has higher 24um dust emission relative to the starlight and 8um emission. This warm infrared color may due to strong UV radiation field or other mechanisms (e.g., shocks) within this region which may destroy the Polycyclic Aromatic Hydrocarbons and enhance the small grain emission at 24um. ",Multi-wavelength Study of Young Massive Star Clusters in the Interacting   Galaxy ARP 24
"  The propagation of light through a Universe of (a) isothermal mass spheres amidst (b) a homogeneous matter component, is considered. We demonstrate by an analytical proof that as long as a small light bundle passes {\it through} sufficient number of (a) at various impact parameters - a criterion of great importance - its average convergence will exactly compensate the divergence within (b). The net effect on the light is statistically the same as if all the matter in (a) is `fully homogenized'. When applying the above ideas towards understanding the angular size of the primary acoustic peaks of the microwave background, however, caution is needed. The reason is that most (by mass) of (a) are in galaxies - their full mass profiles are not sampled by passing light - at least the inner 20 kpc regions of these systems are missed by the majority of rays, while the rest of the rays would map back to unresolvable but magnified, randomly located spots to compensate for the loss in angular size. Therefore, a scanning pair of WMAP beams finds most frequently that the largest temperature difference occurs when each beam is placed at diametrically opposite points of the Dyer-Roeder collapsed sections. This is the {\it mode} magnification, which corresponds to the acoustic {\it peaks}, and is less than the mean (or the homogeneous pre-clumping angular size). Since space was seen to be Euclidean without taking the said adjustment into account, the true density of the Universe should be supercritical. Our analysis gives $\Omega_m =$ 0.278 $\pm$ 0.040 and $\Omega_{\Lambda} =$ 0.782 $\pm$ 0.040. ",Are the WMAP angular magnification measurements consistent with an   inhomogeneous critical density Universe?
"  The neutrino mixing parameters are thoroughly studied using renormalization-group evolution of Dirac neutrinos with recently proposed parametrization of the neutrino mixing angles referred as `high-scale mixing relations'. The correlations among all neutrino mixing and $CP$ violating observables are investigated. The predictions for the neutrino mixing angle $\theta_{23}$ are precise, and could be easily tested by ongoing and future experiments. We observe that the high scale mixing unification hypothesis is incompatible with Dirac neutrinos due to updated experimental data. ",Precise predictions for Dirac neutrino mixing
"  We present a program for the numerical evaluation of form factors entering the calculation of one-loop amplitudes with up to six external legs. The program is written in Fortran95 and performs the reduction to a certain set of basis integrals numerically, using a formalism where inverse Gram determinants can be avoided. It can be used to calculate one-loop amplitudes with massless internal particles in a fast and numerically stable way. ",Golem95: a numerical program to calculate one-loop tensor integrals with   up to six external legs
"  We performed neutron imaging of ferromagnetic transitions in Ni$_3$Al and HgCr$_2$Se$_4$ crystals. These neutron depolarization measurements revealed bulk magnetic inhomogeneities in the ferromagnetic transition temperature with spatial resolution of about 100~$\mu$m. To obtain such spatial resolution, we employed a novel neutron microscope equipped with Wolter mirrors as a neutron image-forming lens and a focusing neutron guide as a neutron condenser lens. The images of Ni$_3$Al show that the sample does not homogeneously go through the ferromagnetic transition; the improved resolution allowed us to identify a distribution of small grains with slightly off-stoichiometric composition. Additionally, neutron depolarization imaging experiments on the chrome spinel, HgCr$_2$Se$_4$, under pressures up to 15~kbar highlight the advantages of the new technique especially for small samples or sample environments with restricted sample space. The improved spatial resolution enables one to observe domain formation in the sample while decreasing the acquisition time despite having a bulky pressure cell in the beam. ",High-resolution neutron depolarization microscopy of the ferromagnetic   transitions in Ni$_3$Al and HgCr$_2$Se$_4$ under pressure
"  We present new 2 cm and 6 cm maps of H2CO, radio recombination lines, and the radio continuum in the W51 star forming complex acquired with Arecibo and the Green Bank Telescope at ~50"" resolution. We use H2CO absorption to determine the relative line-of-sight positions of molecular and ionized gas. We measure gas densities using the H2CO densitometer, including continuous measurements of the dense gas mass fraction (DGMF) over the range $10^4$ cm$^{-3}$ < n(H$_2$) < $10^6$ cm$^{-3}$- this is the first time a dense gas mass fraction has been measured over a range of densities with a single data set. The DGMF in W51A is high,f >~70% above $n>10^4$ cm$^{-3}$, while it is low, f<20%, in W51 B. We did not detect any H2CO emission throughout the W51 GMC; all gas dense enough to emit under normal conditions is in front of bright continuum sources and therefore is seen in absorption instead. The data set has been made public at http://dx.doi.org/10.7910/DVN/26818. Conclusions. (1) The dense gas fraction in the W51 A and B clouds shows that W51 A will continue to form stars vigorously, while star formation has mostly ended in W51 B. The lack of dense, star-forming gas around W51 C indicates that collect-and-collapse is not acting or is inefficient in W51. (2) Ongoing high-mass star formation is correlated with n ~ 1x10$^5$ cm$^{-3}$ gas. Gas with n > 10$^4$ cm$^{-3}$ is weakly correlated with low and moderate mass star formation, but does not strongly correlate with high-mass star formation. (3) The nondetection of H$_2$CO emission implies that the emission detected in other galaxies, e.g. Arp 220, comes from high-density gas that is not directly affiliated with already-formed massive stars. Either the non-star-forming ISM of these galaxies is very dense, implying the star formation density threshold is higher, or H II regions have their emission suppressed. ",The dense gas mass fraction in the W51 cloud and its protoclusters
"  NGC 4151 is the brightest Seyfert 1 nucleus in X-rays. It was the first object to show short time delays in the Fe K band, which were attributed to relativistic reverberation, providing a new tool for probing regions at the black hole scale. Here, we report the results of a large XMM-Newton campaign in 2015 to study these short delays further. Analyzing high quality data that span time scales between hours and decades, we find that neutral and ionized absorption contribute significantly to the spectral shape. Accounting for their effects, we find no evidence for a relativistic reflection component, contrary to early work. Energy-dependent lags are significantly measured in the new data, but with an energy profile that does not resemble a broad iron line, in contrast to the old data. The complex lag-energy spectra, along with the lack of strong evidence for a relativistic spectral component, suggest that the energy-dependent lags are produced by absorption effects. The long term spectral variations provide new details on the variability of the narrow Fe K$\alpha$ line . We find that its variations are correlated with, and delayed with respect to, the primary X-ray continuum. We measure a delay of $\tau= 3.3^{+1.8}_{-0.7}$ days, implying an origin in the inner broad line region (BLR). The delay is half the H$\beta$ line delay, suggesting a geometry that differs slightly from the optical BLR. ",Revisiting The Spectral and Timing Properties of NGC 4151
"  The heterogeneous edge-cloud computing paradigm can provide a more optimal direction to deploy scientific workflows than traditional distributed computing or cloud computing environments. Due to the different sizes of scientific datasets and some of these datasets must keep private, it is still a difficult problem to finding an data placement strategy that can minimize data transmission as well as placement cost. To address this issue, this paper combines advantages of both edge and cloud computing to construct a data placement model, which can balance data transfer time and data placement cost using intelligent computation. The most difficult research challenge the model solved is to consider many constrain in this hybrid computing environments, which including shared datasets within individual and among multiple workflows across various geographical regions. According to the constructed model, the study propose a new data placement strategy named DE-DPSO-DPS, which using a discrete particle swarm optimization algorithm with differential evolution (DE-DPSO-DPA) to distribute these scientific datasets. The strategy also not only consider the characteristics such as the number and storage capacity of edge micro-datacenters, the bandwidth between different datacenters and the proportion of private datasets, but also analysis the performance of algorithm during the workflows execution. Comprehensive experiments are designed in simulated heterogeneous edge-cloud computing environments demonstrate that the data placement strategy can effectively reduce the data transmission time and placement cost as compared to traditional strategies for data-sharing scientific workflows. ",Optimal Data Placement for Data-Sharing Scientific Workflows in   Heterogeneous Edge-Cloud Computing Environments
"  In this paper, we propose the Quantile Option Architecture (QUOTA) for exploration based on recent advances in distributional reinforcement learning (RL). In QUOTA, decision making is based on quantiles of a value distribution, not only the mean. QUOTA provides a new dimension for exploration via making use of both optimism and pessimism of a value distribution. We demonstrate the performance advantage of QUOTA in both challenging video games and physical robot simulators. ",QUOTA: The Quantile Option Architecture for Reinforcement Learning
"  We consider a system of nonlinear partial differential equations that describes an age-structured population living in changing environment on $N$ patches. We prove existence and uniqueness of solution and analyze large time behavior of the system in time-independent case, for periodically changing and for irregularly varying environment. Under the assumption that every patch can be reached from every other patch, directly or through several intermediary patches, and that net reproductive operator has spectral radius larger than one, we prove that population is persistent on all patches. If the spectral radius is less or equal one, extinction on all patches is imminent. ",Persistence analysis of the age-structured population model on several   patches
  This talk reports on various aspects of the divergence of perturbative expansions in the context of matching QCD onto heavy quark effective theory. Implications for exclusive and inclusive decays of heavy mesons are discussed. ,Matching to all orders and power corrections in heavy quark effective   theory
"  In this work, we perform a spectral analysis of flipped multilevel Toeplitz sequences, i.e., we study the asymptotic spectral behaviour of $\{Y_{\boldsymbol{n}}T_{\boldsymbol{n}}(f)\}_{\boldsymbol{n}}$, where $T_{\boldsymbol{n}}(f)$ is a real, square multilevel Toeplitz matrix generated by a function $f\in L^1([-\pi,\pi]^d)$ and $Y_{\boldsymbol{n}}$ is the exchange matrix, which has $1$s on the main anti-diagonal. In line with what we have shown for unilevel flipped Toeplitz matrix sequences, the asymptotic spectrum is determined by a $2\times 2$ matrix-valued function whose eigenvalues are $\pm |f|$. Furthermore, we characterize the eigenvalue distribution of certain preconditioned flipped multilevel Toeplitz sequences with an analysis that covers both multilevel Toeplitz and circulant preconditioners. Finally, all our findings are illustrated by several numerical experiments. ",The asymptotic spectrum of flipped multilevel Toeplitz matrices and of   certain preconditionings
"  In scene understanding, robotics benefit from not only detecting individual scene instances but also from learning their possible interactions. Human-Object Interaction (HOI) Detection infers the action predicate on a <human, predicate, object> triplet. Contextual information has been found critical in inferring interactions. However, most works only use local features from single human-object pair for inference. Few works have studied the disambiguating contribution of subsidiary relations made available via graph networks. Similarly, few have learned to effectively leverage visual cues along with the intrinsic semantic regularities contained in HOIs. We contribute a dual-graph attention network that effectively aggregates contextual visual, spatial, and semantic information dynamically from primary human-object relations as well as subsidiary relations through attention mechanisms for strong disambiguating power. We achieve comparable results on two benchmarks: V-COCO and HICO-DET. Code is available at \url{https://github.com/birlrobotics/vs-gats}. ",Visual-Semantic Graph Attention Networks for Human-Object Interaction   Detection
"  We uncover the existence of Dirac and exceptional points in waveguides made of anisotropic materials, and study the transition between them. Dirac points in the dispersion diagram appear at propagation directions where the matrix describing the eigenvalue problem for bound states splits into two blocks, sorting the eigenmodes either by polarization or by inner mode symmetry. Introducing a non-Hermitian channel via a suitable leakage mechanism causes the Dirac points to transform into exceptional points connected by a Fermi arc. The exceptional points arise as improper hybrid leaky states and, importantly, are found to occur always out of the anisotropy symmetry planes. ",Transition from Dirac points to exceptional points in anisotropic   waveguides
"  Scheduling Bag-of-Tasks (BoT) applications on the cloud can be more challenging than grid and cluster environ- ments. This is because a user may have a budgetary constraint or a deadline for executing the BoT application in order to keep the overall execution costs low. The research in this paper is motivated to investigate task scheduling on the cloud, given two hard constraints based on a user-defined budget and a deadline. A heuristic algorithm is proposed and implemented to satisfy the hard constraints for executing the BoT application in a cost effective manner. The proposed algorithm is evaluated using four scenarios that are based on the trade-off between performance and the cost of using different cloud resource types. The experimental evaluation confirms the feasibility of the algorithm in satisfying the constraints. The key observation is that multiple resource types can be a better alternative to using a single type of resource. ",Task Scheduling on the Cloud with Hard Constraints
"  We report experimental observation of electrically-tunable coherent perfect absorption (CPA) of terahertz (THz) radiation in graphene. We develop a reflection-type tunable THz cavity formed by a large-area graphene layer, a metallic reflective electrode and an electrolytic medium in between. Ionic gating in the THz cavity allows us to tune the Fermi energy of graphene up to 1eV and to achieve critical coupling condition at 2.8 THz with absorption of 99%. With the enhanced THz absorption, we were able to measure the Fermi energy dependence of the transport scattering time of highly doped graphene. Furthermore, we demonstrate flexible active THz surfaces that yield large modulation in the THz reflectivity with low insertion losses. We anticipate that the gate-tunable CPA will lead efficient active THz optoelectronics applications. ",Observation of gate-tunable coherent perfect absorption of terahertz   radiation in graphene
"  We investigate the finite temperature charge density wave (CDW) transition of lattice Bose gases within optical cavities in the deep Mott-insulator limit. We find a new critical regime emerges at a temperature around one-half of the on-site interaction energy, where the first order CDW transition at low temperatures terminates at a critical point and changes to a second order one. By directly calculating the critical exponents and constructing the effective theory in the corresponding critical regime, we find the emergent criticality belongs to the five-dimensional Ising universality class. Direct experimental observation of the emergent criticality can be readily performed by current experimental set-ups operated in the temperature regime around half the on-site interaction energy. ",Emergent criticality and universality class of the finite temperature   charge density wave transition in lattice Bose gases within optical cavities
"  In this paper, we attempt to provide mathematical models of Mendelian and Non-Mendelian inheritances of the bisexual population system having Fisher's {\textbf{1:1}} principle. In our model, we always assume that distributions of the same phenotype of female and male populations are equal. We study the evolution of a Mendelian trait. As an application of a non-Mendelian inheritance, we construct a quadratic stochastic operator that describes transmission of {\textbf{ABO}} and Rh blood groups. ",Mendelian and Non-Mendelian Quadratic Operators
"  In this paper, we describe a framework for similarity based retrieval and clustering from a 3D human database. Our technique is based on both body and head shape representation and the retrieval is based on similarity of both of them. The 3D human database used in our study is the CAESAR anthropometric database which contains approximately 5000 bodies. We have developed a web-based interface for specifying the queries to interact with the retrieval system. Our approach performs the similarity based retrieval in a reasonable amount of time and is a practical approach. ",Retrieval and Clustering from a 3D Human Database based on Body and Head   Shape
"  In the context of the Covid-19 pandemic, many were quick to spread deceptive information. I investigate here how reasoning in Description Logics (DLs) can detect inconsistencies between trusted medical sources and not trusted ones. The not-trusted information comes in natural language (e.g. ""Covid-19 affects only the elderly""). To automatically convert into DLs, I used the FRED converter. Reasoning in Description Logics is then performed with the Racer tool. ",Detecting fake news for the new coronavirus by reasoning on the Covid-19   ontology
"  We consider two particles of spin-1/2 interacting with a one-dimensional N-spin array, which is an exactly solvable model. The dynamics of entanglement and quantum discord (QD) of the spins of the two particles is investigated by regarding the 1D N-spin array as the environment. It is found that although the entanglement may suffers a sudden death and a sudden birth in the evolution, it can neither be generated nor become larger than its initial value. Different from the entanglement dynamics, QD can be amplified, and even be generated by the interaction between particles and the common environment. We also observe that QD decays asymptotically to zero and later experiences a rival when the average number of excitation in the 1D N-spin array becomes larger in the case of nonzero inter-distance between two particles. ",Quantum correlations of two qubits interacting with a macroscopic medium
"  In this article, Einstein-Maxwell space-time has been considered in connection to some of the astrophysical solutions as previously obtained by Tolman (1939) and Bayin (1978). The effect of inclusion of charge into these solutions has been investigated thoroughly and also the nature of fluid pressure and mass density throughout the sphere have been discussed. Mass-radius and mass-charge relations have been derived for various cases of the charged matter distribution. Two cases are obtained where perfect fluid with positive pressures give rise to electromagnetic mass models such that gravitational mass is of purely electromagnetic origin. ",Physical properties of Tolman-Bayin solutions: some cases of static   charged fluid spheres in general relativity
"  Estimating predictive uncertainty is crucial for many computer vision tasks, from image classification to autonomous driving systems. Hamiltonian Monte Carlo (HMC) is an sampling method for performing Bayesian inference. On the other hand, Dropout regularization has been proposed as an approximate model averaging technique that tends to improve generalization in large scale models such as deep neural networks. Although, HMC provides convergence guarantees for most standard Bayesian models, it does not handle discrete parameters arising from Dropout regularization. In this paper, we present a robust methodology for improving predictive uncertainty in classification problems, based on Dropout and Hamiltonian Monte Carlo. Even though Dropout induces a non-smooth energy function with no such convergence guarantees, the resulting discretization of the Hamiltonian proves empirical success. The proposed method allows to effectively estimate the predictive accuracy and to provide better generalization for difficult test examples. ",Improving Predictive Uncertainty Estimation using Dropout -- Hamiltonian   Monte Carlo
"  Let $q \ge 3$ be a period. There are at least two $(1,q)$-periodic trajectories inside any smooth strictly convex billiard table, and all of them have the same length when the table is an ellipse or a circle. We quantify the chaotic dynamics of axisymmetric billiard tables close to their borders by studying the asymptotic behavior of the differences of the lengths of their axisymmetric $(1,q)$-periodic trajectories as $q \to +\infty$. Based on numerical experiments, we conjecture that, if the billiard table is a generic axisymmetric analytic strictly convex curve, then these differences behave asymptotically like an exponentially small factor $q^{-3} e^{-r q}$ times either a constant or an oscillating function, and the exponent $r$ is half of the radius of convergence of the Borel transform of the well-known asymptotic series for the lengths of the $(1,q)$-periodic trajectories. Our experiments are restricted to some perturbed ellipses and circles, which allows us to compare the numerical results with some analytical predictions obtained by Melnikov methods and also to detect some non-generic behaviors due to the presence of extra symmetries. Our computations require a multiple-precision arithmetic and have been programmed in PARI/GP. ",Exponentially small asymptotic formulas for the length spectrum in some   billiard tables
"  Single-cell RNA sequencing provides tremendous insights to understand biological systems. However, the noise from dropout can corrupt the downstream biological analysis. Hence, it is desirable to impute the dropouts accurately. In this work, we propose a simple and powerful dropout imputation method (scGNN) by applying a bottlenecked Graph Convolutional Neural Network on an induced hierarchical cell similarity graph. We show scGNN has competitive performance against state-of-the-art baselines across three datasets and can improve downstream analysis. ",scGNN: scRNA-seq Dropout Imputation via Induced Hierarchical Cell   Similarity Graph
"  We investigate the influences of variables on a Boolean function $f$ based on the quantum Bernstein-Vazirani algorithm. A previous paper (Floess et al. in Math. Struct. in Comp. Science 23: 386, 2013) has proved that if a $n$-variable Boolean function $f(x_1,\ldots,x_n)$ does not depend on an input variable $x_i$, using the Bernstein-Vazirani circuit to $f$ will always obtain an output $y$ that has a $0$ in the $i$th position. We generalize this result and show that after one time running the algorithm, the probability of getting a 1 in each position $i$ is equal to the dependence degree of $f$ on the variable $x_i$, i.e. the influence of $x_i$ on $f$. On this foundation, we give an approximation algorithm to evaluate the influence of any variable on a Boolean function. Next, as an application, we use it to study the Boolean functions with juntas, and construct probabilistic quantum algorithms to learn certain Boolean functions. Compared with the deterministic algorithms given by Floess et al., our probabilistic algorithms are faster. ",A quantum algorithm for approximating the influences of Boolean   functions and its applications
"  In this paper we continue our study, begun in part I, of the exceptional set of integers, not restricted by elementary congruence conditions, which cannot be represented as sums of three or four squares of primes. We correct a serious oversight in our first paper, but make further progress on the exponential sums estimates needed, together with an embellishment of the previous sieve technique employed. This leads to an improvement in our bounds for the maximal size of the exceptional sets. ",On sums of squares of primes II
  We study bosons interacting with an abelian Chern-Simons field on Riemann surfaces of genus $g>0$. It is shown that a singular gauge transformation brings the hamiltonian to free form. The transformed wave functions furnish a multi-component representation of the braid group studied by Imbo and March-Russell. The construction constitutes a proof of the equivalence of bosons coupled to a Chern-Simons field and anyons and generalizes the well known equivalence of the two pictures on the plane. ,The statistics transmuting Chern-Simons field and the braid group on   Riemann surfaces of genus g>0
"  In this paper, we introduce a definition of $\lambda$-hypersurfaces of weighted volume-preserving mean curvature flow in Euclidean space. We prove that $\lambda$-hypersurfaces are critical points of the weighted area functional for the weighted volume-preserving variations. Furthermore, we classify complete $\lambda$-hypersurfaces with polynomial area growth and $H-\lambda\geq 0$, which are generalizations of the results due to Huisken, Colding-Minicozzi. We also define a $\mathcal{F}$-functional and study $\mathcal{F}$-stability of $\lambda$-hypersurfaces, which extend a result of Colding-Minicozzi. Lower bound growth and upper bound growth of the area for complete and non-compact $\lambda$-hypersurfaces are also studied. ",Complete $\lambda$-hypersurfaces of weighted volume-preserving mean   curvature flow
"  We discuss the phenomenological consequences of theories which describe sterile neutrinos in large extra dimensions. We show that the Kaluza-Klein tower of the singlet neutrinos, albeit tiny individual contribution in electroweak processes, act cumulatively, giving rise to non-universality of the weak interactions of the light neutrinos and to flavour-violating radiative processes. Owing to these non-decoupling effects of th Kaluza--Klein neutrinos, we derive strong constraints on the parameters of the theory that originates from the non-observation of flavour-violating and universality-breaking phenomena. In this theory we propose a four-neutrino model which can reconcile the existing data coming from underground experiments in terms of neutrino oscillations, together with the hint from the LSND experiment and a possible neutrino contribution to the hot dark matter of the Universe. ",Phenomenology of neutrino physics in the Kaluza-Klein theories of low   scale gravity
  We study the analytic continuation problem for a germ of a biholomorphic mapping from a non-minimal real hypersurface $M\subset\CC{n}$ into a real hyperquadric $\mathcal Q\subset\CP{n}$ and prove that under certain non-degeneracy conditions any such germ extends locally biholomorphically along any path lying in the complement $U\setminus X$ of the complex hypersurface $X$ contained in $M$ for an appropriate neighborhood $U\supset X$. Using the monodromy representation for the multiple-valued mapping obtained by the analytic continuation we establish a connection between nonminimal real hypersurfaces and singular complex ODEs. ,Analytic Continuation of Holomorphic Mappings From Non-minimal   Hypersurfaces
  We derive a fully discrete Inverse Scattering Transform as a method for solving the initial-value problem for the Q3$_\delta$ lattice (difference-difference) equation for real-valued solutions. The initial condition is given on an infinite staircase within an N-dimensional lattice and must obey a given summability condition. The forward scattering problem is one-dimensional and the solution to Q3$_\delta$ is expressed through the solution of a singular integral equation. The solutions obtained depend on N discrete independent variables and N parameters. ,A Discrete Inverse Scattering Transform for Q3$_\delta$
"  We study the mechanism of single top production at the LHC in the framework of an effective electroweak Lagrangian, analyzing the sensitivity of different observables to the magnitude of the effective couplings that parametrize new physics beyond the Standard Model. The observables relevant to the distinction between left and right effective couplings involve in practice the measurement of the spin of the top and this can be achieved only indirectly by measuring the angular distribution of its decay products. We show that the presence of effective right-handed couplings implies that the top is not in a pure spin state. A unique spin basis is singled out which allows one to connect top decay products angular distribution with the polarized top differential cross section. We present a complete analytical expression of the differential polarized cross section of the relevant perturbative subprocess including general effective couplings. The mass of the bottom quark, which actually turns out to be more relevant than naively expected, is retained. Finally we analyze different aspects the total cross section relevant to the measurement of new physics through the effective couplings. The above analysis also applies to anti-top production in a straightforward way. ",Measuring effective electroweak couplings in single top production at   the LHC
"  The potential model for nuclear astrophysical reactions requires a considerably shallow nuclear potential when a square-well potential is employed to fit experimental data. We discuss the origin of this apparently different behavior from that obtained with a smooth Woods-Saxon potential, for which a deep potential is often employed. We argue that due to the sharp change of the potential at the boundary the radius parameter tends to be large in the square-well model, which results in a large absorption radius. The wave function then needs to be suppressed in the absorption region, which can eventually be achieved by using a shallow potential. We thus clarify the reason why the square-well potential has been able to reproduce a large amount of fusion data. ",Potential model for nuclear astrophysical fusion reactions with a   square-well potential
"  Observing artificial satellites is a relatively new and unique branch of astronomy that is very interesting and dynamic. One specific aspect of observing these objects is that although they appear amongst the celestial background, as deep-sky objects do, their apparent locations amongst this background depend on where you are standing on Earth at a given time. This effect is known as parallax. When a satellite is observed at a specific time from a specific location, the satellite's equatorial coordinates can be determined using astrometric means. Its range from the observer, however, is still unknown unless the observer knows the satellite's precise orbit elements or has easy access to a radar station. However, when two or more observers, separated by some distance, observe the same satellite at the same time, their observations can be used to determine the range of the satellite using the satellite's observed trigonometric parallax. ",Determining the Range of an Artificial Satellite Using its Observed   Trigonometric Parallax
"  Human activity recognition is typically addressed by detecting key concepts like global and local motion, features related to object classes present in the scene, as well as features related to the global context. The next open challenges in activity recognition require a level of understanding that pushes beyond this and call for models with capabilities for fine distinction and detailed comprehension of interactions between actors and objects in a scene. We propose a model capable of learning to reason about semantically meaningful spatiotemporal interactions in videos. The key to our approach is a choice of performing this reasoning at the object level through the integration of state of the art object detection networks. This allows the model to learn detailed spatial interactions that exist at a semantic, object-interaction relevant level. We evaluate our method on three standard datasets (Twenty-BN Something-Something, VLOG and EPIC Kitchens) and achieve state of the art results on all of them. Finally, we show visualizations of the interactions learned by the model, which illustrate object classes and their interactions corresponding to different activity classes. ",Object Level Visual Reasoning in Videos
"  The advent of data science has spurred interest in estimating properties of distributions over large alphabets. Fundamental symmetric properties such as support size, support coverage, entropy, and proximity to uniformity, received most attention, with each property estimated using a different technique and often intricate analysis tools.   We prove that for all these properties, a single, simple, plug-in estimator---profile maximum likelihood (PML)---performs as well as the best specialized techniques. This raises the possibility that PML may optimally estimate many other symmetric properties. ",A Unified Maximum Likelihood Approach for Optimal Distribution Property   Estimation
"  This paper develops a scattering theory to examine how point impurities affect transport through quantum wires. While some of our new results apply specifically to hard-walled wires, others--for example, an effective optical theorem for two-dimensional waveguides--are more general. We apply the method of images to the hard-walled guide, explicitly showing how scattering from an impurity affects the wire's conductance. We express the effective cross section of a confined scatterer entirely in terms of the empty waveguide's Green's function, suggesting a way in which to use semiclassical methods to understand transport properties of smooth wires. In addition to predicting some new phenomena, our approach provides a simple physical picture for previously observed effects such as conductance dips and confinement-induced resonances. ",Hall of Mirrors Scattering from an Impurity in a Quantum Wire
"  Thermal Nyquist noise fluctuations of high-$Q$ Bulk Acoustic Wave (BAW) cavities have been observed at cryogenic temperatures with a DC Superconducting Quantum Interference Device (SQUID) amplifier. High $Q$ modes with bandwidths of few tens of milliHz produce thermal fluctuations with a Signal-To-Noise ratio of up to 23dB. The estimated effective temperature from the Nyquist noise is in good agreement with the physical temperature of the device, confirming the validity of the equivalent circuit model and the non-existence of any excess resonator self-noise. The measurements also confirm that the quality factor remains extremely high ($Q>10^8$ at low order overtones) for very weak (thermal) system motion at low temperatures, when compared to values measured with relatively strong external excitation. This result represents an enabling step towards operating such a high-Q acoustic device at the standard quantum limit. ",Observation of the Fundamental Nyquist Noise Limit in an Ultra-High   $Q$-Factor Cryogenic Bulk Acoustic Wave Cavity
"  The multitask diffusion LMS is an efficient strategy to simultaneously infer, in a collaborative manner, multiple parameter vectors. Existing works on multitask problems assume that all agents respond to data synchronously. In several applications, agents may not be able to act synchronously because networks can be subject to several sources of uncertainties such as changing topology, random link failures, or agents turning on and off for energy conservation. In this work, we describe a model for the solution of multitask problems over asynchronous networks and carry out a detailed mean and mean-square error analysis. Results show that sufficiently small step-sizes can still ensure both stability and performance. Simulations and illustrative examples are provided to verify the theoretical findings. The framework is applied to a particular application involving spectral sensing. ",Multitask diffusion adaptation over asynchronous networks
"  In network MIMO cellular systems, subsets of base stations (BSs), or remote radio heads, are connected via backhaul links to central units (CUs) that perform joint encoding in the downlink and joint decoding in the uplink. Focusing on the uplink, an effective solution for the communication between BSs and the corresponding CU on the backhaul links is based on compressing and forwarding the baseband received signal from each BS. In the presence of ergodic fading, communicating the channel state information (CSI) from the BSs to the CU may require a sizable part of the backhaul capacity. In a prior work, this aspect was studied by assuming a Compress-Forward-Estimate (CFE) approach, whereby the BSs compress the training signal and CSI estimation takes place at the CU. In this work, instead, an Estimate-Compress-Forward (ECF) approach is investigated, whereby the BSs perform CSI estimation and forward a compressed version of the CSI to the CU. This choice is motivated by the information theoretic optimality of separate estimation and compression. Various ECF strategies are proposed that perform either separate or joint compression of estimated CSI and received signal. Moreover, the proposed strategies are combined with distributed source coding when considering multiple BSs. ""Semi-coherent"" strategies are also proposed that do not convey any CSI or training information on the backhaul links. Via numerical results, it is shown that a proper design of ECF strategies based on joint received signal and estimated CSI compression or of semi-coherent schemes leads to substantial performance gains compared to more conventional approaches based on non-coherent transmission or the CFE approach. ",Joint Signal and Channel State Information Compression for the Backhaul   of Uplink Network MIMO Systems
"  Towards experimental confirmations of the type-I seesaw mechanism, we explore a prospect of discovering the heavy Majorana right-handed neutrinos (RHNs) from a resonant production of a new massive gauge boson ($Z^{\prime}$) and its subsequent decay into a pair of RHNs ($Z^{\prime}\to NN$) at the future LHC. Recent simulation studies have shown that the discovery of the RHNs through this process is promising in the future. However, the current LHC data very severely constrains the production cross section of the $Z^{\prime}$ boson into a dilepton final states, $pp \to Z^{\prime}\to \ell^{+}\ell^{-} $ ($\ell=e$ or $\mu$). Extrapolating the current bound to the future, we find that a significant enhancement of the branching ratio ${\rm BR}(Z^{\prime}\to NN$) over ${\rm BR}(Z^{\prime}\to \ell^{+}\ell^{-}$) is necessary for the future discovery of RHNs. As a well-motivated simple extension of the Standard Model (SM) to incorporate the $Z^\prime$ boson and the type-I seesaw mechanism, we consider the minimal U(1)$_X$ model. We point out that this model can yield a significant enhancement up to ${\rm BR}(Z^{\prime}\to NN)/{\rm BR}(Z^{\prime}\to \ell^{+}\ell^{-}) \simeq 5$ (per generation). This is in sharp contrast with the minimal $B-L$ model, a benchmark scenario commonly used in simulation studies, which predicts ${\rm BR}(Z^{\prime}\to NN)/{\rm BR}(Z^{\prime}\to \ell^{+}\ell^{-}) \simeq 0.5$ (per generation). With such an enhancement and a realistic model-parameter choice to reproduce the neutrino oscillation data, we conclude that the possibility of discovering RHNs with a $300 \; {\rm fb}^{-1}$ luminosity implies that the $Z^\prime$ boson will be discovered with a luminosity of $170.5 \;{\rm fb}^{-1}$ ($125 \; {\rm fb}^{-1}$) for the normal (inverted) hierarchy of the light neutrino mass pattern. ",Enhanced pair production of heavy Majorana neutrinos at LHC
"  We have used medium resolution spectra to search for evidence that proto-stellar objects accrete at high rates during their early 'assembly phase'. Models predict that depleted lithium and reduced luminosity in T-Tauri stars are key signatures of 'cold' high-rate accretion occurring early in a star's evolution.   We found no evidence in 168 stars in NGC 2264 and the Orion Nebula Cluster for strong lithium depletion through analysis of veiling corrected 6708 angstrom lithium spectral line strengths. This suggests that 'cold' accretion at high rates (M_dot > 5 x 10-4 M_sol yr-1) occurs in the assembly phase of fewer than 0.5 per cent of 0.3 < M < 1.9 M_sol stars.   We also find that the dispersion in the strength of the 6708 angstrom lithium line might imply an age spread that is similar in magnitude to the apparent age spread implied by the luminosity dispersion seen in colour magnitude diagrams. Evidence for weak lithium depletion (< 10 per cent in equivalent width) that is correlated with luminosity is also apparent, but we are unable to determine whether age spreads or accretion at rates less than 5 x 10-4 M_sol yr-1 are responsible. ","No evidence for intense, cold accretion onto YSOs from measurements of   Li in T-Tauri stars"
"  Adaptation level and animal spirits (Middleton 1996) presented a psychophysical theory of confidence levels based on the oldest and probably most widely observed law in psychology, the sensitivity to adaptation level. For Americans, whose attachments to employment and livelihood are often tenuous in a country without a European-style social safety net, it is the sensitivity to the unemployment rate that drives confidence levels. In Animal spirits and recession forecasting (Middleton 2001; see also Ball 2001), the adaptation level theoretic metric of animal spirits, A, was combined with the slope of the U.S. Treasury yield curve in a logistic recession forecasting model that has correctly predicted every turning point in the economy since then. The model currently forecasts increasing confidence and an end to the recession in mid-2009. The question, given the severity of the current slump globally, is whether this forecast is plausible in the face of possibly very large increases in macroeconomic volatility. ","Animal Spirits in America, April 2009"
"  The aim of this paper is to report on a novel text reduction technique, called Text Denoising, that highlights information-rich content when processing a large volume of text data, especially from the biomedical domain. The core feature of the technique, the text readability index, embodies the hypothesis that complex text is more information-rich than the rest. When applied on tasks like biomedical relation bearing text extraction, keyphrase indexing and extracting sentences describing protein interactions, it is evident that the reduced set of text produced by text denoising is more information-rich than the rest. ",Extracting Information-rich Part of Texts using Text Denoising
"  From a time series whose data are embedded in heavy noise, we construct an Hilbert space operator (J-operator) whose discrete spectrum represents the signal while the essential spectrum located on the unit circle, is associated with the noise. Furthermore the essential spectrum, in the absence of signal, is built from roots of unity (""clock"" distribution). These results are independent of the statistical properties of the noise that can be Gaussian, non-Gaussian, pink or even without second moment (Levy). The presence of the signal has for effect to break the clock angular distribution of the essential spectrum on the unit circle. A discontinuity, proportional to the intensity of the signal, appears in the angular distribution. The sensitivity of this method is definitely better than standard techniques. We build an example that supports our claims. ",Signal induced Symmetry Breaking in Noise Statistical Properties of Data   Analysis
"  The Hamiltonian of 2+1 dimensional Yang Mills theory was derived by Karabali, Kim and Nair by using point splitting regularization. But in calculating e.g. the vacuum wave functional this scheme was left in favour of arguments. Here we follow up a conjecture of Leigh, Minic and Yelnikov of how this gap might be filled by including all positive powers of the regularization parameter ($\ep \to +0$). Admittedly, though we concentrate on the ground state in the large $N$ limit, only two such powers could be included due to the increasing complexity of the task. ",Hamiltonian YM 2+1: note on point splitting regularization
  We present our progress on the study of extinction laws along three diferent lines. [a] We compare how well different families of extinction laws fit existing photometric data for Galactic sightlines and we find that the Ma\'iz Apell\'aniz et al. (2014) family provides better results than those of Cardelli et al. (1989) or Fitzpatrick (1999). [b] We describe the HST/STIS spectrophotometry in the 1700-10 200 Angstrom range that we are obtaining for several tens of sightlines in 30 Doradus with the purpose of deriving an improved wavelength-detailed family of extinction laws. [c] We present the study we are conducting on the behavior of the extinction law in the infrared by combining 2MASS and WISE photometry with Spitzer and ISO spectrophotometry. ,Progress towards a universal family of UV-IR extinction laws
"  Detonation of a three-dimensional reactive non-isotropic molecular crystal is modeled using molecular dynamics simulations. The detonation process is initiated by an impulse, followed by the creation of a stable fast reactive shock wave. The terminal shock velocity is independent of the initiation conditions. Further analysis shows supersonic propagation decoupled from the dynamics of the decomposed material left behind the shock front. The dependence of the shock velocity on crystal nonlinear compressibility resembles solitary behavior. These properties categorize the phenomena as a weak detonation. The dependence of the detonation wave on microscopic potential parameters was investigated. An increase in detonation velocity with the reaction exothermicity reaching a saturation value is observed. In all other respects the model crystal exhibits typical properties of a molecular crystal. ",Molecular Dynamics Simulations of Weak Detonations
"  The outskirts of galaxies offer extreme environments where we can test our understanding of the formation, evolution, and destruction of molecules and their relationship with star formation and galaxy evolution. We review the basic equations that are used in normal environments to estimate physical parameters like the molecular gas mass from CO line emission and dust continuum emission. Then we discuss how those estimates may be affected when applied to the outskirts, where the average gas density, metallicity, stellar radiation field, and temperature may be lower. We focus on observations of molecular gas in the outskirts of the Milky Way, extragalactic disk galaxies, early-type galaxies, groups, and clusters. The scientific results show the versatility of molecular gas, as it has been used to trace Milky Way spiral arms out to a galactocentric radius of 15 kpc, to study star formation in extended ultraviolet disk galaxies, to probe galaxy interactions in polar ring S0 galaxies, and to investigate ram pressure stripping in clusters. We highlight the physical stimuli that accelerate the formation of molecular gas, including internal processes such as spiral arm compression and external processes such as interactions. ",Molecular Gas in the Outskirts of Galaxies
"  We report on the status of the calculation of deep-inelastic structure functions at three loops in perturbative QCD. The method employed allows to calculate the Mellin moments of structure functions analytically as a general function of N. As an illustration, we present the leading fermionic contributions to the non-singlet anomalous dimension of F_2 at three loops and, as a new result, to the non-singlet coefficient function of F_2 at three loops. ",Towards deep-inelastic structure functions at three loops
"  We show that the cohomology of the perfect cone (also called first Voronoi) toroidal compactification of the moduli space of complex principally polarized abelian varieties stabilizes, in close to the top degree. Moreover, we show that this stable cohomology is purely algebraic, and we compute it in degree up to 13. Our explicit computations and stabilization results apply in greater generality to various toroidal compactifications and partial compactifications, and in particular we show that the cohomology of the matroidal partial compactification stabilizes (in low degree). For degree up to 8, we describe explicitly the generators of the cohomology. We also discuss various approaches to computing all of the stable cohomology in arbitrary degree. ",Stable cohomology of the perfect cone toroidal compactification of   ${\mathcal A}_g$
"  This paper contains a reformulation of any $n$-player finite, static game into a framework of distributed, dynamical system based on agents' payoff-based deviations. The reformulation generalizes the method employed in the second part of the study of countries' relation formation problem in Li and Morse (2017) to the case of any finite, static game. In the paper two deviation rules are provided and possible applications of this framework are discussed. ","A Distributed, Dynamical System View of Finite, Static Games"
"  The creation of well-thermalized, hot and dense plasmas is attractive for warm dense matter studies. We investigate collisionally induced energy absorption of an ultraintense and ultrashort laser pulse in a solid copper target using particle-in-cell simulations. We find that, upon irradiation by a $2\times10^{20}{\rm\,W\,cm^{-2}}$ intensity, $60{\rm\,fs}$ duration, circularly polarized laser pulse, the electrons in the collisional simulation rapidly reach a well-thermalized distribution with ${\sim}3.5{\rm\,keV}$ temperature, while in the collisionless simulation the absorption is several orders of magnitude weaker. Circular polarization inhibits the generation of suprathermal electrons, while ensuring efficient bulk heating through inverse bremsstrahlung, a mechanism usually overlooked at relativistic laser intensity. An additional simulation, taking account of both collisional and field ionization, yields similar results: the bulk electrons are heated to ${\sim}2.5{\rm\,keV}$, but with a somewhat lower degree of thermalization than in the pre-set, fixed-ionization case. The collisional absorption mechanism is found to be robust against variations in the laser parameters. At fixed laser pulse energy, increasing the pulse duration rather than the intensity leads to a higher electron temperature. ",Fast collisional electron heating and relaxation in thin foils driven by   a circularly polarized ultraintense short-pulse laser
"  We propose a minimal extension of the Standard Model by two real singlet fields that could provide a good candidate for light Dark Matter, and give a strong first order electroweak phase transition. As a result, there are two CP even scalars; one is lighter than \sim 70 GeV, and the other one with mass in the range of 280-400 GeV; and consistent with electroweak precision tests. We show that the light scalar mass can be as small as 25 GeV while still being consistent with the LEP data. The predicted dark matter scattering cross section is large enough to accommodate CoGeNT and can be probed by future XENON experiment. We also show that for dark matter mass around 2 GeV, the branching fraction of the process (B^+\rightarrowK^++2(DM)) can be accessible in SuperB factories. ","Light Dark Matter, Light Higgs and the Electroweak Phase Transition"
"  Nowadays cloud computing adoption as a form of hosted application and services is widespread due to decreasing costs of hardware, software, and maintenance. Cloud enables access to a shared pool of virtual resources hosted in large energy-hungry data centers for diverse information and communication services with dynamic workloads. The huge energy consumption of cloud data centers results in high electricity bills as well as emission of a large amount of carbon dioxide gas. Needless to say, efficient resource management in cloud environments has become one of the most important priorities of cloud providers and consequently has increased the interest of researchers to propose novel energy saving solutions. This chapter presents a scientific and taxonomic survey of recent energy efficient cloud resource management' solutions in cloud environments. The main objective of this study is to propose a novel complete taxonomy for energy-efficient cloud resource management solutions, review recent research advancements in this area, classify the existing techniques based on our proposed taxonomy, and open up new research directions. Besides, it reviews and surveys the literature in the range of 2015 through 2021 in the subject of energy-efficient cloud resource management techniques and maps them to its proposed taxonomy, which unveils novel research directions and facilitates the conduction of future researches. ",Recent Advances in Energy Efficient Resource Management Techniques in   Cloud Computing Environments
"  The physical aspects - mechanics and thermodynamics - of operation of martensite rotor heat engine (MRHE) on the basis of martensite-austenite structural phase transition with the transition temperature in the region of low-potential water temperatures have been studied. The engine converts the thermal energy of low-potential water into the elastic energy of working body (spring, ribbon or wire) made of the material with shape memory effect. At some simplifying assumptions, the analytical expressions are obtained for the thermal efficiency and the power of MRHE of different type. The registration of head hydraulic resistance and heat conductivity of working body material is made and the maximum value of power produced by the engine at the given mechanical and heat conditions is calculated.   The recommendations are given on the optimal choice of engine parameters. On the basis of numerical estimations for nitinol, the possibility of application of MRHE is shown for efficient and ecologically pure production of electric energy both on local (geothermal waters, waste water of industrial enterprises, etc.) and global (warm ocean stream) scales. ",The efficiency and power of the martensite rotor heat engine. I
"  Results of theoretical studies of the quantum unstable systems caused that there are rather widespread belief that a universal feature od the quantum decay process is the presence of three time regimes of the decay process: the early time (initial) leading to the Quantum Zeno (or Anti Zeno) Effects, ""exponential"" (or ""canonical"") described by the decay law of the exponential form, and late time characterized by the decay law having inverse--power law form. Based on the fundamental principles of the quantum theory we give the proof that there is no time interval in which the survival probability (decay law) could be a decreasing function of time of the purely exponential form but even at the ""exponential"" regime the decay curve is oscillatory modulated with a smaller or a large amplitude of oscillations depending on parameters of the model considered. ","The true quantum face of the ""exponential"" decay law"
"  The $(1+3)$-dimensional Dirac equation of the fermions moving in ideal Aharonov-Bohm rings in the de Sitter expanding universe is used for deriving the exact expressions of the general relativistic partial currents and corresponding energies. In the de Sitter geometry, these quantities depend on time but these are related each other just as in the non-relativistic case or in special relativity. A specific relativistic effect is the saturation of the partial currents for high values of the total angular momentum. The total relativistic persistent current at $T=0$ takes over this property even though it is evolving in time because of the de Sitter expansion. ",Aharonov-Bohm rings in de Sitter expanding universe
"  We examine the uncertainty of the calculation of the atmospheric neutrino flux and present a way to reduce it using accurately measured atmospheric muon flux. Considering the difference of the hadronic interaction model and the real one as a variation of hadronic interaction, we find a quantitative estimation method for the error of the atmospheric neutrino flux calculation from the residual of the reconstruction of the atmospheric muon flux observed in a precision experiment, by the study of atmospheric neutrino and muon fluxes response to the variation of hadronic interaction. However, the efficiencty of this method is largely dependent on the observation site of the atmospheric muon flux, as the relation of the error of the atmospheric neutrino flux calculation and the residual of the reconstruction of the atmospheric muon flux is also largely dependent on the muon observation site, especially for the low energy neutrinos. We calculate several observation sites, near Kamioka at sea level, same but 2770m a.s.l.., Hanle India (4500m a.s.l.), and at Balloon altitude ($\sim$ 32km). Then we estimate how stringently can the atmospheric muon reduce the error in the calculation of the atmospheric neutrino flux. We also discuss on the source of error which is difficult to reduce by only the observation of atmospheric muon. ",Reduction of the Uncertainty in the Atmospheric Neutrino Flux Prediction   Below 1 GeV Using Accurately Measured Atmospheric Muon Flux
"  Using the Voros star product, we investigate the status of the two particle correlation function to study the possible extent to which the previously proposed violation of the Pauli principle may impact at low energies. The results show interesting features which are not present in the computations made using the Moyal star product. ",Voros product and the Pauli principle at low energies
"  In some delta Scuti stars, only one or two radial modes are excited (usually the fundamental mode and/or first overtone mode) and the observed peak-to-peak amplitudes exceed 0.3 mag (V). These stars are known as High Amplitude Delta Scuti (HADS) variables. We here present a detailed photometric and spectroscopic analysis of the HADS star TYC 3637-1152-1. We have derived a metallicity close to solar, a spectral type of F4V and an age of log t = 9.1. Employing archival time series data from different sources, two frequencies f0 =10.034 c/d and f1 =12.681 c/d and their harmonics and linear combinations were identified. The period ratio of f0/f1 = 0.791 puts this star into a peculiar position in the Petersen diagram, from which we conclude that TYC 3637-1152-1 is a unique object with peculiar pulsational properties that indicate a transitional state between HADS stars pulsating in the fundamental and first overtone modes and stars pulsating in higher overtones. ",TYC 3637-1152-1 - a High Amplitude delta Scuti star with peculiar   pulsational properties
  We calculate the electromagnetic self-force on a stationary linear distribution of four-current in the spacetime of multiple cosmic strings. It is shown that if the current is infinitely thin and stretched along a line which is parallel to the strings the problem admits an explicit solution. ,Self-forces in the Spacetime of Multiple Cosmic Strings
"  Within integrated tokamak plasma modelling, turbulent transport codes are typically the computational bottleneck limiting their routine use outside of post-discharge analysis. Neural network (NN) surrogates have been used to accelerate these calculations while retaining the desired accuracy of the physics-based models. This paper extends a previous NN model, known as QLKNN-hyper-10D, by incorporating the impact of impurities, plasma rotation and magnetic equilibrium effects. This is achieved by adding a light impurity fractional density ($n_{imp,light} / n_e$) and its normalized gradient, the normalized pressure gradient ($\alpha$), the toroidal Mach number ($M_{tor}$) and the normalized toroidal flow velocity gradient. The input space was sampled based on experimental data from the JET tokamak to avoid the curse of dimensionality. The resulting networks, named QLKNN-jetexp-15D, show good agreement with the original QuaLiKiz model, both by comparing individual transport quantity predictions as well as comparing its impact within the integrated model, JINTRAC. The profile-averaged RMS of the integrated modelling simulations is <10% for each of the 5 scenarios tested. This is non-trivial given the potential numerical instabilities present within the highly nonlinear system of equations governing plasma transport, especially considering the novel addition of momentum flux predictions to the model proposed here. An evaluation of all 25 NN output quantities at one radial location takes $\sim$0.1 ms, $10^4$ times faster than the original QuaLiKiz model. Within the JINTRAC integrated modelling tests performed in this study, using QLKNN-jetexp-15D resulted in a speed increase of only 60 - 100 as other physics modules outside of turbulent transport become the bottleneck. ",Neural network surrogate of QuaLiKiz using JET experimental data to   populate training space
"  This paper introduces a new prototype system for controlling a PC by head movements and also with voice commands. Our system is a multimodal interface concerned with controlling the computer. The selected modes of interaction are speech and gestures. We are seeing the revolutionary of computers and information technologies into daily practice. Healthy people use keyboard, mouse, trackball, or touchpad for controlling the PC. However these peripheries are usually not suitable for handicapped people. They may have problems using these standard peripheries, for example when they suffer from myopathy, or cannot move their hands after an injury. Our system has been developed to provide computer access for people with severe disabilities. This system tracks the computer user's Head movements with a video camera and translates them into the movements of the mouse pointer on the screen and the voice as button presses. Therefore we are coming with a proposal system that can be used with handicapped people to control the PC. ",A Prototype System for Controlling a Computer by Head Movements and   Voice Commands
"  Most excited hadrons have multiparticle strong decay modes, which can often be described as resulting from intermediate states containing one or two resonances. In a theoretical approach, such a description in terms of quasi-two-particle initial and final states leads to unitarity violations, because of the complex masses of the involved resonances. In the present paper, an empirical algebraic procedure is presented to restore unitarity of the S-matrix while preserving its symmetry. Preliminary results are presented in a first application to S-wave pion-pion scattering, in the framework of the Resonance-Spectrum Expansion. ",Complex masses in the S-matrix
"  From a pseudo-triangulation with $n$ tetrahedra $T$ of an arbitrary closed orientable connected 3-manifold (for short, {\em a 3D-space}) $M^3$, we present a gem $J '$, inducing $\IS^3$, with the following characteristics: (a) its number of vertices is O(n); (b) it has a set of $p$ pairwise disjoint couples of vertices $\{u_i,v_i\}$, each named {\em a twistor}; (c) in the dual $(J ')^\star$ of $J '$ a twistor becomes a pair of tetrahedra with an opposite pair of edges in common, and it is named {\em a hinge}; (d) in any embedding of $(J ')^\star \subset \IS^3$, the $\epsilon$-neighborhood of each hinge is a solid torus; (e) these $p$ solid tori are pairwise disjoint; (f) each twistor contains the precise description on how to perform a specific surgery based in a Denh-Lickorish twist on the solid torus corresponding to it; (g) performing all these $p$ surgeries (at the level of the dual gems) we produce a gem $G '$ with $|G '|=M^3$; (h) in $G '$ each such surgery is accomplished by the interchange of a pair of neighbors in each pair of vertices: in particular, $|V(G ')=|V(J ')|$.   This is a new proof, {\em based on a linear polynomial algorithm}, of the classical Theorem of Wallace (1960) and Lickorish (1962) that every 3D-space has a framed link presentation in $\IS^3$ and opens the way for an algorithmic method to actually obtaining the link by an $O(n^2)$-algorithm. This is the subject of a companion paper soon to be released. ",Combinatorial Dehn-Lickorish Twists and Framed Link Presentations of   3-Manifolds Revisited
"  We present a study of the discrete clouds and filaments in the Magellanic Stream using a new high-resolution survey of neutral hydrogen (\HI) conducted with H75 array of the Australia Telescope Compact Array, complemented by single-dish data from the Parkes Galactic All-Sky Survey (GASS). From the individual and combined datasets, we have compiled a catalog of 251 clouds and list their basic parameters, including a morphological description useful for identifying cloud interactions. We find an unexpectedly large number of head-tail clouds in the region. The implication for the formation mechanism and evolution is discussed. The filaments appear to originate entirely from the Small Magellanic Cloud and extend into the northern end of the Magellanic Bridge. ",The Magellanic Stream and Debris Clouds
"  Fast radio bursts (FRBs) are milliseconds radio transients with large dispersion measures (DMs). An outstanding question is the relation between repeating FRBs and those with a single burst. In this paper, we study the energy distribution of the repeating FRB 121102. For a power-law distribution of energy $dN/dE\propto E^{-\alpha_E}$, we show that the value of $\alpha_E$ is in a narrow range $1.6-1.8$ for bursts observed by different telescopes at different frequencies, which indicates a universal energy distribution for FRB 121102. Interestingly, similar power-law index of energy distribution for non-repeating FRBs observed by Parkes and ASKAP is also found. However, if low-energy bursts below completeness threshold of Arecibo are discarded for FRB 121102, the slope could be up to 2.2. Implications of such a universal energy distribution are discussed. ",A universal energy distribution for FRB 121102
"  In this paper, we obtain new results on the critical points of a polynomial. We discuss the Sendov conjecture for polynomials of degree nine. ",On the Sendov conjecture and the critical points of polynomials
"  The present paper focuses on the study of t-stabilities on a triangulated category in the sense of Gorodentsev, Kuleshov and Rudakov. We give an equivalent description for the finest t-stability on a piecewise hereditary triangulated category and, describe the semistable subcategories and final HN triangles for (exceptional) coherent sheaves in $D^b(\rm{coh}\mathbb{X})$, which is the bounded derived category of coherent sheaves on the weighted projective line $\mathbb{X}$ of weight type (2). Furthermore, we show the existence of a t-exceptional triple for $D^b(\rm{coh}\mathbb{X})$. As an application, we obtain a result of Dimitrov--Katzarkov which states that each stability condition $\sigma$ in the sense of Bridgeland admits a $\sigma$-exceptional triple for the acyclic triangular quiver $Q$. Note that this implies the connectedness of the space of stability conditions associated to $Q$. ",T-stabilities for a weighted projective line
"  Gravitation, the universal attractive force, acts upon all matter (and radiation) relentlessly. Left to itself, gravity would pull everything together and the Universe would be nothing but a gigantic black hole. Nature throws almost every bit of physics - rotation, magnetic field, heat, quantum effects and so on, at gravity to escape such a fate. In this series of articles we shall explore systems where the eternal pull of gravity has been held off by one or another such means. ",Gravity Defied (from potato asteroids to magnetised neutron stars) I :   The self-gravitating objects
"  Models for structure formation attempt to predict the power spectrum of density perturbations in the present universe from the initial power spectrum and the nature of dark matter. Observational constraints on the power spectrum at different scales in the present epoch can, therefore, be used to eliminate (or choose between) different theoretical models. Such a comparison is fairly easy at large scales (at which linear theory is valid), and one can use observations like the MBR anisotropy, large scale steaming motions etc to constrain the models. But to discriminate between the models effectivley, it is necessay to constrain the power spectrum at small scales. The most reliable constraints on the power spectra at small scales come from the predicted abundance of bound systems which can be estimated reasonably accurately using Press-Schecter (or similar) methods$^1$. In the past, this method has been used in conjunction with the quasar abundance$^{2-4}$ and cluster abundance$^{5-7}$. We show here that the abundance of damped lyman alpha systems (DLAS, hereafter), provides a far stronger constraint on the models for structure formation. Models with a mixture of hot and cold dark matter $^{8-11}$ (which are consistent with large scale observations) are strongly ruled out by the DLAS constraints while models with cosmological constant $^{12}$ are marginally inconsistent. It is also possible to combine the constraints from the abundance of clusters, DLAS and QSO's to obtain model-independent bounds on the power spectrum at the nonlinear scales. These bounds are to be respected by any viable model for structure formation. ",Constraints on the Models for Structure Formation from the Abundance of   Damped Lyman Alpha Systems
"  Compared with laborious pixel-wise dense labeling, it is much easier to label data by scribbles, which only costs 1$\sim$2 seconds to label one image. However, using scribble labels to learn salient object detection has not been explored. In this paper, we propose a weakly-supervised salient object detection model to learn saliency from such annotations. In doing so, we first relabel an existing large-scale salient object detection dataset with scribbles, namely S-DUTS dataset. Since object structure and detail information is not identified by scribbles, directly training with scribble labels will lead to saliency maps of poor boundary localization. To mitigate this problem, we propose an auxiliary edge detection task to localize object edges explicitly, and a gated structure-aware loss to place constraints on the scope of structure to be recovered. Moreover, we design a scribble boosting scheme to iteratively consolidate our scribble annotations, which are then employed as supervision to learn high-quality saliency maps. As existing saliency evaluation metrics neglect to measure structure alignment of the predictions, the saliency map ranking metric may not comply with human perception. We present a new metric, termed saliency structure measure, to measure the structure alignment of the predicted saliency maps, which is more consistent with human perception. Extensive experiments on six benchmark datasets demonstrate that our method not only outperforms existing weakly-supervised/unsupervised methods, but also is on par with several fully-supervised state-of-the-art models. Our code and data is publicly available at https://github.com/JingZhang617/Scribble_Saliency. ",Weakly-Supervised Salient Object Detection via Scribble Annotations
"  In a recent preprint (astro-ph/9905144) Tereno has tried to find the physical 3-velocity (V) at the Event Horizon of a Kruskal Black Hole. This has been done in the backdrop of the recent work by Mitra (astro-ph/9904162) where it was shown that the radial geodesic of material particle, unphysically, becomes null at the Event Horizon. Although Tereno stops short of finding the precise value of V at r=2M, he concludes that V <1. It is pointed out with reference to Eq.(13) of Tereno's work that since his delta = (r -2M)/r tends to 0 as r tends to 2M, V indeed tends to 1. It appears that Tereno's conclusion is driven by his inability to conceive proper limiting value of fractions. Similarly, his idea that, the velocity addition formula of Sp. Theory of Relativity breaks down when both the velocities approach unity is due his same inability. In particular, our central result that Schwarschild BHs must have M=0 has been obtained independently from three different considerations (gr-qc/9810038, astro-ph/9904162, 163). And we also offer here the essential physical reason why the speed of free fall at the Event Horizon must be equal to the speed of light in coordinate system. Yet we are thankful to Tereno for making the first attempt to scientifically criticize our relevant work. ",Comment on ``Velocity at the Schwarzschild Horizon Revisited'' by I.   Tereno
"  Self-supervised deep learning methods have leveraged stereo images for training monocular depth estimation. Although these methods show strong results on outdoor datasets such as KITTI, they do not match performance of supervised methods on indoor environments with camera rotation. Indoor, rotated scenes are common for less constrained applications and pose problems for two reasons: abundance of low texture regions and increased complexity of depth cues for images under rotation. In an effort to extend self-supervised learning to more generalised environments we propose two additions. First, we propose a novel Filled Disparity Loss term that corrects for ambiguity of image reconstruction error loss in textureless regions. Specifically, we interpolate disparity in untextured regions, using the estimated disparity from surrounding textured areas, and use L1 loss to correct the original estimation. Our experiments show that depth estimation is substantially improved on low-texture scenes, without any loss on textured scenes, when compared to Monodepth by Godard et al. Secondly, we show that training with an application's representative rotations, in both pitch and roll, is sufficient to significantly improve performance over the entire range of expected rotation. We demonstrate that depth estimation is successfully generalised as performance is not lost when evaluated on test sets with no camera rotation. Together these developments enable a broader use of self-supervised learning of monocular depth estimation for complex environments. ",Self-Supervised Monocular Depth Estimation of Untextured Indoor Rotated   Scenes
"  We apply a cross-correlation technique to infer the $S>3$mJy radio luminosity function (RLF) from the NRAO VLA sky survey (NVSS) to $z\sim3.5$. We measure $\Sigma$ the over density of radio sources around spectroscopically confirmed quasars. $\Sigma$ is related to the space density of radio sources at the distance of the quasars and the clustering strength between the two samples, hence knowledge of one constrains the other. Under simple assumptions we find $\Phi\propto (1+z)^{3.7\pm0.7}$ out to $z\sim2$. Above this redshift the evolution slows and we constrain the evolution exponent to $<1.01$ ($2\sigma$). This behaviour is almost identical to that found by previous authors for the bright end of the RLF potentially indicating that we are looking at the same population. This suggests that the NVSS is dominated by a single population; most likely radio sources associated with high-excitation cold-mode accretion. Inversely, by adopting a previously modelled RLF we can constrain the clustering of high-redshift radio sources and find a clustering strength consistent with $r_0=15.0\pm 2.5$ Mpc up to $z\sim3.5$. This is inconsistent with quasars at low redshift and some measurements of the clustering of bright FRII sources. This behaviour is more consistent with the clustering of lower luminosity radio galaxies in the local universe. Our results indicate that the high-excitation systems dominating our sample are hosted in the most massive galaxies at all redshifts sampled. ",Counting quasar--radio source pairs to derive the millijansky radio   luminosity function and clustering strength to z=3.5
"  Making measurements on single quantum systems is considered difficult, almost impossible if the state is a-priori unknown. Protective measurements suggest a possibility to measure single quantum systems and gain some new information in the process. Protective measurement is described, both in the original and generalized form. The degree to which the system and the apparatus remain entangled in a protective measurement, is assessed. A possible experimental test of protective measurements is discussed. ",Protective Measurements: Probing Single Quantum Systems
"  We report on a search for charmless hadronic B decays to the three-body final states, K0S h+ pi-, K+ h- pi0, K0S h+ pi0 (h+- denotes a charged pion or kaon), and their charge conjugates, using 13.5 fb^{-1} of integrated luminosity produced with center-of-mass energies near 10.6 GeV, and collected with the CLEO detector. We observe the decay B --> K0 pi+ pi- with a branching fraction (50 +10-9(stat.) +-7(syst.)) x 10^{-6} and the decay B --> K*+(892) pi- with a branching fraction (16 +6-5(stat.) +-2(syst.)) x 10^{-6}. ",Observation of B to K_S^0 pi+ pi- and Evidence for B to K*pm pi mp
"  We demonstrate that the effective third-order nonlinear susceptibility of a graphene sheet can be enhanced by more than two orders of magnitude by patterning it into a graphene metasurface. In addition, in order to gain deeper physical insights into this phenomenon, we introduce a novel homogenization method, which is subsequently used to characterize quantitatively this nonlinearity enhancement effect by calculating the effective linear and nonlinear susceptibility of graphene metasurfaces. The accuracy of the proposed homogenization method is demonstrated by comparing its predictions with those obtained from the Kramers-Kronig relations. This work may open up new opportunities to explore novel physics pertaining to nonlinear optical interactions in graphene metasurfaces. ",Plasmon-induced nonlinearity enhancement and homogenization of graphene   metasurfaces
  Nanophotonic circuits based on polished diamond thin films are prepared. These circuits cover a wide wavelength range across the entire visible spectrum. Integrated devices are surface functionalized site-specifically and in parallel using dip-pen nanolithography with a minimum linewidth of 100 nm. Multicolor fluorescence is coupled into the underlying photonic network using microring resonators and grating structures. ,Diamond Nanophotonic Circuits Functionalized by Dip-pen Nanolithography
"  We prove the following theorem. Suppose that $M$ is a trim DFA on the Boolean alphabet $0,1$. The language $\L(M)$ is well-ordered by the lexicographic order $\slex$ iff whenever the non sink states $q,q.0$ are in the same strong component, then $q.1$ is a sink. It is easy to see that this property is sufficient. In order to show the necessity, we analyze the behavior of a $\slex$-descending sequence of words. This property is used to obtain a polynomial time algorithm to determine, given a DFA $M$, whether $\L(M)$ is well-ordered by the lexicographic order. Last, we apply an argument in \cite{BE,BEa} to give a proof that the least nonregular ordinal is $\omega^\omega $. ",A Note on Ordinal DFAs
"  We generalize the Lee-Suzuki iteration method for summing the folded diagram series to the case where the unperturbed model-space energies are non-degenerate. A condition is derived for the convergence of the iteration scheme and this depends on the choice of the model space projection operators. Two choices are examined, in the first the projection operators are defined in terms of the unperturbed states and in the second they are defined in terms of the eigenfunctions obtained at each stage of the iteration. As is illustrated by calculations with a simple model, the second procedure gives the better convergence and, by suitable choice of the starting energies, allows the reproduction of any subset of the exact eigenvalues. ",Iterative Solution for Effective Interactions in a System with   Non-degenerate Unperturbed Energies
"  We show that certain functional inequalities, e.g.\ Nash-type and Poincar\'e-type inequalities, for infinitesimal generators of $C_0$ semigroups are preserved under subordination in the sense of Bochner. Our result improves \cite[Theorem 1.3]{BM} by A.\ Bendikov and P.\ Maheux for fractional powers, and it also holds for non-symmetric settings. As an application, we will derive hypercontractivity, supercontractivity and ultracontractivity of subordinate semigroups. ",Functional Inequalities and Subordination: Stability of Nash and   Poincar\'e inequalities
"  In daily life, graphic symbols, such as traffic signs and brand logos, are ubiquitously utilized around us due to its intuitive expression beyond language boundary. We tackle an open-set graphic symbol recognition problem by one-shot classification with prototypical images as a single training example for each novel class. We take an approach to learn a generalizable embedding space for novel tasks. We propose a new approach called variational prototyping-encoder (VPE) that learns the image translation task from real-world input images to their corresponding prototypical images as a meta-task. As a result, VPE learns image similarity as well as prototypical concepts which differs from widely used metric learning based approaches. Our experiments with diverse datasets demonstrate that the proposed VPE performs favorably against competing metric learning based one-shot methods. Also, our qualitative analyses show that our meta-task induces an effective embedding space suitable for unseen data representation. ",Variational Prototyping-Encoder: One-Shot Learning with Prototypical   Images
"  Whether transcranial direct current stimulation (tDCS) benefits stroke rehabilitation remains unclear. To investigate how tDCS reorganizes brain circuitry, nineteen post-stroke patients underwent rehabilitation sessions with bi-hemispheric real vs sham tDCS intervention. Resting motor threshold measurements showed tDCS evoked higher excitability in the motor cortex that enhanced the descending conduction from the lesioned primary motor cortex to the target hand muscle. Granger causality analysis further revealed brain circuitry rewiring among the lesioned cerebellum, premotor, and primary motor cortex in the tDCS group compared to the sham owing to the newly formed connections close to the anodal electrode. Rebuilding of these critical pathways was clear via the increase of event related desynchronisation (ERD) and white matter integrity in the same lesioned region. Furthermore, only the tDCS group demonstrated a positive recovery trend in the penumbra regions by the longitudinal functional magnetic resonance imaging (fMRI) analysis. To interpret tDCS mechanism, we introduce a polarized gamma-aminobutyric acid (GABA) theory, where GABAA receptor activity depends on the orientation of dipolar GABA that can be manipulated by tDCS field. Results suggest that tDCS intervention lowers motor excitability via re-orienting GABA, leading to reorganization of the lesioned cortical network, and the motor descending pathway, finally the recovery of motor function. ",How transcranial direct current stimulation facilitates post-stroke   rehabilitation
"  The associated magnetic moments of the periodic rotational motion of methyl groups in hexamethylbenzene C$_6$(CH$_3$)$_6$ were recently identified to contribute to its overall magnetic susceptibility. Those measurements however, were only performed on hydrogenous polycrystalline samples. We report magnetic susceptibility measurements on single crystalline C$_6$(CH$_3$)$_6$ in the cases where the applied magnetic field is parallel and perpendicular to the molecular basal planes. In the former case, metastable behavior near the onset temperature T$_{C-H}$=118 K is identified while in the latter, no anomalous behavior is observed. Similar anomalies are observed in deuterated hexamethylbenzene C$_6$(CD$_3$)$_6$ (where D is deuterium), however, T$_{C-D}$ occurs 14 K higher at 132 K. In addition, a peak anomaly identified near 42 K is suggested to be due to the onset of coherent quantum tunneling of deuterons. The near cubic ground state is proposed to be the result of a more radical form of the Jahn-Teller effect occurring in a molecular solid where the lattice distorts to remove the orbital degeneracies of the protons to lower its energy. The apparent magnetic anisotropy and isotope effect provide evidence that apart from electrons, not only protons, but also deuterons establish strongly correlated behavior. ",Isotope Effect on the Magnetic Properties of Hexamethylbenzene: Evidence   of Magnetism Based on Correlated Motion of Deuterons
"  The theory and applications of dynamic derivatives on time scales has recently received considerable attention. The primary purpose of this paper is to give basic properties of diamond-$\alpha$ derivatives which are a linear combination of delta and nabla dynamic derivatives on time scales. We prove a generalized version of Jensen's inequality on time scales via the diamond-$\alpha$ integral and present some corollaries, including H\""{o}lder's and Minkowski's diamond-$\alpha$ integral inequalities. ",Diamond-$\alpha$ Jensen's Inequality on Time Scales
"  The performance of standard learning procedures has been observed to differ widely across groups. Recent studies usually attribute this loss discrepancy to an information deficiency for one group (e.g., one group has less data). In this work, we point to a more subtle source of loss discrepancy---feature noise. Our main result is that even when there is no information deficiency specific to one group (e.g., both groups have infinite data), adding the same amount of feature noise to all individuals leads to loss discrepancy. For linear regression, we thoroughly characterize the effect of feature noise on loss discrepancy in terms of the amount of noise, the difference between moments of the two groups, and whether group information is used or not. We then show this loss discrepancy does not vanish immediately if a shift in distribution causes the groups to have similar moments. On three real-world datasets, we show feature noise increases the loss discrepancy if groups have different distributions, while it does not affect the loss discrepancy on datasets where groups have similar distributions. ",Feature Noise Induces Loss Discrepancy Across Groups
"  We performed spectroscopic observations of the small-separation lensed quasar SDSS J1001+5027, whose images have an angular separation $\theta \sim 2.^{\!\!\prime\prime}86$, and placed constraints on the physical properties of gas clouds in the vicinity of the quasar (i.e., in the outflowing wind launched from the accretion disk). The two cylinders of sight to the two lensed images go through the same region of the outflowing wind and they become fully separated with no overlap at a very large distance from the source ($\sim 330$ pc). We discovered a clear difference in the profile of the CIV broad absorption line (BAL) detected in the two lensed images in two observing epochs. Because the kinematic components in the BAL profile do not vary in concert, the observed variations cannot be reproduced by a simple change of ionization state. If the variability is due to gas motion around the background source (i.e., the continuum source), the corresponding rotational velocity is $v_{rot}\geq 18,000$ km/s, and their distance from the source is $r\leq 0.06$ pc assuming Keplerian motion. Among three MgII and three CIV NAL systems that we detected in the spectra, only the MgII system at $z_{abs} = 0.8716$ shows a hint of variability in its MgI profile on a rest-frame time scale of $\Delta t_{rest}$ $\leq 191$ days and an obvious velocity shear between the sightlines whose physical separation is $\sim 7$ kpc. We interpret this as the result of motion of a cosmologically intervening absorber, perhaps located in a foreground galaxy. ",Spectroscopic Observations of the Outflowing Wind in the Lensed Quasar   SDSS J1001+5027
"  In the present paper, we introduce a multi-type display calculus for dynamic epistemic logic, which we refer to as Dynamic Calculus. The display-approach is suitable to modularly chart the space of dynamic epistemic logics on weaker-than-classical propositional base. The presence of types endows the language of the Dynamic Calculus with additional expressivity, allows for a smooth proof-theoretic treatment, and paves the way towards a general methodology for the design of proof systems for the generality of dynamic logics, and certainly beyond dynamic epistemic logic. We prove that the Dynamic Calculus adequately captures Baltag-Moss-Solecki's dynamic epistemic logic, and enjoys Belnap-style cut elimination. ",Multi-type Display Calculus for Dynamic Epistemic Logic
"  Advances in neural variational inference have facilitated the learning of powerful directed graphical models with continuous latent variables, such as variational autoencoders. The hope is that such models will learn to represent rich, multi-modal latent factors in real-world data, such as natural language text. However, current models often assume simplistic priors on the latent variables - such as the uni-modal Gaussian distribution - which are incapable of representing complex latent factors efficiently. To overcome this restriction, we propose the simple, but highly flexible, piecewise constant distribution. This distribution has the capacity to represent an exponential number of modes of a latent target distribution, while remaining mathematically tractable. Our results demonstrate that incorporating this new latent distribution into different models yields substantial improvements in natural language processing tasks such as document modeling and natural language generation for dialogue. ",Piecewise Latent Variables for Neural Variational Text Processing
"  The 1/[-i\omega + D(\omega, q)q^2] diffusion pole in the localized phase transfers to the 1/\omega Berezinskii-Gorkov singularity, which can be analyzed by the instanton method (M V. Sadovskii, 1982; J. L. Cardy, 1978). Straightforward use of this approach leads to contradictions, which do not disappear even if the problem is extremely simplied by taking zero-dimensional limit. On the contrary, they are extremely sharpened in this case and become paradoxes. The main paradox is specified by the following statements: (i) the 1/\omega singularity is determined by high orders of perturbation theory, (ii) the high-order behaviors for two quantities \Phi^{RA} and U^{RA} are the same, and (iii) \Phi^{RA} has the 1/\omega singularity, whereas U^{RA} does not have it. Solution to the paradox indicates that the instanton method makes it possible to obtain only the 1/(\omega + i\gamma) singularity, where the parameter \gamma remains indefinite and must be determined from additional conditions. This conceptually confirms the necessity of the self-consistent treatment for the diffusion coefficient that is used in the Vollhardt-Wolfle type theories. ",Localization Theory in Zero Dimension and the Structure of Diffusion   Poles
"  The chiral phase transition and equation of state are studied within a new self-consistent mean-field approximation of the two-flavor Nambu$-$Jona-Lasinio model. In this newly developed model, modifications to the chemical potential $\mu$ and chiral chemical potential $\mu_5$ is naturally included by adding vector and axial-vector channels from Fierz-transformed Lagrangian to the standard Lagrangian. In proper-time scheme, the chiral phase transition is a crossover in the $T-\mu$ plane. But when $\mu_5$ is increased, our study shows that there may exist first order phase transition. Furthermore, the chiral imbalance will soften the equation of state of quark matter. The mass-radius relations and tidal deformability of quark stars are calculated. As $\mu_5$ increases, the maximum mass and radius decrease. The vector channel and axial-vector channel have opposite influence on the equation of state. However, when EOS is constrained by astronomical observations, the shape of the mass-radius curve can be used to determine whether there is chiral imbalance in the dense object, and thus indirectly proving the CP violation in the dense matter. Our study shows a different influence of the chiral imbalance on the chiral phase transition in contrary to tree-momentum-cutoff scheme. ",The chiral phase transition and equation of state in the chiral   imbalance
"  Industrial cyber-infrastructure is normally a multilayered architecture. The purpose of the layered architecture is to hide complexity and allow independent evolution of the layers. In this paper, we argue that this traditional strict layering results in poor transparency across layers affecting the ability to significantly improve resiliency. We propose a contract-based methodology where components across and within the layers of the cyber-infrastructure are associated with contracts and a light-weight resilience manager. This allows the system to detect faults (contract violation monitored using observers) and react (change contracts dynamically) effectively. It results in (1) improving transparency across layers; helps resiliency, (2) decoupling fault-handling code from application code; helps code maintenance, (3) systematically generate error-free fault handling code; reduces development time. Using an industrial case study, we demonstrate the proposed methodology. ",CLAIR: A Contract-based Framework for Developing Resilient CPS   Architectures
  We argue that the quantized non-Abelian gauge theory can be obtained as the infrared limit of the corresponding classical gauge theory in a higher dimension. We show how the transformation from classical to quantum dynamics emerges and calculate Planck's constant from quantities defined in the underlying classical field theory. ,Quantum Dynamics from Classical Dissipative Systems
  We present a measurement of the differential cross section as a function of transverse momentum of the Z boson in ppbar collisions at sqrt{s}=1.8 TeV using data collected by the D0 experiment at the Fermilab Tevatron Collider during 1994--1996. We find good agreement between our data and the NNLO resummation prediction and extract values of the non-perturbative parameters for the resummed prediction from a fit to the differential cross section. ,Measurement of the inclusive differential cross section for Z bosons as   a function of transverse momentum in pbarp collisions at sqrt{s}=1.8 TeV
"  Let $\alpha\in(0,1)\setminus{\Bbb Q}$ and $K=\{(e^z,e^{\alpha z}):\,|z|\leq1\}\subset{\Bbb C}^2$. If $P$ is a polynomial of degree $n$ in ${\Bbb C}^2$, normalized by $\|P\|_K=1$, we obtain sharp estimates for $\|P\|_{\Delta^2}$ in terms of $n$, where $\Delta^2$ is the closed unit bidisk. For most $\alpha$, we show that $\sup_P\|P\|_{\Delta^2}\leq\exp(Cn^2\log n)$. However, for $\alpha$ in a subset ${\mathcal S}$ of the Liouville numbers, $\sup_P\|P\|_{\Delta^2}$ has bigger order of growth. We give a precise characterization of the set ${\mathcal S}$ and study its properties. ","Polynomial estimates, exponential curves and Diophantine approximation"
"  We establish existence of positive non-decreasing radial solutions for a nonlocal nonlinear Neumann problem both in the ball and in the annulus. The nonlinearity that we consider is rather general, allowing for supercritical growth (in the sense of Sobolev embedding). The consequent lack of compactness can be overcome, by working in the cone of non-negative and non-decreasing radial functions. Within this cone, we establish some a priori estimates which allow, via a truncation argument, to use variational methods for proving existence of solutions. As a side result, we prove a strong maximum principle for nonlocal Neumann problems, which is of independent interest. ",A nonlocal supercritical Neumann problem
"  We consider a market where a finite number of players trade an asset whose supply is a stochastic process. The price formation problem consists of finding a price process that ensures that when agents act optimally to minimize their trading costs, the market clears, and supply meets demand. This problem arises in market economies, including electricity generation from renewable sources in smart grids. Our model includes noise in the supply side, which is counterbalanced in the consumption side by storing energy or reducing the demand according to a dynamic price process. By solving a constrained minimization problem, we prove that the Lagrange multiplier corresponding to the market-clearing condition defines the solution of the price formation problem. For the linear-quadratic structure, we characterize the price process using optimal control techniques, and we include two numerical approaches for the price computation. ",A random-supply Mean Field Game price model
"  We define a notion of {\it positive part} of a lattice $\Lambda$ and we endow the set of such positive parts with a topology. We then study some properties of this topology, by comparing it with the one of $V^*/\RM_{> 0}$, where $V^*$ is the dual vector space of $\RM \otimes_\ZM \Lambda$. ",Topologie sur l'ensemble des parties positives d'un r\'eseau
"  Discriminative correlation filters show excellent performance in object tracking. However, in complex scenes, the apparent characteristics of the tracked target are variable, which makes it easy to pollute the model and cause the model drift. In this paper, considering that the secondary peak has a greater impact on the model update, we propose a method for detecting the primary and secondary peaks of the response map. Secondly, a novel confidence function which uses the adaptive update discriminant mechanism is proposed, which yield good robustness. Thirdly, we propose a robust tracker with correlation filters, which uses hand-crafted features and can improve model drift in complex scenes. Finally, in order to cope with the current trackers' multi-feature response merge, we propose a simple exponential adaptive merge approach. Extensive experiments are performed on OTB2013, OTB100 and TC128 datasets. Our approach performs superiorly against several state-of-the-art trackers while runs at speed in real time. ",Improving Model Drift for Robust Object Tracking
"  Robots assisting us in factories or homes must learn to make use of objects as tools to perform tasks, e.g., a tray for carrying objects. We consider the problem of learning commonsense knowledge of when a tool may be useful and how its use may be composed with other tools to accomplish a high-level task instructed by a human. We introduce a novel neural model, termed TANGO, for predicting task-specific tool interactions, trained using demonstrations from human teachers instructing a virtual robot. TANGO encodes the world state, comprising objects and symbolic relationships between them, using a graph neural network. The model learns to attend over the scene using knowledge of the goal and the action history, finally decoding the symbolic action to execute. Crucially, we address generalization to unseen environments where some known tools are missing, but alternative unseen tools are present. We show that by augmenting the representation of the environment with pre-trained embeddings derived from a knowledge-base, the model can generalize effectively to novel environments. Experimental results show a 60.5-78.9% absolute improvement over the baseline in predicting successful symbolic plans in unseen settings for a simulated mobile manipulator. ",TANGO: Commonsense Generalization in Predicting Tool Interactions for   Mobile Manipulators
"  Evolution is presented as a trial-and-error process that produces a progressive accumulation of knowledge. At the level of technology, this leads to ephemeralization, i.e. ever increasing productivity, or decreasing of the friction that normally dissipates resources. As a result, flows of matter, energy and information circulate ever more easily across the planet. This global connectivity increases the interactions between agents, and thus the possibilities for conflict. However, evolutionary progress also reduces social friction, via the creation of institutions. The emergence of such ""mediators"" is facilitated by stigmergy: the unintended collaboration between agents resulting from their actions on a shared environment. The Internet is a near ideal medium for stigmergic interaction. Quantitative stigmergy allows the web to learn from the activities of its users, thus becoming ever better at helping them to answer their queries. Qualitative stigmergy stimulates agents to collectively develop novel knowledge. Both mechanisms have direct analogues in the functioning of the human brain. This leads us to envision the future, super-intelligent web as a ""global brain"" for humanity. The feedback between social and technological advances leads to an extreme acceleration of innovation. An extrapolation of the corresponding hyperbolic growth model would forecast a singularity around 2040. This can be interpreted as the evolutionary transition to the Global Brain regime. ",Accelerating Socio-Technological Evolution: from ephemeralization and   stigmergy to the global brain
"  A new functional form for the exchange enhancement in the generalized gradient approximation within density functional theory is given. The functional form satisfies the constraints used to construct the Perdew-Burke-Ernzerhof (PBE) functional but can be systematically varied using one parameter. This gives the possibility to estimate the reliability of a computational result or to fit the parameter for a certain problem. Compared to other semi-empirical functionals, the present has the advantage that only one physically transparent parameter is used and that the fitted functional will obey the same exact conditions as PBE functional. Furthermore the simple form of the exchange enhancement means that oscillating terms in the exchange potential are avoided. ",Functional form of the generalized gradient approximation for exchange:   The PBE$\alpha$ functional
"  Mesoscopic solid state Aharonov-Bohm interferometers have been used to measure the ""intrinsic"" phase, $\alpha_{QD}$, of the resonant quantum transmission amplitude through a quantum dot (QD). For a two-terminal ""closed"" interferometer, which conserves the electron current, Onsager's relations require that the measured phase shift $\beta$ only ""jumps"" between 0 and $\pi$. Additional terminals open the interferometer but then $\beta$ depends on the details of the opening. Using a theoretical model, we present quantitative criteria (which can be tested experimentally) for $\beta$ to be equal to the desired $\alpha_{QD}$: the ""lossy"" channels near the QD should have both a small transmission and a small reflection. ",Which phase is measured in the mesoscopic Aharonov-Bohm interferometer?
"  In this paper we give a comprehensive treatment of a two-penalty boundary obstacle problem for a divergence form elliptic operator, motivated by applications to fluid dynamics and thermics. Specifically, we prove existence, uniqueness and optimal regularity of solutions, and establish structural properties of the free boundary. The proofs are based on tailor-made monotonicity formulas of Almgren, Weiss, and Monneau-type, combined with the classical theory of oblique derivative problems. ",Existence and regularity results for the penalized thin obstacle problem   with variable coefficients
"  POLAR is a compact wide field space-borne detector dedicated for precise measurements of the linear polarization of hard X-rays emitted by transient sources in the energy range from 50 keV to 500 keV. It consists of 1600 plastic scintillator bars grouped in 25 detector modules that are used as gamma-ray detection material. Its energy range sensitivity is optimized for detection of the prompt emission photons from the gamma-ray bursts. Measurements of the GRB polarization provide unique information on emission mechanisms as well as on composition and structure of the GRB jets. The POLAR instrument was developed by international collaboration of Switzerland, China and Poland. It was launched in space on-board the China Space Laboratory TG-2 on September 15th, 2016. Based on the ground calibration data, several high voltage and threshold settings were calculated and verified in order to obtain various energy ranges and optimized signal to background conditions for different measurement purposes. In this paper we present optimization procedure details and current test results. ",Optimization of the final settings for the Space-borne Hard X-ray   Compton Polarimeter POLAR
"  In this letter, we propose a control framework for human-in-the-loop systems, in which many human decision makers are involved in the feedback loop composed of a plant and a controller. The novelty of the framework is that the decision makers are weakly controlled; in other words, they receive a set of admissible control actions from the controller and choose one of them in accordance with their private preferences. For example, the decision makers can decide their actions to minimize their own costs or by simply relying on their experience and intuition. A class of controllers which output set-valued signals is proposed, and it is shown that the overall control system is stable independently of the decisions made by the humans. Finally, a learning algorithm is applied to the controller that updates the controller parameters to reduce the achievable minimal costs for the decision makers. Effective use of the algorithm is demonstrated in a numerical experiment. ",Weak Control for Human-in-the-loop Systems
"  In Feferman's work, explicit mathematics and theories of generalized inductive definitions play a central role. One objective of this article is to describe the connections with Martin-Lof type theory and constructive Zermelo-Fraenkel set theory. Proof theory has contributed to a deeper grasp of the relationship between different frameworks for constructive mathematics. Some of the reductions are known only through ordinal-theoretic characterizations. The paper also addresses the strength of Voevodsky's univalence axiom. A further goal is to investigate the strength of intuitionistic theories of generalized inductive definitions in the framework of intuitionistic explicit mathematics that lie beyond the reach of Martin-Lof type theory. ",Proof Theory of Constructive Systems: Inductive Types and Univalence
"  We consider a well-known static, axially symmetric, vacuum solution of Einstein equations belonging to Weyl's class and determine the fundamental frequencies of small harmonic oscillations of test particles around stable circular orbits in the equatorial plane. We discuss the radial profiles of frequencies of the radial, latitudinal (vertical), and azimuthal (Keplerian) harmonic oscillations relative to the comoving and distant observers and compare with the corresponding ones in the Schwarzschild and Kerr geometries. We show that there exist latitudinal and radial frequencies of harmonic oscillations of particles moving along the circular orbits for which it is impossible to determine whether the central gravitating object is described by the slowly rotating Kerr solution or by a slightly deformed static space-time. ",Harmonic oscillations of neutral particles in the $\gamma$-metric
"  We present the discovery of three new Southern Hemisphere T dwarfs identified in the Two Micron All Sky Survey. These objects, 2MASS 0348-6022, 2MASS 0516-0445, and 2MASS 2228-4310, have classifications T7, T5.5, and T6.5, respectively. Using linear absolute magnitude/spectral type relations derived from T dwarfs with measured parallaxes, we estimate spectrophotometric distances for these discoveries; the closest, 2MASS 0348-6022, is likely within 10 pc of the Sun. Proper motions and estimated tangential velocities are consistent with membership in the Galactic disk population. We also list Southern Hemisphere T dwarf candidates that were either not found in subsequent near-infrared imaging observations and are most likely uncatalogued minor planets, or have near-infrared spectra consistent with background stars. ",The 2MASS Wide-Field T Dwarf Search. II. Discovery of Three T Dwarfs in   the Southern Hemisphere
"  Let G be a finite group, let p be a prime number, and let K be a field of characteristic 0 and k be a field of characteristic p, both large enough. In this note we state explicit formulae for the primitive idempotents of K\otimes pp_k(G), where pp_k(G) is the ring of p-permutation kG-modules. ",The primitive idempotents of the p-permutation ring
"  We determine the shapes of all degree $4$ number fields that are Galois. These lie in four infinite families depending on the Galois group and the tame versus wild ramification of the field. In the $V_4$ case, each family is a two-dimensional space of orthorhombic lattices and we show that the shapes are equidistributed, in a regularized sense, in these spaces as the discriminant goes to infinity (with respect to natural measures). We also show that the shape is a complete invariant in some natural families of $V_4$-quartic fields. For $C_4$-quartic fields, each family is a one-dimensional space of tetragonal lattices and the shapes make up a discrete subset of points in these spaces. We prove asymptotics for the number of fields with a given shape in this case. ",The shapes of Galois quartic fields
"  The aim of this short note is to develop a (co)homology theory for topological spaces together with the specialisation preorder. A known way to construct such a (co)homology is to define a partial order on the topological space starting from the preorder, and then to consider some (co)homology for the obtained poset; however, we will prove that every topological space with the above preorder consists of two disjoint parts (one called 'poset part', and the other one called 'complementary part', which is not a poset in general): this suggests an improvement of the previous method that also takes into account the poset part, and this is indeed what we will study here. ",A (co)homology theory for some preordered topological spaces
"  Bistable nanomagnets store a binary bit of information. Exchange coupled nanomagnets can increase the thermal stability at low dimensions. Here we show that the antiferromagnetically (AFM) coupled nanomagnets can be highly stable at low dimensions than that of the ferromagnetically (FM) coupled nanomagnets. By solving stochastic Landau-Lifshitz-Gilbert equation of magnetization dynamics at room temperature, we analyze the stability of the exchange coupled nanomagnets in the presence of correlated, uncorrelated, and anti-correlated noise. The results show that the correlated noise can make the stability of the AFM coupled nanomagnets very high. Such finding will lead to very high-density non-volatile storage and logic devices in our future information processing systems. ",Colossal stability of antiferromagnetically exchange coupled nanomagnets
"  We present late-time Hubble Space Telescope (HST) ultraviolet (UV) and optical observations of the site of SN 2011dh in the galaxy M51, ~1164 days post-explosion. At the SN location, we observe a point source that is visible at all wavelengths, that is significantly fainter than the spectral energy distribution (SED) of the Yellow Supergiant progenitor observed prior to explosion. The previously reported photometry of the progenitor is, therefore, completely unaffected by any sources that may persist at the SN location after explosion. In comparison with the previously reported late-time photometric evolution of SN 2011dh, we find that the light curve has plateaued at all wavelengths. The SED of the late-time source is clearly inconsistent with a SED of stellar origin. Although the SED is bright at UV wavelengths, there is no strong evidence that the late-time luminosity originates solely from a stellar source corresponding to the binary companion, although a partial contribution to the observed UV flux from a companion star can not be ruled out. ",Did the progenitor of SN2011dh have a binary companion?
"  Observing a high-statistics neutrino signal from the supernova explosions in the Galaxy is a major goal of low-energy neutrino astronomy. The prospects for detecting all flavors of neutrinos and antineutrinos from the core-collapse supernova (ccSN) in operating and forthcoming large liquid scintillation detectors (LLSD) are widely discussed now. One of proposed LLSD is Baksan Large Volume Scintillation Detector (BLVSD). This detector will be installed at the Baksan Neutrino Observatory (BNO) of the Institute for Nuclear Research, Russian Academy of Sciences, at a depth of 4800 m.w.e. Low-energy neutrino astronomy is one of the main lines of research of the BLVSD. ",Prospects of the search for neutrino bursts from Supernovae with Baksan   Large Volume Scintillation Detector
  The table of Gradshteyn and Ryzhik contains some integrals that can be expressed in terms of the incomplete beta function. We describe some elementary properties of this function and use them to check some of the formulas in the mentioned table. ,The integrals in Gradshteyn and Ryzhik. Part 11: The incomplete beta   function
"  A two-dimensional electron gas exposed to a tilted magnetic field is considered with the Rashba spin-orbit interaction and the Zeeman effect. An exact solution for the eigenvalues were obtained assuming that two opposite spin states of adjacent Landau levels have equal probability. No crossings between adjacent eigenenergies were observed unlike in the perpendicular-magnetic-field case. The absence of crossings lead to quenched beating structures in the oscillations of the density of states (DOS). Persistent spin-splittings were observed at the weak magnetic field region. The splittings, however, can be effectively screened by an increased Landau level broadening. The results shed light on how spins can be controlled through the Rashba interaction strength, the disorder-related broadening and the magnetic field tilt angle. ",Quenching of the DOS beats in a two-dimensional electron gas in tilted   magnetic fields
"  We investigate steady state entanglement in an open quantum system, specifically a single atom in a driven optical cavity with cavity loss and spontaneous emission. The system reaches a steady pure state when driven very weakly. Under these conditions, there is an optimal value for atom-field coupling to maximize entanglement, as larger coupling favors a loss port due to the cavity enhanced spontaneous emission. We address ways to implement measurements of entanglement witnesses and find that normalized cross-correlation functions are indicators of the entanglement in the system. The magnitude of the equal time intensity-field cross correlation between the transmitted field of the cavity and the fluorescence intensity is proportional to the concurrence for weak driving fields. ",Steady State Entanglement in Cavity QED
"  Let M and N be smooth manifolds without boundary. Immersion theory suggests that an understanding of the space of smooth embeddings emb(M,N) should come from an analysis of the cofunctor V |--> emb(V,N) from the poset O of open subsets of M to spaces. We therefore abstract some of the properties of this cofunctor, and develop a suitable calculus of such cofunctors, Goodwillie style, with Taylor series and so on. The terms of the Taylor series for the cofunctor V |--> emb(V,N) are explicitly determined. In a sequel to this paper, we introduce the concept of an analytic cofunctor from O to spaces, and show that the Taylor series of an analytic cofunctor F converges to F. Deep excision theorems due to Goodwillie and Goodwillie-Klein imply that the cofunctor V |--> emb(V,N) is analytic when dim(N)-dim(M) > 2. ",Embeddings from the point of view of immersion theory: Part I
  In this paper we show that both of the Green-Schwarz anomaly factorization formula for the gauge group $E_8\times E_8$ and the Ho\v{r}ava-Witten anomaly factorization formula for the gauge group $E_8$ can be derived through modular forms of weight 14. This answers a question of J. H. Schwarz. We also establish generalizations of these factorization formulas and obtain a new Ho\v{r}ava-Witten type factorization formula. ,Anomaly Cancellation and Modularity. II: $E_8\times E_8$ case
"  In this paper a novel multi-hop relay-assisted hybrid FSO / RF system is presented. It is assumed that direct RF connection between mobile users and source Base Station is impossible, therefore a relay connects RF users to the source Base Station via a FSO link. Source and destination Base Stations are connected via a multi-hop relay-assisted hybrid FSO / RF link. FSO link is investigated over moderate to saturate regimes of atmospheric turbulence. Also RF link is assumed to have Rayleigh fading. For the first time, new exact and asymptotic expressions are derived in closed-form for Bit Error Rate (BER) and the Outage Probability (P_out), of the proposed system. MATLAB simulations are performed to validate obtained analytical results. Results indicate that the proposed structure has low dependence on the number of users, therefore, the proposed structure is suitable for cells which encounter different populations during a day, because there is little performance difference between systems with different number of users. Also the proposed structure, at Negative exponential atmospheric turbulence has small dependence on the number of relays, but this dependence is a bit more for Gamma-Gamma atmospheric turbulence. Therefore, the proposed structure increases capacity whereas maintaining performance of the system. ",New expression on the performance of a novel multi-hop relay-assisted   hybrid FSO / RF communication system
"  It is proposed that the quantum mechanics of N D4-branes and M D0-branes on the quintic is described by the dimensional reduction of a certain U(N)xU(M) quiver gauge theory, whose superpotential encodes the defining quintic polynomial. It is shown that the moduli space on the Higgs branch exactly reproduces the moduli space of degree N hypersurfaces in the quintic endowed with the appropriate line bundle, and that the cohomology growth reproduces the D4-D0 black hole entropy. ",D4-D0 Branes on the Quintic
"  We present new results obtained from a series of follow-up e+e- coincidence measurements in heavy-ion collisions, utilizing an improved experimental set-up at the double-Orange beta-spectrometer of GSI. The collision system U+Ta was reinvestigated in three independent runs at beam energies in the range (6.0-6.4)xA MeV and different target thicknesses, with the objective to reproduce a narrow sum-energy e+e- line at ~635 keV observed previously in this collision system. At improved statistical accuracy, the line could not be found in these new data. For the ''fission'' scenario, an upper limit (1 sigma) on its production probability per collision of 1.3x10^{-8} can be set which has to be compared to the previously reported value of [4.9 +- 0.8 (stat.) +- 1.0 (syst)]x10^{-7}. In the light of the new results, a reanalysis of the old data shows that the continuous part of the spectrum at the line position is significantly higher than previously assumed, thus reducing the production probability of the line by a factor of two and its statistical significance to < 3.4sigma. ",New Results on e+e- Line Emission in U+Ta Collisions
"  It is known that an engine with ideal efficiency ($\eta =1$ for a chemical engine and $e = e_{\rm Carnot}$ for a thermal one) has zero power because a reversible cycle takes an infinite time. However, at least from a theoretical point of view, it is possible to conceive (irreversible) engines with nonzero power that can reach ideal efficiency. Here this is achieved by replacing the usual linear transport law by a sublinear one and taking the step-function limit for the particle current (chemical engine) or heat current (thermal engine) versus the applied force. It is shown that in taking this limit exact thermodynamic inequalities relating the currents to the entropy production are not violated. ",Engines with ideal efficiency and nonzero power for sublinear transport   laws
"  Group consensus implies reaching multiple groups where agents belonging to the same cluster reach state consensus. This paper focuses on linear multi-agent systems under nonnegative directed graphs. A new necessary and sufficient condition for ensuring group consensus is derived, which requires the spanning forest of the underlying directed graph and that of its quotient graph induced with respect to a clustering partition to contain equal minimum number of directed trees. This condition is further shown to be equivalent to containing cluster spanning trees, a commonly used topology for the underlying graph in the literature. Under a designed controller gain, lower bound of the overall coupling strength for achieving group consensus is specified. Moreover, the pattern of the multiple consensus states formed by all clusters is characterized when the overall coupling strength is large enough. ",Group Consensus of Linear Multi-agent Systems under Nonnegative Directed   Graphs
"  We prove that the complement of a $\sigma$-compact subset of a topological space that has a $\pi$-tree also has a $\pi$-tree. To do this, we construct the foliage hybrid operation, which deals with foliage trees (that is, set-theoretic trees with a `leaf' at each node). Then using this operation we modify a $\pi$-tree of a space and get a $\pi$-tree for its subspace. ",The complement of a $\sigma$-compact subset of a space with a $\pi$-tree   also has a $\pi$-tree
"  In this paper, we analyse the phase space structure of the roaming dynamics in a two degree of freedom potential energy surface consisting of two identical planar Morse potentials separated by a distance. This potential energy surface was previously studied in [1], and it has two potential wells surrounded by an unbounded flat region containing no critical points. We study the phase space mechanism for the transference between the wells using the method of Lagrangian descriptors. ",Revealing Roaming on the Double Morse Potential Energy Surface with   Lagrangian Descriptors
"  We present observations of main-belt comet 358P/PANSTARRS (P/2012 T1) obtained using the Gemini South telescope from 2017 July to 2017 December, as the object approached perihelion for the first time since its discovery. We find best-fit IAU phase function parameters of H_R=19.5+/-0.2 mag and G_R=-0.22+/-0.13 for the nucleus, corresponding to an effective radius of r_N=0.32+/-0.03 km (assuming an albedo of p_R=0.05). The object appears significantly brighter (by >1 mag) than expected starting in 2017 November, while a faint dust tail oriented approximately in the antisolar direction is also observed on 2017 December 18. We conclude that 358P has become active again for the first time since its previously observed active period in 2012-2013. These observations make 358P the seventh main-belt comet candidate confirmed to exhibit recurrent activity near perihelion with intervening inactivity away from perihelion, strongly indicating that its activity is sublimation-driven. Fitting a linear function to the ejected dust masses inferred for 358P in 2017 when it is apparently active, we find an average net dust production rate of 2.0+/-0.6 kg/s (assuming a mean effective particle radius of 1 mm) and an estimated activity start date of 2017 November 8+/-4 when the object was at a true anomaly of 316+/-1 deg and a heliocentric distance of R=2.54 AU. Insufficient data is currently available to ascertain whether activity strength has changed between the object's 2012-2013 and 2017 active periods. Further observations are therefore highly encouraged during the object's upcoming observing window (2018 August through 2019 May). ",The Reactivation and Nucleus Characterization of Main-Belt Comet   358P/PANSTARRS (P/2012 T1)
"  Recently Quantum Computation has generated a lot of interest due to the discovery of a quantum algorithm which can factor large numbers in polynomial time. The usefulness of a quantum com puter is limited by the effect of errors. Simulation is a useful tool for determining the feasibility of quantum computers in the presence of errors. The size of a quantum computer that can be simulat ed is small because faithfully modeling a quantum computer requires an exponential amount of storage and number of operations. In this paper we define simulation models to study the feasibility of quantum computers. The most detailed of these models is based directly on a proposed imple mentation. We also define less detailed models which are exponentially less complex but still pro duce accurate results. Finally we show that the two different types of errors, decoherence and inaccuracies, are uncorrelated. This decreases the number of simulations which must be per formed. ",Models to Reduce the Complexity of Simulating a Quantum Computer
"  Diffusion MRI may enable non-invasive mapping of axonal microstructure. Most approaches infer axon diameters from effects of time-dependent diffusion on the diffusion-weighted MR signal by modelling axons as straight cylinders. Axons do not, however, run in straight trajectories and so far, the impact of the axonal trajectory on diameter estimation has not been systematically investigated. Here, we employ a toy-model of axons, which we refer to as undulating thin-fiber model, to analyze the impact of undulating trajectories on the diffusion-time dependence represented by the diffusion spectrum. We analyze the spectrum by its height (diffusivity at high frequencies), width (half width at half maximum), and low-frequency behavior (power law exponent). Results show that microscopic orientation dispersion of the thin-fibers is the main parameter that determines the characteristics of the diffusion spectra. Straight cylinders and undulating thin-fibers have virtually identical spectra at lower frequencies. If the straight-cylinder assumption is used to interpret data from undulating thin axons, the diameter is overestimated by an amount proportional to the undulation amplitude and the microscopic orientation dispersion. At high frequencies (short diffusion times), spectra from cylinders and undulating thin-fibers differ. The spectra from the undulating thin-fibers can also differ from that of cylinders by exhibiting power law behaviors with exponents below two. In conclusion, we argue that the non-straight nature of axonal trajectories should not be ignored when analyzing dMRI data and that careful experiments may enable separation of diffusion within straight cylinders and diffusion in undulating thin-fibers. ",Time-dependent diffusion in undulating structures: Impact on axon   diameter estimation
"  We revisit Wyman's ""other"" scalar field solution of the Einstein equations and its Sultana generalization to positive cosmological constant, which has a finite 3-space and corresponds to a special case of a stiff fluid solution proposed by Buchdahl and Land and, later, by Iba\~nez and Sanz to model relativistic stars. However, there is a hidden cosmological constant and the peculiar geometry prevents the use of this spacetime to model relativistic stars. ",The curious case of the Buchdahl-Land-Sultana-Wyman-Iba\~nez-Sanz   spacetime
"  Commonly used metrics for evaluation of object detection systems (precision, recall, mAP) do not give complete information about their suitability of use in safety critical tasks, like obstacle detection for collision avoidance in Autonomous Vehicles (AV). This work introduces the Risk Ranked Recall ($R^3$) metrics for object detection systems. The $R^3$ metrics categorize objects within three ranks. Ranks are assigned based on an objective cyber-physical model for the risk of collision. Recall is measured for each rank. ",Risk Ranked Recall: Collision Safety Metric for Object Detection Systems   in Autonomous Vehicles
"  Tenfold speedups can be brought to ADMM for Semidefinite Programming with virtually no decrease in robustness and provable convergence simply by projecting approximately to the Semidefinite cone. Instead of computing the projections via ""exact"" eigendecompositions that scale cubically with the matrix size and cannot be warm-started, we suggest using state-of-the-art factorization-free, approximate eigensolvers thus achieving almost quadratic scaling and the crucial ability of warm-starting. Using a recent result from [Goulart et al., 2019] we are able to circumvent the numerically instability of the eigendecomposition and thus maintain a tight control on the projection accuracy, which in turn guarranties convergence, either to a solution or a certificate of infeasibility, of the ADMM algorithm. To achieve this, we extend recent results from [Banjac et al., 2017] to prove that reliable infeasibility detection can be performed with ADMM even in the presence of approximation errors. In all of the considered problems of SDPLIB that ""exact"" ADMM can solve in a few thousand iterations, our approach brings a significant, up to 20x, speedup without a noticable increase on ADMM's iterations. Further numerical results underline the robustness and efficiency of the approach. ",Efficient Semidefinite Programming with approximate ADMM
"  Based on the novel view that a micro-entity could be considered as a particle associated with a field partaking of the energy of particle which are both described by deterministic causal equations of motion, we examine the success of our new theory in elucidating the underlying physics of the double-slit experiment. Here, we explain with clear details how each micro-particle scatters from one of the slits at a given time. After the scattering through one of the slits, the particle shares some of its energy with its surrounding field and a particle-field system is again formed which its motion is governed by a deterministic dynamics during its flight towards the detecting screen. The interference pattern is then explained by showing how the final location of each particle-field system at the time of reaching the detecting screen is distributed according to an angular distribution (equal to the what quantum theory predicts for the fringe effects in a two-slit experiment). The probabilistic nature of such a distribution can be explained by considering the variations of the kinetic energy of the particle-field system at different local situations. ",On A New Formulation of Micro-phenomena: The Double-slit Experiment
"  The neutron transition densities of the $2^+-8^+$ levels in $^{90}$Zr were extracted in the process of analysing ({\bf p},p') scattering at 400 Mev. Its comparison with the proton transition densities for these levels was undertaken. The radial shapes of the experimental neutron and proton transition densities for each state were found to be different. ",Neutrons transition densities for the $2^+-8^+$ multiplet of states in   $^{90}$Zr
"  We present a color analysis of the galaxy populations of candidate clusters of galaxies from the Palomar Distant Cluster Survey (Postman et al.\ 1996). The survey was conducted in two broad band filters that closely match $V$ and $I$ and contains a total of 79 candidate clusters of galaxies, covering an estimated redshift range $0.2 \simless z \simless 1.2$. We examine the color evolution in the 57 richest clusters from this survey. The intermediate redshift ($0.2 \simless z \simless 0.4$) clusters show a distinct locus of galaxy colors in the color--magnitude diagram. This ridge line corresponds well with the expected no--evolution color of present--day elliptical galaxies at these redshifts. In clusters at redshifts of $z \simgreat 0.5$, this red envelope has shifted bluewards compared to the ``no--evolution'' prediction. By $z \sim 0.8$ there are only a few galaxies which are as red in their rest-frame as present--day ellipticals. The detected evolution is consistent with passive aging of stellar populations formed at redshifts of $z \simgreat 2$. Though the uncertainties are large, the Butcher--Oemler effect is observed in the Palomar clusters. The fraction of blue galaxies increases with the estimated redshift of the cluster at a 96.2\% confidence level. The measured blue fractions of the intermediate redshift clusters ($f_{b} \sim 0.2 - 0.3$) are consistent with those found previously by Butcher \& Oemler (1984). The trend in the Palomar clusters suggests that $f_{b}$ can be greater than 0.4 in clusters of galaxies at redshifts of $z \simgreat 0.6$. ",The Palomar Distant Cluster Survey : III. The Colors of the Cluster   Galaxies
"  We present the results of a calculation of the thermal spectrum from a 2D, moving mesh, high-accuracy, viscous hydrodynamical simulation of an accreting supermassive black hole binary. We include viscous heating, shock heating, and radiative cooling, evolving for longer than a viscous time so that we reach a quasi-steady accretion state. In agreement with previous work, we find that gas is efficiently stripped from the inner edge of the circumbinary disk and enters the cavity along accretion streams, which feed persistent ""mini-disks"" surrounding each black hole. We also find that emission from the shock-heated mini-disks and accretion streams prevents any deficit in high-energy emission that may be expected inside the circumbinary cavity, and instead leads to a characteristic brightening of the spectrum beginning in soft X-rays. ",Characteristic Signatures in the Thermal Emission from Accreting Binary   Black Holes
"  A basic principle of physics is the freedom to locally choose any unit system when describing physical quantities. Its implementation amounts to treating Weyl invariance as a fundamental symmetry of all physical theories. In this thesis, we study the consequences of this ""unit invariance"" principle and find that it is a unifying one. Unit invariance is achieved by introducing a gauge field called the scale, designed to measure how unit systems vary from point to point. In fact, by a uniform and simple Weyl invariant coupling of scale and matter fields, we unify massless, massive, and partially massless excitations. As a consequence, masses now dictate the response of physical quantities to changes of scale. This response is calibrated by certain ""tractor Weyl weights"". Reality of these weights yield Breitenlohner-Freedman stability bounds in anti de Sitter spaces. Another valuable outcome of our approach is a general mechanism for constructing conformally invariant theories. In particular, we provide direct derivations of the novel Weyl invariant Deser--Nepomechie vector and spin three-half theories as well as new higher spin generalizations thereof. To construct these theories, a ""tractor calculus"" coming from conformal geometry is employed, which keeps manifest Weyl invariance at all stages. In fact, our approach replaces the usual Riemannian geometry description of physics with a conformal geometry one. Within the same framework, we also give a description of fermionic and interacting supersymmetric theories which again unifies massless and massive excitations. ",Unit Invariance as a Unifying Principle of Physics
"  We present MadDM v.3.0, a numerical tool to compute particle dark matter observables in generic new physics models. The new version features a comprehensive and automated framework for dark matter searches at the interface of collider physics, astrophysics and cosmology and is deployed as a plugin of the MadGraph5_aMC@NLO platform, inheriting most of its features. With respect to the previous version, MadDM v.3.0 can now provide predictions for indirect dark matter signatures in astrophysical environments, such as the annihilation cross section at present time and the energy spectra of prompt photons, cosmic rays and neutrinos resulting from dark matter annihilation. MadDM indirect detection features support both $2\to2$ and $2 \to n$ dark matter annihilation processes. In addition, the ability to compare theoretical predictions with experimental constraints is extended by including the Fermi-LAT likelihood for gamma-ray constraints from dwarf spheroidal galaxies and by providing an interface with the nested sampling algorithm PyMultinNest to perform high dimensional parameter scans efficiently. We validate the code for a wide set of dark matter models by comparing the results from MadDM v.3.0 to existing tools and results in the literature. ",MadDM v.3.0: a Comprehensive Tool for Dark Matter Studies
"  Agitation is one of the neuropsychiatric symptoms with high prevalence in dementia which can negatively impact the Activities of Daily Living (ADL) and the independence of individuals. Detecting agitation episodes can assist in providing People Living with Dementia (PLWD) with early and timely interventions. Analysing agitation episodes will also help identify modifiable factors such as ambient temperature and sleep as possible components causing agitation in an individual. This preliminary study presents a supervised learning model to analyse the risk of agitation in PLWD using in-home monitoring data. The in-home monitoring data includes motion sensors, physiological measurements, and the use of kitchen appliances from 46 homes of PLWD between April 2019-June 2021. We apply a recurrent deep learning model to identify agitation episodes validated and recorded by a clinical monitoring team. We present the experiments to assess the efficacy of the proposed model. The proposed model achieves an average of 79.78% recall, 27.66% precision and 37.64% F1 scores when employing the optimal parameters, suggesting a good ability to recognise agitation events. We also discuss using machine learning models for analysing the behavioural patterns using continuous monitoring data and explore clinical applicability and the choices between sensitivity and specificity in-home monitoring applications. ",Designing A Clinically Applicable Deep Recurrent Model to Identify   Neuropsychiatric Symptoms in People Living with Dementia Using In-Home   Monitoring Data
"  In this paper, we propose a generalized scale mixture family of distributions, namely the Power Exponential Scale Mixture (PESM) family, to model the sparsity inducing priors currently in use for sparse signal recovery (SSR). We show that the successful and popular methods such as LASSO, Reweighted $\ell_1$ and Reweighted $\ell_2$ methods can be formulated in an unified manner in a maximum a posteriori (MAP) or Type I Bayesian framework using an appropriate member of the PESM family as the sparsity inducing prior. In addition, exploiting the natural hierarchical framework induced by the PESM family, we utilize these priors in a Type II framework and develop the corresponding EM based estimation algorithms. Some insight into the differences between Type I and Type II methods is provided and of particular interest in the algorithmic development is the Type II variant of the popular and successful reweighted $\ell_1$ method. Extensive empirical results are provided and they show that the Type II methods exhibit better support recovery than the corresponding Type I methods. ",Type I and Type II Bayesian Methods for Sparse Signal Recovery using   Scale Mixtures
"  Real-world object detection is highly desired to be equipped with the learning expandability that can enlarge its detection classes incrementally. Moreover, such learning from only few annotated training samples further adds the flexibility for the object detector, which is highly expected in many applications such as autonomous driving, robotics, etc. However, such sequential learning scenario with few-shot training samples generally causes catastrophic forgetting and dramatic overfitting. In this paper, to address the above incremental few-shot learning issues, a novel Incremental Few-Shot Object Detection (iFSOD) method is proposed to enable the effective continual learning from few-shot samples. Specifically, a Double-Branch Framework (DBF) is proposed to decouple the feature representation of base and novel (few-shot) class, which facilitates both the old-knowledge retention and new-class adaption simultaneously. Furthermore, a progressive model updating rule is carried out to preserve the long-term memory on old classes effectively when adapt to sequential new classes. Moreover, an inter-task class separation loss is proposed to extend the decision region of new-coming classes for better feature discrimination. We conduct experiments on both Pascal VOC and MS-COCO, which demonstrate that our method can effectively solve the problem of incremental few-shot detection and significantly improve the detection accuracy on both base and novel classes. ",Towards Generalized and Incremental Few-Shot Object Detection
"  The memory effect upon glassification is studied in the glass to rubber transition of vulcanized rubber with the strain as a controlling parameter. A phenomenological model is proposed taking the history of the temperature and the strain into account, by which the experimental results are interpreted. The data and the model demonstrate that the glassy state memorizes the time-course of strain upon glassification, not as a single parameter but as the history itself. The data also show that the effect of irreversible deformation in the glassy state is beyond the scope of the present model.   Authors' remark: The title of the paper in the accepted version is above. The title appeared in PRL is the one changed by a Senior Assistant Editor after acceptance of the paper. The recovery of the title was rejected in the correction process. ",History Memorized and Recalled upon Glass Transition
"  DP-coloring (also known as correspondence coloring) is a generalization of list coloring developed recently by Dvo\v{r}\'{a}k and Postle. In this paper we introduce and study the fractional DP-chromatic number $\chi_{DP}^\ast(G)$. We characterize all connected graphs $G$ such that $\chi_{DP}^\ast(G) \leqslant 2$: they are precisely the graphs with no odd cycles and at most one even cycle. By a theorem of Alon, Tuza, and Voigt, the fractional list-chromatic number $\chi_\ell^\ast(G)$ of any graph $G$ equals its fractional chromatic number $\chi^\ast(G)$. This equality does not extend to fractional DP-colorings. Moreover, we show that the difference $\chi^\ast_{DP}(G) - \chi^\ast(G)$ can be arbitrarily large, and, furthermore, $\chi^\ast_{DP}(G) \geq d/(2 \ln d)$ for every graph $G$ of maximum average degree $d \geq 4$. On the other hand, we show that this asymptotic lower bound is tight for a large class of graphs that includes all bipartite graphs as well as many graphs of high girth and high chromatic number. ",Fractional DP-Colorings of Sparse Graphs
"  We present a BVI optical photometric study of the old open cluster Ruprecht 6 using the data obtained with the SMARTS 1.0 m telescope at the CTIO, Chile. Its color-magnitude diagrams show the clear existence of the main-sequence stars, of which turn-off point is located around V ~ 18.45 mag and B-V ~ 0.85 mag. Three red clump (RC) stars are identified at V = 16.00 mag, I = 14.41 mag and B-V = 1.35 mag. From the mean Ks-band magnitude of RC stars (Ks=12.39 +- 0.21 mag) in Ruprecht 6 from 2MASS photometry and the known absolute magnitudes of the RC stars (M_Ks = -1.595 +- 0.025 mag), we obtain the distance modulus to Ruprecht 6 (m-M)_0 = 13.84 +- 0.21 mag (d=5.86 +- 0.60 kpc). From the (J-K_s) and (B-V) colors of the RC stars, comparison of the (B-V) and (V-I) colors of the bright stars in Ruprecht 6 with those of the intrinsic colors of dwarf and giant stars, and the PARSEC isochrone fittings, we derive the reddening values of E(B-V) = 0.42 mag and E(V-I) = 0.60 mag. Using the PARSEC isochrone fittings onto the color-magnitude diagrams, we estimate the age and metallicity to be: log (t) =9.50 +- 0.10 (t =3.16 +- 0.82 Gyr) and [Fe/H] = -0.42 +- 0.04 dex. We present the Galactocentric radial metallicity gradient analysis for old (age > 1 Gyr) open clusters of Dias et al. catalog, which likely follow a single relation of [Fe/H] =(-0.034 +- 0.007) R_GC + (0.190 +- 0.080) (rms = 0.201) for the whole radial range or dual relation of [Fe/H] =(-0.077 +- 0.017) R_GC + (0.609 +- 0.161) (rms = 0.152) and constant ([Fe/H] ~ -0.3 dex) value, inside and outside of R_GC ~ 12 kpc, respectively. The metallicity and Galactocentric radius (13.28 +- 0.54 kpc) of Ruprecht 6 obtained in this study seem to be consistent with both of the relations. ",BVI Photometric Study of the Old Open Cluster Ruprecht 6
"  This paper presents the development of a Supervisory Control and Data Acquisition (SCADA) system testbed used for cybersecurity research. The testbed consists of a water storage tank's control system, which is a stage in the process of water treatment and distribution. Sophisticated cyber-attacks were conducted against the testbed. During the attacks, the network traffic was captured, and features were extracted from the traffic to build a dataset for training and testing different machine learning algorithms. Five traditional machine learning algorithms were trained to detect the attacks: Random Forest, Decision Tree, Logistic Regression, Naive Bayes and KNN. Then, the trained machine learning models were built and deployed in the network, where new tests were made using online network traffic. The performance obtained during the training and testing of the machine learning models was compared to the performance obtained during the online deployment of these models in the network. The results show the efficiency of the machine learning models in detecting the attacks in real time. The testbed provides a good understanding of the effects and consequences of attacks on real SCADA environments ",SCADA System Testbed for Cybersecurity Research Using Machine Learning   Approach
"  Product Bundling and offering products to customers is of critical importance in retail marketing. In general, product bundling and offering products to customers involves two main issues, namely identification of product taste according to demography and product evaluation and selection to increase sales. The former helps to identify, analyze and understand customer needs according to the demo-graphical characteristics and correspondingly transform them into a set of specifications and offerings for people. The latter, concerns with how to determine the best product strategy and offerings for the customer in helping the retail market to improve their sales. Existing research has focused only on identifying patterns for a particular dataset and for a particular setting. This work aims to develop an explicit decision support for the retailers to improve their product segmentation for different settings based on the people characteristics and thereby promoting sales by efficient knowledge discovery from the existing sales and product records. The work presents a framework, which models an association relation mapping between the customers and the clusters of products they purchase in an existing location and helps in finding rules for a new location. The methodology is based on the integration of popular data mining approaches such as clustering and association rule mining. It focuses on the discovery of rules that vary according to the economic and demographic characteristics and concentrates on marketing of products based on the population. ",Retail Market analysis in targeting sales based on Consumer Behaviour   using Fuzzy Clustering - A Rule Based Mode
"  Seven Earth-sized planets, TRAPPIST-1 system, were discovered in February 2017. Three of these planets are in the habitable zone (HZ) of their star, making them potentially habitable planets a mere 40 light years away. Discovery of the closest potentially habitable planet to us just a year before -- Proxima~b, and a realization that Earth-type planets in HZ are a common occurrence provides the impetus to the pursuit for life outside the Solar System. The search for life has two goals: Earth similarity and habitability. An index was recently proposed, Cobb-Douglas Habitability Score (CDHS), based on Cobb-Douglas production function, which computes the habitability score by using measured and estimated planetary parameters like radius, density, escape velocity and surface temperature of a planet. The proposed metric with exponents accounting for metric elasticity, is endowed with analytical properties that ensure global optima and can be scaled to accommodate a finite number of input parameters. We show that the model is elastic, and the conditions on elasticity to ensure global maxima can scale as the number of predictor parameters increase. K-Nearest Neighbour classification algorithm, embellished with probabilistic herding and thresholding restriction, utilizes CDHS scores and labels exoplanets to appropriate classes via feature-learning methods. The algorithm works on top of a decision-theoretical model using the power of convex optimization and machine learning. A second approach, based on a novel feature-learning and tree-building method classifies the same planets without computing the CDHS of the planets and produces a similar outcome. The convergence of the two different approaches indicates the strength of the proposed scheme and the likelihood of the potential habitability of the recent discoveries. ",Theoretical Validation of Potential Habitability via Analytical and   Boosted Tree Methods: An Optimistic Study on Recently Discovered Exoplanets
  We study a generalized nonconvex Burer-Monteiro formulation for low-rank minimization problems. We use recent results on non-Euclidean first order methods to provide efficient and scalable algorithms. Our approach uses geometries induced by quartic kernels on matrix spaces; for unconstrained cases we introduce a novel family of Gram kernels that considerably improves numerical performances. Numerical experiments for Euclidean distance matrix completion and symmetric nonnegative matrix factorization show that our algorithms scale well and reach state of the art performance when compared to specialized methods. ,Quartic First-Order Methods for Low-Rank Minimization
"  We generalize the vacuum static black strings with negative cosmological constant recently discussed in literature, by including an electromagnetic field. These higher-dimensional configurations have no dependence on the `compact' extra dimension, and their boundary topology is the product of time and $S^{d-3}\times S^1$ or $H^{d-3}\times S^1$. Rotating generalizations of the even dimensional black string configurations are considered as well. Different from the static, neutral case, no regular limit is found for a vanishing event horizon radius. We explore numerically the general properties of such solutions and, using a counterterm prescription, we compute their conserved charges and discuss their thermodynamics. We find that the thermodynamics of the black strings follows the pattern of the corresponding black hole solutions in AdS backgrounds. ",Black strings with negative cosmological constant: inclusion of electric   charge and rotation
"  The {\em chromatic gap} is the difference between the chromatic number and the clique number of a graph. Here we investigate $\gap(n)$, the maximum chromatic gap over graphs on $n$ vertices. Can the extremal graphs be explored? While computational problems related to the chromatic gap are hopeless, an interplay between Ramsey theory and matching theory leads to a simple and (almost) exact formula for $\gap(n)$ in terms of Ramsey numbers. ",The chromatic gap and its extremes
"  Many low energy hadrons, such as the rho, can be observed as resonances in scattering experiments. A proposal by L\""uscher enables one to determine infinite volume elastic scattering phases from the two-particle energy spectrum measured from finite periodic lattices. In this work, we generalize the formalism to the case where the total momentum of the particles is non-zero; i.e. the lattice frame is not the center-of-mass frame of the scattering particles. There are several advantages to this procedure including making a wider variety of center of mass energies accessible with a fixed lattice volume, and making the avoided level crossing in a P-wave decay occur with a smaller volume. The formalism is tested with a simple lattice model of two fields with different masses and a 3-point coupling in 3+1 dimensions. We find remarkable agreement between the rest-frame and non-rest-frame scattering. ",Resonance Scattering Phase Shifts on a Non-Rest Frame Lattice
"  Model Agnostic Meta-Learning (MAML) is one of the most representative of gradient-based meta-learning algorithms. MAML learns new tasks with a few data samples using inner updates from a meta-initialization point and learns the meta-initialization parameters with outer updates. It has recently been hypothesized that representation reuse, which makes little change in efficient representations, is the dominant factor in the performance of the meta-initialized model through MAML in contrast to representation change, which causes a significant change in representations. In this study, we investigate the necessity of representation change for the ultimate goal of few-shot learning, which is solving domain-agnostic tasks. To this aim, we propose a novel meta-learning algorithm, called BOIL (Body Only update in Inner Loop), which updates only the body (extractor) of the model and freezes the head (classifier) during inner loop updates. BOIL leverages representation change rather than representation reuse. This is because feature vectors (representations) have to move quickly to their corresponding frozen head vectors. We visualize this property using cosine similarity, CKA, and empirical results without the head. BOIL empirically shows significant performance improvement over MAML, particularly on cross-domain tasks. The results imply that representation change in gradient-based meta-learning approaches is a critical component. ",BOIL: Towards Representation Change for Few-shot Learning
  We study two-photon excitation using biphotons generated via the process of spontaneous parametric down-conversion in a nonlinear crystal. We show that the focusing of these biphotons yields an excitation distribution that is essentially the same as the distribution of one-photon excitation at the pump wavelength. We also demonstrate that biphoton excitation in the image region yields a distribution whose axial width is approximately that of the crystal thickness and whose transverse width is that of the pump at the input to the crystal. ,Biphoton focusing for two-photon excitation
"  Point Pair Features is a widely used method to detect 3D objects in point clouds, however they are prone to fail in presence of sensor noise and background clutter. We introduce novel sampling and voting schemes that significantly reduces the influence of clutter and sensor noise. Our experiments show that with our improvements, PPFs become competitive against state-of-the-art methods as it outperforms them on several objects from challenging benchmarks, at a low computational cost. ",Going Further with Point Pair Features
"  By means of exact diagonalization we study the low-energy states of seven electrons in the lowest Landau level which are confined by a cylindric external potential modelling the rest of a macroscopic system and thus controlling the filling factor $\nu $. Wigner crystal is found to be the ground state for filling factors between $ \nu = 1/3$ and $ \nu = 1/5$ provided electrons interact via the bare Coulomb potential. Even at $\nu =1/5$ the solid state has lower energy than the Laughlin's one, although the two energies are rather close. We also discuss the role of pseudopotential parameters in the lowest Landau level and demonstrate that the earlier reported gapless state, appearing when the short-range part of the interaction is suppressed, has nothing in common with the Wigner crystalization in pure Coulomb case. ",Wigner Crystalization in the Lowest Landau Level for $\nu \ge 1/5$
"  Direct imagery and long-slit, spatially resolved echellograms of the high excitation planetary nebula NGC 1501 allowed us to study in detail the expansion velocity field, the physical conditions (electron temperature, electron density, ionization) and the spatial distribution of the nebular gas. An electron temperature of 11500 K and a turbulence of 18 km/s are derived by comparing the Halpha and [OIII] emission line profiles, but large, small scale fluctuations of both these quantities are present in the ionized gas. The radial density distribution shows external peaks up to 1400 cm-3; they have steep outwards profiles and extended inwards tails probably originated by Rayleigh-Taylor instability and winds interaction. The complexity of the expanding motions indicates that the main part of NGC 1501 is a thin ellipsoid of moderate ellipticity, but the presence of a pair of large lobes along both the major and the intermediate axes and of a multitude of smaller bumps spread on the whole nebular surface, makes the general 3-D structure of NGC 1501 like a boiling, tetra-lobed shell. This peculiar morphology can be qualitatively explained in terms of interaction of the slow nebular material with the intense and fast wind from the WC4/OVI central star. ",The tetra-lobed planetary nebula NGC 1501
"  The Illinois Express Quantum Network (IEQNET) is a program to realize metro-scale quantum networking over deployed optical fiber using currently available technology. IEQNET consists of multiple sites that are geographically dispersed in the Chicago metropolitan area. Each site has one or more quantum nodes (Q-nodes) representing the communication parties in a quantum network. Q-nodes generate or measure quantum signals such as entangled photons and communicate the results via standard, classical, means. The entangled photons in IEQNET nodes are generated at multiple wavelengths, and are selectively distributed to the desired users via optical switches. Here we describe the network architecture of IEQNET, including the Internet-inspired layered hierarchy that leverages software-defined-networking (SDN) technology to perform traditional wavelength routing and assignment between the Q-nodes. Specifically, SDN decouples the control and data planes, with the control plane being entirely classical. Issues associated with synchronization, calibration, network monitoring, and scheduling will be discussed. An important goal of IEQNET is demonstrating the extent to which the control plane can coexist with the data plane using the same fiber lines. This goal is furthered by the use of tunable narrow-band optical filtering at the receivers and, at least in some cases, a wide wavelength separation between the quantum and classical channels. We envision IEQNET to aid in developing robust and practical quantum networks by demonstrating metro-scale quantum communication tasks such as entanglement distribution and quantum-state teleportation. ",Illinois Express Quantum Network (IEQNET): Metropolitan-scale   experimental quantum networking over deployed optical fiber
"  We describe the main features of the BMW survey of serendipitous X-ray clusters, based on the still unexploited ROSAT-HRI archival observations. The sky coverage, surface density and first deep optical CCD images of the candidates indicate that this sample can represent an excellent complement to the existing PSPC deep cluster surveys and will provide us with a fully independent probe of the evolution of the cluster abundance, in addition to significantly increasing the number of clusters known at z>0.6. ",The BMW X-ray Cluster Survey
"  By generalizing the measurements on the game experiments of mixed strategy Nash equilibrium, we study the dynamical pattern in a representative dynamic stochastic general equilibrium (DSGE). The DSGE model describes the entanglements of the three variables (output gap [$y$], inflation [$\pi$] and nominal interest rate [$r$]) which can be presented in 3D phase space. We find that, even though the trajectory of $\pi\!-\!y\!-\!r$ in phase space appears highly stochastic, it can be visualized and quantified. It exhibits as clockwise cycles, counterclockwise cycles and weak cycles, respectively, when projected onto $\pi\!-\!y$, $y\!-\!r$ and $r\!-\!\pi$ phase planes. We find also that empirical data of United State (1960-2013) significantly exhibit same cycles. The resemblance between the cycles in general equilibrium and the cycles in mixed strategy Nash equilibrium suggest that, there generally exists dynamical fine structures accompanying with equilibrium. The fine structure, describing the entanglement of the non-equilibrium (the constantly deviating from the equilibrium), displays as endless cycles. ",Cycling in stochastic general equilibrium
"  Anisotropy data analysis leaves a significant degeneracy between primeval spectral index (n_s) and cosmic opacity to CMB photons (\tau). Low--l polarization measures, in principle, can remove it. We perform a likelihood analysis to see how cosmic variance possibly affects such a problem. We find that, for a sufficiently low noise level (\sigma_{pix}) and if \tau is not negligibly low, the degeneracy is greatly reduced, while the residual impact of cosmic variance on n_s and \tau determinations is under control. On the contrary, if \sigma_{pix} is too high, cosmic variance effects appear to be magnified. We apply general results to specific experiments and find that, if favorable conditions occur, it is possible that a 2--\sigma detection of a lower limit on \tau is provided by the SPOrt experiment. Furthermore, if the PLANCK experiment will measure polarization with the expected precision, the error on low--l harmonics is adequate to determine \tau, without significant magnification of the cosmic variance. This however indicates that high sensitivity might be more important than high resolution in \tau determinations. We also outline that a determination of \tau is critical to perform detailed analyses on the nature of dark energy and/or on the presence of primeval gravitational waves. ",Cosmic opacity to CMB photons and polarization measurements
"  We generalize nonadiabatic holonomic quantum computation in a resonant $\Lambda$ configuration proposed in [New J. Phys. 14 (2012) 103035] to the case of off-resonant driving lasers. We show that any single-qubit holonomic gate can be realized by separately varying the detuning, amplitude, and phase of the lasers. ",Nonadiabatic holonomic single-qubit gates in off-resonant $\Lambda$   systems
"  The Magellanic Clouds offer a unique variety of star forming regions seen as bright nebulae of ionized gas, related to bright young stellar associations. Nowadays, observations with the high resolving efficiency of the Hubble Space Telescope allow the detection of the faintest infant stars, and a more complete picture of clustered star formation in our dwarf neighbors has emerged. I present results from our studies of the Magellanic Clouds, with emphasis in the young low-mass pre-main sequence populations. Our data include imaging with the Advanced Camera for Surveys of the association LH~95 in the Large Magellanic Cloud, the deepest observations ever taken with HST of this galaxy. I discuss our findings in terms of the Initial Mass Function, which we constructed with an unprecedented completeness down to the sub-solar regime, as the outcome of star formation in the low-metallicity environment of the LMC. ",The sub-solar Initial Mass Function in the Large Magellanic Cloud
"  Linear conductance below $2e^2/h$ shows resonance peaks in highly asymmetric quantum point contacts (QPCs). As the channel length increases, the number of peaks also increases. At the same time, differential conductance exhibits zero bias anomalies (ZBAs) in correspondence with every other peak in the linear conductance. This even odd effect, observable in the longer channels, is consistent with the formation of quasi-localized states within the QPC. In rare cases, triple peaks are observed, indicating the formation of a spin one Kondo effect when the electron filling number is even. Changing the gate voltage tunes this spin triplet to a singlet which exhibits no ZBA. The triple-peak provides the first evidence suggestive of a spin singlet triplet transition in a QPC, and the presence of a ferromagnetic spin interaction between electrons. ",Quasibound States and Evidence for a Spin 1 Kondo Effect in Asymmetric   Quantum Point Contacts
"  We report the discovery of a planetary system orbiting TOI-763 (aka CD-39 7945), a $V=10.2$, high proper motion G-type dwarf star that was photometrically monitored by the TESS space mission in Sector 10. We obtain and model the stellar spectrum and find an object slightly smaller than the Sun, and somewhat older, but with a similar metallicity. Two planet candidates were found in the light curve to be transiting the star. Combining TESS transit photometry with HARPS high-precision radial velocity follow-up measurements confirm the planetary nature of these transit signals. We determine masses, radii, and bulk densities of these two planets. A third planet candidate was discovered serendipitously in the radial velocity data. The inner transiting planet,TOI-763 b, has an orbital period of $P_\mathrm{b}$ = 5.6~days, a mass of $M_\mathrm{b}$ = $9.8\pm0.8$ $M_\oplus$, and a radius of $R_\mathrm{b}$ = $2.37\pm0.10$ $R_\oplus$. The second transiting planet,TOI-763 c, has an orbital period of $P_\mathrm{c}$ = 12.3~days, a mass of $M_\mathrm{c}$ = $9.3\pm1.0$ $M_\oplus$, and a radius of $R_\mathrm{c}$ = $2.87\pm0.11$ $R_\oplus$. We find the outermost planet candidate to orbit the star with a period of $\sim$48~days. If confirmed as a planet it would have a minimum mass of $M_\mathrm{d}$ = $9.5\pm1.6$ $M_\oplus$. We investigated the TESS light curve in order to search for a mono transit by planet~d without success. We discuss the importance and implications of this planetary system in terms of the geometrical arrangements of planets orbiting G-type stars. ",The TOI-763 system: sub-Neptunes orbiting a Sun-like star
"  This paper investigates the symbol error probability~(SEP) of point-to-point massive multiple-input multiple-output (MIMO) systems using equally likely PAM, PSK, and square QAM signallings in the presence of transmitter correlation. The receiver has perfect knowledge of the channel coefficients, while the transmitter only knows first- and second-order channel statistics. With a zero-forcing~(ZF) detector implemented at the receiver side, we design and derive closed-form expressions of the optimal precoders at the transmitter that minimizes the average SEP over channel statistics for various modulation schemes. We then unveil some nice structures on the resulting minimum average SEP expressions, which naturally motivate us to explore the use of two useful mathematical tools to systematically study their asymptotic behaviors. The first tool is the Szeg\""o's theorem on large Hermitian Toeplitz matrices and the second tool is the well-known limit: $\lim_{x\to\infty}(1+1/x)^x=e$. The application of these two tools enables us to attain very simple expressions of the SEP limits as the number of the transmitter antennas goes to infinity. A major advantage of our asymptotic analysis is that the asymptotic SEP converges to the true SEP when the number of antennas is moderately large. As such, the obtained expressions can serve as effective SEP approximations for massive MIMO systems even when the number of antennas is not very large. For the widely used exponential correlation model, we derive closed-form expressions for the SEP limits of both optimally precoded and uniformly precoded systems. Extensive simulations are provided to demonstrate the effectiveness of our asymptotic analysis and compare the performance limit of optimally precoded and uniformly precoded systems. ",Average SEP-Optimal Precoding for Correlated Massive MIMO with ZF   Detection: An Asymptotic Analysis
"  We introduce the domain structure for stationary black hole space-times. Given a set of commuting Killing vector fields of the space-time the domain structure lives on the submanifold where at least one of the Killing vector fields have zero norm. Depending on which Killing vector field has zero norm the submanifold is naturally divided into domains. A domain corresponds either to a set of fixed points of a spatial symmetry or to a Killing horizon, depending on whether the characterizing Killing vector field is space-like or time-like near the domain. The domain structure provides invariants of the space-time, both topological and geometrical. It is defined for any space-time dimension and any number of commuting Killing vector fields. We examine the domain structure for asymptotically flat space-times and find a canonical form for the metric of such space-times. The domain structure generalizes the rod structure introduced for space-times with D-2 commuting Killing vector fields. We analyze in detail the domain structure for Minkowski space, the Schwarzschild-Tangherlini black hole and the Myers-Perry black hole in six and seven dimensions. Finally we consider the possible domain structures for asymptotically flat black holes in six and seven dimensions. ",Domain Structure of Black Hole Space-Times
"  This article studies a numerical relativity approach to the initial value problem in Anti-de Sitter spacetime relevant for dual non-equilibrium evolution of strongly coupled non-Abelian plasma undergoing Bjorken expansion. In order to use initial conditions for the metric obtained in arXiv:0906.4423 we introduce new, ADM formalism-based scheme for numerical integration of Einstein's equations with negative cosmological constant. The key novel element of this approach is the choice of lapse function vanishing at fixed radial position, enabling, if needed, efficient horizon excision. Various physical aspects of the gauge theory thermalization process in this setup have been outlined in our companion article arXiv:1103.3452. In this work we focus on the gravitational side of the problem and present full technical details of our setup. We discuss in particular the ADM formalism, the explicit form of initial states, the boundary conditions for the metric on the inner and outer edges of the simulation domain, the relation between boundary and bulk notions of time, the procedure to extract the gauge theory energy-momentum tensor and non-equilibrium apparent horizon entropy, as well as the choice of point for freezing the lapse. Finally, we comment on various features of the initial profiles we consider. ",A numerical relativity approach to the initial value problem in   asymptotically Anti-de Sitter spacetime for plasma thermalization - an ADM   formulation
"  Heterodyne holography is a variant of phase shifting holography in which reference and signal arms are controlled by acousto optic modulators. In this review paper, we will briefy describe the method and its properties, and we will illustrate its advantages in experimental applications. ",Heterodyne Holography with full control of both signal and reference   arms
"  The van der Waals heterostructures of two-dimensional (2D) atomic crystals constitute a new paradigm in nanoscience. Hybrid devices of graphene with insulating 2D hexagonal boron nitride (h-BN) have emerged as promising nanoelectronic architectures through demonstrations of ultrahigh electron motilities and charge-based tunnel transistors. Here, we expand the functional horizon of such 2D materials demonstrating the quantum tunneling of spin-polarized electrons through atomic planes of CVD grown h-BN. We report excellent tunneling behavior of h-BN layers together with tunnel spin injection and transport in graphene using ferromagnet/h-BN contacts. Employing h-BN tunnel contacts, we observe enhancements in both spin signal amplitude and lifetime by an order of magnitude. We demonstrate spin transport and precession over micrometer-scale distances with spin lifetime up to 0.46 nanosecond. Our results and complementary magnetoresistance calculations illustrate that CVD h-BN tunnel barrier provides a reliable, reproducible and alternative approach to address the conductivity mismatch problem for spin injection into graphene. ",Enhanced Tunnel Spin Injection into Graphene using Chemical Vapor   Deposited Hexagonal Boron Nitride
"  Discrete abstractions of continuous and hybrid systems have recently been the topic of great interest from both the control systems and the computer science communities, because they provide a sound mathematical framework for analysing and controlling embedded systems. In this paper we give a further contribution to this research line, by addressing the problem of symbolic control design of nonlinear systems with infinite states specifications, modelled by differential equations. We first derive the symbolic controller solving the control design problem, given in terms of discrete abstractions of the plant and the specification systems. We then present an algorithm which integrates the construction of the discrete abstractions with the design of the symbolic controller. Space and time complexity analysis of the proposed algorithm is performed and a comparison with traditional approaches currently available in the literature for symbolic control design, is discussed. Some examples are included, which show the interest and applicability of our results. ",Integrated symbolic control design for nonlinear systems with infinite   states specifications
"  In this paper, we solve the l2-l1 sparse recovery problem by transforming the objective function of this problem into an unconstrained differentiable function and apply a limited-memory trust-region method. Unlike gradient projection-type methods, which uses only the current gradient, our approach uses gradients from previous iterations to obtain a more accurate Hessian approximation. Numerical experiments show that our proposed approach eliminates spurious solutions more effectively while improving the computational time to converge. ",Trust-Region Methods for Sparse Relaxation
"  In bilateral accounting of resource consumption both the consumer and provider independently measure the amount of resources consumed by the consumer. The problem here is that potential disparities between the provider's and consumer's accountings, might lead to conflicts between the two parties that need to be resolved. We argue that with the proper mechanisms available, most of these conflicts can be solved online, as opposite to in court resolution; the design of such mechanisms is still a research topic; to help cover the gap, in this paper we propose a peer--to--peer protocol for online dispute resolution over storage consumption. The protocol is peer--to--peer and takes into consideration the possible causes (e.g, transmission delays, unsynchronized metric collectors, etc.) of the disparity between the provider's and consumer's accountings to make, if possible, the two results converge. ",A Peer to Peer Protocol for Online Dispute Resolution over Storage   Consumption
"  A lingering mystery in core-collapse supernova theory is how collective neutrino oscillations affect the dynamics. All previously identified flavor instabilities, some of which might make the effects considerable, are essentially collisionless phenomena. Here it is shown that collisional instabilities exist as well. They are associated with asymmetries between the neutrino and antineutrino interaction rates, are possibly prevalent deep inside supernovae, and pose an unusual instance of decoherent interactions with a thermal environment causing the sustained growth of quantum coherence. ",Collisional flavor instabilities of supernova neutrinos
"  Let $\mathrm{G}$ be a split reductive group, $K$ be a non-Archimedean local field, and $O$ be its ring of integers. Satake isomorphism identifies the algebra of compactly supported invariants $\mathbb{C}_c[\mathrm{G}(K)/\mathrm{G}(O))]^{\mathrm{G}(O)}$ with a complexification of the algebra of characters of finite-dimensional representations $\mathcal{O}(\mathrm{G}^L(\mathbb{C}))^{\mathrm{G}^L(\mathbb{C})}$ of the Langlands dual group. In this note we report on the results of the study of analogues of such an isomorphism for finite groups. In our setup we replaced Gelfand pair $\mathrm{G}(O)\subset \mathrm{G}(K)$ by a finite pair $H\subset G$. It is convenient to rewrite the character side of the isomorphism as $\mathcal{O}(\mathrm{G}^L(\mathbb{C}))^{\mathrm{G}^L(\mathbb{C})}=\mathcal{O}((\mathrm{G}^L(\mathbb{C})\times \mathrm{G}^L(\mathbb{C}))/\mathrm{G}^L(\mathbb{C}))^{\mathrm{G}^L(\mathbb{C})}$. We replace diagonal Gelfand pair $\mathrm{G}^L(\mathbb{C})\subset \mathrm{G}^L(\mathbb{C})\times \mathrm{G}^L(\mathbb{C})$ by a dual finite pair $\check{H}\subset \check{G}$ and use Satake isomorphism as a defining property of the duality. In this text we make a preliminary study of such duality and compute a number of nontrivial examples of dual pairs $(H,G)$ and $(\check{H}, \check{G})$. We discuss a possible relation of our constructions to String Topology. ",Duality for finite Gelfand pairs
"  Low-density networks of molecules or colloids are formed at low temperatures when the interparticle interactions are valence limited. Prototypical examples are networks of patchy particles, where the limited valence results from highly directional pairwise interactions. We combine extensive Langevin simulations and Wertheim's theory of association to study these networks. We find a scale-free (relaxation) dynamics within the liquid-gas coexistence region, which differs from that usually observed for isotropic particles. While for isotropic particles the relaxation dynamics is driven by surface tension (coarsening), when the valence is limited, the slow relaxation proceeds through the formation of an intermediate non-equilibrium gel via a geometrical percolation transition in the Random Percolation universality class. ",Dynamics of a network fluid within the liquid-gas coexistence region
"  The periodically varying Lorentz force of the periodic solar magnetic field generated by the solar dynamo can induce two kinds of motions: torsional oscillations and periodic variations in the meridional circulation. Observational evidence now exists for both these kinds of motions. We discuss our ongoing effort in theoretically studying the variations of the meridional circulation. Then we present our theoretical model of torsional oscillations, which addresses the question why these oscillations start before sunspot cycles at latitudes higher than where sunspots are seen. ",Back-reactions of dynamo-generated magnetic fields: Torsional   oscillations and variations in meridional circulation
"  In our derivation of the second law of thermodynamics from the relation of adiabatic accessibility of equilibrium states we stressed the importance of being able to scale a system's size without changing its intrinsic properties. This leaves open the question of defining the entropy of macroscopic, but unscalable systems, such as gravitating bodies or systems where surface effects are important. We show here how the problem can be overcome, in principle, with the aid of an `entropy meter'. An entropy meter can also be used to determine entropy functions for non-equilibrium states and mesoscopic systems. ",Entropy Meters and the Entropy of Non-extensive Systems
"  Chiral phase transition is investigated in an $SU(3)_L \times SU(3)_R$ symmetric vector meson extended linear sigma model with additional constituent quarks and Polyakov loops (extended Polyakov quark meson model). The parameterization of the Lagrangian is done at zero temperature in a hybrid approach, where the mesons are treated at tree-level, while the constituent quarks at 1-loop level. The temperature and baryochemical potential dependence of the two assumed scalar condensates are calculated from the hybrid 1-loop level equations of states. The order of the phase transition along the $T=0$ and $\mu_B=0$ axes are determined for various parameterization scenarios. We find that in order to have a first order phase transition at $T=0$ as a function of $\mu_B$ a light isoscalar particle is needed. ",Chiral phase transition scenarios from the vector meson extended   Polyakov quark meson model
"  We present an analysis of high-resolution ALMA interferometry of CO(4-3) line emission and dust continuum in the ""Ruby"" (PLCK_G244.8+54.9), a bright, gravitationally lensed galaxy at z = 3.0 discovered with the Planck all-sky survey. The Ruby is the brightest of Planck's Dusty GEMS, a sample of 11 of the brightest gravitationally lensed high-redshift galaxies on the extragalactic sub-mm sky. We resolve the high-surface-brightness continuum and CO line emission of the Ruby in several extended clumps along a partial, nearly circular Einstein ring with 1.4"" diameter around a massive galaxy at z = 1.5. Local star-formation intensities are up to 2000 M$_{\odot}$ yr$^{-1}$ kpc$^{-2}$, amongst the highest observed at high redshift, and clearly in the range of maximal starbursts. Gas-mass surface densities are a few $\times$ 10$^4$ M$_{\odot}$ pc$^{-2}$. The Ruby lies at, and in part even above, the starburst sequence in the Schmidt-Kennicutt diagram, and at the limit expected for star formation that is self-regulated through the kinetic energy injection from radiation pressure, stellar winds, and supernovae. We show that these processes can also inject sufficient kinetic energy and momentum into the gas to explain the turbulent line widths, which are consistent with marginally gravitationally bound molecular clouds embedded in a critically Toomre-stable disk. The star-formation efficiency is in the range 1-10% per free-fall time, consistent with the notion that the pressure balance that sets the local star-formation law in the Milky Way may well be universal out to the highest star-formation intensities. AGN feedback is not necessary to regulate the star formation in the Ruby, in agreement with the absence of a bright AGN component in the infrared and radio regimes. ",Planck's dusty GEMS. IV. Star formation and feedback in a maximum   starburst at z=3 seen at 60-pc resolution
"  Numerical solutions to wave-type PDEs utilizing method-of-lines require the ODE solver's stability domain to include a large stretch of the imaginary axis surrounding the origin. We show here that extrapolation based solvers of Gragg-Bulirsch-Stoer (GBS) type can meet this requirement. Extrapolation methods utilize several independent time stepping sequences, making them highly suited for parallel execution. Traditional extrapolation schemes use all time stepping sequences to maximize the method's order of accuracy. The present method instead maintains a desired order of accuracy while employing additional time stepping sequences to shape the resulting stability domain. We optimize the extrapolation coefficients to maximize the stability domain's imaginary axis coverage. This yields a family of explicit schemes that approaches maximal time step size for wave propagation problems. On a computer with several cores we achieve both high order and fast time to solution compared with traditional ODE integrators. ",A parallel-in-time approach for wave-type PDEs
"  Using an effective potential method, a replica formulism is set up for describing supercooled liquids near their glass transition. The resulting potential is equivalent to that for an Ising spin glass in a magnetic field. Results taken from the droplet picture of spin glasses are then used to provide an explanation of the main features of fragile glasses. ",The Thermodynamic Glass Transition in Finite Dimensions
"  Any discrete action of a group on a locally compact Hadamard space extends to a topological action on the virtual boundary. Croke and Kleiner introduced a class of so-called admissible actions and associated geometric data which determine the topological conjugacy class of the boundary action. They also posed the question whether their results hold for a wider class of actions. We show that, for the natural generalization, their question has to be answered in the negative: There is an admissible action of higher rank on a pair of Hadamard spaces with equivalent geometric data and an equivariant quasi-isometry which does not extend continuously to the virtual boundaries. ",Virtual boundaries of Hadamard spaces with admissible actions of higher   rank
"  In this paper we obtain a general expression for the n-defect matrix for the sinh-Gordon model. This in turn generate the general B\""acklund transformations (BT) for a system with $n$ type-I defects, through a gauge transformation. ",The sinh-Gordon defect matrix generalized for n defects
"  In this paper we construct the Wilson short distance operator product expansion for the gluon, quark and ghost propagators in QCD, including operators of dimension two and three, namely, A^2, m^2, m A^2, \ovl{\psi} \psi and m^3. We compute analytically the coefficient functions of these operators at three loops for all three propagators in the general covariant gauge. Our results, taken in the Landau gauge, should help to improve the accuracy of extracting the vacuum expectation values of these operators from lattice simulation of the QCD propagators. ",Wilson Expansion of QCD Propagators at Three Loops: Operators of   Dimension Two and Three
"  We derive the relativistic factor for splitting of the $g$-factors of a fermion and its anti-fermion partner, which is important for placing constraints on dimension-5, $CPT$-odd and Lorentz-invariance-violating interactions from experiments performed in a cyclotron. From existing data, we extract limits (1$\sigma$) on the coupling strengths of the temporal component, $f^0$, of a background field (including the field amplitude), which is responsible for such $g$-factor splitting, with an electron, proton, and muon: $|f^0_e|< 2.3 \times 10^{-12} ~\mu_{\textrm{B}}$, $|f^0_p|< 4 \times 10^{-9} ~\mu_{\textrm{B}}$, and $|f^0_\mu|< 8 \times 10^{-11} ~\mu_{\textrm{B}}$, respectively, in the laboratory frame. From existing data, we also extract limits on the coupling strengths of the spatial components, $d^{\perp}$, of related dimension-5 interactions of a background field with an electron, proton, neutron, and muon: $| {d}_e^{\perp} | \lesssim 10^{-9} ~\mu_{\textrm{B}}$, $| {d}_p^{\perp} | \lesssim 10^{-9} ~\mu_{\textrm{B}}$, $| {d}_n^{\perp} | \lesssim 10^{-10} ~\mu_{\textrm{B}}$, and $| {d}_\mu^{\perp} | \lesssim 10^{-9} ~\mu_{\textrm{B}}$, respectively, in the laboratory frame. ",Tests of CPT and Lorentz symmetry from muon anomalous magnetic dipole   moment
"  We investigate avalanches associated with plastic rearrangements and the nature of structural change in the prototypical strong glass, silica, computationally. Although qualitative aspects of yielding in silica are similar to other glasses, we find that the statistics of avalanches exhibits non-trivial behaviour. Investigating the statistics of avalanches and clusters in detail, we propose and verify a new relation between exponents characterizing the size distribution of avalanches and clusters. Across the yielding transition, anomalous structural change and densification, associated with a suppression of tetrahedral order, is observed to accompany strain localisation. ",Avalanches and Structural Change in Cyclically Sheared Silica Glass
"  Artificial spin ices (ASI) have been widely investigated as magnetic metamaterials with exotic properties governed by their geometries. In parallel, interest in X-ray photon orbital angular momentum (OAM) has been rapidly growing. Here we show that a square ASI with a programmed topological defect, a double edge dislocation, imparts OAM to scattered X-rays. Unlike single dislocations, a double dislocation does not introduce magnetic frustration, and the ASI equilibrates to its antiferromagnetic (AF) ground state. The topological charge of the defect differs with respect to the structural and magnetic order; thus, X-ray diffraction from the ASI produces photons with even and odd OAM quantum numbers at the structural and AF Bragg conditions, respectively. The magnetic transitions of the ASI allow the AF OAM beams to be switched on and off by modest variations of temperature and applied magnetic field. These results demonstrate ASIs can serve as metasurfaces for reconfigurable X-ray optics that could enable selective probes of electronic and magnetic properties. ",Switchable X-ray Orbital Angular Momentum from an Artificial Spin Ice
"  We prove boundedness and polynomial decay statements for solutions to the spin $\pm1$ Teukolsky-type equation projected to the $\ell=1$ spherical harmonic on Reissner-Nordstr\""om spacetime. The equation is verified by a gauge-invariant quantity which we identify and which involves the electromagnetic and curvature tensor. This gives a first description in physical space of gauge-invariant quantities transporting the electromagnetic radiation in perturbations of a charged black hole.   The proof is based on the use of derived quantities, introduced in previous works on linear stability of Schwarzschild by Dafermos-Holzegel-Rodnianski. The derived quantity verifies a Fackerell-Ipser-type equation, with right hand side vanishing at the $\ell=1$ spherical harmonics. The boundedness and decay for the projection to the $\ell\geq 2$ spherical harmonics are implied by the boundedness and decay for the Teukolsky system of spin $\pm2$ obtained in our previous work.   The spin $\pm1$ Teukolsky-type equation is verified by the curvature and electromagnetic components of a gravitational and electromagnetic perturbation of the Reissner-Nordstr\""om spacetime. Consequently, together with the estimates obtained in our previous work, these bounds allow to prove the full linear stability of Reissner-Nordstr\""om metric for small charge to coupled gravitational and electromagnetic perturbations. ","Boundedness and decay for the Teukolsky equation of spin $\pm1$ on   Reissner-Nordstr\""om spacetime: the $\ell=1$ spherical mode"
"  Deep neural networks are vulnerable to adversarial attacks. Recent studies about adversarial robustness focus on the loss landscape in the parameter space since it is related to optimization and generalization performance. These studies conclude that the difficulty of adversarial training is caused by the non-smoothness of the loss function: i.e., its gradient is not Lipschitz continuous. However, this analysis ignores the dependence of adversarial attacks on model parameters. Since adversarial attacks are optimized for models, they should depend on the parameters. Considering this dependence, we analyze the smoothness of the loss function of adversarial training using the optimal attacks for the model parameter in more detail. We reveal that the constraint of adversarial attacks is one cause of the non-smoothness and that the smoothness depends on the types of the constraints. Specifically, the $L_\infty$ constraint can cause non-smoothness more than the $L_2$ constraint. Moreover, our analysis implies that if we flatten the loss function with respect to input data, the Lipschitz constant of the gradient of adversarial loss tends to increase. To address the non-smoothness, we show that EntropySGD smoothens the non-smooth loss and improves the performance of adversarial training. ",Smoothness Analysis of Adversarial Training
"  Applications of the Dirac equation with an anomalous magnetic moment are considered for description of characteristics of electrons, muons and quarks. The Dirac equation with four-dimensional scalar and vector potentials is reduced to a form suitable for a numerical integration. When a certain type of the potential is chosen, solutions can approximate quark states inside hadrons. In view of complicated behaviour of quarks in a confinement domain some generalizations are considered such as the Dirac-Gursey-Lee equation, the Dirac equation in a five-dimensional Minkowski space, the Dirac equation in a quantum phase space. Extended symmetries for the Dirac equation and its generalizations are considered, which can be used for investigation of properties of solutions of these equations and subsequent applications in particle physics. ",Some examples of uses of Dirac equation and its generalizations in   particle physics
"  We report the studies of high-quality HgTe/(Cd,Hg)Te quantum wells (QWs) with a width close to the critical one $d_c$, corresponding to the topological phase transition and graphene like band structure in view of their applications for Quantum Hall Effect (QHE) resistance standards. We show that in the case of inverted band ordering, the coexistence of conducting topological helical edge states together with QHE chiral states degrades the precision of the resistance quantization. By experimental and theoretical studies we demonstrate how one may reach very favorable conditions for the QHE resistance standards: low magnetic fields allowing to use permanent magnets ( B $\leq$ 1.4T) and simultaneously realtively high teperatures (liquid helium, T $\geq$ 1.3K). This way we show that HgTe QW based QHE resistance standards may replace their graphene and GaAs counterparts and pave the way towards large scale fabrication and applications of QHE metrology devices. ",Perspectives of HgTe Topological Insulators for Quantum Hall Metrology
"  The electrochemical oxidation of carbon monoxide adsorbed (COad) on platinum-on-carbon electrodes was studied via a methodology in which pre-adsorbed CO was partially oxidized by applying potentiostatic pulses for certain durations. The residual COad was analyzed using stripping voltammetry that involved the deconvolution of COad oxidation peaks of voltammograms to quantify the weakly and strongly bound species of COad. The data obtained for various potentials and temperatures were fit to a model based on a nucleation and growth mechanism. The resulting fit produced potential- and temperature-dependent rate parameters that provided insight into the oxidation mechanism of the two COad species. Irrespective of the applied potential or temperature, the concentration of weakly bound COad species decreased exponentially with time. In contrast, the strongly bound COad species showed a gradual transition of mechanisms, from progressive nucleation at relatively low potentials to exponential decay at high potentials. ",Quantifying Oxidation Rates of Carbon Monoxide on a Pt/C Electrode
"  We investigate the electronic structure of 4d transition metal oxides, CaRuO3 and SrRuO3. The analysis of the photoemission spectra reveals significantly weak electron correlation strength (U/W ~ 0.2) as expected in 4d systems and resolves the long standing issue that arose due to the prediction of large U/W similar to 3d-systems. It is shown that the bulk spectra, thermodynamic parameters and optical properties in these systems can consistently be described using first principle approaches. The observation of different surface and bulk electronic structures in these weakly correlated 4d systems is unusual. ","Evidence against strong correlation in 4d transition metal oxides,   CaRuO3 and SrRuO3"
"  Information retrieval (IR) for precision medicine (PM) often involves looking for multiple pieces of evidence that characterize a patient case. This typically includes at least the name of a condition and a genetic variation that applies to the patient. Other factors such as demographic attributes, comorbidities, and social determinants may also be pertinent. As such, the retrieval problem is often formulated as ad hoc search but with multiple facets (e.g., disease, mutation) that may need to be incorporated. In this paper, we present a document reranking approach that combines neural query-document matching and text summarization toward such retrieval scenarios. Our architecture builds on the basic BERT model with three specific components for reranking: (a). document-query matching (b). keyword extraction and (c). facet-conditioned abstractive summarization. The outcomes of (b) and (c) are used to essentially transform a candidate document into a concise summary that can be compared with the query at hand to compute a relevance score. Component (a) directly generates a matching score of a candidate document for a query. The full architecture benefits from the complementary potential of document-query matching and the novel document transformation approach based on summarization along PM facets. Evaluations using NIST's TREC-PM track datasets (2017--2019) show that our model achieves state-of-the-art performance. To foster reproducibility, our code is made available here: https://github.com/bionlproc/text-summ-for-doc-retrieval. ",Literature Retrieval for Precision Medicine with Neural Matching and   Faceted Summarization
"  This article offers a reappraisal of Fung's method for quasilinear viscoelasticity. It is shown that a number of negative features exhibited in other works, commonly attributed to the Fung approach, are merely a consequence of the way it has been applied. The approach outlined herein is shown to yield improved behaviour, and offers a straightforward scheme for solving a wide range of models. Results from the new model are contrasted with those in the literature for the case of uniaxial elongation of a bar: for an imposed stretch of an incompressible bar, and for an imposed load. In the last case, a numerical solution to a Volterra integral equation is required to obtain the results. This is achieved by a high order discretisation scheme. Finally, the stretch of a compressible viscoelastic bar is determined for two distinct materials: Horgan-Murphy and Gent. ",On nonlinear viscoelastic deformations - a reappraisal of Fung's   quasilinear viscoelastic model
"  Statefinder diagnostic is a useful method which can differ one dark energy model from each others. In this letter, we apply this method to a holographic dark energy model from Ricci scalar curvature, called the Ricci dark energy model(RDE). We plot the evolutionary trajectories of this model in the statefinder parameter-planes, and it is found that the parameter of this model plays a significant role from the statefinder viewpoint. In a very special case, the statefinder diagnostic fails to discriminate LCDM and RDE models, thus we apply a new diagnostic called the Om diagnostic proposed recently to this model in this case in Appendix A and it works well. ",Statefinder Diagnosis for Ricci Dark Energy
"  Classical molecular dynamics (MD) simulations will be able to reach sampling in the second timescale within five years, producing petabytes of simulation data at current force field accuracy. Notwithstanding this, MD will still be in the regime of low-throughput, high-latency predictions with average accuracy. We envisage that machine learning (ML) will be able to solve both the accuracy and time-to-prediction problem by learning predictive models using expensive simulation data. The synergies between classical, quantum simulations and ML methods, such as artificial neural networks, have the potential to drastically reshape the way we make predictions in computational structural biology and drug discovery. ",Simulations meet Machine Learning in Structural Biology
"  Identifying highly susceptible individuals in spreading processes is of great significance in controlling outbreaks. In this paper, we explore the susceptibility of people in susceptible-infectious-recovered (SIR) and rumor spreading dynamics. We first study the impact of community structure on people's susceptibility. Despite that the community structure can reduce the infected population given same infection rates, it will not deterministically affect nodes' susceptibility. We find the susceptibility of individuals is sensitive to the choice of spreading dynamics. For SIR spreading, since the susceptibility is highly correlated to nodes' influence, the topological indicator k-shell can better identify highly susceptible individuals, outperforming degree, betweenness centrality and PageRank. In contrast, in rumor spreading model, where nodes' susceptibility and influence have no clear correlation, degree performs the best among considered topological measures. Our finding highlights the significance of both topological features and spreading mechanisms in identifying highly susceptible population. ",Identification of highly susceptible individuals in complex networks
"  In this paper we prove some sharp weighted norm inequalities for the multi(sub)linear maximal function $\Mm$ introduced in \cite{LOPTT} and for multilinear Calder\'on-Zygmund operators. In particular we obtain a sharp mixed ""$A_p-A_{\infty}$"" bound for $\Mm$, some partial results related to a Buckley-type estimate for $\Mm$, and a sufficient condition for the boundedness of $\Mm$ between weighted $L^p$ spaces with different weights taking into account the precise bounds.   Next we get a bound for multilinear Calder\'on-Zygmund operators in terms of dyadic positive multilinear operators in the spirit of the recent work. Then we obtain a multilinear version of the ""$A_2$ conjecture"". Several open problems are posed. ",Sharp weighted bounds for multilinear maximal functions and   Calder\'on-Zygmund operators
"  High penetrations of intermittent renewable energy resources in the power system require large balancing reserves for reliable operations. Aggregated and coordinated behind-the-meter loads can provide these fast reserves, but represent energy-constrained and uncertain reserves (in their energy state and capacity). To optimally dispatch uncertain, energy-constrained reserves, optimization-based techniques allow one to develop an appropriate trade-off between closed-loop performance and robustness of the dispatch. Therefore, this paper investigates the uncertainty associated with energy-constrained aggregations of flexible, behind-the-meter distributed energy resources (DERs). The uncertainty studied herein is associated with estimating the state of charge and the capacity of an aggregation of DERs (i.e., a virtual energy storage system or VESS). To that effect, a risk-based chance-constrained control strategy is developed that optimizes the operational risk of unexpectedly saturating the VESS against deviating generators from their scheduled set-points. The controller coordinates energy-constrained VESSs to minimize unscheduled participation of and overcome ramp-rate limited generators for balancing variability from renewable generation, while taking into account grid conditions. To illustrate the effectiveness of the proposed method, simulation-based analysis is carried out on an augmented IEEE RTS-96 network with uncertain energy resources and temperature-based dynamic line ratings. ",Optimal corrective dispatch of uncertain virtual energy storage systems
  The concept of freeness was introduced by Voiculescu in the context of operator algebras. Later it was observed that it is also relevant for large random matrices. We will show how the combination of various free probability results with a linearization trick allows to address successfully the problem of determining the asymptotic eigenvalue distribution of general selfadjoint polynomials in independent random matrices. ,Free probability and random matrices
"  A novel solid state based charge qubit is presented. The system consists of a one-dimensional wire with a pair of qubits embedded at its center. It is shown that the system supports collective states localized in the left and right sides of the wire and therefore, as a whole, performs as a single qubit. The couplings between the ground and excited states of the two central qubits are inversely proportional making them fully asynchronized and allowing for coherent manipulation and gate operations. Initialization and measurement devices, such as leads and charge detectors, connected to the edges of the wire are modeled by a continuum of energy states. The coupling to the continuum is discussed using the effective non-Hermitian Hamiltonian. At weak continuum coupling, all internal states uniformly acquire small decay widths. This changes dramatically as the coupling strength increases: the width distribution undergoes a sharp restructuring and is no longer uniformly divided among the eigenstates. Two broad resonances localized at the ends of the wire are formed. These superradiant states (analogous to Dicke states in quantum optics), effectively protect the remaining internal states from decaying into the continuum and hence increase the lifetime of the qubit. Environmental noise is introduced by considering random Gaussian fluctuations of electronic energies. The interplay between decoherence and superradiance is studied by solving the stochastic Liouville equation. In addition to increasing the lifetime, the emergence of the superradiant states increases the qubit coherence. ",Environment-Protected Solid State Based Distributed Charge Qubit
"  Vision transformers rely on a patch token based self attention mechanism, in contrast to convolutional networks. We investigate fundamental differences between these two families of models, by designing a block sparsity based adversarial token attack. We probe and analyze transformer as well as convolutional models with token attacks of varying patch sizes. We infer that transformer models are more sensitive to token attacks than convolutional models, with ResNets outperforming Transformer models by up to $\sim30\%$ in robust accuracy for single token attacks. ",Adversarial Token Attacks on Vision Transformers
"  A survey of linearized cosmological fluid equations with a number of different matter components is made. To begin with, the one-component case is reconsidered to illustrate some important mathematical and physical points rarely discussed in the literature. The work of some previous studies of two-component systems are examined and re-analyzed to point out some deficiencies of solutions, and further solutions and physical interpretation are then presented. This leads into a general two-component model with variable velocity dispersion parameters and mass density fractions of each component. The equations, applicable to both hot dark matter (HDM) and cold dark matter (CDM) universes are solved in the long wavelength limit. This region is of interest, because some modes in this range of wavenumbers are Jeans unstable. The mixture Jeans wavenumber of the two-component system is introduced and interpreted, and the solutions are discussed, particularly in comparison to analogous solutions previously derived for plasma modes. This work is applicable to that region in the early Universe ($20 < z < 140$), where large scale structure formation is thought to have occurred. ",Two-Component Cosmological Fluids with Gravitational Instabilities
"  Conversations have an intrinsic one-to-many property, which means that multiple responses can be appropriate for the same dialog context. In task-oriented dialogs, this property leads to different valid dialog policies towards task completion. However, none of the existing task-oriented dialog generation approaches takes this property into account. We propose a Multi-Action Data Augmentation (MADA) framework to utilize the one-to-many property to generate diverse appropriate dialog responses. Specifically, we first use dialog states to summarize the dialog history, and then discover all possible mappings from every dialog state to its different valid system actions. During dialog system training, we enable the current dialog state to map to all valid system actions discovered in the previous process to create additional state-action pairs. By incorporating these additional pairs, the dialog policy learns a balanced action distribution, which further guides the dialog model to generate diverse responses. Experimental results show that the proposed framework consistently improves dialog policy diversity, and results in improved response diversity and appropriateness. Our model obtains state-of-the-art results on MultiWOZ. ",Task-Oriented Dialog Systems that Consider Multiple Appropriate   Responses under the Same Context
"  Traveling fronts describe the transition between two alternative states in a great number of physical and biological systems. Examples include the spread of beneficial mutations, chemical reactions, and the invasions by foreign species. In homogeneous environments, the alternative states are separated by a smooth front moving at a constant velocity. This simple picture can break down in structured environments such as tissues, patchy landscapes, and microfluidic devices. Habitat fragmentation can pin the front at a particular location or lock invasion velocities into specific values. Locked velocities are not sensitive to moderate changes in dispersal or growth and are determined by the spatial and temporal periodicity of the environment. The synchronization with the environment results in discontinuous fronts that propagate as periodic pulses. We characterize the transition from continuous to locked invasions and show that it is controlled by positive density-dependence in dispersal or growth. We also demonstrate that velocity locking is robust to demographic and environmental fluctuations and examine stochastic dynamics and evolution in locked invasions. ","Pinned, locked, pushed, and pulled traveling waves in structured   environments"
"  Environmental contamination and human exposure to dyes have dramatically increased over the past decades because of their increasing use in such industries as textiles, paper, plastics, tannery and paints. These dyes can cause deterioration in water quality by imparting color to the water and inducing the photosynthetic activity of aquatic organisms by hindering light penetration. Moreover, some of the dyes are considered carcinogenic and mutagenic for human health. Therefore, efficient treatment and removal of dyes from wastewater have attracted considerable attention in recent years. Photocatalysis, due to its mild reaction condition, high degradation, broad applied area and facile manipulation, is a promising method of solving environmental pollution problems. In this paper, we report the synthesis of graphene oxide-tin oxide (GO-SnO2) nanocomposite and the effectiveness of this composite in decolorizing Methylene Blue. Tin oxide was prepared by liquid phase co-precipitation method and graphene oxide-tin oxide (GOSnO2) nanocomposite were prepared by solution mixing method. Tin oxide (SnO2) nanoparticles have been ardently investigated as photocatalyst for water purification and environment decontamination but the photon generated electron and hole pair (EHP) recombination is one of the limiting factors. Graphene oxide-tin oxide (GO-SnO2) nanocomposite is very propitious to overcome this limitation for photocatalytic application. The as-synthesized graphene oxide (GO) and GO-SnO2 nanocomposite were characterized by X-ray Diffraction (XRD), Scanning Electron Microscopy (SEM), Energy Dispersive X-ray spectroscopy (EDX). The GO-SnO2 nanocomposite showed better photocatalytic degradation efficiency for Methylene Blue compared to SnO2 and Graphene oxide.   Keywords: Graphene Oxide(GO),Methylene Blue, Nanocomposite, Photocatalyst, Photodegradation, Tin Oxide(SnO2). ",Degradation of Methylene Blue using Graphene Oxide-Tin Oxide   Nanocomposite as Photocatalyst
"  Wireless cellular networks feature two emerging technological trends. The first is the direct Device-to-Device (D2D) communications, which enables direct links between the wireless devices that reutilize the cellular spectrum and radio interface. The second is that of Machine-Type Communications (MTC), where the objective is to attach a large number of low-rate low-power devices, termed Machine-Type Devices (MTDs) to the cellular network. MTDs pose new challenges to the cellular network, one if which is that the low transmission power can lead to outage problems for the cell-edge devices. Another issue imminent to MTC is the \emph{massive access} that can lead to overload of the radio interface. In this paper we explore the opportunity opened by D2D links for supporting MTDs, since it can be desirable to carry the MTC traffic not through direct links to a Base Station, but through a nearby relay. MTC is modeled as a fixed-rate traffic with an outage requirement. We propose two network-assisted D2D schemes that enable the cooperation between MTDs and standard cellular devices, thereby meeting the MTC outage requirements while maximizing the rate of the broadband services for the other devices. The proposed schemes apply the principles Opportunistic Interference Cancellation and the Cognitive Radio's underlaying. We show through analysis and numerical results the gains of the proposed schemes. ",Low-Rate Machine-Type Communication via Wireless Device-to-Device (D2D)   Links
"  Recent theoretical models suggest that the early phase of galaxy formation could involve an epoch when galaxies are gas-rich but inefficient at forming stars: a ""dark galaxy"" phase. Here, we report the results of our MUSE (Multi Unit Spectroscopic Explorer) survey for dark galaxies fluorescently illuminated by quasars at $z>3$. Compared to previous studies which are based on deep narrow-band (NB) imaging, our integral field survey provides a nearly uniform sensitivity coverage over a large volume in redshift space around the quasars as well as full spectral information at each location. Thanks to these unique features, we are able to build control samples at large redshift distances from the quasars using the same data taken under the same conditions. By comparing the rest-frame equivalent width (EW$_{0}$) distributions of the Ly$\alpha$ sources detected in proximity to the quasars and in control samples, we detect a clear correlation between the locations of high EW$_{0}$ objects and the quasars. This correlation is not seen in other properties such as Ly$\alpha$ luminosities or volume overdensities, suggesting the possible fluorescent nature of at least some of these objects. Among these, we find 6 sources without continuum counterparts and EW$_{0}$ limits larger than $240\,\mathrm{\AA}$ that are the best candidates for dark galaxies in our survey at $z>3.5$. The volume densities and properties, including inferred gas masses and star formation efficiencies, of these dark galaxy candidates are similar to previously detected candidates at $z\approx2.4$ in NB surveys. Moreover, if the most distant of these are fluorescently illuminated by the quasar, our results also provide a lower limit of $t=60$ Myr on the quasar lifetime. ",Dark Galaxy Candidates at Redshift ~3.5 Detected with MUSE
"  With an average density higher than the nuclear density, neutron stars (NS) provide a unique test-ground for nuclear physics, quantum chromodynamics (QCD), and nuclear superfluidity. Determination of the fundamental interactions that govern matter under such extreme conditions is one of the major unsolved problems of modern physics, and -- since it is impossible to replicate these conditions on Earth -- a major scientific motivation for SKA. The most stringent observational constraints come from measurements of NS bulk properties: each model for the microscopic behaviour of matter predicts a specific density-pressure relation (its `Equation of state', EOS). This generates a unique mass-radius relation which predicts a characteristic radius for a large range of masses and a maximum mass above which NS collapse to black holes. It also uniquely predicts other bulk quantities, like maximum spin frequency and moment of inertia. The SKA, in Phase 1 and particularly in Phase 2 will, thanks to the exquisite timing precision enabled by its raw sensitivity, and surveys that dramatically increase the number of sources: 1) Provide many more precise NS mass measurements (high mass NS measurements are particularly important for ruling out EOS models); 2) Allow the measurement of the NS moment of inertia in highly relativistic binaries such as the Double Pulsar; 3) Greatly increase the number of fast-spinning NS, with the potential discovery of spin frequencies above those allowed by some EOS models; 4) Improve our knowledge of new classes of binary pulsars such as black widows and redbacks (which may be massive as a class) through sensitive broad-band radio observations; and 5) Improve our understanding of dense matter superfluidity and the state of matter in the interior through the study of rotational glitches, provided that an ad-hoc campaign is developed. ",Probing the neutron star interior and the Equation of State of cold   dense matter with the SKA
"  Automatic facial emotion recognition is a challenging task that has gained significant scientific interest over the past few years, but the problem of emotion recognition for a group of people has been less extensively studied. However, it is slowly gaining popularity due to the massive amount of data available on social networking sites containing images of groups of people participating in various social events. Group emotion recognition is a challenging problem due to obstructions like head and body pose variations, occlusions, variable lighting conditions, variance of actors, varied indoor and outdoor settings and image quality. The objective of this task is to classify a group's perceived emotion as Positive, Neutral or Negative. In this report, we describe our solution which is a hybrid machine learning system that incorporates deep neural networks and Bayesian classifiers. Deep Convolutional Neural Networks (CNNs) work from bottom to top, analysing facial expressions expressed by individual faces extracted from the image. The Bayesian network works from top to bottom, inferring the global emotion for the image, by integrating the visual features of the contents of the image obtained through a scene descriptor. In the final pipeline, the group emotion category predicted by an ensemble of CNNs in the bottom-up module is passed as input to the Bayesian Network in the top-down module and an overall prediction for the image is obtained. Experimental results show that the stated system achieves 65.27% accuracy on the validation set which is in line with state-of-the-art results. As an outcome of this project, a Progressive Web Application and an accompanying Android app with a simple and intuitive user interface are presented, allowing users to test out the system with their own pictures. ",Group Emotion Recognition Using Machine Learning
"  We investigate the properties of the spectral function A(omega,U) of correlated electrons within the Hubbard model and dynamical mean-field theory. Curves of A(omega,U) vs. omega for different values of the interaction U are found to intersect near the band-edges of the non-interacting system. For a wide range of U the crossing points are located within a sharply confined region. The precise location of these 'isosbestic points' depends on details of the non-interacting band structure. Isosbestic points of dynamic quantities therefore provide valuable insights into microscopic energy scales of correlated systems. ",Isosbestic points in the spectral function of correlated electrons
"  We study the flow of a spinor (F=1) Bose-Einstein condensate in the presence of an obstacle. We consider the cases of ferromagnetic and polar spin-dependent interactions and find that the system demonstrates two speeds of sound that are identified analytically. Numerical simulations reveal the nucleation of macroscopic nonlinear structures, such as dark solitons and vortex-antivortex pairs, as well as vortex rings in one- and higher-dimensional settings respectively, when a localized defect (e.g., a blue-detuned laser beam) is dragged through the spinor condensate at a speed larger than the second critical speed. ",Spinor Bose-Einstein condensate flow past an obstacle
"  We investigate the thermal cosmology and terrestrial and astrophysical phenomenology of a sub-GeV hadrophilic dark sector. The specific construction explored in this work features a Dirac fermion dark matter candidate interacting with a light scalar mediator that dominantly couples to the up-quark. The correct freeze-out relic abundance may be achieved via dark matter annihilation directly to hadrons or through secluded annihilation to scalar mediators. A rich and distinctive phenomenology is present in this scenario, with probes arising from precision meson decays, proton beam dump experiments, colliders, direct detection experiments, supernovae, and nucleosynthesis. In the future, experiments such as NA62, REDTOP, SHiP, SBND, and NEWS-G will be able to explore a significant portion of the cosmologically motivated parameter space. ",Probing Light Dark Matter with a Hadrophilic Scalar Mediator
"  The status of SUSY searches at LEP2 up to centre-of-mass energy of 202 GeV is presented. Search strategies for sleptons, squarks, charginos and neutralinos are discussed in the framework of Minimal Supersymmetric Standard Model with R-parity conservation. With no indication for the production of these particles new limits are set on their masses. ",MSSM SUSY Searches at LEP2
"  We study the robustness of flow networks against cascading failures under a partial load redistribution model. In particular, we consider a flow network of $N$ lines with initial loads $L_1, \ldots, L_N$ and free-spaces (i.e., redundant space) $S_1, \ldots, S_N$ that are independent and identically distributed with joint distribution $P_{LS}(x,y)=\mathbb{P}(L \leq x, S \leq y)$. The capacity $C_i$ is the maximum load allowed on line $i$, and is given by $C_i=L_i + S_i$. When a line fails due to overloading, it is removed from the system and $(1-\varepsilon)$-fraction of the load it was carrying (at the moment of failing) gets redistributed equally among all remaining lines in the system; hence we refer to this as the {\it partial} load redistribution model. The rest (i.e., $\varepsilon$-fraction) of the load is assumed to be lost or absorbed, e.g., due to advanced circuitry disconnecting overloaded power lines or an inter-connected network/material absorbing a fraction of the flow from overloaded lines. We analyze the robustness of this flow network against random attacks that remove a $p$-fraction of the lines. Our contributions include (i) deriving the final fraction of alive lines $n_{\infty}(p,\varepsilon)$ for all $p, \varepsilon \in (0,1)$ and confirming the results via extensive simulations; (ii) showing that partial redistribution might lead to (depending on the parameter $0<\varepsilon \leq 1$) the order of transition at the critical attack size $p^{*}$ changing from first to second-order; and (iii) proving analytically that flow networks achieve maximum robustness (quantified by the area $\int_{0}^{1} n_{\infty}(p,\varepsilon) \mathrm{d}p$) when all lines have the same free-space regardless of their initial load. The optimality of equal free-space allocation is also confirmed on real-world data from the UK National Power Grid. ",Robustness of flow networks against cascading failures under partial   load redistribution
"  A two-phase model and its application to wavefields numerical simulation are discussed in the context of modeling of compressible fluid flows in elastic porous media. The derivation of the model is based on a theory of thermodynamically compatible systems and on a model of nonlinear elastoplasticity combined with a two-phase compressible fluid flow model. The governing equations of the model include phase mass conservation laws, a total momentum conservation law, an equation for the relative velocities of the phases, an equation for mixture distortion, and a balance equation for porosity. They form a hyperbolic system of conservation equations that satisfy the fundamental laws of thermodynamics. Two types of phase interaction are introduced in the model: phase pressure relaxation to a common value and interfacial friction. Inelastic deformations also can be accounted for by source terms in the equation for distortion. The thus formulated model can be used for studying general compressible fluid flows in a deformable elastoplastic porous medium, and for modeling wave propagation in a saturated porous medium. Governing equations for small-amplitude wave propagation in a uniform porous medium saturated with a single fluid are derived. They form a first-order hyperbolic PDE system written in terms of stress and velocities and, like in Biot's model, predict three types of waves existing in real fluid-saturated porous media: fast and slow longitudinal waves and shear waves. For the numerical solution of these equations, an efficient numerical method based on a staggered-grid finite difference scheme is used. The results of solving some numerical test problems are presented and discussed ",Modeling wavefields in saturated elastic porous media based on   thermodynamically compatible system theory for multiphase mixtures
"  A finite element program is presented to simulate the process of packing and coiling elastic wires in two- and three-dimensional confining cavities. The wire is represented by third order beam elements and embedded into a corotational formulation to capture the geometric nonlinearity resulting from large rotations and deformations. The hyperbolic equations of motion are integrated in time using two different integration methods from the Newmark family: an implicit iterative Newton-Raphson line search solver, and an explicit predictor-corrector scheme, both with adaptive time stepping. These two approaches reveal fundamentally different suitability for the problem of strongly self-interacting bodies found in densely packed cavities. Generalizing the spherical confinement symmetry investigated in recent studies, the packing of a wire in hard ellipsoidal cavities is simulated in the frictionless elastic limit. Evidence is given that packings in oblate spheroids and scalene ellipsoids are energetically preferred to spheres. ",Finite Element Simulation of Dense Wire Packings
"  In energy constrained wireless sensor networks, it is significant to make full use of the limited energy and maximize the network lifetime even when facing some unexpected situation. In this paper, all sensor nodes are grouped into clusters, and for each cluster, it has a mobile cluster head to manage the whole cluster. We consider an emergent situation that one of the mobile cluster heads is broken down, and hence the whole cluster is consequently out of work. An efficient approach is proposed for recovering the failure cluster by selecting multiple static sensor nodes as the cluster heads to collect packets and transmit them to the sink node. Improved simulated annealing algorithm is utilized to achieve the uniform deployment of the cluster heads. The new cluster heads are dynamically changed in order to keep balanced energy consumption. Among the new cluster heads, packets are transmitted through multi-hop forwarding path which is cost-lowest path found by Dijkstra's algorithm. A balanced energy consumption model is provided to help find the cost-lowest path and prolong the lifetime of the network. The forwarding path is updated dynamically according to the cost of the path and residual energy of the node in that path. The experimental results show that the failure cluster is recovered and the lifetime of the cluster is prolonged. ",A Failure Self-recovery Strategy with Balanced Energy Consumption for   Wireless Ad Hoc Networks
"  We study the Yamabe flow on compact Riemannian manifolds of dimensions greater than two with minimal boundary. Convergence to a metric with constant scalar curvature and minimal boundary is established in dimensions up to seven, and in any dimensions if the manifold is spin. ",Convergence of the Yamabe flow on manifolds with minimal boundary
"  We performed deep optical observations of the area of the new supernova remnant G 69.4+1.2 in the emission lines of [O III], Halpha+[N II] and [S II]. The low ionization images reveal diffuse and filamentary emission in the central and south, south-west areas of our field. Estimates of the [S II]/Halpha ratio suggest that the detected emission in these areas originates from shock heated gas, while the strong extended source in the north must be an HII region. The medium ionization image of [O III] shows a single filament close to the field center. Emission from [O III] is not detected elsewhere in the field but only in the north from LBN 069.96+01.35. Deep long-slit spectra taken at the position of the [O III] filament suggest shock velocities ~120 km/s, while in other areas velocities around 50 km/s are expected. The sulfur lines ratio indicates electron densities less than 120 cm^{-3}. The absolute Halpha flux is ~5 x 10^{-17} erg s^{-1} cm^{-2} arcsec^{-2}. The optical emission is very well correlated with the radio emission, especially in the south west. The soft X-ray emission detected in the ROSAT All-Sky survey shows a satisfactory degree of correlation with the optical data in the south-west suggesting their association. ",Optical observations of the supernova remnant G 69.4+1.2
"  We study nuclear effects of charged current deep inelastic neutrino-iron scattering in the framework of a chi^2 analysis of parton distribution functions (PDFs). We extract a set of iron PDFs which are used to compute x_Bj-dependent and Q^2-dependent nuclear correction factors for iron structure functions which are required in global analyses of free nucleon PDFs. We compare our results with nuclear correction factors from neutrino-nucleus scattering models and correction factors for charged lepton-iron scattering. We find that, except for very high x_Bj, our correction factors differ in both shape and magnitude from the correction factors of the models and charged-lepton scattering. ",Parton distribution function uncertainties & nuclear corrections for the   LHC
"  In this paper, we will show that if two meromorphic mappings $f$ and $g$ of $\mathbb C^m$ into $\mathbb P^n(\mathbb C)$ have the same inverse images for $(2n+2)$ moving hyperplanes $\{a_i\}_{i=1}^{2n+2}$ with multiplicities counted to level $l_0$ then the map $f\times g$ must be algebraically degenerated over the field $\mathcal R\{a_i\}_{i=1}^{2n+2}$, where $l_0=3n^3(n+1)q(q-2)$ with $q=\binom{2n+2}{n+2}$. Our result generalizes the previous result for fixed hyperplanes case of Fujimoto and also improves his result by giving an explicit estimate for the number $l_0$. ",Two meromorphic mappings having the same inverse images of moving   hyperplanes
"  The dynamics of samples in the continuous-imaginary-time quantum world-line Monte Carlo simulations with extended ensembles are investigated. In the case of a conventional flat ensemble on the one-dimensional quantum S=1 bi-quadratic model, the asymmetric behavior of Monte Carlo samples appears in the diffusion process in the space of the number of vertices. We prove that a local diffusivity is asymptotically proportional to the number of vertices, and we demonstrate the asymmetric behavior in the flat ensemble case. On the basis of the asymptotic form, we propose the weight of an optimal ensemble as $1/\sqrt{n}$, where $n$ denotes the number of vertices in a sample. It is shown that the asymmetric behavior completely vanishes in the case of the proposed ensemble on the one-dimensional quantum S=1 bi-quadratic model. ",Diffusion in the Continuous-Imaginary-Time Quantum World-Line Monte   Carlo Simulations with Extended Ensembles
"  We revisit the results of Harvie (2000) and show how correcting for a reporting mistake in some of the estimated parameter values leads to significantly different conclusions, including realistic parameter values for the Philips curve and estimated equilibrium employment rates exhibiting on average one tenth of the relative error of those obtained in Harvie (2000). ",A comment on 'Testing Goodwin: growth cycles in ten OECD countries'
"  Background and aim: Image registration and alignment are the main limitations of augmented reality-based knee replacement surgery. This research aims to decrease the registration error, eliminate outcomes that are trapped in local minima to improve the alignment problems, handle the occlusion, and maximize the overlapping parts. Methodology: markerless image registration method was used for Augmented reality-based knee replacement surgery to guide and visualize the surgical operation. While weight least square algorithm was used to enhance stereo camera-based tracking by filling border occlusion in right to left direction and non-border occlusion from left to right direction. Results: This study has improved video precision to 0.57 mm~0.61 mm alignment error. Furthermore, with the use of bidirectional points, for example, forwards and backwards directional cloud point, the iteration on image registration was decreased. This has led to improve the processing time as well. The processing time of video frames was improved to 7.4~11.74 fps. Conclusions: It seems clear that this proposed system has focused on overcoming the misalignment difficulty caused by movement of patient and enhancing the AR visualization during knee replacement surgery. The proposed system was reliable and favorable which helps in eliminating alignment error by ascertaining the optimal rigid transformation between two cloud points and removing the outliers and non-Gaussian noise. The proposed augmented reality system helps in accurate visualization and navigation of anatomy of knee such as femur, tibia, cartilage, blood vessels, etc. ",A Novel Visualization System of Using Augmented Reality in Knee   Replacement Surgery: Enhanced Bidirectional Maximum Correntropy Algorithm
"  Density-functional theory is utilized to investigate the zero-temperature transition from a Fermi liquid to an inhomogeneous stripe, or Wigner crystal phase, predicted to occur in a one-component, spin-polarized, two-dimensional dipolar Fermi gas. Correlations are treated semi-exactly within the local-density approximation using an empirical fit to Quantum Monte Carlo data. We find that the inclusion of the nonlocal contribution to the Hartree-Fock energy is crucial for the onset of an instability to an inhomogeneous density distribution. Our density-functional theory supports a transition to both a one-dimensional stripe phase, and a triangular Wigner crystal. However, we find that there is an instability first to the stripe phase, followed by a transition to the Wigner crystal at higher coupling. ",Density-functional theory for the crystalline phases of a   two-dimensional dipolar Fermi gas
"  Star cluster formation is a major mode of star formation in the extreme conditions of interacting galaxies and violent starbursts. These newly-formed clusters are built from recycled gas, pre-enriched to various levels within the interacting galaxies. Hence, star clusters of different ages represent a fossil record of the chemical enrichment history of their host galaxy, as well as of the host galaxy's violent star formation history. We present a new set of evolutionary synthesis models of our GALEV code, specifically developed to include the gaseous emission of presently forming star clusters, and a new tool to analyse multi-color observations with our models. First results for newly-born clusters in the dwarf starburst galaxy NGC 1569 are presented. ",Young star clusters: Metallicity tracers in external galaxies
"  Lieu, Mittaz, Bonamente, Durret and Kaastra have provided a document which claims to rebut the finding by Bowyer, Berghoefer and Korpela presented at the Ringburg Workshop (April 1999) that excess EUV emission detected in some clusters of galaxies is an artifact of the background subtraction employed. We provide here a response to their claims. ","Response to the Document ``Origin of the Extended EUV Emission from the   Abell 2199 and Abell 1795 Clusters of Galaxies'' by Lieu, Mittaz, Bonamente,   Durret and Kaastra"
"  Dynamics of a fluxon in a stack of inductively coupled long Josephson junctions is studied analytically and numerically. We demonstrate that the fluxon has a maximum velocity, which does not necessarily coincide with any of the characteristic Josephson plasma wave velocities. The maximum fluxon velocity is found by means of numerical simulations of the quasi-infinite system. Using the variational approximation, we propose a simple analytical formula for the dependence of the fluxon's maximum velocity on the coupling constant and on the distribution of critical currents in different layers. This analysis yields rather precise results in the limit of small dissipation. The simulations also show that nonzero dissipation additionally stabilizes the fluxon. ",Maximum velocity of a fluxon in a stack of coupled Josephson junctions
"  In mixed traffic scenarios, a certain number of pedestrians might coexist in a small area while interacting with vehicles. In this situation, every pedestrian must simultaneously react to the surrounding pedestrians and vehicles. Analytical modeling of such collective pedestrian motion can benefit intelligent transportation practices like shared space design and urban autonomous driving. This work proposed the sub-goal social force model (SG-SFM) to describe the collective pedestrian motion under vehicle influence. The proposed model introduced a new design of vehicle influence on pedestrian motion, which was smoothly combined with the influence of surrounding pedestrians using the sub-goal concept. This model aims to describe generalized pedestrian motion, i.e., it is applicable to various vehicle-pedestrian interaction patterns. The generalization was verified by both quantitative and qualitative evaluation. The quantitative evaluation was conducted to reproduce pedestrian motion in three different datasets, HBS, CITR, and DUT. It also compared two different ways of calibrating the model parameters. The qualitative evaluation examined the simulation of collective pedestrian motion in a series of fundamental vehicle-pedestrian interaction scenarios. The above evaluation results demonstrated the effectiveness of the proposed model. ",Sub-Goal Social Force Model for Collective Pedestrian Motion Under   Vehicle Influence
"  For thermally fluctuating 2-d systems, like solid surfaces, time and space correlation of the local surface height diverge logarithmically in the rough phase, whereas saturation is obtained below the roughening transition. A 2-d Langevin formalism, allowing to recover for long times and/or large distances these asymptotic behaviors, is presented. An overall expression for correlation functions that are related to atom hopping rates and surface stiffnesses is given. Considering anisotropic systems allows describing vicinal surfaces. At finite times, time correlations cross over to power laws alpha*t^(1/n) (n = 1, 2 or 4), within limited time ranges as it was observed for isolated fluctuating steps. Limits of time ranges are related to stiffnesses and diffusion anisotropies. Application to the analysis of STM images of Cu(115) below the roughening transition is given. ",Time-space height correlations of thermally fluctuating 2-d systems.   Application to vicinal surfaces and analysis of STM images of Cu(115)
"  Weak lensing by large-scale structure is a powerful probe of cosmology and of the dark universe. This cosmic shear technique relies on the accurate measurement of the shapes and redshifts of background galaxies and requires precise control of systematic errors. The Monte Carlo Control Loops (MCCL) is a forward modelling method designed to tackle this problem. It relies on the Ultra Fast Image Generator (UFig) to produce simulated images tuned to match the target data statistically, followed by calibrations and tolerance loops. We present the first end-to-end application of this method, on the Dark Energy Survey (DES) Year 1 wide field imaging data. We simultaneously measure the shear power spectrum $C_{\ell}$ and the redshift distribution $n(z)$ of the background galaxy sample. The method includes maps of the systematic sources, Point Spread Function (PSF), an Approximate Bayesian Computation (ABC) inference of the simulation model parameters, a shear calibration scheme, and the fast estimation of the covariance matrix. We find a close statistical agreement between the simulations and the DES Y1 data using an array of diagnostics. In a non-tomographic setting, we derive a set of $C_\ell$ and $n(z)$ curves that encode the cosmic shear measurement, as well as the systematic uncertainty. Following a blinding scheme, we measure the combination of $\Omega_m$, $\sigma_8$, and intrinsic alignment amplitude $A_{\rm{IA}}$, defined as $S_8D_{\rm{IA}} = \sigma_8(\Omega_m/0.3)^{0.5}D_{\rm{IA}}$, where $D_{\rm{IA}}=1-0.11(A_{\rm{IA}}-1)$. We find $S_8D_{\rm{IA}}=0.895^{+0.054}_{-0.039}$, where systematics are at the level of roughly 60\% of the statistical errors. We discuss these results in the context of earlier cosmic shear analyses of the DES Y1 data. Our findings indicate that this method and its fast runtime offer good prospects for cosmic shear measurements with future wide-field surveys. ",Monte Carlo Control Loops for cosmic shear cosmology with DES Year 1
"  We investigate the existence and uniqueness issues of the 3D incompressible Hall-magnetohydrodynamic system supplemented with initial velocity $u_0$ and magnetic field $B_0$ in critical regularity spaces.In the case where $u_0,$ $B_0$ and the current $J_0:=\nabla\times B_0$ belong to the homogeneous Besov space $\dot B^{\frac 3p-1}_{p,1},$ $\:1\leq p<\infty,$ and are small enough, we establish a global result and the conservation of higher regularity.If the viscosity is equal to the magnetic resistivity, then we obtain the global well-posedness provided $u_0,$ $B_0$ and $J_0$ are small enough in the \emph{larger} Besov space $\dot B^{\frac12}_{2,r},$ $r\geq1.$If $r=1,$ then we also establish the local existence for large data, and exhibit continuation criteria for solutions with critical regularity. Our results rely on an extended formulation of the Hall-MHD system, that has some similarities with the incompressibleNavier-Stokes equations. ",On the well-posedness of the Hall-magnetohydrodynamics system in   critical spaces
"  This paper concerns the facial geometry of the set of $n \times n$ correlation matrices. The main result states that almost every set of $r$ vertices generates a simplicial face, provided that $r \leq \sqrt{\mathrm{c} n}$, where $\mathrm{c}$ is an absolute constant. This bound is qualitatively sharp because the set of correlation matrices has no simplicial face generated by more than $\sqrt{2n}$ vertices. ",Simplicial faces of the set of correlation matrices
"  The precision of new HERA data on jet photoproduction opens up the possibility to discriminate between different models of the photon structure. This requires equally precise theoretical predictions from perturbative QCD calculations. In the past years, next-to-leading order calculations for the photoproduction of jets at HERA have become available. Using the kinematic cuts of recent ZEUS analyses, we compare the predictions of three calculations for different dijet and three-jet distributions. We find that in general all three calculations agree within the statistical accuracy of the Monte Carlo integration yielding reliable theoretical predictions. In certain restricted regions of phase space, the calculations differ by up to 5%. ",Detailed Comparison of Next-to-Leading Order Predictions for Jet   Photoproduction at HERA
"  Markov random fields (MRFs) are difficult to evaluate as generative models because computing the test log-probabilities requires the intractable partition function. Annealed importance sampling (AIS) is widely used to estimate MRF partition functions, and often yields quite accurate results. However, AIS is prone to overestimate the log-likelihood with little indication that anything is wrong. We present the Reverse AIS Estimator (RAISE), a stochastic lower bound on the log-likelihood of an approximation to the original MRF model. RAISE requires only the same MCMC transition operators as standard AIS. Experimental results indicate that RAISE agrees closely with AIS log-probability estimates for RBMs, DBMs, and DBNs, but typically errs on the side of underestimating, rather than overestimating, the log-likelihood. ",Accurate and Conservative Estimates of MRF Log-likelihood using Reverse   Annealing
"  This paper introduces a new activation checkpointing method which allows to significantly decrease memory usage when training Deep Neural Networks with the back-propagation algorithm. Similarly to checkpoint-ing techniques coming from the literature on Automatic Differentiation, it consists in dynamically selecting the forward activations that are saved during the training phase, and then automatically recomputing missing activations from those previously recorded. We propose an original computation model that combines two types of activation savings: either only storing the layer inputs, or recording the complete history of operations that produced the outputs (this uses more memory, but requires fewer recomputations in the backward phase), and we provide an algorithm to compute the optimal computation sequence for this model. This paper also describes a PyTorch implementation that processes the entire chain, dealing with any sequential DNN whose internal layers may be arbitrarily complex and automatically executing it according to the optimal checkpointing strategy computed given a memory limit. Through extensive experiments, we show that our implementation consistently outperforms existing checkpoint-ing approaches for a large class of networks, image sizes and batch sizes. ",Optimal checkpointing for heterogeneous chains: how to train deep neural   networks with limited memory
"  An important area of anti-crisis public administration is the development of small businesses. They are an important part of the economy of developed and developing countries, provide employment for a significant part of the population and tax revenues to budgets, and contribute to increased competition and the development of entrepreneurial abilities of citizens. Therefore, the primary task of the state Federal and regional policy is to reduce administrative barriers and risks, time and resources spent on opening and developing small businesses, problems with small businesses ' access to Bank capital [8], etc. Despite the loud statements of officials, administrative barriers to the development of small businesses in trade and public catering are constantly increasing, including during the 2014-2016 crisis. ",Modern risks of small businesses
"  We report investigation of phonons and oxygen diffusion in Bi2O3 and (Bi0.7Y0.3)2O3. The phonon spectra have been measured in Bi2O3 at high temperatures up to 1083 K using inelastic neutron scattering. Ab-initio calculations have been used to compute the individual contributions of the constituent atoms in Bi2O3 and (Bi0.7Y0.3)2O3 to the total phonon density of states. Our computed results indicate that as temperature is increased, there is a complete loss of sharp peak structure in the vibrational density of states. Ab-initio molecular dynamics simulations show that even at 1000 K in {\delta}-phase Bi2O3, Bi-Bi correlations remain ordered in the crystalline lattice while the correlations between O-O show liquid like disordered behavior. In the case of (Bi0.7Y0.3)2O3, the O-O correlations broadened at around 500 K indicating that oxygen conductivity is possible at such low temperatures in (Bi0.7Y0.3)2O3 although the conductivity is much less than that observed in the undoped high temperature {\delta}-phase of Bi2O3. This result is consistent with the calculated diffusion coefficients of oxygen and observation by QENS experiments. Our ab-initio molecular dynamics calculations predict that macroscopic diffusion is attainable in (Bi0.7Y0.3)2O3 at much lower temperatures, which is more suited for technological applications. Our studies elucidate the easy directions of diffusion in {\delta}-Bi2O3 and (Bi0.7Y0.3)2O3. ",Phonons and Oxygen Diffusion in Bi2O3 and (Bi0.7Y0.3)2O3
  Studies of single and double-spin asymmetries in pion electro-production in semi-inclusive deep-inelastic scattering of 5.8 GeV polarized electrons from unpolarized and longitudinally polarized targets at the Thomas Jefferson National Accelerator Facility using CLAS discussed. We present a Bessel-weighting strategy to extract transverse-momentum-dependent parton distribution functions. ,Studies of TMDs with CLAS
"  Over the next decade, observations conducted with ALMA and the SKA will reveal the process of mass assembly and accretion onto young stars and will be revolutionary for studies of star formation. Here we summarise the capabilities of ALMA and discuss recent results from its early science observations. We then review infrared and radio variability observations of both young low-mass and high-mass stars. A time domain SKA radio continuum survey of star forming regions is then outlined. This survey will produce radio light-curves for hundreds of young sources, providing for the first time a systematic survey of radio variability across the full range of stellar masses. These light-curves will probe the magnetospheric interactions of young binary systems, the origins of outflows, trace episodic accretion on the central sources and potentially constrain the rotation rates of embedded sources. ",Star and Stellar Cluster Formation: ALMA-SKA Synergies
"  Four generalizations of the Phase Integral Approximation (PIA) to sets of N ordinary differential equations of the Schroedinger type: u_j''(x) + Sum{k = 1 to N} R_{jk}(x) u_k(x) = 0, j = 1 to N, are described. The recurrence relations for higher order corrections are given in the form valid in arbitrary order and for the matrix R_{jk} either hermitian or non-hermitian. For hermitian and negative definite R matrices, the Wronskian conserving PIA theory is formulated which generalizes Fulling's current conserving theory pertinent to positive definite R matrices. The idea of a modification of the PIA, well known for one equation: u''(x) + R(x) u(x) = 0, is generalized to sets. A simplification of Wronskian or current conserving theories is proposed which in each order eliminates one integration from the formulas for higher order corrections. If the PIA is generated by a non-degenerate eigenvalue of the R matrix, the eliminated integration is the only one present. In that case, the simplified theory becomes fully algorithmic and is generalized to non-hermitian R matrices. General theory is illustrated by a few examples generated automatically by using author's program in Mathematica, published in arXiv:0710.5406. ",Phase Integral Approximation for coupled ODEs of the Schroedinger type
"  A minimal model based on individual interactions is proposed to study the non-Poisson statistical properties of human behavior: individuals in the system interact with their neighbors, the probability of an individual acting correlates to its activity, and all individuals involved in action will change their activities randomly. The model creates rich non-Poisson spatial-temporal properties in the activities of individuals, in agreement with the patterns of human communication behaviors. Our findings provide insight into various human activities, embracing a range of realistic social interacting systems, particularly, intriguing bimodal phenomenons. This model bridges priority queues and punctuated equilibrium, and our modeling and analysis is likely to shed light on non-Poisson phenomena in many complex systems. ",Punctuated equilibrium dynamics in human communications
"  Let $X$ be a $v$-set, $\B$ a set of 3-subsets (triples) of $X$, and $\B^+\cup\B^-$ a partition of $\B$ with $|\B^-|=s$. The pair $(X,\B)$ is called a simple signed Steiner triple system, denoted by ST$(v,s)$, if the number of occurrences of every 2-subset of $X$ in triples $B\in\B^+$ is one more than the number of occurrences in triples $B\in\B^-$. In this paper we prove that $\st(v,s)$ exists if and only if $v\equiv1,3\pmod6$, $v\ne7$, and $s\in\{0,1,...,s_v-6,s_v-4,s_v\}$, where $s_v=v(v-1)(v-3)/12$ and for $v=7$, $s\in\{0,2,3,5,6,8,14\}$. ",Simple signed Steiner triple systems
"  In this talk we review recent investigations of the non-supersymmetric heterotic SO(16)xSO(16) string on orbifolds and smooth Calabi-Yaus. Using such supersymmetry preserving backgrounds allows one to re-employ commonly known model building techniques. We will argue that tachyons do not appear on smooth Calabi-Yaus to leading order in alpha' and g_s. Twisted tachyons may arise on singular orbifolds, where some of these approximations break down. However, they get lifted in full blow-up. Finally, we show that model searches is viable by identifying over 12,000 of SM-like models on various orbifold geometries. ",Model building with the non-supersymmetric heterotic SO(16)xSO(16)   string
"  When developing models for regulated decision making, sensitive features like age, race and gender cannot be used and must be obscured from model developers to prevent bias. However, the remaining features still need to be tested for correlation with sensitive features, which can only be done with the knowledge of those features. We resolve this dilemma using a fully homomorphic encryption scheme, allowing model developers to train linear regression and logistic regression models and test them for possible bias without ever revealing the sensitive features in the clear. We demonstrate how it can be applied to leave-one-out regression testing, and show using the adult income data set that our method is practical to run. ",CryptoCredit: Securely Training Fair Models
"  We investigate the zero-temperature excitation spectrum of two-dimensional soft-core bosons for a wide range parameters and across the phase transition from a superfluid to a supersolid state. Based on mean field calculations and recent Quantum Monte Carlo results, we demonstrate the applicability of the Bogoliubov-de Gennes equations, even at high interaction strengths where the system forms an insulating cluster crystal. Interestingly, our study reveals that the maximum energy of the longitudinal phonon band in the supersolid phase connects to the maxon energy of the superfluid at the phase transition. ",Elementary excitations of ultracold soft-core bosons across the   superfluid-supersolid phase transition
"  Silicon-substituted hydroxyapatite (SiHA) macroporous scaffolds have been prepared by robocasting. In order to optimize their bone regeneration properties, we have manufactured these scaffolds presenting different microstructures: nanocrystalline and crystalline. Moreover, their surfaces have been decorated with vascular endothelial growth factor (VEGF) to evaluate the potential coupling between vascularization and bone regeneration. In vitro cell culture tests evidence that nanocrystalline SiHA hinders pre-osteblast proliferation, whereas the presence of VEGF enhances the biological functions of both endothelial cells and pre-osteoblasts. The bone regeneration capability has been evaluated using an osteoporotic sheep model. In vivo observations strongly correlate with in vitro cell culture tests. Those scaffolds made of nanocrystalline SiHA were colonized by fibrous tissue, promoted inflammatory response and fostered osteoclast recruitment. These observations discard nanocystalline SiHA as a suitable material for bone regeneration purposes. On the contrary, those scaffolds made of crystalline SiHA and decorated with VEGF exhibited bone regeneration properties, with high ossification degree, thicker trabeculae and higher presence of osteoblasts and blood vessels. Considering these results, macroporous scaffolds made of SiHA and decorated with VEGF are suitable bone grafts for regeneration purposes, even in adverse pathological scenarios such as osteoporosis. ",Silicon substituted hydroxyapatite/VEGF scaffolds stimulate bone   regeneration in osteoporotic sheep
"  We describe a method for spectral cleaning and timing calibration of short voltage time series data from individual radio interferometer receivers. It makes use of the phase differences in Fast Fourier Transform (FFT) spectra across antenna pairs. For strong, localized terrestrial sources these are stable over time, while being approximately uniform-random for a sum over many sources or for noise. Using only milliseconds-long datasets, the method finds the strongest interfering transmitters, a first-order solution for relative timing calibrations, and faulty data channels. No knowledge of gain response or quiescent noise levels of the receivers is required. With relatively small data volumes, this approach is suitable for use in an online system monitoring setup for interferometric arrays.   We have applied the method to our cosmic-ray data collection, a collection of measurements of short pulses from extensive air showers, recorded by the LOFAR radio telescope. Per air shower, we have collected 2 ms of raw time series data for each receiver. The spectral cleaning has a calculated optimal sensitivity corresponding to a power signal-to-noise ratio of 0.08 (or -11 dB) in a spectral window of 25 kHz, for 2 ms of data in 48 antennas. This is well sufficient for our application. Timing calibration across individual antenna pairs has been performed at 0.4 ns precision; for calibration of signal clocks across stations of 48 antennas the precision is 0.1 ns. Monitoring differences in timing calibration per antenna pair over the course of the period 2011 to 2015 shows a precision of 0.08 ns, which is useful for monitoring and correcting drifts in signal path synchronizations.   A cross-check method for timing calibration is presented, using a pulse transmitter carried by a drone flying over the array. Timing precision is similar, 0.3 ns. ",Timing calibration and spectral cleaning of LOFAR time series data
"  Unlike terrestrial communications, unmanned aerial vehicle (UAV) communications have some advantages such as line-of-sight (LoS) environment and flexible mobility, but the interference will be still inevitable. In this paper, we analyze the effect of interference on the UAV communications by considering the LoS probability and different channel fadings for LoS and non-line-of-sight (NLoS) links, affected by the elevation angle of communication link. We then derive a closed-form outage probability in the presence of interfering node for all the possible scenarios and environments of main and interference links. After discussing the impacts of transmitting and interfering node parameters on the outage probability, we show the existence of the optimal height of UAV that minimizes the outage probability. We also show NLoS environment can be better than LoS environment if the average received power of interference is more dominant than that of transmitting signal in UAV communications. ",Outage Probability of UAV Communications in the Presence of Interference
"  In this paper, we propose pass-phrase dependent background models (PBMs) for text-dependent (TD) speaker verification (SV) to integrate the pass-phrase identification process into the conventional TD-SV system, where a PBM is derived from a text-independent background model through adaptation using the utterances of a particular pass-phrase. During training, pass-phrase specific target speaker models are derived from the particular PBM using the training data for the respective target model. While testing, the best PBM is first selected for the test utterance in the maximum likelihood (ML) sense and the selected PBM is then used for the log likelihood ratio (LLR) calculation with respect to the claimant model. The proposed method incorporates the pass-phrase identification step in the LLR calculation, which is not considered in conventional standalone TD-SV systems. The performance of the proposed method is compared to conventional text-independent background model based TD-SV systems using either Gaussian mixture model (GMM)-universal background model (UBM) or Hidden Markov model (HMM)-UBM or i-vector paradigms. In addition, we consider two approaches to build PBMs: speaker-independent and speaker-dependent. We show that the proposed method significantly reduces the error rates of text-dependent speaker verification for the non-target types: target-wrong and imposter-wrong while it maintains comparable TD-SV performance when imposters speak a correct utterance with respect to the conventional system. Experiments are conducted on the RedDots challenge and the RSR2015 databases that consist of short utterances. ",Incorporating Pass-Phrase Dependent Background Models for Text-Dependent   Speaker Verification
"  In this article, we investigate explosive bond percolation (EBP) with product rule, formally known as Achlioptas process, on a scale-free multifractal weighted planar stochastic lattice (WPSL). One of the key features of the EBP transition is the delay, compared to corresponding random bond percolation (RBP), in the onset of spanning cluster. However, when it happens, it happens so dramatically that initially it was believed, albeit ultimately proved wrong, that explosive percolation (EP) exhibits first order transition. In the case of EP, much efforts were devoted to resolving the issue of its order of transition and almost no effort being devoted to find critical point, critical exponents etc., to classify it into universality classes. This is in sharp contrast to the classical random percolation. We do not even know all the exponents of EP for regular planar lattice or for Erd\""{o}s-Renyi network. We first find numerically the critical point $p_c$ and then obtain all the critical exponents $\beta, \gamma, \nu$ as well as the Fisher exponent $\tau$ and the fractal dimension $d_f$ of the spanning cluster. We also compare our results for EBP with those of the RBP and find that all the exponents of EBP obeys the same scaling relations as do the RBP. Our findings suggests that EBP is no special except the fact that the exponent $\beta$ is unusually small compared to that of RBP. ",Explosive percolation on scale-free multifractal weighted planar   stochastic lattice
  We prove that the distribution of second degrees in the Bollob\'as--Riordan random graph model obeys the power law. We consider the model with parameter m = 1 (the number of edges equals the number of nodes). ,The distribution of second degrees in the Bollob\'as--Riordan random   graph model
"  It is shown that the presence of a vector doublet is suitable to address neutrino mass, dark matter, and the recent muon anomalous magnetic moment. ",Novel imprint of a vector doublet
"  In this paper we introduce and show some new notions and results on cg-frames of Hilbert spaces. We define cg-orthonormal bases for a Hilbert space H and verify their properties and relations with cg-frames. Actually, we present that every cg-frame can be represented as a composition of a cg-orthonormal basis and an operator under some conditions. Also, we find for any cg-frame an induced c-frame and study their properties and relations. Moreover, we show that every cg-frame can be written as aggregate of two Parseval cg-frames. In addition, We show each cg-frame as a summation of a cg-orthonormal basis and a cg-Riesz basis. ",Characterization of continuous g-frames via operators
"  A two-dimensional second-order topological superconductor exhibits a finite gap in both bulk and edges, with the nontrivial topology manifesting itself through Majorana zero modes localized at the corners, i.e., Majorana corner states. We investigate a time-reversal-invariant topological superconductor in two dimension and demonstrate that an in-plane magnetic field could transform it into a second-order topological superconductor. A detailed analysis reveals that the magnetic field gives rise to mass terms which take distinct values among the edges, and Majorana corner states naturally emerge at the intersection of two adjacent edges with opposite masses. With the rotation of the magnetic field, Majorana corner states localized around the boundary may hop from one corner to a neighboring one and eventually make a full circle around the system when the field rotates by $2\pi$. In the end we briefly discuss physical realizations of this system. ",Tunable Majorana corner states in a two-dimensional second-order   topological superconductor induced by magnetic fields
"  We introduce pretty clean modules, extending the notion of clean modules by Dress, and show that pretty clean modules are sequentially Cohen-Macaulay. We also extend a theorem of Dress on shellable simplicial complexes to multicomplexes. ",Finite Filtrations of Modules and Shellable Multicomplexes
"  We introduce linear programs encoding regular expressions of finite languages. We show that, given a language, the optimum value of the associated linear program is a lower bound on the size of any regular expression of the language. Moreover we show that any regular expression can be turned into a dual feasible solution with an objective value that is equal to the size of the regular expression. For binomial languages we can relax the associated linear program using duality theorem. We use this relaxation to prove lower bounds on the size of regular expressions of binomial and threshold languages. ",Lower Bounds on Regular Expression Size
  We prove the Central Limit Theorem for finite-dimensional vectors of linear eigenvalue statistics of submatrices of Wigner random matrices under the assumption that test functions are sufficiently smooth. We connect the asymptotic covariance to a family of correlated Gaussian Free Fields. ,Central Limit Theorem for Linear Eigenvalue Statistics for Submatrices   of Wigner Random Matrices
"  We present a pedagogical analysis of the symplectic group $\mathrm{Sp}(4,\mathbb{R})$ and its Lie algebra, and derive new factorised forms of the group elements. These results are then used to describe two linearly-coupled quantum scalar fields. Such systems are found to be placed in four-mode squeezed states, which are constructed explicitly in the Fock space. They are shown to generalise the two-mode squeezed states of single-field systems, with additional transfers of quanta between the two fields. The structure of the state is also investigated in phase space by means of the Wigner function. Finally, we study the reduced single-field system obtained by tracing out one of the two fields. This analysis is done both in the Fock space and in the phase space, and allow us to discuss environmental effects in the case of linear interactions. In particular, we find that there is always a range of interaction coupling for which decoherence occurs without substantially affecting the power spectra (hence the observables) of the system. Applications in the context of cosmology are also discussed. ","Four-mode squeezed states: two-field quantum systems and the symplectic   group $\mathrm{Sp}(4,\mathbb{R})$"
"  Certain monotonicity properties of the Poisson approximation to the binomial distribution are established. As a natural application of these results, exact (rather than approximate) tests of hypotheses on an unknown value of the parameter $p$ of the binomial distribution are presented. ",Monotonicity properties of the Poisson approximation to the binomial   distribution
"  The glued-trees problem is the only example known to date for which quantum annealing provides an exponential speedup, albeit by partly using excited state evolution, in an oracular setting. How robust is this speedup to noise on the oracle? To answer this, we construct phenomenological short-range and long-range noise models, and noise models that break or preserve the reflection symmetry of the spectrum. We show that under the long-range noise models an exponential quantum speedup is retained. However, we argue that a classical algorithm with an equivalent long-range noise model also exhibits an exponential speedup over the noiseless model. In the quantum setting the long-range noise is able to lift the spectral gap of the problem so that the evolution changes from diabatic to adiabatic. In the classical setting, long-range noise creates a significant probability of the walker landing directly on the EXIT vertex. Under short-range noise the exponential speedup is lost, but a polynomial quantum speedup is retained for sufficiently weak noise. In contrast to noise range, we find that breaking of spectral symmetry by the noise has no significant impact on the performance of the noisy algorithms. Our results about the long-range models highlight that care must be taken in selecting phenomenological noise models so as not to change the nature of the computational problem. We conclude from the short-range noise model results that the exponential speedup in the glued-trees problem is not robust to noise, but a polynomial quantum speedup is still possible. ",Sensitivity of quantum speedup by quantum annealing to a noisy oracle
"  The spin- and energy-dependent interface reflectivity of a ferromagnetic (FM) film in contact with a nonmagnetic (NM) film is calculated using a first-principles transport method and incorporated into the superdiffusive spin transport model to study the femtosecond laser-induced ultrafast demagnetization of Fe|NM and Ni|NM (NM= Au, Al & Pt) bilayers. By comparing the calculated demagnetization with transparent and real interfaces, we demonstrate that the spin-dependent reflection of hot electrons has a noticeable influence on the ultrafast demagnetization and the associated terahertz electromagnetic radiation. In particular, a spin filtering effect is found at the Fe|NM interface that increases the spin current injected into the NM metal, which enhances both the resulting demagnetization and the resulting THz emission. This suggests that the THz radiation can be optimized by tailoring the interface, indicating a very large tunability. ",Interface reflectivity of a superdiffusive spin current in ultrafast   demagnetization and THz emission
"  The 3-d BTZ black hole represents an orbifold of $AdS_3$ gravity. The UV as well as the IR region of the CFT is governed by a gauged SL(2, R) WZW model. In the UV it corresponds to a light-cone gauging (Liouville model) whereas in the IR it is a space-like gauging (2-d black hole). ",Orbifolds of AdS(3) and fixpoints of the CFT
"  We show that fundamental learning tasks, such as finding an approximate linear separator or linear regression, require memory at least \emph{quadratic} in the dimension, in a natural streaming setting. This implies that such problems cannot be solved (at least in this setting) by scalable memory-efficient streaming algorithms. Our results build on a memory lower bound for a simple linear-algebraic problem -- finding orthogonal vectors -- and utilize the estimates on the packing of the Grassmannian, the manifold of all linear subspaces of fixed dimension. ",Space lower bounds for linear prediction in the streaming model
"  An important step in the development of value alignment (VA) systems in AI is understanding how values can interrelate with facts. Designers of future VA systems will need to utilize a hybrid approach in which ethical reasoning and empirical observation interrelate successfully in machine behavior. In this article we identify two problems about this interrelation that have been overlooked by AI discussants and designers. The first problem is that many AI designers commit inadvertently a version of what has been called by moral philosophers the ""naturalistic fallacy,"" that is, they attempt to derive an ""ought"" from an ""is."" We illustrate when and why this occurs. The second problem is that AI designers adopt training routines that fail fully to simulate human ethical reasoning in the integration of ethical principles and facts. Using concepts of quantified modal logic, we proceed to offer an approach that promises to simulate ethical reasoning in humans by connecting ethical principles on the one hand and propositions about states of affairs on the other. ",Grounding Value Alignment with Ethical Principles
  Polar crown prominences are made of chromospheric plasma partially circling the Suns poles between 60 and 70 degree latitude. We aim to diagnose the 3D dynamics of a polar crown prominence using high cadence EUV images from the Solar Dynamics Observatory (SDO)/AIA at 304 and 171A and the Ahead spacecraft of the Solar Terrestrial Relations Observatory (STEREO-A)/EUVI at 195A. Using time series across specific structures we compare flows across the disk in 195A with the prominence dynamics seen on the limb. The densest prominence material forms vertical columns which are separated by many tens of Mm and connected by dynamic bridges of plasma that are clearly visible in 304/171A two-color images. We also observe intermittent but repetitious flows with velocity 15 km/s in the prominence that appear to be associated with EUV bright points on the solar disk. The boundary between the prominence and the overlying cavity appears as a sharp edge. We discuss the structure of the coronal cavity seen both above and around the prominence. SDO/HMI and GONG magnetograms are used to infer the underlying magnetic topology. The evolution and structure of the prominence with respect to the magnetic field seems to agree with the filament linkage model. ,On the structure and evolution of a polar crown prominence/filament   system
"  In this paper, we consider weighted nonbinary repeat multiple-accumulate (WNRMA) code ensembles obtained from the serial concatenation of a nonbinary rate-1/n repeat code and the cascade of L>= 1 accumulators, where each encoder is followed by a nonbinary random weighter. The WNRMA codes are assumed to be iteratively decoded using the turbo principle with maximum a posteriori constituent decoders. We derive the exact weight enumerator of nonbinary accumulators and subsequently give the weight enumerators for WNRMA code ensembles. We formally prove that the symbol-wise minimum distance of WNRMA code ensembles asymptotically grows linearly with the block length when L >= 3 and n >= 2, and L=2 and n >= 3, for all powers of primes q >= 3 considered, where q is the field size. Thus, WNRMA code ensembles are asymptotically good for these parameters. We also give iterative decoding thresholds, computed by an extrinsic information transfer chart analysis, on the q-ary symmetric channel to show the convergence properties. Finally, we consider the binary image of WNRMA code ensembles and compare the asymptotic minimum distance growth rates with those of binary repeat multiple-accumulate code ensembles. ",On the Analysis of Weighted Nonbinary Repeat Multiple-Accumulate Codes
"  The electron dephasing time $\tau_{\phi}$ in a diffusive quantum dot is calculated by considering the interaction between the electron and dynamical defects, modelled as two-level system. Using the standard tunneling model of glasses, we obtain a linear temperature dependence of $1/\tau_{\phi}$, consistent with the experimental observation. However, we find that, in order to obtain dephasing times on the order of nanoseconds, the number of two-level defects needs to be substantially larger than the typical concentration in glasses. We also find a finite system-size dependence of $\tau_{\phi}$, which can be used to probe the effectiveness of surface-aggregated defects. ",Dephasing of Electrons by Two-Level Defects in Quantum Dots
"  We derive and investigate the dispersion relation for accretion disks with retarded or advanced heating. We follow the alpha-prescription but allow for a time offset (\tau) between heating and pressure perturbations, as well as for a diminished response of heating to pressure variations. We study in detail solutions of the dispersion relation for disks with radiation-pressure fraction 1 - \beta . For \tau <0 (delayed heating) the number and sign of real solutions for the growth rate depend on the values of the time lag and the ratio of heating response to pressure perturbations, \xi . If the delay is larger than a critical value (e.g., if \Omega \tau <-125 for \alpha =0.1, \beta =0 and \xi =1) two real solutions exist, which are both negative. These results imply that retarded heating may stabilize radiation-pressure dominated accretion disks. ",Stability of radiation-pressure dominated disks. I. The dispersion   relation for a delayed heating alpha-viscosity prescription
"  We investigate whether a spontaneously-broken gauge theory of the group $SU(2,2)$ may be a genuine competitor to General Relativity. The basic ingredients of the theory are an $SU(2,2)$ gauge field $A_{\mu}$ and a Higgs field $W$ in the adjoint representation of the group with the Higgs field producing the symmetry breaking $SU(2,2)\rightarrow SO(1,3)\times SO(1,1)$. The action for gravity is polynomial in $\{A_{\mu},W\}$ and the field equations are first-order in derivatives of these fields. The new $SO(1,1)$ symmetry in the gravitational sector is interpreted in terms of an emergent scale symmetry and the recovery of conformalized General Relativity and fourth-order Weyl conformal gravity as limits of the theory- following imposition of Lagrangian constraints- is demonstrated. Maximally symmetric spacetime solutions to the full theory are found and stability of the theory around these solutions is investigated; it is shown that regions of the theory's parameter space describe perturbations identical to that of General Relativity coupled to a massive scalar field and a massless one-form field. The coupling of gravity to matter is considered and it is shown that actions for all fields are naturally gauge-invariant, polynomial in fields and yield first-order field equations; no auxiliary fields are introduced. Familiar Yang-Mills and Klein-Gordon type Lagrangians are recovered on-shell in the General-Relativistic limit of the theory. In this formalism, the General-Relativistic limit and the breaking of scale invariance appear as two sides of the same coin and it is shown that the latter generates mass terms for Higgs and spinor fields. ",A first-order approach to conformal gravity
"  We construct classes of K\""ahler groups that do not have finite classifying spaces and are not commensurable to subdirect products of surface groups. Each of these groups is the fundamental group of the generic fibre of a holomorphic map from a product of Kodaira fibrations onto an elliptic curve. ","Kodaira fibrations, K\""ahler groups, and finiteness properties"
"  Impact-cratering processes on small bodies are thought to be mainly controlled by the local material strength because of their low surface gravity, and craters that are as large as the parent bodies should be affected by the target curvature. Although cratering processes on planar surfaces in the strength-controlled regime have been studied extensively, the mechanism by which target curvature affects the cratering processes remains unclear. Herein, we report on a series of impact experiments that used spherical targets with various diameters. The resultant craters consisted of a deep circular pit and an irregular-shaped spall region around the pit, which is consistent with the features reported in a number of previous cratering experiments on planar surfaces. However, the volume and radius of the craters increased with the normalized curvature. The results indicate that the increase in the spall-region volume and radius mainly contributes to the increase in the whole crater volume and radius, although the volume, depth, and radius of pits remain constant with curvature. The results of our model indicate that the geometric effect due to curvature (i.e., whereby the distance from the equivalent center to the target free surface is shorter for higher curvature values) contributes to increases in the cratering efficiency. Our results suggest that the impactors that produce the largest craters (basins) on some asteroids are thus smaller than what is estimated by current scaling laws, which do not take into account the curvature effects. ",Increase in cratering efficiency with target curvature in   strength-controlled craters
"  Using the method of spectral decimation and a modified version of Kirchhoffs Matrix-Tree Theorem, a closed form solution to the number of spanning trees on approximating graphs to a fully symmetric self-similar structure on a finitely ramified fractal is given in Theorem (3.4). Examples calculated include the Sierpinski Gasket, a non p.c.f. analog of the Sierpinski Gasket, the Diamond fractal, and the Hexagasket. For each example, the asymptotic complexity constant is found. Dropping the fully symmetry assumption, it is shown that the limsup and liminf of the asymptotic complexity constant exist. ",Counting Spanning Trees on Fractal Graphs
"  We investigate the effect of surface anisotropy in a spherical many-spin magnetic nanoparticle. By computing minor loops, two-dimensional (2D) and 3D energyscape, and by investigating the behavior of the net magnetization, we show that in the case of not too strong surface anisotropy the behavior of the many-spin particle may be modeled by that of a macrospin with an effective energy containing uniaxial and cubic anisotropy terms. This holds for both the transverse and N\'eel's surface anisotropy models. ",Surface-induced cubic anisotropy in nanomagnets
"  Routine single-sample haplotype-resolved assembly remains an unresolved problem. Here we describe a new algorithm that combines PacBio HiFi reads and Hi-C chromatin interaction data to produce a haplotype-resolved assembly without the sequencing of parents. Applied to human and other vertebrate samples, our algorithm consistently outperforms existing single-sample assembly pipelines and generates assemblies of comparable quality to the best pedigree-based assemblies. ",Robust haplotype-resolved assembly of diploid individuals without   parental data
"  We investigate latent-space scalability for multi-task collaborative intelligence, where one of the tasks is object detection and the other is input reconstruction. In our proposed approach, part of the latent space can be selectively decoded to support object detection while the remainder can be decoded when input reconstruction is needed. Such an approach allows reduced computational resources when only object detection is required, and this can be achieved without reconstructing input pixels. By varying the scaling factors of various terms in the training loss function, the system can be trained to achieve various trade-offs between object detection accuracy and input reconstruction quality. Experiments are conducted to demonstrate the adjustable system performance on the two tasks compared to the relevant benchmarks. ",Latent-space scalability for multi-task collaborative intelligence
"  This paper proposes a method for performing continual learning of predictive models that facilitate the inference of future frames in video sequences. For a first given experience, an initial Variational Autoencoder, together with a set of fully connected neural networks are utilized to respectively learn the appearance of video frames and their dynamics at the latent space level. By employing an adapted Markov Jump Particle Filter, the proposed method recognizes new situations and integrates them as predictive models avoiding catastrophic forgetting of previously learned tasks. For evaluating the proposed method, this article uses video sequences from a vehicle that performs different tasks in a controlled environment. ",Continual Learning of Predictive Models in Video Sequences via   Variational Autoencoders
"  Experiments (Mullin and Kreswell, 2005) show that transition to turbulence can start at Reynolds numbers lower than it is predicted by the linear stability analysis - the subcritical transition to turbulence. To explain these observations qualitatively we suggest that the onset of subcritical instability is related to decline of viscosity of the fluid: friction between fluid layers fails with the increase of the velocity gradient. To describe the declinie of friction theoretically we relax the the assumption of the stability of the fluid material and introduce a constant of fluid strength. Particularly, we enhance the Navier-Stokes model with a failure description by introducing the fluid strength in the constitutive equation for the viscous stress. The clasical model is obtained from the enhanced one when strength goes to infinity. We use the modified Navier-Stokes model to analyze the Couette flow between two parallel plates and find that the lateral perturbations can destabilize the flow and the critical Reynolds number is proportional to the fluid strength. The latter means that the classical Navier-Stokes model of a stable material with infinite strength does not capture the subcritical transition to turbulence while the mofified model does. ",Transition to turbulence through decline of viscosity
"  From Doppler velocity maps of active regions constructed from spectra obtained by the Extreme-ultraviolet Imaging Spectrometer (EIS) on the Hinode spacecraft we observe large areas of outflow (20-50 km/s) that can persist for at least a day. These outflows occur in areas of active regions that are faint in coronal spectral lines formed at typical quiet Sun and active region temperatures. The outflows are positively correlated with non-thermal velocities in coronal plasmas. The bulk mass motions and non-thermal velocities are derived from spectral line centroids and line widths, mostly from a strong line of Fe XII at 195.12 Angstroms. The electron temperature of the outflow regions estimated from an Fe XIII to Fe XII line intensity ratio is about 1.2-1.4 MK. The electron density of the outflow regions derived from a density sensitive intensity ratio of Fe XII lines is rather low for an active region. Most regions average around 7E10+8 cm(-3), but there are variations on pixel spatial scales of about a factor of 4. We discuss results in detail for two active regions observed by EIS. Images of active regions in line intensity, line width, and line centroid are obtained by rastering the regions. We also discuss data from the active regions obtained from other orbiting spacecraft that support the conclusions obtained from analysis of the EIS spectra. The locations of the flows in the active regions with respect to the longitudinal photospheric magnetic fields suggest that these regions might be tracers of long loops and/or open magnetic fields that extend into the heliosphere, and thus the flows could possibly contribute significantly to the solar wind. ",Flows and Non-thermal Velocities in Solar Active Regions Observed with   the Extreme-ultraviolet Imaging Spectrometer on Hinode: A Tracer of Active   Region Sources of Heliospheric Magnetic Fields?
"  One-loop contributions to the decay $H\rightarrow \nu_l\bar{\nu}_l\gamma$ with $l=e, \mu, \tau$ within standard model framework are revisited in this paper. We derive two representations for the form factors in this calculation. As a result, the computations are not only checked numerically by verifying the ultraviolet finiteness of the results but also confirming the ward identity of the amplitude. We find that the results are good stability with varying ultraviolet cutoff parameters as well as satisfy the ward identity. In phenomenological results, all the physical results are examined with the present input parameters. Especially, we study the partial decay widths for the decay channels in both cases of the detected photon and invisible photon. Differential decay widths are also generated as a function of energy of final photon. ",One-loop contributions to the decay $H\rightarrow   \nu_l\bar{\nu}_l\gamma$ in standard model revisited
"  This paper deals with the computation of sectional curvature for the manifolds of $N$ landmarks (or feature points) in D dimensions, endowed with the Riemannian metric induced by the group action of diffeomorphisms. The inverse of the metric tensor for these manifolds (i.e. the cometric), when written in coordinates, is such that each of its elements depends on at most 2D of the ND coordinates. This makes the matrices of partial derivatives of the cometric very sparse in nature, thus suggesting solving the highly non-trivial problem of developing a formula that expresses sectional curvature in terms of the cometric and its first and second partial derivatives (we call this Mario's formula). We apply such formula to the manifolds of landmarks and in particular we fully explore the case of geodesics on which only two points have non-zero momenta and compute the sectional curvatures of 2-planes spanned by the tangents to such geodesics. The latter example gives insight to the geometry of the full manifolds of landmarks. ","Sectional Curvature in terms of the Cometric, with Applications to the   Riemannian Manifolds of Landmarks"
"  Let $\Lambda=kQ/I$ be a Koszul algebra over a field $k$, where $Q$ is a finite quiver. An algorithmic method for finding a minimal projective resolution $\mathbb{F}$ of the graded simple modules over $\Lambda$ is given in Green-Solberg. This resolution is shown to have a ""comultiplicative"" structure in Green-Hartman-Marcos-Solberg, and this is used to find a minimal projective resolution $\mathbb{P}$ of $\Lambda$ over the enveloping algebra $\Lambda^e$. Using these results we show that the multiplication in the Hochschild cohomology ring of $\L$ relative to the resolution $\mathbb{P}$ is given as a cup product and also provide a description of this product. This comultiplicative structure also yields the structure constants of the Koszul dual of $\L$ with respect to a canonical basis over $k$ associated to the resolution $\mathbb{F}$. The natural map from the Hochschild cohomology to the Koszul dual of $\Lambda$ is shown to be surjective onto the graded centre of the Koszul dual. ",Multiplicative structures for Koszul algebras
"  Double-tearing modes (DTMs) have been proposed as a driver of `off-axis sawtooth' crashes in reverse magnetic shear tokamak configurations. Recently differential rotation provided by equilibrium sheared flows has been shown capable of decoupling the two DTM resonant layers, slowing the growth the instability. In this work we instead supply this differential rotation using an electron diamagnetic drift, which emerges in the presence of an equilibrium pressure gradient and finite Larmor radius physics. Diamagnetic drifts have the additional benefit of stabilizing reconnection local to the two tearing layers. Conducting linear and nonlinear simulations with the extended MHD code MRC-3d, we consider an m=2, n=1 cylindrical double-tearing mode. We show that asymmetries between the resonant layers and the emergence of an ideal MHD instability cause the DTM evolution to be highly dependent on the location of the pressure gradient. By locating a strong drift near the outer, dominant resonant surface are we able to saturate the mode and preserve the annular current ring, suggesting that the appearance of DTM activity in advanced tokamaks depends strongly on the details of the plasma pressure profile. ",Effect of electron diamagnetic drifts on cylindrical double-tearing   modes
"  We used extensive ground-based multisite and archival spectroscopy to derive observational constraints for a seismic modelling of the magnetic beta Cep star V2052 Ophiuchi. The line-profile variability is dominated by a radial mode (f_1=7.14846 d^{-1}) and by rotational modulation (P_rot=3.638833 d). Two non-radial low-amplitude modes (f_2=7.75603 d^{-1} and f_3=6.82308 d^{-1}) are also detected. The four periodicities that we found are the same as the ones discovered from a companion multisite photometric campaign (Handler et al. 2012) and known in the literature. Using the photometric constraints on the degrees l of the pulsation modes, we show that both f_2 and f_3 are prograde modes with (l,m)=(4,2) or (4,3). These results allowed us to deduce ranges for the mass (M \in [8.2,9.6] M_o) and central hydrogen abundance (X_c \in [0.25,0.32]) of V2052 Oph, to identify the radial orders n_1=1, n_2=-3 and n_3=-2, and to derive an equatorial rotation velocity v_eq \in [71,75] km s^{-1}. The model parameters are in full agreement with the effective temperature and surface gravity deduced from spectroscopy. Only models with no or mild core overshooting (alpha_ov \in [0,0.15] local pressure scale heights) can account for the observed properties. Such a low overshooting is opposite to our previous modelling results for the non-magnetic beta Cep star theta Oph having very similar parameters, except for a slower surface rotation rate. We discuss whether this result can be explained by the presence of a magnetic field in V2052 Oph that inhibits mixing in its interior. ",Multisite spectroscopic seismic study of the beta Cep star V2052 Oph:   inhibition of mixing by its magnetic field
"  We show that, over every number field, the degree four del Pezzo surfaces that violate the Hasse principle are Zariski dense in the moduli scheme. ",Del Pezzo surfaces of degree four violating the Hasse principle are   Zariski dense in the moduli scheme
"  We present a new framework to treat the dissipation and fluctuation dynamics associated with nucleon-nucleon scattering in heavy-ion collisions. The two-body collision processes are effectively described in terms of the diffusion of nucleons in viscous nuclear media, governed by a set of Langevin equations in momentum space. The new framework combined with the usual mean field dynamics can be used to simulate heavy-ion collisions at intermediate energies. As a proof of principle, we simulate Au + Au reactions and obtain results consistent with other existing codes under the same constrained conditions. We also study the formation of fragments in Sn + Sn reactions at 50 MeV/nucleon, and results are discussed and compared with two other models commonly employed for collisions. ",One-body Langevin dynamics in heavy-ion collisions at intermediate   energies
"  Global optimality analysis in sub-Riemannian problem on the Lie group SH(2) is considered. We cutout open dense domains in the preimage and in the image of the exponential mapping based on the description of Maxwell strata. We then prove that the exponential mapping restricted to these domains is a diffeomorphism. Based on the proof of diffeomorphism, the cut time, i.e., time of loss of global optimality is computed on SH(2). We also consider the global structure of the exponential mapping and obtain an explicit description of cut locus and optimal synthesis. ",Cut Locus and Optimal Synthesis in Sub-Riemannian Problem on the Lie   Group SH(2)
"  We study the four infinite families KA(n), KB(n), KD(n), KQ(n) of finite dimensional Hopf (in fact Kac) algebras constructed respectively by A. Masuoka and L. Vainerman: isomorphisms, automorphism groups, self-duality, lattices of coideal subalgebras. We reduce the study to KD(n) by proving that the others are isomorphic to KD(n), its dual, or an index 2 subalgebra of KD(2n). We derive many examples of lattices of intermediate subfactors of the inclusions of depth 2 associated to those Kac algebras, as well as the corresponding principal graphs, which is the original motivation.   Along the way, we extend some general results on the Galois correspondence for depth 2 inclusions, and develop some tools and algorithms for the study of twisted group algebras and their lattices of coideal subalgebras. This research was driven by heavy computer exploration, whose tools and methodology we further describe. ",Exploration of finite dimensional Kac algebras and lattices of   intermediate subfactors of irreducible inclusions
"  Glucose homeostasis is controlled by the islets of Langerhans which are equipped with alpha-cells increasing the blood glucose level, beta-cells decreasing it, and delta-cells the precise role of which still needs identifying. Although intercellular communications between these endocrine cells have recently been observed, their roles in glucose homeostasis have not been clearly understood. In this study, we construct a mathematical model for an islet consisting of two-state alpha-, beta-, and delta-cells, and analyze effects of known chemical interactions between them with emphasis on the combined effects of those interactions. In particular, such features as paracrine signals of neighboring cells and cell-to-cell variations in response to external glucose concentrations as well as glucose dynamics, depending on insulin and glucagon hormone, are considered explicitly. Our model predicts three possible benefits of the cell-to-cell interactions: First, the asymmetric interaction between alpha- and beta-cells contributes to the dynamic stability while the perturbed glucose level recovers to the normal level. Second, the inhibitory interactions of delta-cells for glucagon and insulin secretion prevent the wasteful co-secretion of them at the normal glucose level. Finally, the glucose dose-responses of insulin secretion is modified to become more pronounced at high glucose levels due to the inhibition by delta-cells. It is thus concluded that the intercellular communications in islets of Langerhans should contribute to the effective control of glucose homeostasis. ",Beneficial effects of intercellular interactions between pancreatic   islet cells in blood glucose regulation
"  This paper is a new step towards getting rid of nonlocality from quantum physics. This is an attempt to structure the nonlocality mess. ""Quantum nonlocality"" is Janus faced. One its face is projection (Einstein-L\""uders) nonlocality and another Bell nonlocality. The first one is genuine quantum nonlocality, the second one is subquantum nonlocality. Recently it was shown that Bell ""nonlocality"" is a simple consequence of the complementarity principle. We now show that projection nonlocality has no connection with physical space. Projection state update is generalization of the well known operation of probability update used in classical inference. We elevate the role of interpretations of a quantum state. By using the individual (physical) interpretation, one can really get the illusion of a spooky action at a distance resulting from L\""uders' state update. The statistical interpretation combined with treating the quantum formalism as machinery for update of probability is known as the V\""axj\""o interpretation. Here one follows the standard scheme of probability update adjusted to the quantum calculus of probability. The latter is based on operating with states represented by vectors (or density operators). We present in parallel classical and quantum probability updates. From this presentation, it is clear that both classical and quantum ""faster-than-light change of statistical correlation"" take place in mental and not physical space. ",Two faced Janus of quantum nonlocality
"  We explore neural painters, a generative model for brushstrokes learned from a real non-differentiable and non-deterministic painting program. We show that when training an agent to ""paint"" images using brushstrokes, using a differentiable neural painter leads to much faster convergence. We propose a method for encouraging this agent to follow human-like strokes when reconstructing digits. We also explore the use of a neural painter as a differentiable image parameterization. By directly optimizing brushstrokes to activate neurons in a pre-trained convolutional network, we can directly visualize ImageNet categories and generate ""ideal"" paintings of each class. Finally, we present a new concept called intrinsic style transfer. By minimizing only the content loss from neural style transfer, we allow the artistic medium, in this case, brushstrokes, to naturally dictate the resulting style. ",Neural Painters: A learned differentiable constraint for generating   brushstroke paintings
"  Deep learning has been achieving top performance in many tasks. Since training of a deep learning model requires a great deal of cost, we need to treat neural network models as valuable intellectual properties. One concern in such a situation is that some malicious user might redistribute the model or provide a prediction service using the model without permission. One promising solution is digital watermarking, to embed a mechanism into the model so that the owner of the model can verify the ownership of the model externally. In this study, we present a novel attack method against watermark, query modification, and demonstrate that all of the existing watermark methods are vulnerable to either of query modification or existing attack method (model modification). To overcome this vulnerability, we present a novel watermarking method, exponential weighting. We experimentally show that our watermarking method achieves high verification performance of watermark even under a malicious attempt of unauthorized service providers, such as model modification and query modification, without sacrificing the predictive performance of the neural network model. ",Robust Watermarking of Neural Network with Exponential Weighting
"  We discuss a few simple modifications to time-dependent density matrix renormalization group (DMRG) algorithms which allow to access larger time scales. We specifically aim at beginners and present practical aspects of how to implement these modifications almost effortlessly within any standard matrix product state (MPS) based formulation of the method. Most importantly, we show how to 'combine' the Schroedinger and Heisenberg time evolutions of arbitrary pure states |psi> and operators A in the evaluation of <A>_psi(t)=<psi|A(t)|psi>. This includes quantum quenches. The generalization (non-)thermal mixed state dynamics <A>_rho(t)=Tr[rho A(t)] induced by an initial density matrix rho is straightforward. In the context of equilibrium (ground state or finite temperature T>0) correlation functions, one can extend the simulation time by a factor of two by 'exploiting time translation invariance', which is efficiently implementable within MPS DMRG. We present a simple analytic argument for why a recently-introduced disentangler succeeds in reducing the effort of time-dependent simulations at T>0. Finally, we advocate the python programming language as an elegant option for beginners to set up a DMRG code. ",Extending the range of real time density matrix renormalization group   simulations
"  The distribution of block maxima of sequences of independent and identically-distributed random variables is used to model extreme values in many disciplines. The traditional extreme value (EV) theory derives a closed-form expression for the distribution of block maxima under asymptotic assumptions, and is generally fitted using annual maxima or excesses over a high threshold, thereby discarding a large fraction of the available observations. The recently-introduced Metastatistical Extreme Value Distribution (MEVD), a non-asymptotic formulation based on doubly stochastic distributions, has been shown to offer several advantages compared to the traditional EV theory. In particular, MEVD explicitly accounts for the variability of the process generating the extreme values, and uses all the available information to perform high-quantile inferences. Here we review the derivation of the MEVD, analyzing its assumptions in detail, and show that its general formulation includes other doubly stochastic approaches to extreme value analysis that have been recently proposed. ",Doubly stochastic distributions of extreme events
"  The Rossiter-McLaughlin (hereafter RM) effect is a key tool for measuring the projected spin-orbit angle between stellar spin axes and orbits of transiting planets. However, the measured radial velocity (RV) anomalies produced by this effect are not intrinsic and depend on both instrumental resolution and data reduction routines. Using inappropriate formulas to model the RM effect introduces biases, at least in the projected velocity Vsin(i) compared to the spectroscopic value. Currently, only the iodine cell technique has been modeled, which corresponds to observations done by, e.g., the HIRES spectrograph of the Keck telescope. In this paper, we provide a simple expression of the RM effect specially designed to model observations done by the Gaussian fit of a cross-correlation function (CCF) as in the routines performed by the HARPS team. We derived also a new analytical formulation of the RV anomaly associated to the iodine cell technique. For both formulas, we modeled the subplanet mean velocity v_p and dispersion beta_p accurately taking the rotational broadening on the subplanet profile into account. We compare our formulas adapted to the CCF technique with simulated data generated with the numerical software SOAP-T and find good agreement up to Vsin(i) < 20 km/s. In contrast, the analytical models simulating the two different observation techniques can disagree by about 10 sigma in Vsin(i) for large spin-orbit misalignments. It is thus important to apply the adapted model when fitting data. ",New analytical expressions of the Rossiter-McLaughlin effect adapted to   different observation techniques
"  We propose a new adiabatic algorithm for the unsorted database search problem. This algorithm saves two thirds of qubits than Grover's algorithm in realizations. Meanwhile, we analyze the time complexity of the algorithm by both perturbative method and numerical simulation. The results show it provides a better speedup than the previous adiabatic search algorithm. ",Complete Adiabatic Quantum Search in Unsorted Databases
  Pair distribution function for delocalized quarks in the strongly coupled quark gluon plasma (sQGP) as well as in the states at intermediate stages of crossover from hadronic matter to sQGP are calculated using a molecule-like aggregation model. The shapes of the obtained pair distribution functions exhibit the character of liquid. The increasing correlation length in the process of crossover indicates a diminishing viscosity of the fluid system. ,Pair distribution function of strongly coupled quark gluon plasma in a   molecule-like aggregation model
"  This paper develops a new approach to the modeling and analysis of HetNets that accurately incorporates coupling across the locations of users and base stations, which exists due to the deployment of small cell base stations (SBSs) at the places of high user density (termed user hotspots in this paper). Modeling the locations of the geographical centers of user hotspots as a homogeneous Poisson Point Process (PPP), we assume that the users and SBSs are clustered around each user hotspot center independently with two different distributions. The macrocell base station (BS) locations are modeled by an independent PPP. This model is consistent with the user and SBS configurations considered by 3GPP. Using this model, we study the performance of a typical user in terms of coverage probability and throughput for two association policies: i) Policy 1, under which a typical user is served by the open-access BS that provides maximum averaged received power, and ii) Policy 2, under which the typical user is served by the small cell tier if the maximum averaged received power from the open-access SBSs is greater than a certain power threshold; and macro tier otherwise. A key intermediate step in our analysis is the derivation of distance distributions from a typical user to the open-access and closed-access interfering SBSs. Our analysis demonstrates that as the number of SBSs reusing the same resource block increases, coverage probability decreases whereas throughput increases. Therefore, contrary to the usual assumption of orthogonal channelization, it is reasonable to assign the same resource block to multiple SBSs in a given cluster as long as the coverage probability remains acceptable. This approach to HetNet modeling and analysis significantly generalizes the state-of-the-art approaches that are based on modeling the locations of BSs and users by independent PPPs. ",Poisson Cluster Process Based Analysis of HetNets with Correlated User   and Base Station Locations
"  In recent work we have developed a new unfolding method for computing one-loop modular integrals in string theory involving the Narain partition function and, possibly, a weak almost holomorphic elliptic genus. Unlike the traditional approach, the Narain lattice does not play any role in the unfolding procedure, T-duality is kept manifest at all steps, a choice of Weyl chamber is not required and the analytic structure of the amplitude is transparent. In the present paper, we generalise this procedure to the case of Abelian Z_N orbifolds, where the integrand decomposes into a sum of orbifold blocks that can be organised into orbits of the Hecke congruence subgroup {\Gamma}_0(N). As a result, the original modular integral reduces to an integral over the fundamental domain of {\Gamma}_0(N), which we then evaluate by extending our previous techniques. Our method is applicable, for instance, to the evaluation of one-loop corrections to BPS-saturated couplings in the low energy effective action of closed string models, of quantum corrections to the K\""ahler metric and, in principle, of the free-energy of superstring vacua. ",Rankin-Selberg methods for closed strings on orbifolds
"  Multiple sclerosis lesion activity segmentation is the task of detecting new and enlarging lesions that appeared between a baseline and a follow-up brain MRI scan. While deep learning methods for single-scan lesion segmentation are common, deep learning approaches for lesion activity have only been proposed recently. Here, a two-path architecture processes two 3D MRI volumes from two time points. In this work, we investigate whether extending this problem to full 4D deep learning using a history of MRI volumes and thus an extended baseline can improve performance. For this purpose, we design a recurrent multi-encoder-decoder architecture for processing 4D data. We find that adding more temporal information is beneficial and our proposed architecture outperforms previous approaches with a lesion-wise true positive rate of 0.84 at a lesion-wise false positive rate of 0.19. ",4D Deep Learning for Multiple Sclerosis Lesion Activity Segmentation
"  We present the leading experimental constraints on supersymmetric models with R-parity violation (RPV) and a long-lived lightest superpartner (LSP). We consider both the well-motivated dynamical RPV scenario as well as the conventional holomorphic RPV operators. Guided by naturalness, we study the cases of stop, gluino, and higgsino LSPs with several possible leading decay channels in each case. The CMS displaced dijet and the ATLAS multitrack displaced vertex searches have been fully recast, with all cuts and vertex reconstruction algorithms applied. Heavy charged stable particle searches by CMS are also applied. In addition, we consider representative bounds for prompt LSP decays that are directly applicable. Our main results are exclusion plots in the $m_{\rm LSP}-\tau_{\rm LSP}$ plane for the various scenarios. We find that the natural parameter space ($m_{\tilde{t}} <800$ GeV, $m_{\tilde{g}}<1500$ GeV, $m_{\tilde{H}}<800$ GeV) is excluded for a long-lived LSP ($\tau_{\rm LSP} \gtrsim 1$ mm). ",Phenomenology of a Long-Lived LSP with R-Parity Violation
"  Publication bias is a major concern in conducting systematic reviews and meta-analyses. Various sensitivity analysis or bias-correction methods have been developed based on selection models and they have some advantages over the widely used bias-correction method of the trim-and-fill method. However, likelihood methods based on selection models may have difficulty in obtaining precise estimates and reasonable confidence intervals or require a complicated sensitivity analysis process. In this paper, we develop a simple publication bias adjustment method utilizing information on conducted but still unpublished trials from clinical trial registries. We introduce an estimating equation for parameter estimation in the selection function by regarding the publication bias issue as a missing data problem under missing not at random. With the estimated selection function, we introduce the inverse probability weighting (IPW) method to estimate the overall mean across studies. Furthermore, the IPW versions of heterogeneity measures such as the between-study variance and the I2 measure are proposed. We propose methods to construct asymptotic confidence intervals and suggest intervals based on parametric bootstrapping as an alternative. Through numerical experiments, we observed that the estimators successfully eliminate biases and the confidence intervals had empirical coverage probabilities close to the nominal level. On the other hand, the asymptotic confidence interval is much wider in some scenarios than the bootstrap confidence interval. Therefore, the latter is recommended for practical use. ",Adjusting for publication bias in meta-analysis via inverse probability   weighting using clinical trial registries
"  This work presents a noise reduction method with perceptually relevant preservation of the interaural time difference (ITD) of the residual noise in binaural hearing aids. The interaural coherence (IC) concept, previously applied to the Multichannel Wiener Filter (MWF) for preservation of the spatial subjective sensation of diffuse noise fields, is proposed here to both preserve and emphasize the ITD binaural cues of a directional acoustic noise source. It is demonstrated that the previously developed MWF-ITD technique may decrease the original IC magnitude of the processed noise, consequently increasing the variance of the interaural phase difference (IPD) of the output signals. It is shown that the MWF-IC technique concomitantly minimizes a nonlinear function of the difference between input and output IPD, which is strictly related to ITD, and preserves the natural coherence of the directional noise captured by the reference microphones. Objective measures and psychoacoustic experiments corroborate the theoretical findings, showing the MWF-IC technique provides relevant noise reduction, while preserving the original ITD subjective perception and original lateralization for a directional noise source. These results are especially relevant for hearing aid designers, since they indicate the MWF-IC as a noise reduction technique that provides resid-ual noise spatial preservation for both diffuse and directional noise sources in frequencies below 1.5 kHz. ",Perceptually Relevant Preservation of Interaural Time Differences in   Binaural Hearing Aids
"  We study possible optically excited bound states in monolayer MoS2: excitons and trions. For this purpose we formulate and apply a generalized time-dependent density-matrix functional approach for bound states of multiple excitations. The approach was used in the cases of three different types of the exchange-correlation (XC) kernel: 1) two local kernels: a phenomenological contact and the adiabatic local-density approximation (ALDA) (X and XC); 2) gradient-corrected X kernels: GEA, PW91 and PBE; and 3) two long-range (LR) kernels: a phenomenological (Coulomb) and Slater kernels. In the case of exciton, we find that LDA and its gradient-corrected kernels lead to too weak binding energy comparing to the experimental data, while the LR kernels are capable to reproduce the experimental results. Similarly, in the LR case (as well as in the case of local kernel), one can obtain the experimental value of the trion binding energy by taking into account the screening effects. Our results suggest that similar to the excitons, the LR structure of the XC kernel is necessary to describe the trion bound states. Our calculations for the first time confirm theoretically with time-dependent density-functional theory approach that in agreement with experimental data the exciton and trion binding energies are of order of hundreds (excitons) and tenth (trions) meVs, which can be used in different technological applications at the room temperature regime. The approach can be straightforwardly extended on the case of bound states and nonequilibrium response of systems with larger number of bound electrons and holes, including biexcitons. ",Time-dependent density-matrix functional theory for trion excitations:   application to monolayer MoS2
"  Model-based methods for recommender systems have been studied extensively in recent years. In systems with large corpus, however, the calculation cost for the learnt model to predict all user-item preferences is tremendous, which makes full corpus retrieval extremely difficult. To overcome the calculation barriers, models such as matrix factorization resort to inner product form (i.e., model user-item preference as the inner product of user, item latent factors) and indexes to facilitate efficient approximate k-nearest neighbor searches. However, it still remains challenging to incorporate more expressive interaction forms between user and item features, e.g., interactions through deep neural networks, because of the calculation cost.   In this paper, we focus on the problem of introducing arbitrary advanced models to recommender systems with large corpus. We propose a novel tree-based method which can provide logarithmic complexity w.r.t. corpus size even with more expressive models such as deep neural networks. Our main idea is to predict user interests from coarse to fine by traversing tree nodes in a top-down fashion and making decisions for each user-node pair. We also show that the tree structure can be jointly learnt towards better compatibility with users' interest distribution and hence facilitate both training and prediction. Experimental evaluations with two large-scale real-world datasets show that the proposed method significantly outperforms traditional methods. Online A/B test results in Taobao display advertising platform also demonstrate the effectiveness of the proposed method in production environments. ",Learning Tree-based Deep Model for Recommender Systems
"  We determine, to the first order in the radius of Anti-de-Sitter, the realisation of the $OSp(6,2|2)$ superconformal algebra on vector fields. We then calculate, to this order, the superspace metric describing the background of $AdS_7\times S^4$. The coordinates we work with are adapted to a 6+5 splitting of the eleven dimensional superspace. Finally, we deduce in a manifestly supersymmetric form the equations governing the dynamics of the fivebrane near the boundary of $AdS_7$. ",Super Fivebranes near the boundary of $AdS_7\times S^4$
"  An important tool for the analysis of results of numerical simulations of lattice QCD is chiral perturbation theory. In Wilson chiral perturbation theory the effects of the finite lattice spacing $a$ are taken into account. In recent years the effects of isospin splitting on the masses of hadrons have been investigated in Monte Carlo simulations. Correspondingly, in this article we derive the expansions of the masses of the pseudoscalar mesons in chiral perturbation theory at next-to-leading order for twisted mass lattice QCD with three light quark flavours, taking the mass difference between the up and down quarks into account. The results include terms up to orders $m_q^2$ in the quark masses, $\Delta m^2$ in the mass splitting between up- and down quarks, and $a^2$ in the lattice spacing, respectively. ",Chiral perturbation theory for three-flavour lattice QCD with isospin   splitting
"  The segmentation and classification of animals from camera-trap images is due to the conditions under which the images are taken, a difficult task. This work presents a method for classifying and segmenting mammal genera from camera-trap images. Our method uses Multi-Layer Robust Principal Component Analysis (RPCA) for segmenting, Convolutional Neural Networks (CNNs) for extracting features, Least Absolute Shrinkage and Selection Operator (LASSO) for selecting features, and Artificial Neural Networks (ANNs) or Support Vector Machines (SVM) for classifying mammal genera present in the Colombian forest. We evaluated our method with the camera-trap images from the Alexander von Humboldt Biological Resources Research Institute. We obtained an accuracy of 92.65% classifying 8 mammal genera and a False Positive (FP) class, using automatic-segmented images. On the other hand, we reached 90.32% of accuracy classifying 10 mammal genera, using ground-truth images only. Unlike almost all previous works, we confront the animal segmentation and genera classification in the camera-trap recognition. This method shows a new approach toward a fully-automatic detection of animals from camera-trap images. ",Automatic Recognition of Mammal Genera on Camera-Trap Images using   Multi-Layer Robust Principal Component Analysis and Mixture Neural Networks
"  We demonstrate coherent optical control of a single hole spin confined to an InAs/GaAs quantum dot. A superposition of hole spin states is created by fast (10-100 ps) dissociation of a spin-polarized electron-hole pair. Full control of the hole-spin is achieved by combining coherent rotations about two axes: Larmor precession of the hole-spin about an external Voigt geometry magnetic field, and rotation about the optical-axis due to the geometric phase shift induced by a picosecond laser pulse resonant with the hole-trion transition. ",Coherent optical control of the spin of a single hole in a quantum dot
"  We study supercritical branching processes under the influence of an i.i.d. emigration component. We provide conditions, under which the lifetime of the process is finite respectively has a finite expectation. A new version of the Kesten-Stigum theorem is obtained and the extinction probability for a large initial population size is related to the tail behaviour of the emigration. ",On Supercritical Branching Processes with Emigration
"  The ground-state phase diagram of a half-filled anisotropic Kondo lattice model is calculated within a mean-field theory. For small transverse exchange coupling $J_{\perp}<J_{\perp c1}$, the ground state shows an antiferromagnetic long-range order with finite staggered magnetizations of both localized spins and conduction electrons. When $J_{\perp}>J_{\perp c2}$, the long-range order is destroyed and the system is in a disordered Kondo singlet state with a hybridization gap. Both ground states can describe the low-temperature phases of Kondo insulating compounds. Between these two distinct phases, there may be a coexistent regime as a result of the balance between local Kondo screening and magnetic interactions. ",Coexisting Kondo singlet state with antiferromagnetic long-range order:   A possible ground state for Kondo insulators
"  In this paper, we study the interactions among interconnected autonomous microgrids, and propose a joint energy trading and scheduling strategy. Each interconnected microgrid not only schedules its local power supply and demand, but also trades energy with other microgrids in a distribution network. Specifically, microgrids with excessive renewable generations can trade with other microgrids in deficit of power supplies for mutual benefits. Since interconnected microgrids operate autonomously, they aim to optimize their own performance and expect to gain benefits through energy trading. We design an incentive mechanism using Nash bargaining theory to encourage proactive energy trading and fair benefit sharing. We solve the bargaining problem by decomposing it into two sequential problems on social cost minimization and trading benefit sharing, respectively. For practical implementation, we propose a decentralized solution method with minimum information exchange overhead. Numerical studies based on realistic data demonstrate that the total cost of the interconnected-microgrids operation can be reduced by up to 13.2% through energy trading, and an individual participating microgrid can achieve up to 29.4% reduction in its cost through energy trading. ",Incentivizing Energy Trading for Interconnected Microgrids
"  We study the vertical extent of propeller structures in Saturn's rings. Our focus lies on the gap region of the propeller and on non-inclined propeller moonlets. In order to describe the vertical structure of propellers we extend the model of Spahn and Sremcevic (2000) to include the vertical direction. We find that the gravitational interaction of ring particles with the non-inclined moonlet does not induce considerable vertical excursions of ring particles, but causes a considerable thermal motion in the ring plane. We expect ring particle collisions to partly convert the lateral induced thermal motion into vertical excursions of ring particles. For the gap region of the propeller, we calculate gap averaged propeller heights on the order of 0.7 Hill radii, which is of the order of the moonlet radius. In our model the propeller height decreases exponentially until viscous heating and collisional cooling balance. We estimate Hill radii of 370m and 615m for the propellers Earhart and Bleriot. Our model predicts about 120km for the azimuthal extent of the Earhart propeller at Saturn's 2009 equinox, being consistent with values determined from Cassini images. ",Vertical structures induced by embedded moonlets in Saturn's rings: the   gap region
"  We focus on the resolved stellar populations of one early- and four transition-type dwarf galaxies in the Sculptor group, with the aim to examine the potential presence of population gradients and place constraints on their mean metallicities. We use deep HST images to construct CMDs, from which we select stellar populations that trace different evolutionary phases in order to constrain their range of ages and metallicities, as well as to examine their spatial distribution. In addition, we use the resolved stars in the RGB in order to derive photometric metallicities. All studied dwarfs contain intermediate-age stars with ages of ~1Gyr and older as traced by the luminous asymptotic giant branch and red clump stars, while the transition-type dwarfs contain also stars younger than ~1Gyr as traced by a young main sequence and vertical red clump stars. Moreover, the spatial distribution of the stars that trace different evolutionary phases shows a population gradient in all transition-type dwarfs. The derived error-weighted mean metallicities, assuming purely old stellar populations, range from -1.5dex for ESO294-G010 to -1.9dex for Scl-dE1, and should be considered as lower limits to their true metallicities. Assuming intermediate-age stellar populations to dominate the dwarfs, we derive upper limits for the metallicities that are 0.3 to 0.2 dex higher than the metallicities derived assuming purely old populations. We discuss how photometric metallicity gradients are affected by the age-metallicity degeneracy, which prevents strong conclusions regarding their actual presence. Finally, the transition-type dwarfs lie beyond the virial radius of their closest bright galaxy, as also observed for the LG transition-type dwarfs. Scl-dE1 is the only dSph in our sample and is an outlier in a potential morphology-distance relation, similar as the two isolated dSphs of the LG, Tucana and Cetus. ",Population gradients and photometric metallicities in early- and   transition-type dwarf galaxies: Clues from the Sculptor group
"  We consider a generic system composed of a fixed number of particles distributed over a finite number of energy levels. We make only general assumptions about system's properties and the entropy. System's constraints other than fixed number of particles can be included by appropriate reduction of system's state space. For the entropy we consider three generic cases. It can have a maximum in the interior of system's state space or on the boundary. On the boundary we can have another two cases. There the entropy can increase linearly with increase of the number of particles and in the another case grows slower than linearly. The main results are approximations of system's sum of states using Laplace's method. Estimates of the error terms are also included. As an application, we prove the law of large numbers which yields the most probable state of the system. This state is the one with the maximal entropy. We also find limiting laws for the fluctuations. These laws are different for the considered cases of the entropy. They can be mixtures of Normal, Exponential and Discrete distributions. Explicit rates of convergence are provided for all the theorems. ",Approximations of the Sum of States by Laplace's Method for a System of   Particles with a Finite Number of Energy Levels and Application to Limit   Theorems
"  A plethora of active matter models exist that describe the behavior of self-propelled particles (or swimmers), both with and without hydrodynamics. However, there are few studies that consider shape-anisotropic swimmers and include hydrodynamic interactions. Here, we introduce a simple method to simulate self-propelled colloids interacting hydrodynamically in a viscous medium using the lattice-Boltzmann technique. Our model is based on raspberry-type viscous coupling and a force/counter-force formalism which ensures that the system is force free. We consider several anisotropic shapes and characterize their hydrodynamic multipolar flow field. We demonstrate that shape-anisotropy can lead to the presence of a strong quadrupole and octupole moments, in addition to the principle dipole moment. The ability to simulate and characterize these higher-order moments will prove crucial for understanding the behavior of model swimmers in confining geometries. ",Lattice-Boltzmann Hydrodynamics of Anisotropic Active Matter
"  In recent years, the mixed phosphates based polyanionic electrode materials have attracted great attention in sodium-ion batteries due to their structural stability during cycling and open framework for ion diffusion. Here, we report the electrochemical performance of Na$_{4}$Co$_{3}$(PO$_{4}$)$_{2}$P$_{2}$O$_{7}$/nitrogen doped carbon (NCPP/NC) composite as a negative electrode (anode) for sodium ion batteries in the working potential range of 0.01--3.0~V. It delivers a reversible discharge capacity of 250~mAhg$^{-1}$ at 0.5~C current rate, which corresponds to the insertion/extraction of four sodium ions. The rate capability study indicates the reversible mechanism and highly stable capacity (61 mAhg$^{-1}$) even at high rate up to 5~C as compared to pristine NCPP. The incorporation of the N doped carbon spheres in the composite is expected to enhance the electronic/ionic conductivity, which plays an important role in improving the performance and stability up to 400 cycles at 1~C rate. Intriguingly, the analysis of cyclic voltammetry data measured at different scan rates confirm the capacitive/diffusive controlled mechanism and the extracted diffusion coefficient is found to be around 10$^{-10}$ cm$^2$s$^{-1}$. Our results demonstrate that the NCPP/NC composite is also a potential candidate as anode in sodium-ion batteries due to its three dimensional framework, cost effectiveness, enhanced specific capacity as well as further possibility of improving the stability. ",Na$_{4}$Co$_{3}$(PO$_{4}$)$_{2}$P$_{2}$O$_{7}$/NC composite as a   negative electrode for sodium-ion batteries
"  The class of locally stationary processes assumes that there is a time-varying spectral representation, that is, the existence of finite second moment. We propose the $\alpha$-stable locally stationary process by modifying the innovations into stable distributions and the indirect inference to estimate this type of model. Due to the infinite variance, some of interesting properties such as time-varying auto-correlation cannot be defined. However, since the $\alpha$-stable family of distributions is closed under linear combination which includes the possibility of handling asymmetry and thicker tails, the proposed model has the same tail behavior throughout the time. In this paper, we propose this new model, present theoretical properties of the process and carry out simulations related to the indirect inference in order to estimate the parametric form of the model. Finally, an empirical application is illustrated. ",Indirect inference for locally stationary ARMA processes with stable   innovations
"  For a $k$-uniform hypergraph $H$, we obtain some trace formulas for the Laplacian tensor of $H$, which imply that $\sum_{i=1}^nd_i^s$ ($s=1,\ldots,k$) is determined by the Laplacian spectrum of $H$, where $d_1,\ldots,d_n$ is the degree sequence of $H$. Using trace formulas for the Laplacian tensor, we obtain expressions for some coefficients of the Laplacian polynomial of a regular hypergraph. We give some spectral characterizations of odd-bipartite hypergraphs, and give a partial answer to a question posed by Shao et al \cite{ShaoShanWu}. We also give some spectral properties of power hypergraphs, and show that a conjecture posed by Hu et al \cite{HuQiShao} holds under certain conditons. ",Some spectral properties of uniform hypergraphs
"  In the present paper, we investigate non-homeomorphic mappings of Riemannian surfaces of Sobolev class. We have obtained some estimates of distortion of moduli of families of curves. As consequence, we have obtained results about the boundary behavior of such mappings between domains on Riemannian surfaces. ",On boundary and global behavior of mappings with branching on Riemannian   surfaces
"  In many real world situations, collective decisions are made using voting and, in scenarios such as committee or board elections, employing voting rules that return multiple winners. In multi-winner approval voting (AV), an agent submits a ballot consisting of approvals for as many candidates as they wish, and winners are chosen by tallying up the votes and choosing the top-$k$ candidates receiving the most approvals. In many scenarios, an agent may manipulate the ballot they submit in order to achieve a better outcome by voting in a way that does not reflect their true preferences. In complex and uncertain situations, agents may use heuristics instead of incurring the additional effort required to compute the manipulation which most favors them. In this paper, we examine voting behavior in single-winner and multi-winner approval voting scenarios with varying degrees of uncertainty using behavioral data obtained from Mechanical Turk. We find that people generally manipulate their vote to obtain a better outcome, but often do not identify the optimal manipulation. There are a number of predictive models of agent behavior in the COMSOC and psychology literature that are based on cognitively plausible heuristic strategies. We show that the existing approaches do not adequately model real-world data. We propose a novel model that takes into account the size of the winning set and human cognitive constraints, and demonstrate that this model is more effective at capturing real-world behaviors in multi-winner approval voting scenarios. ",Modeling Voters in Multi-Winner Approval Voting
"  Text to speech (TTS) and automatic speech recognition (ASR) are two dual tasks in speech processing and both achieve impressive performance thanks to the recent advance in deep learning and large amount of aligned speech and text data. However, the lack of aligned data poses a major practical problem for TTS and ASR on low-resource languages. In this paper, by leveraging the dual nature of the two tasks, we propose an almost unsupervised learning method that only leverages few hundreds of paired data and extra unpaired data for TTS and ASR. Our method consists of the following components: (1) a denoising auto-encoder, which reconstructs speech and text sequences respectively to develop the capability of language modeling both in speech and text domain; (2) dual transformation, where the TTS model transforms the text $y$ into speech $\hat{x}$, and the ASR model leverages the transformed pair $(\hat{x},y)$ for training, and vice versa, to boost the accuracy of the two tasks; (3) bidirectional sequence modeling, which addresses error propagation especially in the long speech and text sequence when training with few paired data; (4) a unified model structure, which combines all the above components for TTS and ASR based on Transformer model. Our method achieves 99.84% in terms of word level intelligible rate and 2.68 MOS for TTS, and 11.7% PER for ASR on LJSpeech dataset, by leveraging only 200 paired speech and text data (about 20 minutes audio), together with extra unpaired speech and text data. ",Almost Unsupervised Text to Speech and Automatic Speech Recognition
"  We describe the design and deployment of GREENBURST, a commensal Fast Radio Burst (FRB) search system at the Green Bank Telescope. GREENBURST uses the dedicated L-band receiver tap to search over the 960$-$1920 MHz frequency range for pulses with dispersion measures out to $10^4$ pc cm$^{-3}$. Due to its unique design, GREENBURST will obtain data even when the L-band receiver is not being used for scheduled observing. This makes it a sensitive single pixel detector capable of reaching deeper in the radio sky. While single pulses from Galactic pulsars and rotating radio transients will be detectable in our observations, and will form part of the database we archive, the primary goal is to detect and study FRBs. Based on recent determinations of the all-sky rate, we predict that the system will detect approximately one FRB for every 2$-$3 months of continuous operation. The high sensitivity of GREENBURST means that it will also be able to probe the slope of the FRB source function, which is currently uncertain in this observing band. ",GREENBURST: a commensal fast radio burst search back-end for the Green   Bank Telescope
"  Suspensions of superheated superconducting grains are a detecting composite material. Each grain in the supension is a microcalorimeter with an energy threshold defined by its equatorial magnetic field for a given temperature. The higher the matrix density, the larger the gamma stopping power. For several years, cylindrical cells of such suspensions about 2 cm long and 0.4 mm in diameter can be read out in real time. As a result, using two independent cells, one can record a time coincidence between them. This could be potentially very useful for positron cameras where two diametrically opposite cells are simultaneously knocked by 511 keV gammas. This paper, based on the state of art in SSG in high density matrix, discusses such a feasibility. ",Preliminary Study of the Feasibility of a Non Crystalline Positron   Emission Tomography Using a Suspension of Superheated Superconducting Grains   (SSG) in High Density Dielectric Matrix (HDDM) as Detector
"  We present three Far Ultraviolet Spectroscopic Explorer (FUSE) observations of the Narrow-Line Seyfert 1 galaxy NGC4051. The most prominent features in the far-ultraviolet (FUV) spectrum are the OVI emission and absorption lines and the HI Lyman series absorption lines which are detected up to the Lyman edge. We also identify weak emission from NIII, CIII, and HeII. The CIII line shows absorption while none is detected in the NIII and HeII lines. In HI and CIII we detect two main absorption systems at outflow velocities of -50+/-30 and -240+/-40 km/s, as well as a possible third one at ~ -450 km/s. These systems are consistent in velocity with the 10 absorption systems found previously in CIV, NV, and SiIV, though the individual systems are blended together in the FUV spectrum. We estimate column densities of the two main absorption systems and find that the HI column density is lower for systems with larger outflow velocity. We detect no flux or spectral variations of NGC4051 at FUV wavelengths during three epochs spanning one year. This is consistent with the optical light curve which shows no variations between the three epochs. It is also consistent with the X-ray light curve which shows consistent flux levels at the three epochs of the FUSE observations, although the X-ray light curve shows strong variations on much shorter timescales. ",Far Ultraviolet Spectroscopic Explorer Spectroscopy of Absorption and   Emission Lines from the Narrow-Line Seyfert 1 Galaxy NGC 4051
"  I review the AdS/hydrodynamics correspondence, which provides a 1-1 map between large wavelength features of AdS black branes and conformal fluid flows. In this thesis I consider boundaries between nonrelativistic flows, applying the usual boundary conditions for viscous fluids. I find that a naive application of the correspondence to these boundaries yields a surface layer in the gravity theory whose stress tensor is not equal to that given by the Israel matching conditions. In particular, while neither stress tensor satisfies the null energy condition and both have nonvanishing momentum, only Israel's tensor has stress. The disagreement arises entirely from corrections to the metric due to multiple derivatives of the flow velocity, which violate Israel's finiteness assumption in the thin wall limit. ",Surface Layers in the Gravity/Hydrodynamics Correspondence
"  The visualization advantages of ternary plots are illustrated for the PMNS neutrino mixing matrix. Unitarity constraints are incorporated automatically, in part, since barycentric plots of this type allow three variables with a fixed sum to be plotted as mere points inside an equilateral triangle on a plane. ",Ternary Plots for Neutrino Mixing Visualization
"  The linear motor driving the target for the Muon Ionisation Cooling Experiment has been redesigned to improve its reliability and performance. A new coil-winding technique is described which produces better magnetic alignment and improves heat transport out of the windings. Improved field-mapping has allowed the more precise construction to be demonstrated, and an enhanced controller exploits the full features of the hardware, enabling increased acceleration and precision. The new user interface is described and analysis of performance data to monitor friction is shown to allow quality control of bearings and a measure of the ageing of targets during use. ",The design and performance of an improved target for MICE
"  We study the probability that the origin is connected to the sphere of radius r (an arm event) in critical percolation in high dimensions, namely when the dimension d is large enough or when d>6 and the lattice is sufficiently spread out. We prove that this probability decays like 1/r^2. Furthermore, we show that the probability of having k disjoint arms to distance r emanating from the vicinity of the origin is 1/r^2k. ",Arm exponents in high dimensional percolation
"  We prove the equivalence between the simplicial Orlicz cohomology and the Orlicz-de Rham cohomology in the case of Lie groups. Since the first one is a quasi-isometry invariant for uniformly contractible simplicial complexes with bounded geometry, we obtain the invariance of the second one in the case of contractible Lie groups. We also define the Orlicz cohomology of a Gromov-hyperbolic space relative to a point on its boundary at infinity, for which the same results are true. ",De Rham's theorem for Orlicz cohomology in the case of Lie groups
"  Non-line-of-sight (NLOS) imaging techniques use light that diffusely reflects off of visible surfaces (e.g., walls) to see around corners. One approach involves using pulsed lasers and ultrafast sensors to measure the travel time of multiply scattered light. Unlike existing NLOS techniques that generally require densely raster scanning points across the entirety of a relay wall, we explore a more efficient form of NLOS scanning that reduces both acquisition times and computational requirements. We propose a circular and confocal non-line-of-sight (C2NLOS) scan that involves illuminating and imaging a common point, and scanning this point in a circular path along a wall. We observe that (1) these C2NLOS measurements consist of a superposition of sinusoids, which we refer to as a transient sinogram, (2) there exists computationally efficient reconstruction procedures that transform these sinusoidal measurements into 3D positions of hidden scatterers or NLOS images of hidden objects, and (3) despite operating on an order of magnitude fewer measurements than previous approaches, these C2NLOS scans provide sufficient information about the hidden scene to solve these different NLOS imaging tasks. We show results from both simulated and real C2NLOS scans. ",Efficient Non-Line-of-Sight Imaging from Transient Sinograms
"  The E_8-manifold has several natural framed link descriptions, and we give an efficient method (via `grapes') for showing that they are indeed the same 4-manifold. This leads to explicit handle pictures for the perturbation of singular fibers in an elliptic surface to a collection of fishtails. In the same vein, we show how the degeneration of a regular fiber to a singular fiber in an elliptic surface provides rich examples of Gromov's compactness theorem. ","The E_8-manifold, singular fibers and handlebody decompositions"
"  We present Hubble Space Telescope/WFPC2 images of sixteen dwarf galaxies as part of our snapshot survey of nearby galaxy candidates. We derive their distances from the luminosity of the tip of the red giant branch stars with a typical accuracy of ~12%. The resulting distances are 4.26 Mpc (KKH 5), 4.74 Mpc (KK 16), 4.72 Mpc (KK 17), 4.66 Mpc (ESO 115-021), 4.43 Mpc (KKH 18), 3.98 Mpc (KK 27), 4.61 Mpc (KKH 34), 4.99 Mpc (KK 54), 4.23 Mpc (ESO 490-017), 4.90 Mpc (FG 202), 5.22 Mpc (UGC 3755), 5.18 Mpc (UGC 3974), 4.51 Mpc (KK 65), 5.49 Mpc (UGC 4115), 3.78 Mpc (NGC 2915), and 5.27 Mpc (NGC 6503). Based on distances and radial velocities of 156 nearby galaxies, we plot the local velocity-distance relation, which has a slope of H_0 = 73 km/(c * Mpc) and a radial velocity dispersion of 85 km/s. When members of the M81 and CenA groups are removed, and distance errors are taken into account, the radial velocity dispersion drops to sigma_v=41 km/s. The local Hubble flow within 5 Mpc exibits a significant anisotropy, with two infall peculiar velocity regions directed towards the Supergalactic poles. However, two observed regions of outflow peculiar velocity, situated on the Supergalactic equator, are far away (~50 degr.) from the Virgo/anti-Virgo direction, which disagrees with a spherically symmetric Virgo-centric flow. About 63% of galaxies within 5 Mpc belong to known compact and loose groups. Apart from them, we found six new probable groups, consisting entirely of dwarf galaxies. ",Local galaxy flows within 5 Mpc
"  Adiabatic cyclic modulation of a one-dimensional periodic potential will result in quantized charge transport, which is termed the Thouless pump. In contrast to the original Thouless pump restricted by the topology of the energy band, here we experimentally observe a generalized Thouless pump that can be extensively and continuously controlled. The extraordinary features of the new pump originate from interband coherence in nonequilibrium initial states, and this fact indicates that a quantum superposition of different eigenstates individually undergoing quantum adiabatic following can also be an important ingredient unavailable in classical physics. The quantum simulation of this generalized Thouless pump in a two-band insulator is achieved by applying delicate control fields to a single spin in diamond. The experimental results demonstrate all principal characteristics of the generalized Thouless pump. Because the pumping in our system is most pronounced around a band-touching point, this work also suggests an alternative means to detect quantum or topological phase transitions. ",Experimental Observation of a Generalized Thouless Pump with a Single   Spin
"  Assessment of cardiovascular disease (CVD) with cine magnetic resonance imaging (MRI) has been used to non-invasively evaluate detailed cardiac structure and function. Accurate segmentation of cardiac structures from cine MRI is a crucial step for early diagnosis and prognosis of CVD, and has been greatly improved with convolutional neural networks (CNN). There, however, are a number of limitations identified in CNN models, such as limited interpretability and high complexity, thus limiting their use in clinical practice. In this work, to address the limitations, we propose a lightweight and interpretable machine learning model, successive subspace learning with the subspace approximation with adjusted bias (Saab) transform, for accurate and efficient segmentation from cine MRI. Specifically, our segmentation framework is comprised of the following steps: (1) sequential expansion of near-to-far neighborhood at different resolutions; (2) channel-wise subspace approximation using the Saab transform for unsupervised dimension reduction; (3) class-wise entropy guided feature selection for supervised dimension reduction; (4) concatenation of features and pixel-wise classification with gradient boost; and (5) conditional random field for post-processing. Experimental results on the ACDC 2017 segmentation database, showed that our framework performed better than state-of-the-art U-Net models with 200$\times$ fewer parameters in delineating the left ventricle, right ventricle, and myocardium, thus showing its potential to be used in clinical practice. ",Segmentation of Cardiac Structures via Successive Subspace Learning with   Saab Transform from Cine MRI
"  Transverse waves are sometimes observed in solar helmet streamers, typically after the passage of a coronal mass ejection (CME). The CME-driven shock wave moves the streamer sideways, and a decaying oscillation of the streamer is observed after the CME passage. Previous works generally reported observations of streamer oscillations taken from a single vantage point (typically the SOHO spacecraft). We conduct a data survey searching for streamer wave events observed by the COR2 coronagraphs onboard the STEREO spacecraft. For the first time, we report observations of streamer wave events from multiple vantage points, by using the COR2 instrument on both STEREO A and B, as well as the SOHO/LASCO C2+C3 coronagraphs. We investigate the properties of streamer waves by comparing the different events and performing a statistical analysis. Common observational features give us additional insight on the physical nature of streamer wave events. The most important conclusion is that there appears to be no relation between the speed of the CME and the phase speed of the resulting streamer wave, indicating that the streamer wave speed is determined by the physical properties of the streamer rather than the properties of the CME. This result makes streamer waves events excellent candidates for coronal seismology studies. From a comparison between the measured phase speeds and the phase speeds calculated from the measured periods and wavelengths, we could determine that the speed of the post-shock solar wind flow in our streamers is around 300 $\mathrm{km \ s}^{-1}$. ",Properties of Streamer Wave Events Observed During the STEREO Era
"  We study perfect state transfer of quantum walks on signed graphs. Our aim is to show that negative edges are useful for perfect state transfer. Specific results we prove include: (1) The signed join of a negative 2-clique with any positive (n,3)-regular graph has perfect state transfer even if the unsigned join does not. Curiously, the perfect state transfer time improves as n increases. (2) A signed complete graph has perfect state transfer if its positive subgraph is a regular graph with perfect state transfer and its negative subgraph is periodic. This shows that signing is useful for creating perfect state transfer since no complete graph (except for the 2-clique) has perfect state transfer. (3) The double-cover of a signed graph has perfect state transfer if the positive subgraph has perfect state transfer and the negative subgraph is periodic. Here, signing is useful for constructing unsigned graphs with perfect state transfer. Furthermore, we study perfect state transfer on a family of signed graphs called the exterior powers which is derived from a many-fermion quantum walk on graphs. ",Perfect State Transfer on Signed Graphs
"  Evolution of fuel droplet evaporation zone and its interaction with the propagating flame front are studied in this work. A general theory is developed to describe the evolutions of flame propagation speed, flame temperature, droplet evaporation onset and completion locations in ignition and propagation of spherical flames. The influences of liquid droplet mass loading, heat exchange coefficient (or evaporation rate) and Lewis number on spherical spray flame ignition are studied. Two flame regimes are considered, i.e., heterogeneous and homogeneous flames, based on the mixture condition near the flame front. The results indicate that the spray flame trajectories are considerably affected by the ignition energy addition. The critical condition for successful ignition for the fuel-rich mixture is coincidence of inner and outer flame balls from igniting kernel and propagating flame. The flame balls always exist in homogeneous mixtures, indicating that ignition failure and critical successful events occur only in purely gaseous mixture. The fuel droplets have limited effects on minimum ignition energy, which however increases monotonically with the Lewis number. Moreover, flame kernel originates from heterogeneous mixtures due to the initially dispersed droplets near the spark. The evaporative heat loss in the burned and unburned zones of homogeneous and heterogeneous spray flames is also evaluated, and the results show that for the failed flame kernels, evaporative heat loss behind and before the flame front first increases and then decreases. The evaporative heat loss before the flame front generally increases, although non-monotonicity exists, when the flame is successfully ignited and propagate outwardly. For heterogeneous flames, the ratio of the heat loss from the burned zone to the total one decreases as the flame expands. ",On the evolution of fuel droplet evaporation zone and its interaction   with the flame front in ignition of spray flames
  We calculate the total cross section for $\pi N \to J/\Psi N$ based on $\rho$-meson exchange. On the basis of this calculation we predict a maximal reaction rate arising from the OZI-violating $J/\Psi{\leftrightarrow}\rho\pi$ vertex in tree-level. Our estimate for the maximum reaction rate is still one order of magnitude smaller than the existing predictions which were based on the other OZI-violating mechanisms. ,J/\Psi production in \pi N collisions
"  Power allocation in spectrum sharing systems is challenging due to excessive interference that the secondary system could impose on the primary system. Therefore, an interference threshold constraint is considered to regulate the secondary system's activity. However, the primary receivers should measure the interference and inform the secondary users accordingly. These cause design complexities, e.g., due to transceiver's hardware impairments, and impose a substantial signaling overhead. We set our main goal to mitigate these requirements in order to make the spectrum sharing systems practically feasible. To cope with the lack of a model we develop a coexisting deep reinforcement learning approach for continuous power allocation in both systems. Importantly, via our solution, the two systems allocate power merely based on geographical location of their users. Moreover, the inter-system signaling requirement is reduced to exchanging only the number of primary users that their QoS requirements are violated. We observe that compared to a centralized agent that allocates power based on full (accurate) channel information, our solution is more robust and strictly guarantees QoS requirements of the primary users. This implies that both systems can operate simultaneously with almost-zero inter-system signaling overhead. ",Power Control in Spectrum Sharing Systems with Almost-Zero Inter-System   Signaling Overhead
"  We propose a policy improvement algorithm for Reinforcement Learning (RL) which is called Rerouted Behavior Improvement (RBI). RBI is designed to take into account the evaluation errors of the Q-function. Such errors are common in RL when learning the $Q$-value from finite past experience data. Greedy policies or even constrained policy optimization algorithms which ignore these errors may suffer from an improvement penalty (i.e. a negative policy improvement). To minimize the improvement penalty, the RBI idea is to attenuate rapid policy changes of low probability actions which were less frequently sampled. This approach is shown to avoid catastrophic performance degradation and reduce regret when learning from a batch of past experience. Through a two-armed bandit with Gaussian distributed rewards example, we show that it also increases data efficiency when the optimal action has a high variance. We evaluate RBI in two tasks in the Atari Learning Environment: (1) learning from observations of multiple behavior policies and (2) iterative RL. Our results demonstrate the advantage of RBI over greedy policies and other constrained policy optimization algorithms as a safe learning approach and as a general data efficient learning algorithm. An anonymous Github repository of our RBI implementation is found at https://github.com/eladsar/rbi. ",Constrained Policy Improvement for Safe and Efficient Reinforcement   Learning
"  By INF we mean Quine's NF set theory, with intuitionistic logic. We define the Church numerals (or better, Church numbers) and elaborate their properties in INF. The Church counting axiom says that iterating successor $n$ times, starting at zero, results in $n$. With the aid of the counting axiom we prove that the set of Church numbers is infinite. This is a new result even with classical logic; that is, just because there is some infinite set, it is not immediate that the set of Church numbers is infinite. Specker showed in 1953 that classical NF proves the existence of an infinite set. It has long been an open problem whether INF can prove that. Now we show that it can be done intuitionistically, with the aid of the Church counting axiom. We also prove, without the aid of the counting axiom, that if the set of Church numbers is not finite, then it is infinite, and Church successor is one-to-one. Consequently, Heyting's arithmetic is interpretable in INF plus the Church counting axiom. ",The Church numbers in NF set theory
"  Due to the rapid longitudinal expansion of the quark-gluon plasma created in heavy-ion collisions, large local-rest-frame momentum-space anisotropies are generated during the system's evolution. These momentum-space anisotropies complicate the modeling of heavy-quarkonium dynamics in the quark-gluon plasma due to the fact that the resulting inter-quark potentials are spatially anisotropic, requiring real-time solution of the 3D Schr\""odinger equation. Herein, we introduce a method for reducing anisotropic heavy-quark potentials to isotropic ones by introducing an effective screening mass that depends on the quantum numbers $l$ and $m$ of a given state. We demonstrate that, using the resulting effective Debye screening masses, one can solve a 1D Schr\""odinger equation and reproduce the full 3D results for the energies and binding energies of low-lying heavy-quarkonium bound states to relatively high accuracy. The resulting effective isotropic potential models could provide an efficient method for including momentum-anisotropy effects in open quantum system simulations of heavy-quarkonium dynamics in the quark-gluon plasma. ",Effective Debye Screening Mass in an Anisotropic Quark Gluon Plasma
"  Many psychological experiments have subjects repeat a task to gain the statistical precision required to test quantitative theories of psychological performance. In such experiments, time-on-task can have sizable effects on performance, changing the psychological processes under investigation. Most research has either ignored these changes, treating the underlying process as static, or sacrificed some psychological content of the models for statistical simplicity. We use particle Markov chain Monte-Carlo methods to study psychologically plausible time-varying changes in model parameters. Using data from three highly-cited experiments we find strong evidence in favor of a hidden Markov switching process as an explanation of time-varying effects. This embodies the psychological assumption of ""regime switching"", with subjects alternating between different cognitive states representing different modes of decision-making. The switching model explains key long- and short-term dynamic effects in the data. The central idea of our approach can be applied quite generally to quantitative psychological theories, beyond the models and data sets that we investigate. ",Time-evolving psychological processes over repeated decisions
"  Many dense magnetic nanoparticle systems exhibit slow dynamics which is qualitatively indistinguishable from that observed in atomic spin glasses and its origin is attributed to dipole interactions among particle moments (or superspins). However, even in dilute nanoparticle systems where the dipole interactions are vanishingly small, slow dynamics is observed and is attributed solely to a broad distribution of relaxation times which in turn comes from that of the anisotropy energy barriers. To clarify characteristic differences between the two types of slow dynamics, we study a simple model of a non-interacting nanoparticle system (a superparamagnet) analytically as well as ferritin (a superparamagnet) and a dense Fe-N nanoparticle system (a superspin glass) experimentally. It is found that superparamagnets in fact show aging (a waiting time dependence) of the thermoremanent-magnetization as well as various memory effects. We also find some dynamical phenomena peculiar only to superspin glasses such as the flatness of the field-cooled magnetization below the critical temperature and memory effects in the zero-field-cooled magnetization. These dynamical phenomena are qualitatively reproduced by the random energy model, and are well interpreted by the so-called droplet theory in the field of the spin-glass study. ",Aging and Memory Effects in Superparamagnets and Superspin Glasses
"  The lowest excitation energies of the given multipole J^pi state (the J^pi yrast energies) are given for even-even nuclei throughout the entire periodic table. The yrast energies were calculated using the recently proposed empirical formula that depends only on the mass number A, and the valence nucleon numbers Np and Nn. We provide a complete tabulation and plots of the yrast energies calculated using the empirical formula together with the ones measured for the natural parity states up to 10+ and for the unnatural parity states up to 10^+ with the hope of encouraging active study on the possible origin of the relationship between the yrast energies, as revealed by the empirical formula. ",Empirical predictions of yrast energies in even-even nuclei
"  Host-based anomaly detectors generate alarms by inspecting audit logs for suspicious behavior. Unfortunately, evaluating these anomaly detectors is hard. There are few high-quality, publicly-available audit logs, and there are no pre-existing frameworks that enable push-button creation of realistic system traces. To make trace generation easier, we created Xanthus, an automated tool that orchestrates virtual machines to generate realistic audit logs. Using Xanthus' simple management interface, administrators select a base VM image, configure a particular tracing framework to use within that VM, and define post-launch scripts that collect and save trace data. Once data collection is finished, Xanthus creates a self-describing archive, which contains the VM, its configuration parameters, and the collected trace data. We demonstrate that Xanthus hides many of the tedious (yet subtle) orchestration tasks that humans often get wrong; Xanthus avoids mistakes that lead to non-replicable experiments. ",Xanthus: Push-button Orchestration of Host Provenance Data Collection
"  The expected possession value (EPV) of a soccer possession represents the likelihood of a team scoring or receiving the next goal at any time instance. By decomposing the EPV into a series of subcomponents that are estimated separately, we develop a comprehensive analysis framework providing soccer practitioners with the ability to evaluate the impact of both observed and potential actions. We show we can obtain calibrated models for all the components of EPV, including a set of yet-unexplored problems in soccer. We produce visually-interpretable probability surfaces for potential passes from a series of deep neural network architectures that learn from low-level spatiotemporal data. Additionally, we present a series of novel practical applications providing coaches with an enriched interpretation of specific game situations. ",A framework for the fine-grained evaluation of the instantaneous   expected value of soccer possessions
"  We propose a quantitative criterion to determine whether the coupled quantum systems can achieve complete synchronization or phase synchronization in the process of analyzing quantum synchronization. Adopting the criterion, we discuss the quantum synchronization effects between optomechanical systems and find that the error between the systems and the fluctuation of error are sensitive to coupling intensity by calculating the largest Lyapunov exponent of the model and quantum fluctuation, respectively. Through taking the appropriate coupling intensity, we can control quantum synchronization even under different logical relationship between switches. Finally, we simulate the dynamical evolution of the system to verify the quantum synchronization criterion and to show the ability of synchronization control. ",Criterion of quantum synchronization and controllable quantum   synchronization based on an optomechanical system
"  We point out two ways to search for low-mass axion dark matter using cosmic microwave background (CMB) polarization measurements. These appear, in particular, to be some of the most promising ways to directly detect fuzzy dark matter. Axion dark matter causes rotation of the polarization of light passing through it. This gives rise to two novel phenomena in the CMB. First, the late-time oscillations of the axion field today cause the CMB polarization to oscillate in phase across the entire sky. Second, the early-time oscillations of the axion field wash out the polarization produced at last-scattering, reducing the polarized fraction (TE and EE power spectra) compared to the standard prediction. Since the axion field is oscillating, the common (static) `cosmic birefringence' search is not appropriate for axion dark matter. These two phenomena can be used to search for axion dark matter at the lighter end of the mass range, with a reach several orders of magnitude beyond current constraints. We set a limit from the washout effect using existing Planck results, and find significant future discovery potential for CMB detectors searching in particular for the oscillating effect. ",Axion Dark Matter Detection with CMB Polarization
"  We show that by capping Co nanoparticles with small amounts of Pt strong changes of the magnetic properties can be induced. The Co nanoparticles have a mean diameter of 2.7 nm. From magnetometry measurements we find that for zero and for small amounts of Pt (nominal thickness t(Pt) < 0.7 nm) the nanoparticles behave superparamagnetic like. With increasing t(Pt) the blocking temperature is enhanced from 16 up to 108 K. Capping with Pd yields comparable results. However, for values t(Pt) > 1 nm a strongly coupled state is encountered resembling a ferromagnet with a T_c approx. 400 K ",Tuning the magnetic properties of Co nanoparticles by Pt capping
"  The purpose of this short paper is to identify the mathematical essence of the superiorization methodology. This methodology has been developed in recent years while attempting to solve specific application-oriented problems. Consequently, superiorization is often presented using the terminology of such problems. A more general approach is provided here by discussing ideas related to superiorization in terms of an abstract mathematical concept, referred to as a problem structure. ",Problem Structures in the Theory and Practice of Superiorization
"  Driven by applications like Micro Aerial Vehicles (MAVs), driver-less cars, etc, localization solution has become an active research topic in the past decade. In recent years, Ultra Wideband (UWB) emerged as a promising technology because of its impressive performance in both indoor and outdoor positioning. But algorithms relying only on UWB sensor usually result in high latency and low bandwidth, which is undesirable in some situations such as controlling a MAV. To alleviate this problem, an Extended Kalman Filter (EKF) based algorithm is proposed to fuse the Inertial Measurement Unit (IMU) and UWB, which achieved 80Hz 3D localization with significantly improved accuracy and almost no delay. To verify the effectiveness and reliability of the proposed approach, a swarm of 6 MAVs is set up to perform a light show in an indoor exhibition hall. Video and source codes are available at https://github.com/lijx10/uwb-localization ",Accurate 3D Localization for MAV Swarms by UWB and IMU Fusion
"  We study the amount and distribution of dark matter substructures within dark matter haloes, using a large set of high-resolution simulations ranging from group size to cluster size haloes, and carried our within a cosmological model consistent with WMAP 7-year data. In particular, we study how the measured properties of subhaloes vary as a function of the parent halo mass, the physical properties of the parent halo, and redshift. The fraction of halo mass in substructures increases with increasing mass. There is, however, a very large halo-to-halo scatter that can be explained only in part by a range of halo physical properties, e.g. concentration. At given halo mass, less concentrated haloes contain significantly larger fractions of mass in substructures because of the reduced strength of tidal disruption. Most of the substructure mass is located at the outskirts of the parent haloes, in relatively few massive subhaloes. This mass segregation appears to become stronger at increasing redshift, and should reflect into a more significant mass segregation of the galaxy population at different cosmic epochs. When haloes are accreted onto larger structures, their mass is significantly reduced by tidal stripping. Haloes that are more massive at the time of accretion (these should host more luminous galaxies) are brought closer to the centre on shorter time-scales by dynamical friction, and therefore suffer of a more significant stripping. The halo merger rate depends strongly on the environment with substructure in more massive haloes suffering more important mergers than their counterparts residing in less massive systems. This should translate into a different morphological mix for haloes of different mass. ",Statistics of Substructures in Dark Matter Haloes
"  Tang and Ding \cite{X. Tang} present a series of quaternary sequences $w(a, b)$ interleaved by two binary sequences $a$ and $b$ with ideal autocorrelation and show that such interleaved quaternary sequences have optimal autocorrelation. In this paper we consider the 4-adic complexity $FC_{w}(4)$ of such quaternary sequence $w=w(a, b)$. We present a general formula on $FC_{w}(4)$, $w=w(a, b)$. As a direct consequence, we obtain a general lower bound $FC_{w}(4)\geq\log_{4}(4^{n}-1)$ where $2n$ is the period of the sequence $w$. By taking $a$ and $b$ to be several types of known binary sequences with ideal autocorrelation ($m$-sequences, twin-prime, Legendre, Hall sequences and their complement, shift or sample sequences), we compute the exact values of $FC_{w}(4)$, $w=w(a, b)$ and show that in most cases $FC_{w}(4)$ reaches or nearly reaches the maximum value $\log_{4}(4^{2n}-1)$. Our results show that the 4-adic complexity of the quaternary sequences defined in \cite{X. Tang} are large enough to resist the attack of the rational approximation algorithm. ",4-Adic Complexity of Interleaved Quaternary Sequences
"  We consider the asymptotic behavior of solutions to the Cauchy problem for the defocusing nonlinear Klein-Gordon equation (NLKG) with exponential nonlinearity in the one spatial dimension with data in the energy space $H^1(\mathbb{R}) \times L^2(\mathbb{R})$. We prove that any energy solution has a global bound of the $L^6_{t,x}$ space-time norm, and hence scatters in $H^1(\mathbb{R}) \times L^2(\mathbb{R})$ as $t\rightarrow\pm \infty$. The proof is based on the argument by Killip-Stovall-Visan (Trans. Amer. Math. Soc. 364 (2012), no. 3, 1571--1631). However, since well-posedness in $H^{1/2}(\mathbb{R}) \times H^{-1/2}(\mathbb{R})$ for NLKG with the exponential nonlinearity holds only for small initial data, we use the $L_t^6 W^{s-1/2,6}_x$-norm for some $s>\frac{1}{2}$ instead of the $L_{t,x}^6$-norm, where $W_x^{s,p}$ denotes the $s$-th order $L^p$-based Sobolev space. ",Scattering for the one-dimensional Klein-Gordon equation with   exponential nonlinearity
"  With millions of apps that can be downloaded from official or third-party market, Android has become one of the most popular mobile platforms today. These apps help people in all kinds of ways and thus have access to lots of user's data that in general fall into three categories: sensitive data, data to be shared with other apps, and non-sensitive data not to be shared with others. For the first and second type of data, Android has provided very good storage models: an app's private sensitive data are saved to its private folder that can only be access by the app itself, and the data to be shared are saved to public storage (either the external SD card or the emulated SD card area on internal FLASH memory). But for the last type, i.e., an app's non-sensitive and non-shared data, there is a big problem in Android's current storage model which essentially encourages an app to save its non-sensitive data to shared public storage that can be accessed by other apps. At first glance, it seems no problem to do so, as those data are non-sensitive after all, but it implicitly assumes that app developers could correctly identify all sensitive data and prevent all possible information leakage from private-but-non-sensitive data. In this paper, we will demonstrate that this is an invalid assumption with a thorough survey on information leaks of those apps that had followed Android's recommended storage model for non-sensitive data. Our studies showed that highly sensitive information from billions of users can be easily hacked by exploiting the mentioned problematic storage model. Although our empirical studies are based on a limited set of apps, the identified problems are never isolated or accidental bugs of those apps being investigated. On the contrary, the problem is rooted from the vulnerable storage model recommended by Android. To mitigate the threat, we also propose a defense framework. ",An Empirical Study on Android for Saving Non-shared Data on Public   Storage
"  The Cell Network Model is a fracture model recently introduced that resembles the microscopical structure and drying process of the parenchymatous tissue of the Bamboo Guadua angustifolia. The model exhibits a power-law distribution of avalanche sizes, with exponent -3.0 when the breaking thresholds are randomly distributed with uniform probability density. Hereby we show that the same exponent also holds when the breaking thresholds obey a broad set of Weibull distributions, and that the humidity decrements between successive avalanches (the equivalent to waiting times for this model) follow in all cases an exponential distribution. Moreover, the fraction of remaining junctures shows an exponential decay in time. In addition, introducing partial breakings and cumulative damages induces a crossover behavior between two power-laws in the avalanche size histograms. This results support the idea that the Cell Network Model may be in the same universality class as the Random Fuse Model. ",Size distribution and waiting times for the avalanches of the Cell   Network Model of Fracture
  We overview a possible mechanism for confining but chirally symmetric matter at low temperatures and large densities. As a new development we employ a diffused quark Fermi surface and show that such diffusion does not destroy possible existence of a confining but chirally symmetric matter at low temperatures and large density. ,Chiral restoration phase transition within the quarkyonic matter
"  We highlight the different uses of the word 'likelihood' that have arisen in statistics and meteorology, and make the recommendation that one of these uses should be dropped to prevent confusion and misunderstanding. ",A note on the use of the word 'likelihood' in statistics and meteorology
"  Ensembles of negatively charged nitrogen vacancy centers (NV-) in diamond have been proposed for sensing of magnetic fields and paramagnetic agents, and as a source of spin-order for the hyperpolarization of nuclei in magnetic resonance applications. To this end, strongly fluorescent nanodiamonds represent promising materials, with large surface areas and dense ensembles of NV-. However, surface effects tend to favor the less useful neutral form, the NV0 centers. Here, we study the fluorescence properties and optically detected magnetic resonance (ODMR) of NV- centers as a function of laser power in strongly fluorescent bulk diamond and in nanodiamonds obtained by nanomilling the native material. In bulk diamond, we find that increasing laser power increases ODMR contrast, consistent with a power-dependent increase in spin-polarization. Surprisingly, in nanodiamonds we observe a non-monotonic behavior, with a decrease in ODMR contrast at higher laser power that can be ascribed to more efficient NV- -> NV0 photoconversion in nanodiamonds compared to bulk diamond, resulting in depletion of the NV- pool. We also studied this phenomenon in cell cultures following internalization of NDs in macrophages. Our findings show that surface effects in nanodiamonds substantially affect the NV properties and provide indications for the adjustment of experimental parameters. ",Divergent effects of laser irradiation on ensembles of nitrogen-vacancy   centers in bulk and nano-diamonds: implications for biosensing
"  We investigate the connections between some simple Maier-Saupe lattice models, with a discrete choice of orientations of the microscopic directors, and a recent proposal of a two-tensor formalism to describe the phase diagrams of nematic liquid-crystalline systems. This two-tensor proposal is used to formulate the statistical problem in terms of fully-connected lattice Hamiltonians, with the local nematic directors restricted to the Cartesian axes. Depending on the choice of interaction parameters, we regain all of the main features of the original mean-field two-tensor calculations. With a standard choice of parameters, we obtain the well-known sequence of isotropic, uniaxial, and biaxial nematic structures, with a Landau multicritical point. With another suitably chosen set of parameters, we obtain two tricritical points, according to some recent predictions of the two-tensor calculations. The simple statistical lattice models are quite easy to work with, for all values of parameters, and the present calculations can be carried out beyond the mean-field level. ",Lattice statistical models for the nematic transitions in   liquid-crystalline systems
"  Molecular dynamics (MD) studies of buffalo prion protein (BufPrP$^\text{C}$) [Zhang JP et al.(2016) J Biomol Struct Dyn 34(4):762-777] showed that the structure of this protein is very stable at room temperature (whether under neutral pH or low pH environments). In order to understand the reason why buffalo is lowly susceptible to prion diseases and why BufPrP$^\text{C}$ is so stable at room temperature, this paper will prolong our MD running time at room temperature and extend our research to higher temperatures to study this BufPrP$^\text{C}$ structure furthermore. From the salt bridge point of view we found an important reason why BufPrP$^\text{C}$ is so stable at room temperature and this might be a nice clue of drug discovery or drug design for the treatment of prion diseases. ",Molecular Dynamics Studies of the Bufallo Prion Protein Structured   Region at Higher Temperatures
  We consider a body in a parallel flow of non-interacting particles. One can imagine that the flow is highly rarefied or consists of light rays. The interaction of particles with the body is perfectly elastic. We introduce the notions of a body of zero resistance and an invisible body and prove that all such bodies do exist. ,Bodies invisible in one direction and bodies of zero total cross section
"  For a recently derived pairwise model of network epidemics with non-Markovian recovery, we prove that under some mild technical conditions on the distribution of the infectious periods, smaller variance in the recovery time leads to higher reproduction number, and consequently to a larger epidemic outbreak, when the mean infectious period is fixed. We discuss how this result is related to various stochastic orderings of the distributions of infectious periods. The results are illustrated by a number of explicit stochastic simulations, suggesting that their validity goes beyond regular networks. ",A monotonic relationship between the variability of the infectious   period and final size in pairwise epidemic modelling
"  This paper has been withdrawn by the author due to the triviality of the considered coordinate transformations. A consistent treatment, based on the extended physical radial coordinate, is presented in the publications of the author 2000 - 2003. ",A New Exact Solution of the Einstein Equations as Revised   Schwarzschild's Solution Without Black Holes
"  In this paper we detail Cortexica's (https://www.cortexica.com) recommendation framework -- particularly, we describe how a hybrid visual recommender system can be created by combining conditional random fields for segmentation and deep neural networks for object localisation and feature representation. The recommendation system that is built after localisation, segmentation and classification has two properties -- first, it is knowledge based in the sense that it learns pairwise preference/occurrence matrix by utilising knowledge from experts (images from fashion blogs) and second, it is content-based as it utilises a deep learning based framework for learning feature representation. Such a construct is especially useful when there is a scarcity of user preference data, that forms the foundation of many collaborative recommendation algorithms. ","Algorithmic clothing: hybrid recommendation, from street-style-to-shop"
"  We prove a differential Harnack inequality for the Endangered Species Equation, a nonlinear parabolic equation. Our derivation relies on an idea related to the parabolic maximum principle. As an application of this inequality, we will show that positive solutions to this equation must blowup in finite time. We also use this inequality to partially answer a question of Hamilton, 2011. ",Harnack Estimate for the Endangered Species Equation
"  We illustrate the utility of the recently developed loop calculus for improving the Belief Propagation (BP) algorithm. If the algorithm that minimizes the Bethe free energy fails we modify the free energy by accounting for a critical loop in a graphical representation of the code. The log-likelihood specific critical loop is found by means of the loop calculus. The general method is tested using an example of the Linear Programming (LP) decoding, that can be viewed as a special limit of the BP decoding. Considering the (155,64,20) code that performs over Additive-White-Gaussian-Noise channel we show that the loop calculus improves the LP decoding and corrects all previously found dangerous configurations of log-likelihoods related to pseudo-codewords with low effective distance, thus reducing the code's error-floor. ",Loop Calculus Helps to Improve Belief Propagation and Linear Programming   Decodings of Low-Density-Parity-Check Codes
"  This paper explores the relation between convex functions and the geometry of space-times and semi-Riemannian manifolds (an investigation initiated by Gibbons-Ishibashi). Specifically, we study geodesic connectedness. We give geometric-topological proofs of geodesic connectedness for classes of space-times to which known methods do not apply. For instance: A null-disprisoning space-time is geodesically connected if it supports a proper, nonnegative strictly convex function whose critical set is a point. Timelike strictly convex hypersurfaces of Minkowski space are geodesically connected. We also give a criterion for the existence of a convex function on a semi-Riemannian manifold. We compare our work with previously known results. ",Convex Functions and Geodesic Connectedness of Space-times
"  GdNi is a ferrimagnetic material with a Curie temperature Tc = 69 K which exhibits a large magnetocaloric effect, making it useful for magnetic refrigerator applications. We investigate the electronic structure of GdNi by carrying out x-ray absorption spectroscopy (XAS) and x-ray magnetic circular dichroism (XMCD) at T = 25 K in the ferrimagnetic phase. We analyze the Gd M$_{4,5}$-edge ($3d$ - $4f$) and Ni L$_{2,3}$-edge ($2p$ - $3d$) spectra using atomic multiplet and cluster model calculations, respectively. The atomic multiplet calculation for Gd M$_{4,5}$-edge XAS indicates that Gd is trivalent in GdNi, consistent with localized $4f$ states. On the other hand, a model cluster calculation for Ni L$_{2,3}$-edge XAS shows that Ni is effectively divalent in GdNi and strongly hybridized with nearest neighbour Gd states, resulting in a $d$-electron count of 8.57. The Gd M$_{4,5}$-edge XMCD spectrum is consistent with a ground state configuration of S = 7/2 and L=0. The Ni L$_{2,3}$-edge XMCD results indicate that the antiferromagnetically aligned Ni moments exhibit a small but finite magnetic moment ( $m_{tot}$ $\sim$ 0.12 $\mu_B$ ) with the ratio $m_{o}/m_{s}$ $\sim$ 0.11. Valence band hard x-ray photoemission spectroscopy shows Ni $3d$ features at the Fermi level, confirming a partially filled $3d$ band, while the Gd $4f$ states are at high binding energies away from the Fermi level. The results indicate that the Ni $3d$ band is not fully occupied and contradicts the charge-transfer model for rare-earth based alloys. The obtained electronic parameters indicate that GdNi is a strongly correlated charge transfer metal with the Ni on-site Coulomb energy being much larger than the effective charge-transfer energy between the Ni $3d$ and Gd $4f$ states. ","Electronic structure investigation of GdNi using X-ray absorption,   magnetic circular dichroism and hard x-ray photoemission spectroscopy"
"  We present Chandra/ACIS images of several high-mass star-forming regions. The massive stellar clusters powering these HII regions are resolved at the arcsecond level into hundreds of stellar sources, similar to those seen in closer young stellar clusters. However, we also detect diffuse X-ray emission on parsec scales that is spatially and spectrally distinct from the point source population. For nearby regions (e.g. M17 and Rosette) the emission is soft, with plasma temperatures less than 10 million degrees, in contrast to what is seen in more distant complexes (e.g. RCW49, W51).   This extended emission most likely arises from the fast O-star winds thermalized either by wind-wind collisions or by a termination shock against the surrounding media. We have established that only a small portion of the wind energy and mass appears in the observed diffuse X-ray plasma; in the blister HII regions, we suspect that most of it flows without cooling into the low-density interstellar medium through blow-outs or fissures in the surrounding neutral material. These data provide compelling observational evidence that strong wind shocks are present in HII regions. ",Parsec-scale X-ray Flows in High-mass Star-forming Regions
"  We study the properties of domain walls and domain patterns in ultrathin epitaxial magnetic films with two orthogonal in-plane easy axes, which we call fourfold materials. In these materials, the magnetization vector is constrained to lie entirely in the film plane and has four preferred directions dictated by the easy axes. We prove the existence of $90^\circ$ and $180^\circ$ domain walls in these materials as minimizers of a nonlocal one-dimensional energy functional. Further, we investigate numerically the role of the considered domain wall solutions for pattern formation in a rectangular sample. ",One-dimensional domain walls in thin ferromagnetic films with fourfold   anisotropy
"  Edge computing has become increasingly popular across many domains and enterprises. However, given the locality constraint of edges (i.e., only close-by edges are useful), multiplexing diverse workloads becomes challenging. This results in poor resource utilization in edge resources that are provisioned for peak demand. A simple way to allow multiplexing is through micro-data centers, that bring computation close to the users while supporting diverse workloads throughout the data, along with edges. In this paper, we argue for a hybrid approach of dedicated edge resources within an enterprise and on demand resources in micro-data centers that are shared across entities. We show that this hybrid approach is an effective and cost-efficient way for scaling workloads and removes the need for over-provisioning dedicated resources per enterprise. Moreover, compared to a scaling approach that uses only the edges across enterprises, micro-data centers also form a trusted third party that can maintain important quality of service guarantees such as data privacy, security, and availability. ",Ben\'e: On Demand Cost-Effective Scaling at the Edge
"  The degrees of freedom of any interacting quantum field theory are entangled in momentum space. Thus, in the vacuum state, the infrared degrees of freedom are described by a density matrix with an entanglement entropy. We derive a relation between this density matrix and the conventional Wilsonian effective action. We argue that the entanglement entropy of and mutual information between subsets of field theoretic degrees of freedom at different momentum scales are natural observables in quantum field theory and demonstrate how to compute these in perturbation theory. The results may be understood heuristically based on the scale-dependence of the coupling strength and number of degrees of freedom. We measure the rate at which entanglement between degrees of freedom declines as their scales separate and suggest that this decay is related to the property of decoupling in quantum field theory. ",Momentum-space entanglement and renormalization in quantum field theory
"  A well known cryptographic primitive is so called random access code. Namely, Alice is to send to Bob one of two bits, so that Bob has the choice which bit he wants to learn about. However at any time Alice should not learn Bob's choice, and Bob should learn only the bit of his choice. The task is impossible to accomplish by means of either classical or quantum communication. On the other hand, a concept of correlations stronger than quantum ones, exhibited by so called Popescu- Rohrlich box, was introduced and widely studied. In particular, it is known that Popescu-Rohrlich box enables simulation of the random access code with the support of one bit of communication. Here, we propose a quantum analogue of this phenomenon. Namely, we define an analogue of a random access code, where instead of classical bits, one encodes qubits. We provide a quantum non-signaling box that if supported with two classical bits, allows to simulate a quantum version of random access code. We point out that two bits are necessary. We also show that a quantum random access code cannot be fully quantum: when Bob inputs superposition of two choices, the output will be in a mixed state rather than in a superposition of required states. ",Nonsignaling quantum random access code boxes
"  We show that the fundamental time reversal invariant (TRI) insulator exists in 4+1 dimensions, where the effective field theory is described by the 4+1 dimensional Chern-Simons theory and the topological properties of the electronic structure is classified by the second Chern number. These topological properties are the natural generalizations of the time reversal breaking (TRB) quantum Hall insulator in 2+1 dimensions. The TRI quantum spin Hall insulator in 2+1 dimensions and the topological insulator in 3+1 dimension can be obtained as descendants from the fundamental TRI insulator in 4+1 dimensions through a dimensional reduction procedure. The effective topological field theory, and the $Z_2$ topological classification for the TRI insulators in 2+1 and 3+1 dimensions are naturally obtained from this procedure. All physically measurable topological response functions of the TRI insulators are completely described by the effective topological field theory. Our effective topological field theory predicts a number of novel and measurable phenomena, the most striking of which is the topological magneto-electric effect, where an electric field generates a magnetic field in the same direction, with an universal constant of proportionality quantized in odd multiples of the fine structure constant $\alpha=e^2/\hbar c$. Finally, we present a general classification of all topological insulators in various dimensions, and describe them in terms of a unified topological Chern-Simons field theory in phase space. ",Topological Field Theory of Time-Reversal Invariant Insulators
"  We present a brief overview of random matrix theory (RMT) with the objectives of highlighting the computational results and applications in financial markets as complex systems. An oft-encountered problem in computational finance is the choice of an appropriate epoch over which the empirical cross-correlation return matrix is computed. A long epoch would smoothen the fluctuations in the return time series and suffers from non-stationarity, whereas a short epoch results in noisy fluctuations in the return time series and the correlation matrices turn out to be highly singular. An effective method to tackle this issue is the use of the power mapping, where a non-linear distortion is applied to a short epoch correlation matrix. The value of distortion parameter controls the noise-suppression. The distortion also removes the degeneracy of zero eigenvalues. Depending on the correlation structures, interesting properties of the eigenvalue spectra are found. We simulate different correlated Wishart matrices to compare the results with empirical return matrices computed using the S&P 500 (USA) market data for the period 1985-2016. We also briefly review two recent applications of RMT in financial stock markets: (i) Identification of ""market states"" and long-term precursor to a critical state; (ii) Characterization of catastrophic instabilities (market crashes). ",Complex market dynamics in the light of random matrix theory
"  Wind-blown sand, or 'saltation,' creates sand dunes, erodes geological features, and could be a significant source of dust aerosols on Mars. Moreover, the electrification of sand and dust in saltation, dust storms, and dust devils could produce electric discharges and affect atmospheric chemistry. We present the first calculations of electric fields in martian saltation, using a numerical model of saltation that includes sand electrification, plasma physics, and the adsorption of ions and electrons onto particulates. Our results indicate that electric discharges do not occur in martian saltation. Moreover, we find that the production of hydrogen peroxide and the dissociation of methane by electric fields are less significant than previously thought. Both these species are highly relevant to studies of past and present life on Mars. ",Electrification of wind-blown sand on Mars and its implications for   atmospheric chemistry
"  Transformer-based models have brought a radical change to neural machine translation. A key feature of the Transformer architecture is the so-called multi-head attention mechanism, which allows the model to focus simultaneously on different parts of the input. However, recent works have shown that most attention heads learn simple, and often redundant, positional patterns. In this paper, we propose to replace all but one attention head of each encoder layer with simple fixed -- non-learnable -- attentive patterns that are solely based on position and do not require any external knowledge. Our experiments with different data sizes and multiple language pairs show that fixing the attention heads on the encoder side of the Transformer at training time does not impact the translation quality and even increases BLEU scores by up to 3 points in low-resource scenarios. ",Fixed Encoder Self-Attention Patterns in Transformer-Based Machine   Translation
"  The renormalization method based on the Newton-Maclaurin expansion is applied to study the transient behavior of the solutions to the difference equations as they tend to the steady-states. The key and also natural step is to make the renormalization equations to be continuous such that the elementary functions can be used to describe the transient behavior of the solutions to difference equations. As the concrete examples, we deal with the important second order nonlinear difference equations with a small parameter. The result shows that the method is more natural than the multi-scale method. ",Transient behavior of the solutions to the second order difference   equations by the renormalization method based on Newton-Maclaurin expansion
"  Active galactic nuclei (AGN) probably control the growth of their host galaxies via feedback in the form of wide-angle wind-driven outflows. These establish the observed correlations between supermassive black hole (SMBH) masses and host galaxy properties, e.g. the spheroid velocity dispersion $\sigma$. In this paper we consider the growth of the SMBH once it starts driving a large-scale outflow through the galaxy. To clear the gas and ultimately terminate further growth of both the SMBH and the host galaxy, the black hole must continue to grow its mass significantly, by up to a factor of a few, after reaching this point. The mass increment $\Delta M_{\rm BH}$ depends sensitively on both galaxy size and SMBH spin. The galaxy size dependence leads to $\Delta M_{\rm BH} \propto \sigma^5$ and a steepening of the $M-\sigma$ relation beyond the analytically calculated $M \propto \sigma^4$, in agreement with observation. Slowly--spinning black holes are much less efficient in producing feedback, so at any given $\sigma$ the slowest--spinning black holes should be the most massive. Current observational constraints are consistent with this picture, but insufficient to test it properly; however, this should change with upcoming surveys. ",Slow and fat: low-spin SMBHs are more massive
"  We have observed four X-ray underluminous groups of galaxies using the Giant Meterwave RadioTelescope. The groups NGC 524, 720, 3607, and 4697 are underluminous in relation to the extrapolation of the Lx - T relation from rich clusters and do not show any evidence of current AGN activities that can account for such a departure. The GMRT observations carried out at low frequencies (235 and 610 MHz) were aimed at detecting low surface brightness, steep-spectrum sources indicative of past AGN activities in these groups. No such radio emissions were detected in any of these four groups. The corresponding upper limits on the total energy in relativistic particles is about 3 X 10$^{57}$ erg. This value is more than a factor of 100 less than that required to account for the decreased X-ray luminosities (or, enhanced entropies) of these four groups in the AGN-heating scenario. Alternatively, the AGN activity must have ceased about 4 Gyr ago, allowing the relativistic particles to diffuse out to such a large extent (about 250 kpc) that their radio emission could have been undetected by the current observations. If the latter scenario is correct, the ICM was pre-heated before the assembly of galaxy clusters. ",Limits on the AGN activities in X-ray underluminous galaxy groups
"  We develop Random Batch Methods for interacting particle systems with large number of particles. These methods use small but random batches for particle interactions, thus the computational cost is reduced from $O(N^2)$ per time step to $O(N)$, for a system with $N$ particles with binary interactions. On one hand, these methods are efficient Asymptotic-Preserving schemes for the underlying particle systems, allowing $N$-independent time steps and also capture, in the $N \to \infty$ limit, the solution of the mean field limit which are nonlinear Fokker-Planck equations; on the other hand, the stochastic processes generated by the algorithms can also be regarded as new models for the underlying problems. For one of the methods, we give a particle number independent error estimate under some special interactions. Then, we apply these methods to some representative problems in mathematics, physics, social and data sciences, including the Dyson Brownian motion from random matrix theory, Thomson's problem, distribution of wealth, opinion dynamics and clustering. Numerical results show that the methods can capture both the transient solutions and the global equilibrium in these problems. ",Random batch methods (RBM) for interacting particle systems
"  Room temperature Terahertz stimulated emission and population inversion in optically pumped graphene is reported. We experimentally observe fast relaxation and relatively slow recombination dynamics of photogenerated electrons/holes in an exfoliated graphene on SiO2/Si substrate under pumping with a 1550-nm, 80-fs pulsed fiber laser beam and probing with the corresponding terahertz beam generated by optical rectification in a nonlinear electro optical sensor. The time resolved electric field intensity originating from the coherent terahertz photon emission is electro-optically sampled in an total-reflection geometry. The comparison of terahertz electric fields intensities measured on SiO2/Si substrate and that one from graphene clearly indicate that graphene sheet act like an amplifying medium. The Emission spectra agrees relatively well the pumping photon spectrum and its dependency on the pumping power shows a threshold like behavior, testifying the occurrence of the negative conductivity in the THz spectral range and the population inversion. The threshold pumping intensity > 5*10^6 W/cm^2 is in a good agreement with simulations. ",Amplified Stimulated Terahertz Emission at Room temperature from   Optically Pumped Graphene
"  In this paper we propose a convolution estimator for estimating the density of a response variable that employs an underlying multiple regression framework to enhance the accuracy of density estimates through the incorporation of auxiliary information. Suppose we have a sample consisting of $N$ complete case observations of a response variable and an associated set of covariates, along with an additional sample consisting of $M$ observations of the covariates only. We show that the mean square error of the multiple regression-enhanced convolution estimator converges as $O(N^{-1})$ towards zero, and moreover, for a large fixed $N$, that the mean square error converges as $O(M^{-4/5})$ towards an $O(N^{-1})$ constant. This is the first time that the convergence of a convolution estimator with respect to the amount of additional covariate information has been established. In contrast to convolution estimators based on the Nadaraya-Watson estimator for a nonlinear regression model, the multiple regression-enhanced convolution estimator proposed in this paper does not suffer from the curse of dimensionality. It is particularly useful for scenarios in which one wants to estimate the density of a response variable that is challenging to measure, while being in possession of a large amount of additional covariate information. In fact, an application of this type from the field of ophthalmology motivated our work in this paper. ",A Multiple Regression-Enhanced Convolution Estimator for the Density of   a Response Variable in the Presence of Additional Covariate Information
"  By assuming an aspherical stellar wind with an equatorial disk from a red giant, we investigate the production of Type Ia supernovae (SNe Ia) via symbiotic channel. We estimate that the Galactic birthrate of SNe Ia via symbiotic channel is between $1.03\times 10^{-3}$ and $2.27\times 10^{-5}$ yr$^{-1}$, the delay time of SNe Ia has wide range from $\sim$ 0.07 to 5 Gyr. The results are greatly affected by the outflow velocity and mass-loss rate of the equatorial disk. Using our model, we discuss the progenitors of SN 2002ic and SN 2006X. ",An Alternative Symbiotic Channel to Type Ia Supernovae
"  As the main contribution, this document provides a consistent discretization of a class of fixed-time stable systems, namely predefined-time stable systems. In the unperturbed case, the proposed approach allows obtaining not only a consistent but exact discretization of the considered class of predefined-time stable systems, whereas in the perturbed case, the consistent discretization preserves the predefined-time stability property. All the results are validated through simulations and compared with the conventional explicit Euler scheme, highlighting the advantages of this proposal. ",Consistent Discretization of a Class of Predefined-Time Stable Systems
"  Large scale dynamics of the oceans and the atmosphere are governed by the primitive equations (PEs). It is well-known that the three-dimensional viscous PEs is globally well-posed in Sobolev spaces. On the other hand, the inviscid PEs without rotation is known to be ill-posed in Sobolev spaces, and its smooth solutions can form singularity in finite time. In this paper, we extend the above results in the presence of rotation. First, we construct finite-time blowup solutions to the inviscid PEs with rotation, and establish that the inviscid PEs with rotation is ill-posed in Sobolev spaces in the sense that its perturbation around a certain steady state background flow is both linearly and nonlinearly ill-posed in Sobolev spaces. Its linear instability is of the Kelvin-Helmholtz type similar to the one appears in the context of vortex sheets problem. This implies that the inviscid PEs is also linearly ill-posed in Gevrey class of order $s > 1$, and suggests that a suitable space for the well-posedness is Gevrey class of order $s = 1$, which is exactly the space of analytic functions. ",Finite-time Blowup and Ill-posedness in Sobolev Spaces of the Inviscid   Primitive Equations with Rotation
"  In the light of recent observations which point to an open universe $(\Omega_{0}<1)$, we construct an open singularity-free cosmological model by reconsidering a model originally constructed for a closed universe. Our model starts from a nonsingular state called prematter, governed by an inflationary equation of state $P=(\gamma_{p}-1)\rho$ where $\gamma_{p}$ $(\simeq 10^{-3})$ is a small positive parameter representing the initial vacuum dominance of the universe. Unlike the closed models universe cannot be initially static hence, starts with an initial expansion rate represented by the initial value of the Hubble constant H(0). Therefore, our model is a two-parameter universe model $(\gamma_{p},H(0))$. Comparing the predictions of this model for the present properties of the universe with the recent observational results, we argue that the model constructed in this work could be used as a realistic universe model. ",An Open Singularity-Free Cosmological Model with Inflation
"  We present a thorough investigation of problems that can be solved exactly with the level-1 Quantum Approximate Optimization Algorithm (QAOA). To this end we implicitly define a class of problem Hamiltonians that employed as phase separator in a level-1 QAOA circuit provide unit overlap with a target subspace spanned by a set of computational basis states. For one-dimensional target subspaces we identify instances within the implicitly defined class of Hamiltonians for which Quantum Annealing (QA) and Simulated Annealing (SA) have an exponentially small probability to find the solution. Consequently, our results define a first demarcation line between QAOA, QA and SA, and highlight the fundamental differences between an interference-based search heuristic such as QAOA and heuristics that are based on thermal and quantum fluctuations like SA and QA respectively. Moreover, for two-dimensional solution subspaces we are able to show that the depth of the QAOA circuit grows linearly with the Hamming distance between the two target states. We further show that there are no genuine solutions for target subspaces of dimension higher than $2$ and smaller than $2^n$. We also transfer these results to Instantaneous Quantum Polynomial (IQP) circuits. ",Forbidden subspaces for level-1 QAOA and IQP circuits
"  Neural networks can be powerful function approximators, which are able to model high-dimensional feature distributions from a subset of examples drawn from the target distribution. Naturally, they perform well at generalizing within the limits of their target function, but they often fail to generalize outside of the explicitly learned feature space. It is therefore an open research topic whether and how neural network-based architectures can be deployed for systematic reasoning. Many studies have shown evidence for poor generalization, but they often work with abstract data or are limited to single-channel input. Humans, however, learn and interact through a combination of multiple sensory modalities, and rarely rely on just one. To investigate compositional generalization in a multimodal setting, we generate an extensible dataset with multimodal input sequences from simulation. We investigate the influence of the underlying training data distribution on compostional generalization in a minimal LSTM-based network trained in a supervised, time continuous setting. We find compositional generalization to fail in simple setups while improving with the number of objects, actions, and particularly with a lot of color overlaps between objects. Furthermore, multimodality strongly improves compositional generalization in settings where a pure vision model struggles to generalize. ",Generalization in Multimodal Language Learning from Simulation
"  We show that adversarial examples, i.e., the visually imperceptible perturbations that result in Convolutional Neural Networks (CNNs) fail, can be alleviated with a mechanism based on foveations---applying the CNN in different image regions. To see this, first, we report results in ImageNet that lead to a revision of the hypothesis that adversarial perturbations are a consequence of CNNs acting as a linear classifier: CNNs act locally linearly to changes in the image regions with objects recognized by the CNN, and in other regions the CNN may act non-linearly. Then, we corroborate that when the neural responses are linear, applying the foveation mechanism to the adversarial example tends to significantly reduce the effect of the perturbation. This is because, hypothetically, the CNNs for ImageNet are robust to changes of scale and translation of the object produced by the foveation, but this property does not generalize to transformations of the perturbation. As a result, the accuracy after a foveation is almost the same as the accuracy of the CNN without the adversarial perturbation, even if the adversarial perturbation is calculated taking into account a foveation. ",Foveation-based Mechanisms Alleviate Adversarial Examples
"  We report an analysis of synchronization between two unidirectionally coupled chaotic external cavity master/slave semiconductor lasers with two characteristic delay times, where the delay time in the coupling is different from the delay time in the coupled systems themselves. We demonstrate for the first time that parameter mismatches in photon decay rates for the master and slave lasers can explain the experimental observation that the lag time is equal to the coupling delay time. ",Lag time and parameter mismatches in synchronization of unidirectionally   coupled chaotic external cavity semiconductor lasers
"  We present a search for Trojan companions to 25 transiting exoplanets. We use the technique of Ford & Gaudi, in which a difference is sought between the observed transit time and the transit time that is calculated by fitting a two-body Keplerian orbit to the radial-velocity data. This technique is sensitive to the imbalance of mass at the L4/L5 points of the planet-star orbit. No companions were detected above 2\sigma confidence. The median 2\sigma upper limit is 56 M_\earth, and the most constraining limit is 2.8 M_\earth for the case of GJ 436. A similar survey using forthcoming data from the Kepler satellite mission, along with the radial-velocity data that will be needed to confirm transit candidates, will be sensitive to 10-50 M_\earth Trojan companions in the habitable zones of their parent stars. As a by-product of this study, we present empirical constraints on the eccentricities of the planetary orbits, including those which have previously been assumed to be circular. The limits on eccentricity are of interest for investigations of tidal circularization and for bounding possible systematic errors in the measured planetary radii and the predicted times of secondary eclipses. ",Empirical Constraints on Trojan Companions and Orbital Eccentricities in   25 Transiting Exoplanetary Systems
"  Up to now, Dark Energy evidences are based on the dynamics of the universe on very large scales, above 1 Gpc. Assuming it continues to behave like a cosmological constant $\Lambda$ on much smaller scales, I discuss its effects on the motion of non-relativistic test-particles in a weak gravitational field and I propose a way to detect evidences of $\Lambda \neq 0$ at the scale of about 1 Mpc: the main ingredient is the measurement of galaxy cluster masses. ",Dark Energy and the mass of galaxy clusters
  Extensive ARPES and low-energy inelastic neutron scattering studies of cuprate superconductors can be successfully described using a weak-coupling theory in which quasiparticles on a square lattice interact via scalar and spin-dependent effective interactions. In this article we point out that in Bi$_2$Sr$_2$Ca$_{1-x}$Y$_x$Cu$_2$O$_8$ (Bi2212) both probes are consistent with dominant near-neighbour Heisenberg interactions. We discuss the implications of this finding for the mechanism of high-$T_c$ superconductivity. ,"ARPES, Neutrons, and the High-$T_c$ Mechanism"
"  Organisations, whether in government, industry or commerce, are required to make decisions in a complex and uncertain environment. The way models are used is intimately connected to the way organisations make decisions and the context in which they make them. Typically, in a complex organisation, multiple related models will often be used in support of a decision. For example, engineering models might be combined with financial models and macro-economic models in order to decide whether to invest in new production capability. Different parts of a complex organisation might operate their own related models which might then be presented to a central decision maker. Yet in practice, there is little awareness of the practical challenges of using models in a robust way to support decision making. There is significant scope to improve decision making though an enhanced understanding of the role and limitations of modelling and through the application of cutting edge methodologies and organisational best practice. This report is in the form of a 'white paper', whose purpose is to identify key issues for consideration whist postulating tentative approaches to these issues that might be worthy of further exploration, focussing on both technical and organisational aspects. It begins with a framework for consideration of how model-based decisions are made in organisations. It then looks more closely at the questions of uncertainty and multiple models. It then postulates some technical statistical and organisational approaches for managing some of these issues. Finally, it considers the way forward, and the possible focus for further work. ",The use of multiple models within an organisation
"  The identification of local modules in dynamic networks with known topology has recently been addressed by formulating conditions for arriving at consistent estimates of the module dynamics, typically under the assumption of having disturbances that are uncorrelated over the different nodes. The conditions typically reflect the selection of a set of node signals that are taken as predictor inputs in a MISO identification setup. In this paper an extension is made to arrive at an identification setup for the situation that process noises on the different node signals can be correlated with each other. In this situation the local module may need to be embedded in a MIMO identification setup for arriving at a consistent estimate with maximum likelihood properties. This requires the proper treatment of confounding variables. The result is an algorithm that, based on the given network topology and disturbance correlation structure, selects an appropriate set of node signals as predictor inputs and outputs in a MISO or MIMO identification setup. As a first step in the analysis, we restrict attention to the (slightly conservative) situation where the selected output node signals are predicted based on all of their in-neighbor node signals in the network. ",Local module identification in dynamic networks with correlated noise:   the full input case
"  The domain of numerical simulation is a place where the parallelization of numerical code is common. The definition of a numerical context means the configuration of resources such as memory, processor load and communication graph, with an evolving feature: the resources availability. A feature is often missing: the adaptability. It is not predictable and the adaptable aspect is essential. Without calling into question these implementations of these codes, we create an adaptive use of these implementations. Because the execution has to be driven by the availability of main resources, the components of a numeric computation have to react when their context changes. This paper offers a new architecture, a mobile computing architecture, based on mobile agents and JavaSpace. At the end of this paper, we apply our architecture to several case studies and obtain our first results. ",A Mobile Computing Architecture for Numerical Simulation
  Let $f \in Q(z)$ be a polynomial or rational function of degree 2. A special case of Morton and Silverman's Dynamical Uniform Boundedness Conjecture states that the number of rational preperiodic points of $f$ is bounded above by an absolute constant. A related conjecture of Silverman states that the canonical height $\hat{h}_f(x)$ of a non-preperiodic rational point $x$ is bounded below by a uniform multiple of the height of $f$ itself. We provide support for these conjectures by computing the set of preperiodic and small height rational points for a set of degree 2 maps far beyond the range of previous searches. ,Small dynamical heights for quadratic polynomials and rational functions
"  Special generic maps are higher dimensional versions of Morse functions with exactly two singular points, characterizing spheres topologically except $4$-dimensional cases: in these cases standard spheres are characterized. Canonical projections of unit spheres are special generic. In suitable cases, it is easy to construct special generic maps on manifolds represented as connected sums of products of spheres for example. It is an interesting fact that these maps restrict the topologies and the differentiable structures admitting them strictly in various cases. For example, exotic spheres, which are not diffeomorphic to standard spheres, admit no special generic map into some Euclidean spaces in considerable cases.   In general, it is difficult to find (families of) manifolds admitting no such maps of suitable classes. The present paper concerns a new result on this work where key objects are products of cohomology classes of the manifolds. We can see that closed symplectic maifolds, real projective spaces, and so on, admit no special generic map into a connected open manifold in considerable cases for example. ",Closed manifolds admitting no special generic maps whose codimensions   are negative and their cohomology rings
"  GRB041219a is the brightest burst localised by INTEGRAL. The intense burst occurred about ~250s after the precursor and the long delay enabled optical and near infrared telescopes to observe the prompt emission. We present comprehensive results of the temporal and spectral analyses, including line and afterglow searches using the spectrometer, SPI, aboard INTEGRAL, BAT on Swift and ASM on RXTE. We avail of multi-wavelength data to generate broadband spectra of GRB041219a and afterglow. Spectra for the burst and sub-intervals were fit by the Band model and also by the quasithermal model. The high resolution Germanium spectrometer data were searched for emission and absorption features and for gamma-ray afterglow. The overall burst and sub-intervals are well fit by the Band model. The photon index below the break energy shows a marked change after the quiescent time interval. In addition the spectra are well described by a black body component with a power law. The burst was detected by BAT and ASM during the long quiescent interval in SPI indicating the central engine might not be dormant but that the emission occurs in different bands. No significant emission or absorption features were found and limits of 900 eV and 120 eV are set on the most significant features. No gamma-ray afterglow was detected from the end of the prompt phase to ~12 hours post-burst. Broadband spectra of the prompt emission were generated in 7 time intervals using gamma-ray, x-ray, optical and near-infrared data and these were compared to the high-redshift burst GRB050904. The optical and gamma-ray emission are correlated in GRB041219a. The spectral lag was determined using data from the BAT and it changes throughout the burst. A number of pseudo-redshifts were evaluated and large dispersion in values was found. ",Observations of the intense and ultra-long burst GRB041219a with the   Germanium Spectrometer on INTEGRAL
"  We develop an analytical model to follow the cosmological evolution of magnetic fields in disk galaxies. Our assumption is that fields are amplified from a small seed field via magnetohydrodynamical (MHD) turbulence. We further assume that this process is fast compared to other relevant timescales, and occurs principally in the cold disk gas. We follow the turbulent energy density using the Shabala & Alexander (2009) galaxy formation and evolution model. Three processes are important to the turbulent energy budget: infall of cool gas onto the disk and supernova feedback increase the turbulence; while star formation removes gas and hence turbulent energy from the cold gas. Finally, we assume that field energy is continuously transferred from the incoherent random field into an ordered field by differential galactic rotation. Model predictions are compared with observations of local late type galaxies by Fitt & Alexander (1993) and Shabala et al. (2008). The model reproduces observed magnetic field strengths and luminosities in low and intermediate-mass galaxies. These quantities are overpredicted in the most massive hosts, suggesting that inclusion of gas ejection by powerful AGNs is necessary in order to quench gas cooling and reconcile the predicted and observed magnetic field strengths. ",Magnetic fields in galaxies: I. Radio disks in local late-type galaxies
"  The use of local single-pass methods (like, e.g., the Fast Marching method) has become popular in the solution of some Hamilton-Jacobi equations. The prototype of these equations is the eikonal equation, for which the methods can be applied saving CPU time and possibly memory allocation. Then, some natural questions arise: can local single-pass methods solve any Hamilton-Jacobi equation? If not, where the limit should be set? This paper tries to answer these questions. In order to give a complete picture, we present an overview of some fast methods available in literature and we briefly analyze their main features. We also introduce some numerical tools and provide several numerical tests which are intended to exhibit the limitations of the methods. We show that the construction of a local single-pass method for general Hamilton-Jacobi equations is very hard, if not impossible. Nevertheless, some special classes of problems can be actually solved, making local single-pass methods very useful from the practical point of view. ",Can local single-pass methods solve any stationary   Hamilton-Jacobi-Bellman equation?
"  This is the second paper in a series to study regular representations for vertex operator algebras. In this paper, given a module $W$ for a vertex operator algebra $V$, we construct, out of the dual space $W^{*}$, a family of canonical (weak) $V\otimes V$-modules called ${\cal{D}}_{Q(z)}(W)$ parametrized by a nonzero complex number $z$. We prove that for $V$-modules $W,W_{1}$ and $W_{2}$, a $Q(z)$-intertwining map of type ${W'\choose W_{1}W_{2}}$ in the sense of Huang and Lepowsky exactly amounts to a $V\otimes V$-homomorphism from $W_{1}\otimes W_{2}$ to ${\cal{D}}_{Q(z)}(W)$ and that a $Q(z)$-tensor product of $V$-modules $W_{1}$ and $W_{2}$ in the sense of Huang and Lepowsky amounts to a universal from $W_{1}\otimes W_{2}$ to the functor ${\cal{F}}_{Q(z)}$, where ${\cal{F}}_{Q(z)}$ is a functor from the category of $V$-modules to the category of weak $V\otimes V$-modules defined by ${\cal{F}}_{Q(z)}(W)={\cal{D}}_{Q(z)}(W')$ for a $V$-module $W$. Furthermore, Huang-Lepowsky's $P(z)$ and $Q(z)$-tensor functors for the category of $V$-modules are extended to functors $T_{P(z)}$ and $T_{Q(z)}$ from the category of $V\otimes V$-modules to the category of $V$-modules. It is proved that functors ${\cal{F}}_{P(z)}$ and ${\cal{F}}_{Q(z)}$ are right adjoints of $T_{P(z)}$ and $T_{Q(z)}$, respectively. ",Regular representations and Huang-Lepowsky's tensor functors for vertex   operator algebras
"  A number of settings arise in which it is of interest to predict Principal Component (PC) scores for new observations using data from an initial sample. In this paper, we demonstrate that naive approaches to PC score prediction can be substantially biased toward 0 in the analysis of large matrices. This phenomenon is largely related to known inconsistency results for sample eigenvalues and eigenvectors as both dimensions of the matrix increase. For the spiked eigenvalue model for random matrices, we expand the generality of these results, and propose bias-adjusted PC score prediction. In addition, we compute the asymptotic correlation coefficient between PC scores from sample and population eigenvectors. Simulation and real data examples from the genetics literature show the improved bias and numerical properties of our estimators. ",Convergence and prediction of principal component scores in   high-dimensional settings
"  Relative proper motions and cluster membership probabilities have been derived for ~ 2500 stars in the field of the open star cluster NGC 3766. The cluster has been observed in $B$ and $V$ broadband filters at two epochs separated by ~ 6 years using a wide-field imager mounted on the WFI@ESO2.2m telescope. All CCD frames were reduced using the astrometric techniques described in Anderson et al. (2006). The proper motion r.m.s. error for stars brighter than $V$ ~ 15 mag is 2.0 mas/yr but it gradually increases up to ~4 mas/yr at $V$ ~20 mag. Using proper motion data, membership probabilities have been derived for the stars in the region of the cluster. They indicate that three Be and one Ap stars are member of the cluster. The reddening $E(B-V)=0.22\pm0.05$ mag, a distance 2.5$\pm$0.5 kpc and an age of ~ 20 Myr are derived using stars of $P_{\mu}>70%$. Mass function slope $x=1.60\pm0.10$ is derived for the cluster and cluster was found to be dynamically relaxed. Finally, we provide positions, calibrated $B$ and $V$ magnitudes, relative proper motions and membership probabilities for the stars in the field of NGC 3766. We have produced a catalog that is electronically available to the astronomical community. ",Proper motions and membership probabilities of stars in the region of   open cluster NGC 3766
"  We investigate how additive weak noise (correlated as well as uncorrelated) modifies the parameters of the Gray-Scott (GS) reaction diffusion system by performing numerical simulations and applying a Renormalization Group (RG) analysis in the neighborhood of the spatial scale where biochemical reactions take place. One can obtain the same sequence of spatial-temporal patterns by means of two equivalent routes: (i) by increasing only the noise intensity and keeping all other model parameters fixed, or (ii) keeping the noise fixed, and adjusting certain model parameters to their running scale-dependent values as predicted by the RG. This explicit demonstration validates the dynamic RG transformation for finite scales in a two-dimensional stochastic model and provides further physical insight into the coarse-graining analysis proposed by this scheme. Through several study cases we explore the role of noise and its temporal correlation in self-organization and propose a way to drive the system into a new desired state in a controlled way. ",Dynamic Renormalization Group and Noise Induced Transitions in a   Reaction Diffusion Model
"  We study deviations from tri-bimaximality (TBM) and quark-lepton complementarity (QLC) in a model independent way. The current neutrino experimental data is well approximated by tri-bimaximal generation mixing but the QLC relations are not satisfied with each data of 1$\sigma$ level. This means that there exist deviations from the complementarity. The same fact for the TBM might be checked in the future neutrino experiments. We discuss such deviations from the TBM and QLC, simultaneously. A new ratio between the deviations is introduced, and some interesting points are presented. We also show predicted correlations among leptonic mixing angles at the points. ",Deviations from Tri-Bimaximality and Quark-Lepton Complementarity
"  In this paper, we propose a new, scalable approach for the task of object based image search or object recognition. Despite the very large literature existing on the scalability issues in CBIR in the sense of retrieval approaches, the scalability of media and scalability of features remain an issue. In our work we tackle the problem of scalability and structural organization of features. The proposed features are nested local graphs built upon sets of SURF feature points with Delaunay triangulation. A Bag-of-Visual-Words (BoVW) framework is applied on these graphs, giving birth to a Bag-of-Graph-Words representation. The nested nature of the descriptors consists in scaling from trivial Delaunay graphs - isolated feature points - by increasing the number of nodes layer by layer up to graphs with maximal number of nodes. For each layer of graphs its proper visual dictionary is built. The experiments conducted on the SIVAL data set reveal that the graph features at different layers exhibit complementary performances on the same content. The nested approach, the combination of all existing layers, yields significant improvement of the object recognition performance compared to single level approaches. ",Nested Graph Words for Object Recognition
"  MobilitApp is a platform designed to provide smart mobility services in urban areas. It is designed to help citizens and transport authorities alike. Citizens will be able to access the MobilitApp mobile application and decide their optimal transportation strategy by visualising their usual routes, their carbon footprint, receiving tips, analytics and general mobility information, such as traffic and incident alerts. Transport authorities and service providers will be able to access information about the mobility pattern of citizens to o er their best services, improve costs and planning. The MobilitApp client runs on Android devices and records synchronously, while running in the background, periodic location updates from its users. The information obtained is processed and analysed to understand the mobility patterns of our users in the city of Barcelona, Spain. ",MobilitApp: Analysing mobility data of citizens in the metropolitan area   of Barcelona
"  Treewidth is an important and well-known graph parameter that measures the complexity of a graph. The Kneser graph Kneser(n,k) is the graph with vertex set $\binom{[n]}{k}$, such that two vertices are adjacent if they are disjoint. We determine, for large values of n with respect to k, the exact treewidth of the Kneser graph. In the process of doing so, we also prove a strengthening of the Erd\H{o}s-Ko-Rado Theorem (for large n with respect to k) when a number of disjoint pairs of k-sets are allowed. ",Treewidth of the Kneser Graph and the Erd\H{o}s-Ko-Rado Theorem
"  We introduce generalized dimensional reductions of an integrable 1+1-dimensional dilaton gravity coupled to matter down to one-dimensional static states (black holes in particular), cosmological models and waves. An unusual feature of these reductions is the fact that the wave solutions depend on two variables - space and time. They are obtained here both by reducing the moduli space (available due to complete integrability) and by a generalized separation of variables (applicable also to non integrable models and to higher dimensional theories). Among these new wave-like solutions we have found a class of solutions for which the matter fields are finite everywhere in space-time, including infinity.   These considerations clearly demonstrate that a deep connection exists between static states, cosmologies and waves. We argue that it should exist in realistic higher-dimensional theories as well. Among other things we also briefly outline the relations existing betweenthe low-dimensional models that we have discussed hereand the realistic higher-dimensional ones.   This paper develops further some ideas already present in our previous papers. We briefly reproduce here (without proof) their main results in a more concise form and give an important generalization. ","Dimensional Reduction of Gravity and Relation between Static States,   Cosmologies and Waves"
"  Diluted magnetic semiconductors including Mn-doped GaAs are attractive for gate-controlled spintronics but Curie transition at room temperature with long-range ferromagnetic order is still debatable to date. Here, we report the room-temperature ferromagnetic domains with long-range order in semiconducting V-doped WSe2 monolayer synthesized by chemical vapor deposition. Ferromagnetic order is manifested using magnetic force microscopy up to 360K, while retaining high on/off current ratio of ~105 at 0.1% V-doping concentration. The V-substitution to W sites keep a V-V separation distance of 5 nm without V-V aggregation, scrutinized by high-resolution scanning transmission-electron microscopy, which implies the possibility of the Ruderman-Kittel-Kasuya-Yoshida interaction (or Zener model) by establishing the long-range ferromagnetic order in V-doped WSe2 monolayer through free hole carriers. More importantly, the ferromagnetic order is clearly modulated by applying a back gate. Our findings open new opportunities for using two-dimensional transition metal dichalcogenides for future spintronics. ",Room-temperature ferromagnetism in monolayer WSe2 semiconductor via   vanadium dopant
"  This is the second part in a series of two papers. Here, we give an overview on the dimension theory of some dynamically defined function graphs, like Takagi and Weierstrass function, and we study the dimension of Markovian fractal interpolation functions and generalised Takagi functions generated by non-Markovian dynamics. ",Dimension Theory of some non-Markovian repellers Part II: Dynamically   defined function graphs
"  Short Range wireless devices are becoming more and more popular for ubiquitous sensor and actuator connectivity in industrial communication scenarios. Apart from communication-only scenarios, there are also mission-critical use cases where the distance between the two communicating nodes needs to be determined precisely. Applications such as Automatic Guided Vehicles (AGV's), Automatic Train Pairing additionally require the devices to scan the environment and detect any potential humans/obstacles. Ultra-Wide Band (UWB) has emerged as a promising candidate for Real-Time Ranging and Localization (RTRL) due to advantages such as large channel capacity, better co-existence with legacy systems due to low transmit power, better performance in multipath environments etc. In this paper, we evaluate the performance of a UWB COTS device - TimeDomain P440 which can operate as a ranging radio and a monostatic radar simultaneously. To this end, we evaluate the possibility of using Supervised Learning based estimators for predicting the presence of obstacles by constructing a multiclass hypothesis. Simulation results show that the Ensemble tree based methods are able to calculate the likelihood of obstacle collision with accuracies close to 95%. ",Machine Learning Based Obstacle Detection for Automatic Train Pairing
"  This paper studies the effects of distributed delay coupling on the dynamics in a system of non-identical coupled Stuart-Landau oscillators. For uniform and gamma delay distribution kernels, conditions for amplitude death are obtained in terms of average frequency, frequency detuning and parameters of the coupling, including coupling strength and phase, as well as the mean time delay and the width of the delay distribution. To gain further insight into the dynamics inside amplitude death regions, eigenvalues of the corresponding characteristic equations are computed numerically. Oscillatory dynamics of the system is also investigated using amplitude and phase representation. Various branches of phase-locked solutions are identified, and their stability is analysed for different types of delay distributions. ",Amplitude and phase dynamics in oscillators with distributed-delay   coupling
  We present preliminary results from UKQCD simulations at light quark masses using two flavours of non-pertubatively improved Wilson fermions. We report on the performance of the standard HMC algorithm at these quark masses where m_pi/m_rho < 0.5 in comparison with simulations using improved staggered quarks. ,Improved Wilson QCD simulations at light quark masses
"  Within the context of the standard structure formation scenario, massive present day elliptical galaxies are sometimes thought of as the result of a major merger of spiral systems. Through extensive SPH simulations of merging spirals, we have explored these processes with the aim of quantifying their relaxation times. This is important, as it sets a minimum time interval between the onset of a merger, and the appearance of an elliptical galaxy. We then compare this constraint with predictions of the hierarchical scenario, computed through Press-Schechter merger trees. We find evidence for elliptical systems which appear not to have been formed by a major merger of spirals. ",Dynamical consequences of CDM merger trees
  It is well-known that orthogonal polynomials on the real line satisfy a three-term recurrence relation and conversely every system of polynomials satisfying a three-term recurrence relation is orthogonal with respect to some positive Borel measure on the real line. In this paper we extend this result and show that every system of polynomials satisfying some $(2N+1)$-term recurrence relation can be expressed in terms of orthonormal matrix polynomials for which the coefficients are $N\times N$ matrices. We apply this result to polynomials orthogonal with respect to a discrete Sobolev inner product and other inner products in the linear space of polynomials. As an application we give a short proof of Krein's characterization of orthogonal polynomials with a spectrum having a finite number of accumulation points. ,Orthogonal matrix polynomials and higher order recurrence relations
"  We investigate the properties of Lindblad equations on $d$-dimensional lattices supporting a unique steady-state configuration. We consider the case of a time evolution weakly symmetric under the action of a finite group $G$, which is also a symmetry group for the lattice structure. We show that in such case the steady-state belongs to a relevant subspace, and provide an explicit algorithm for constructing an orthonormal basis of such set. As explicitly shown for a spin-1/2 system, the dimension of such subspace is extremely smaller than the dimension of the set of square operators. As a consequence, by projecting the dynamics within such set, the steady-state configuration can be determined with a considerably reduced amount of resources. We demonstrate the validity of our theoretical results by determinining the \emph{exact} structure of the steady-state configuration of the two dimensional XYZ model in the presence of uniform dissipation, with and without magnetic fields, up to a number of sites equal to 12. As far as we know, this is the first time one is capable of determining the steady-state structure of such model for the 12 sites cluster exactly. Altough in this work we consider explicitly only spin-1/2 systems, our approach can be exploited in the characterisation of arbitrary spin systems, fermion and boson systems (with truncated Fock space), as well as many-particle systems with degrees of freedom having different statistical properties. ",On the complexity of the steady-state of weakly symmetric open quantum   lattices
  Di-jet photoproduction in polarized ep collisions at HERA is studied as a possible tool to determine the parton content of circularly polarized photons. The concept of the `effective parton density' approximation is extended to the spin-dependent case. ,Towards the Parton Densities of Polarized Photons at HERA
"  Binary star systems represent a significant proportion of the Galactic stellar population, with X-ray binaries being an important subset of these for high energy astrophysics. Although hundreds of X-ray binaries are detected in the Milky Way and beyond, only 12 of these systems are listed in the 4FGL-DR2, the latest Fermi-LAT point source catalogue. With such a small number detectable by Fermi-LAT, much is still unknown about the mechanisms by which these systems emit $\gamma$-rays. We present the method and current status of our large-scale survey of the X-ray binary population using over 12 years of Fermi-LAT data, and current catalogues and background models. ",The X-Ray Binary Population with Fermi-LAT
"  The connectivity properties of ad hoc networks have been extensively studied over the past few years, from local observables, to global network properties. In this paper we introduce a novel layer of network dynamics which lives and evolves on top of the ad hoc network. Nodes are assumed selfish and a snow-drift type game is defined dictating the way nodes decide to allocate their cooperative resource efforts towards other nodes in the network. The dynamics are strongly coupled with the physical network causing the cooperation network topology to converge towards a stable equilibrium state, a global maximum of the total pay-off. We study this convergence from a connectivity perspective and analyse the inherent parameter dependence. Moreover, we show that direct reciprocity can be an efficient incentive to promote cooperation within the network and discuss the analogies between our simple yet tractable framework with D2D proximity based services such as LTE-Direct. We argue that cooperative network dynamics have many application in ICT, not just ad hoc networks, and similar models as the one described herein can be devised and studied in their own right. ",Connectivity of Cooperative Ad hoc Networks
"  Information Hiding is considered very important part of our lives. There exist many techniques for securing the information. This paper briefs on the techniques for information hiding and the potential threats to those methods. This paper briefs about cryptanalysis and stegananlysis, two methods for breaching into the security methods. ",Information Hiding and Attacks : Review
"  Monocular depth estimation, which plays a crucial role in understanding 3D scene geometry, is an ill-posed problem. Recent methods have gained significant improvement by exploring image-level information and hierarchical features from deep convolutional neural networks (DCNNs). These methods model depth estimation as a regression problem and train the regression networks by minimizing mean squared error, which suffers from slow convergence and unsatisfactory local solutions. Besides, existing depth estimation networks employ repeated spatial pooling operations, resulting in undesirable low-resolution feature maps. To obtain high-resolution depth maps, skip-connections or multi-layer deconvolution networks are required, which complicates network training and consumes much more computations. To eliminate or at least largely reduce these problems, we introduce a spacing-increasing discretization (SID) strategy to discretize depth and recast depth network learning as an ordinal regression problem. By training the network using an ordinary regression loss, our method achieves much higher accuracy and \dd{faster convergence in synch}. Furthermore, we adopt a multi-scale network structure which avoids unnecessary spatial pooling and captures multi-scale information in parallel.   The method described in this paper achieves state-of-the-art results on four challenging benchmarks, i.e., KITTI [17], ScanNet [9], Make3D [50], and NYU Depth v2 [42], and win the 1st prize in Robust Vision Challenge 2018. Code has been made available at: https://github.com/hufu6371/DORN. ",Deep Ordinal Regression Network for Monocular Depth Estimation
"  We propose a novel formulation of group fairness in the contextual multi-armed bandit (CMAB) setting. In the CMAB setting a sequential decision maker must at each time step choose an arm to pull from a finite set of arms after observing some context for each of the potential arm pulls. In our model arms are partitioned into two or more sensitive groups based on some protected feature (e.g., age, race, or socio-economic status). Despite the fact that there may be differences in expected payout between the groups, we may wish to ensure some form of fairness between picking arms from the various groups. In this work we explore two definitions of fairness: equal group probability, wherein the probability of pulling an arm from any of the protected groups is the same; and proportional parity, wherein the probability of choosing an arm from a particular group is proportional to the size of that group. We provide a novel algorithm that can accommodate these notions of fairness for an arbitrary number of groups, and provide bounds on the regret for our algorithm. We then validate our algorithm using synthetic data as well as two real-world datasets for intervention settings wherein we want to allocate resources fairly across protected groups. ",Group Fairness in Bandit Arm Selection
"  Uniform LBB conditions are desirable to approximate the solution of Navier-Stokes, Oseen, and Stokes equations on anisotropic meshes and to enable anisotropic refinements. We prove such conditions for the second order Taylor-Hood pairs $\mathbb{Q}_2 \times \mathbb{Q}_1$ and $\mathbb{P}_2 \times \mathbb{P}_1$ on a class of anisotropic meshes. These meshes may contain refined edge and corner patches. To this end, we generalise Verf\""urth's trick and recent results by some of the authors. ",The inf-sup stability of the lowest order Taylor-Hood pair on   Anisotropic Meshes
"  In a recent paper, we showed that the stochastic subgradient method applied to a weakly convex problem, drives the gradient of the Moreau envelope to zero at the rate $O(k^{-1/4})$. In this supplementary note, we present a stochastic subgradient method for minimizing a convex function, with the improved rate $\widetilde O(k^{-1/2})$. ",Complexity of finding near-stationary points of convex functions   stochastically
"  We introduce the concept of numeraires of convex sets in the nonnegative orthant of the topological vector space of all random variables built over a probability space. A necessary and sufficient condition for an element of a convex set to be its numeraire is given, inspired from ideas in financial mathematics. ",A structural characterization of numeraires of convex sets of   nonnegative random variables
  In this paper we prove a universal inequality describing the asymptotic behavior of support points for planar continuous curves. As corollaries we get an analogous result for tangent points of differentiable planar curves and some (partially known) assertions on the asymptotic of the mean value points for various classical analytic theorems. Some open questions are formulated. ,Asymptotic behavior of support points for planar curves
"  High mass stars form in groups or clusters within massive cores in dense molecular clumps with sizes of 1pc and masses of 200Msun which are important laboratories for high-mass star formation in order to study the initial conditions. We investigate the physical and chemical properties of high-mass clumps in order to better understand the early evolutionary stages and find targets that show star formation signs. We selected the high-mass clumps from ATLASGAL survey that were identified as dark at 8/24$\mu$m wavelengths and used MALT90 data which provides a molecular line set to investigate the physical and chemical conditions in early evolutionary stages. Eleven sources have significant SiO detection (over 3$\sigma$) which usually indicates outflow activities. Thirteen sources are found with blue profiles in both or either HCO$^+$ and/or HNC lines and clump mass infall rates are estimated to be in the range of 0.2E+3 Msunyr$^{-1}$ $-$ 1.8E-2 Msunyr$^{-1}$. The excitation temperature is obtained as <24K for all sources. The column densities for optically thin lines of H$^{13}$CO$^{+}$ and HN$^{13}$C are in the range of 0.4-8.8(E+12) cm$^{-2}$, and 0.9-11.9(E+12) cm$^{-2}$, respectively, while it is in the range of 0.1-7.5(E+14) cm$^{-2}$ for HCO$^{+}$ and HNC lines. The column densities for N$_{2}$H$^{+}$ were ranging between 4.4-275.7(E+12) cm$^{-2}$ as expected from cold dense regions. Large line widths of N$_{2}$H$^{+}$ might indicate turbulence and large line widths of HCO$^{+}$, HNC, and SiO indicate outflow activities. Mean optical depths are 20.32, and 23.19 for optically thick HCO$^{+}$ and HCN lines, and 0.39 and 0.45 for their optically thin isotopologues H$^{13}$CO$^{+}$ and HN$^{13}$C, respectively. This study reveals the physical and chemical properties of 30 high-mass IR-dark clumps and the interesting targets among them based on their emission line morphology and kinematics. ",MALT90 molecular content on high-mass IR-dark clumps
"  The study and comprehension of complex systems are crucial intellectual and scientific challenges of the 21st century. In this scenario, network science has emerged as a mathematical tool to support the study of such systems. Examples include environmental processes such as wildfires, which are known for their considerable impact on human life. However, there is a considerable lack of studies of wildfire from a network science perspective. Here, employing the chronological network concept -- a temporal network where nodes are linked if two consecutive events occur between them -- we investigate the information that dynamic community structures reveal about the wildfires' dynamics. Particularly, we explore a two-phase dynamic community detection approach, i.e., we applied the Louvain algorithm on a series of snapshots. Then we used the Jaccard similarity coefficient to match communities across adjacent snapshots. Experiments with the MODIS dataset of fire events in the Amazon basing were conducted. Our results show that the dynamic communities can reveal wildfire patterns observed throughout the year. ",Dynamic Community Detection into Analyzing of Wildfires Events
"  Focal plane arrays of bolometers are increasingly employed in astronomy at far--infrared to millimetre wavelengths. The focal plane fields and the detectors are both partially coherent in these systems, but no account has previously been taken of the effect of partial coherence on array performance. In this paper, we use our recently developed coupled--mode theory of detection together with Fisher information matrix techniques from signal processing to characterize the behaviour of partially coherent imaging arrays. We investigate the effects of the size and coherence length of both the source and the detectors, and the packing density of the array, on the amount of information that can be extracted from observations with such arrays. ",Simulations of partially coherent focal plane imaging arrays: Fisher   matrix approach to performance evaluation
"  More than about twenty central stars of planetary nebulae (CSPN) have been observed spectropolarimetrically, yet no clear, unambiguous signal of the presence of a magnetic field in these objects has been found. We perform a statistical (Bayesian) analysis of all the available spectropolarimetric observations of CSPN to constrain the magnetic fields on these objects. Assuming that the stellar field is dipolar and that the dipole axis of the objects are oriented randomly (isotropically), we find that the dipole magnetic field strength is smaller than 400 G with 95% probability using all available observations. The analysis introduced allows integration of future observations to further constrain the parameters of the distribution, and it is general, so that it can be easily applied to other classes of magnetic objects. We propose several ways to improve the upper limits found here. ",Upper limits to the magnetic field in central stars of planetary nebulae
"  A variation of Newton's constant $G$ over cosmological time scales would modify the main-squence time of globular cluster (GC) stars. We have calculated the evolution of low-mass stars typical for GCs both for standard non-varying $G$ and under the assumption of a linear variation of $G$. The age of the isochrones resulting from the latter models then was chosen such that the isochrones mimicked the standard ones at the turnoff. Assuming that the true age of GCs is between $8$ and $20\,\rm Gyr$, and because their apparent age is between $14$ and $18\,\rm Gyr$, we find that today $-35{\times}10^{-12}\,{\rm yr}^{-1}\la\dot{G}/G\la 7{\times}10^{-12}\,{\rm yr}^{-1}$. The upper limit (gravity weaker in the past) is competitive with direct present-day bounds from celestial mechanics. Within independently determined $\dot{G}/G$ limits a time-varying $G$ as an explanation for the discrepancy between the cosmic expansion age and the apparent GC ages is conceivable. ",Time-Variation of Newton's Constant and the Age of Globular Clusters
"  Gravitating bodies in motion, regardless of their constitution, always produce electromagnetic radiation in the form of photon pairs. This phenomenon is an analog of the radiation caused by the motion of dielectric (or magnetic) bodies. It is a member of a wide class of phenomena named dynamical Casimir effects, and it may be viewed as the squeezing of the electromagnetic vacuum. Production of photon pairs is a purely quantum-mechanical effect. Unfortunately, as we show, the emitted radiation is extremely weak as compared to radiation produced by other mechanisms. ",Electromagnetic radiation by gravitating bodies
"  Heterogeneous presentation of a neurological disorder suggests potential differences in the underlying pathophysiological changes that occur in the brain. We propose to model heterogeneous patterns of functional network differences using a demographic-guided attention (DGA) mechanism for recurrent neural network models for prediction from functional magnetic resonance imaging (fMRI) time-series data. The context computed from the DGA head is used to help focus on the appropriate functional networks based on individual demographic information. We demonstrate improved classification on 3 subsets of the ABIDE I dataset used in published studies that have previously produced state-of-the-art results, evaluating performance under a leave-one-site-out cross-validation framework for better generalizeability to new data. Finally, we provide examples of interpreting functional network differences based on individual demographic variables. ",Demographic-Guided Attention in Recurrent Neural Networks for Modeling   Neuropathophysiological Heterogeneity
"  We consider the free energy difference restricted to a finite volume for certain pairs of incongruent thermodynamic states (if they exist) in the Edwards-Anderson Ising spin glass at nonzero temperature. We prove that the variance of this quantity with respect to the couplings grows proportionally to the volume in any dimension greater than or equal to two. As an illustration of potential applications, we use this result to restrict the possible structure of Gibbs states in two dimensions. ",Fluctuation Bounds For Interface Free Energies in Spin Glasses
"  yperbolic polaritons in van der Waals materials recently attract a lot of attention, owing to their strong electromagnetic field confinement, ultraslow group velocities and long lifetimes. Typically, volume confined hyperbolic polaritons (HPs) are studied. Here we show the first near-field optical images of hyperbolic surface polarities, HSPs, which are confined and guided at the edges of thin flakes of a vdW material. To that end, we applied scattering-type scanning near-field optical microscopy (s-SNOM) for launching and real-space nanoimaging of hyperbolic surface phonon polariton modes on a hexagonal boron nitride, h-BN, flake. Our imaging data reveal that the fundamental HSP mode exhibits stronger field confinement, smaller group velocities and nearly identical lifetimes, as compared to the fundamental HP mode of the same h-BN flake. Our experimental data, corroborated by theory, establish a solid basis for future studies and applications of HPs and HSPs in vdW materials. ",Optical Nanoimaging of Hyperbolic Surface Polaritons at the Edges of van   der Waals Materials
"  Radio resources in vehicle-to-vehicle (V2V) communication can be scheduled either by a centralized scheduler residing in the network (e.g., a base station in case of cellular systems) or a distributed scheduler, where the resources are autonomously selected by the vehicles. The former approach yields a considerably higher resource utilization in case the network coverage is uninterrupted. However, in case of intermittent or out-of-coverage, due to not having input from centralized scheduler, vehicles need to revert to distributed scheduling. Motivated by recent advances in reinforcement learning (RL), we investigate whether a centralized learning scheduler can be taught to efficiently pre-assign the resources to vehicles for out-of-coverage V2V communication. Specifically, we use the actor-critic RL algorithm to train the centralized scheduler to provide non-interfering resources to vehicles before they enter the out-of-coverage area. Our initial results show that a RL-based scheduler can achieve performance as good as or better than the state-of-art distributed scheduler, often outperforming it. Furthermore, the learning process completes within a reasonable time (ranging from a few hundred to a few thousand epochs), thus making the RL-based scheduler a promising solution for V2V communications with intermittent network coverage. ",Reinforcement Learning Scheduler for Vehicle-to-Vehicle Communications   Outside Coverage
  We consider the Center projected SU(3) gluodynamics and rewrite it as a dual superconductor theory. The center monopole field plays the role of Higgs field in the dual superconductor theory.   The center monopole creation operator is constructed. ,The derivation of the dual superconductor theory from the Maximal Center   projected SU(3) - gluodynamics
"  We make use of a simple pair correlated wave function approach to obtain results for the ground-state densities and momentum distribution of a one-dimensional three-body bosonic system with different interactions in a harmonic trap. For equal interactions this approach is able to reproduce the known analytical cases of zero and infinite repulsion. We show that our results for the correlations agree with the exact diagonalization in all interaction regimes and with analytical results for the strongly repulsive impurity. This method also enables us to access the more complicated cases of mixed interactions, and the probability densities of these systems are analyzed. ",Correlation properties of a three-body bosonic mixture in a harmonic   trap
"  We have used narrow-band [OIII]$\lambda\lambda$4959,5007 and H$\alpha$+[NII]$\lambda\lambda6548,84$ Hubble Space Telescope (HST) images of 9 luminous (L[OIII]$>10^{42}$erg s$^{-1}$) type 2 QSOs with redshifts $0.1<z<0.5$ in order to constrain the geometry of their Extended Narrow-Line Regions (ENLR), as recent ground-based studies suggest these regions become more spherical at high luminosities due to destruction of the torus. We find instead elongated ENLRs reaching 4 to 19 kpc from the nucleus and bipolar ionization cones in [OIII]/(H$\alpha$+[NII]) excitation maps indicating that the torus survives these luminosities, allowing the escape of $\approx$10 times higher ionizing photon rates along the ionization axis than perpendicularly to it. The exceptional HST angular resolution was key to our success in arriving at these conclusions. Combining our measurements with previous ones based on similar HST data, we have revisited the relation between the ENLR radius R$_{maj}$ (in pc) and L[OIII] (in erg s$^{-1}$) over the range $39<$log(L[OIII])$<43.5$: log(R$_{maj}) = (0.51\pm0.03)$ log(L[OIII])$-18.12\pm0.98$. The radius of the ENLR keeps increasing with L[OIII] in our data, implying that the ENLR can extend to distances beyond the limit of the galaxy if gas is present there $-$ e.g. from AGN outflows or interactions, seen in 6 objects of our sample. We attribute the flattening previously seen in this relation to the fact that the ENLR is matter-bounded, meaning that ionizing photons usually escape to the intergalactic medium in luminous AGN. Estimated ionized gas masses of the ENLRs range from 0.3 to $2\times10^8$ M$_{\odot}$, and estimated powers for associated outflows range from $<0.1\%$ to a few percent of the QSO luminosity. ",Bipolar ionization cones in the Extended Narrow-Line Region of nearby   QSO2s
"  The universal character is a polynomial attached to a pair of partitions and is a generalization of the Schur polynomial. In this paper, we introduce an integrable system of q-difference lattice equations satisfied by the universal character, and call it the lattice q-UC hierarchy. We regard it as generalizing both q-KP and q-UC hierarchies. Suitable similarity and periodic reductions of the hierarchy yield the q-difference Painleve equations of types $A_{2g+1}^{(1)}$ $(g \geq 1)$, $D_5^{(1)}$, and $E_6^{(1)}$. As its consequence, a class of algebraic solutions of the q-Painleve equations is rapidly obtained by means of the universal character. In particular, we demonstrate explicitly the reduction procedure for the case of type $E_6^{(1)}$, via the framework of tau-functions based on the geometry of certain rational surfaces. ",Universal character and q-difference Painlev\'e equations with affine   Weyl groups
"  In this paper we prove that translation structures for which the corresponding vertical translation flows is weakly mixing and disjoint with its inverse, form a $G_\delta$-dense set in every non-hyperelliptic connected component of the moduli space $\mathcal M$. This is in contrast to hyperelliptic case, where for every translation structure the associated vertical flow is isomorphic to its inverse. To prove the main result, we study limits of the off-diagonal 3-joinings of special representations of vertical translation flows. Moreover, we construct a locally defined continuous embedding of the moduli space into the space of measure-preserving flows to obtain the $G_\delta$-condition. ",On typicality of translation flows which are disjoint with their inverse
"  The auto-correlations of arithmetic functions, such as the von Mangoldt function, the M\""obius function and the divisor function, are the subject of classical problems in analytic number theory. The function field analogues of these problems have recently been resolved in the limit of large finite field size $q$. However, in this limit the correlations disappear: the arithmetic functions become uncorrelated. We compute averages of terms of lower order in $q$ which detect correlations. Our results show that there is considerable cancellation in the averaging and have implications for the rate at which correlations disappear when $q \rightarrow\infty$; in particular one cannot expect remainder terms that are of the order of the square-root of the main term in this context. ",Arithmetic correlations over large finite fields
"  The cross section for coherent J/psi photoproduction accompanied by at least one neutron on one side of the interaction point and no neutron activity on the other side, X[n]0[n], is measured with the CMS experiment in ultra-peripheral PbPb collisions at sqrt(s[NN]) = 2.76 TeV. The analysis is based on a data sample corresponding to an integrated luminosity of 159 inverse microbarns, collected during the 2011 PbPb run. The J/psi mesons are reconstructed in the dimuon decay channel, while neutrons are detected using zero degree calorimeters. The measured cross section is dsigma[coh,X[n]0[n]] / dy(J/psi) = 0.36 +/- 0.04 (stat) +/- 0.04 (syst) mb in the rapidity interval 1.8 < abs(y) < 2.3. Using a model for the relative rate of coherent photoproduction processes, this X[z,n,z] measurement gives a total coherent photoproduction cross section of dsigma[coh] / dy(J/psi) = 1.82 +/- 0.22 (stat) +/- 0.20 (syst) +/- 0.19 (theo) mb. The data strongly disfavour the impulse approximation model prediction, indicating that nuclear effects are needed to describe coherent J/psi photoproduction in gamma + Pb interactions. The data are found to be consistent with the leading twist approximation, which includes nuclear gluon shadowing. ",Coherent J/psi photoproduction in ultra-peripheral PbPb collisions at   sqrt(s[NN]) = 2.76 TeV with the CMS experiment
"  To what extent is the citation rate of new papers influenced by the past social relations of their authors? To answer this question, we present a data-driven analysis of nine different physics journals. Our analysis is based on a two-layer network representation constructed from two large-scale data sets, INSPIREHEP and APS. The social layer contains authors as nodes and coauthorship relations as links. This allows us to quantify the social relations of each author, prior to the publication of a new paper. The publication layer contains papers as nodes and citations between papers as links. This layer allows us to quantify scientific attention as measured by the change of the citation rate over time. We particularly study how this change depends on the social relations of their authors, prior to publication. We find that on average the maximum value of the citation rate is reached sooner for authors who either published more papers, or who had more coauthors in previous papers. We also find that for these authors the decay in the citation rate is faster, meaning that their papers are forgotten sooner. ",Citations Driven by Social Connections? A Multi-Layer Representation of   Coauthorship Networks
"  Empirically it has been observed that the performance of deep neural networks steadily improves as we increase model size, contradicting the classical view on overfitting and generalization. Recently, the double descent phenomena has been proposed to reconcile this observation with theory, suggesting that the test error has a second descent when the model becomes sufficiently overparameterized, as the model size itself acts as an implicit regularizer. In this paper we add to the growing body of work in this space, providing a careful study of learning dynamics as a function of model size for the least squares scenario. We show an excess risk bound for the gradient descent solution of the least squares objective. The bound depends on the smallest non-zero eigenvalue of the covariance matrix of the input features, via a functional form that has the double descent behavior. This gives a new perspective on the double descent curves reported in the literature. Our analysis of the excess risk allows to decouple the effect of optimization and generalization error. In particular, we find that in case of noiseless regression, double descent is explained solely by optimization-related quantities, which was missed in studies focusing on the Moore-Penrose pseudoinverse solution. We believe that our derivation provides an alternative view compared to existing work, shedding some light on a possible cause of this phenomena, at least in the considered least squares setting. We empirically explore if our predictions hold for neural networks, in particular whether the covariance of intermediary hidden activations has a similar behavior as the one predicted by our derivations. ",On the Role of Optimization in Double Descent: A Least Squares Study
"  The early stages of a relativistic heavy-ion collision are examined in the framework of an effective classical SU(3) Yang-Mills theory in the transverse plane. We compute the initial energy and number distributions, per unit rapidity, at mid-rapidity, of gluons produced in high energy heavy ion collisions. We discuss the phenomenological implications of our results in light of the recent RHIC data. ",Coherent gluon production in very high energy heavy ion collisions
"  The emerging Cloud-RAN architecture within the fifth generation (5G) of wireless networks plays a vital role in enabling higher flexibility and granularity. On the other hand, Cloud-RAN architecture introduces an additional link between the central, cloudified unit and the distributed radio unit, namely fronthaul (FH). Therefore, the foreseen reliability and latency for 5G services should also be provisioned over the FH link. In this paper, focusing on Ethernet as FH, we present a reliable packet-based FH communication and demonstrate the upper and lower bounds of latency that can be offered. These bounds yield insights into the trade-off between reliability and latency, and enable the architecture design through choice of splitting point, focusing on high layer split between PDCP and RLC and low layer split between MAC and PHY, under different FH bandwidth and traffic properties. Presented model is then analyzed both numerically and through simulation, with two classes of 5G services that are ultra reliable low latency (URLL) and enhanced mobile broadband (eMBB). ",Latency Bounds of Packet-Based Fronthaul for Cloud-RAN with   Functionality Split
"  We show that a sterile neutrino with mass in the 1-20 keV range and a small mixing with the electron neutrino can simultaneously explain the origin of the pulsar motions and the dark matter in the universe. An asymmetric neutrino emission from a hot nascent neutron star can be the explanation of the observed pulsar velocities. In addition to the pulsar kick mechanism based on resonant neutrino transitions, we point out a new possibility: an asymmetric off-resonant emission of sterile neutrinos. The two cases correspond to different values of the masses and mixing angles. In both cases we identify the ranges of parameters consistent with the pulsar kick, as well as cosmological constraints. ",Pulsar kicks from a dark-matter sterile neutrino
"  Some thermodynamical magnitudes of interest in a pure neutron plasma are studied within the framework of the non-relativistic Brueckner-Hartree-Fock approximation at finite density and temperature. We use Skyrme and Gogny forces to describe such a neutron plasma and study the main differences that arise in these two effective parametrizations of the nuclear interaction when a strong magnetic field induces a permanent magnetization in the gas. The existence of a non-zero permanent spin polarization in a neutron plasma is explored in the density-temperature parameter space. We find that for moderate temperatures and in the low density range up to densities $\approx 0.5\rho_0$ both parametrizations predict that as density decreases an increasingly strong magnetization is allowed. In the range $0.5 \rho_0 \lesssim \rho \lesssim 3 \rho_0$ there is an approximately constant polarization that can be as big as $\approx 12%$ for the maximum allowed interior magnetic field $B \approx 10^{18}$ G. For higher densities there is a dramatic difference in the polarization trend followed by Skyrme an Gogny forces. While the former predict a ferromagnetic phase transition, the Gogny forces prevent it keeping the magnetization below 5%. ",Magnetization of a neutron plasma with Skyrme and Gogny forces in the   presence of a strong magnetic field
"  We present a 6-approximation algorithm for the minimum-cost $k$-node connected spanning subgraph problem, assuming that the number of nodes is at least $k^3(k-1)+k$. We apply a combinatorial preprocessing, based on the Frank-Tardos algorithm for $k$-outconnectivity, to transform any input into an instance such that the iterative rounding method gives a 2-approximation guarantee. This is the first constant-factor approximation algorithm even in the asymptotic setting of the problem, that is, the restriction to instances where the number of nodes is lower bounded by a function of $k$. ",Approximating Minimum-Cost k-Node Connected Subgraphs via   Independence-Free Graphs
"  In this work we present, for the first time, the non-perturbative renormalization for the unpolarized, helicity and transversity quasi-PDFs, in an RI' scheme. The proposed prescription addresses simultaneously all aspects of renormalization: logarithmic divergences, finite renormalization as well as the linear divergence which is present in the matrix elements of fermion operators with Wilson lines. Furthermore, for the case of the unpolarized quasi-PDFs, we describe how to eliminate the unwanted mixing with the twist-3 scalar operator. We utilize perturbation theory for the one-loop conversion factor that brings the renormalization functions to the MS-scheme at a scale of 2 GeV. We also explain how to improve the estimates on the renormalization functions by eliminating lattice artifacts. The latter can be computed in one-loop perturbation theory and to all orders in the lattice spacing. We apply the methodology for the renormalization to an ensemble of twisted mass fermions with Nf=2+1+1 dynamical light quarks, and a pion mass of around 375 MeV. ",A complete non-perturbative renormalization prescription for quasi-PDFs
"  We show that the loudest extreme mass-ratio inspirals (EMRIs) detected by the future space-based gravitational wave detector LISA can be used as dark standard sirens, statistically matching their sky localisation region with mock galaxy catalogs. In these Proceedings we focus on a realistic EMRI population scenario and report accuracy predictions for the measure of cosmological parameters, anticipating the potential of EMRIs to simultaneously constrain the Hubble constant, the dark matter, and the dark energy density parameters. ",Gravitational wave cosmology with EMRIs
"  Principles of operation, construction and first test results of a Dielectric Resistive Plate Chamber (DRPC) are described. The detector has shown stability of operation in the avalanche mode of gas amplfication within a wide range of applied voltages. Double-gap DRPCs have demonstrated the MIP registration efficiency of 97% and the time resolution of 180-200 ps. No changes in DRPC operation have been observed with test beam intensities up to 10^3 Hz/cm^2. ",Dielectric Resistive Plate Chamber as a detector for time-of-flight   measurements
"  The influence of microwave radiation (1.2-140 GHz) on resistance of high-mobility two-dimensional electron gas in GaAs quantum wells is studied. Two series of microwave-induced magnetoresistance oscillations periodic in 1/B were observed under microwave radiation. The periods of oscillations are determined by the microwave frequency and power, correspondingly. The experimental data is qualitatively explained by photon-assisted transport and Zener tunneling between Landau orbits. ",Two Types of Microwave-Induced Magnetoresistance Oscillations in a 2D   Electron Gas at Large Filling Factors
"  The purpose of this article is numerical verification of the thory of weak turbulence. We performed numerical simulation of an ensemble of nonlinearly interacting free gravity waves (swell) by two different methods: solution of primordial dynamical equations describing potential flow of the ideal fluid with a free surface and, solution of the kinetic Hasselmann equation, describing the wave ensemble in the framework of the theory of weak turbulence. Comparison of the results demonstrates pretty good applicability of the weak turbulent approach. ","In a book ""Tsunami and Nonlinear Waves"": Numerical Verification of the   Hasselmann equation"
"  Let $\alpha$ be an algebraic integer of degree $d$, which is reciprocal. The house of $\alpha$ is the largest modulus of its conjugates. We proved that $d$-th power of the house of reciprocal $\alpha$ has a limit point. We presented a property of antireciprocal hexanomials. We compute the minimum of the houses of all reciprocal algebraic integers of degree $d$ having the minimal polynomial which is a factor of a $D$-th degree reciprocal or antireciprocal polynomial with at most eight monomials, say $\mathrm{mr}(d)$, for $d$ at most 180, $D\le 1.5d$ and $D\le 210$. We show that it is not necessary to take into account unprimitive polynomials. The computations suggest several conjectures. ",The reciprocal algebraic integers having small houses
"  An intelligent radome utilizing composite metamaterial structures is presented and investigated in this article, which can realize energy isolation and asymmetric propagation of electromagnetic (EM) wave self-adaptively by controlling states of PIN diodes. The whole structure mainly consists of a broadband polarization-sensitive polarization converter (PC) and an active frequency selective rasorber (AFSR) switching between a transmission mode and absorption mode which is used as an energy-selective surface (ESS). Among them, the function of the PC is to make the EM waves transmit asymmetrically, and the purpose of AFSR is to make the high-power waves be reflected or absorbed, which depends on the polarization type of the wave. Thus, the radome can realize both asymmetric propagations of EM wave and electromagnetic shielding. The equivalent circuit models (ECM) and parametric studies are considered to explain the physical operating mechanism of PC and AFSR. The fabricated structure with 7*7 unit cells is experimentally demonstrated and the measured results agree with simulated results well. Considering the distinctive characteristic of self-actuation, the presented concept has the potential application in electromagnetic stealth and HPEMWs shielding to protect communication devices. ",Intelligent Radome Design Using Multilayer Metamaterial Structures to   Realize Energy Isolation and Asymmetric Propagation of Electromagnetic Wave
"  We study scatterings of bosonic massive closed string states at arbitrary mass levels from D-brane. We discover that all the scattering amplitudes can be expressed in terms of the generalized hypergeometric function with special arguments, which terminates to a finite sum and, as a result, the whole scattering amplitudes consistently reduce to the usual beta function. For the simple case of D-particle, we explicitly calculate high-energy limits of a series of the above scattering amplitudes for arbitrary mass levels, and derive infinite linear relations among them for each fixed mass level. The ratios of these high-energy scattering amplitudes are found to be consistent with the decoupling of high-energy zero-norm states of our previous works. ",Scatterings of Massive String States from D-brane and Their Linear   Relations at High Energies
"  Interest in problems of statistical inference connected to measurements of quantum systems has recently increased substantially, in step with dramatic new developments in experimental techniques for studying small quantum systems. Furthermore, theoretical developments in the theory of quantum measurements have brought the basic mathematical framework for the probability calculations much closer to that of classical probability theory. The present paper reviews this field and proposes and interrelates a number of new concepts for an extension of classical statistical inference to the quantum context. ","On Quantum Statistical Inference, II"
"  The relation between the elastic wave equation for plane, isotropic bodies and an underlying classical ray dynamics is investigated. We study in particular the eigenfrequencies of an elastic disc with free boundaries and their connection to periodic rays inside the circular domain. Even though the problem is separable, wave mixing between the shear and pressure component of the wave field at the boundary leads to an effective stochastic part in the ray dynamics. This introduces phenomena typically associated with classical chaos as for example an exponential increase in the number of periodic orbits. Classically, the problem can be decomposed into an integrable part and a simple binary Markov process. Similarly, the wave equation can in the high frequency limit be mapped onto a quantum graph. Implications of this result for the level statistics are discussed. Furthermore, a periodic trace formula is derived from the scattering matrix based on the inside-outside duality between eigen-modes and scattering solutions and periodic orbits are identified by Fourier transforming the spectral density ",Wave chaos in the elastic disc
"  Extensively applied to both light and heavy meson decay and standing as one of the most successful strong decay models is the $^{3}P_{0}$ model, in which $q\bar{q}$ pair production is the dominant mechanism. In this paper we evaluate strong decay amplitudes and partial widths of strange $S$ and $D$ state mesons, namely $ \phi(1020)$, $\phi (1680) $, $ \phi (2050) $, $\phi_1 (1850) $, $\phi_2 (1850) $ and $ \phi_3 (1850) $, in the bound-state corrected $^{3}P_{0}$ decay model (C$^{3}P_{0}$). The C$^{3}P_{0}$ model is obtained in the context of the Fock-Tani formalism, which is a mapping technique. ",Strong decays of strange quarkonia in a corrected 3P0 model
"  Possible violations of Lorentz invariance (LIV) have been investigated for a long time using the observed spectral lags of gamma-ray bursts (GRBs). However, these generally have relied on using a single photon in the highest energy range. Furthermore, the search for LIV lags has been hindered by our ignorance concerning the intrinsic time lag in different energy bands. GRB 160625B, the only burst so far with a well-defined transition from $positive$ lags to $negative$ lags provides a unique opportunity to put new constraints on LIV. Using multi-photon energy bands we consider the contributions to the observed spectral lag from both the intrinsic time lag and the lag by LIV effects, and assuming the intrinsic time lag to have a positive dependence on the photon energy, we obtain robust limits on LIV by directly fitting the spectral lag data of GRB 160625B. Here we show that these robust limits on the quantum gravity energy scales are $E_{\rm QG,1}\geq0.5\times10^{16}$ GeV for the linear, and $E_{\rm QG,2}\geq1.4\times10^{7}$ GeV for the quadratic LIV effects, respectively. In addition, we give for the first time a reasonable formulation of the intrinsic energy-dependent time lag. ",A New Test of Lorentz Invariance Violation: the Spectral Lag Transition   of GRB 160625B
"  The present paper deals with optimisation of Nearest Neighbour rule Classifiers via Genetic Algorithms. The methodology consists on implement a Genetic Algorithm capable of search the input feature space used by the NNR classifier. Results show that is adequate to perform feature reduction and simultaneous improve the Recognition Rate. Some practical examples prove that is possible to Recognise Portuguese Granites in 100%, with only 3 morphological features (from an original set of 117 features), which is well suited for real time applications. Moreover, the present method represents a robust strategy to understand the proper nature of the images treated, and their discriminant features. KEYWORDS: Feature Reduction, Genetic Algorithms, Nearest Neighbour Rule Classifiers (k-NNR). ",Less is More - Genetic Optimisation of Nearest Neighbour Classifiers
"  Actinide-containing complexes present formidable challenges for electronic structure methods due to the large number of degenerate or quasi-degenerate electronic states arising from partially occupied 5f and 6d shells. Conventional multi-reference methods can treat active spaces that are often at the upper limit of what is required for a proper treatment of species with complex electronic structures, leaving no room for verifying their suitability. In this work we address the issue of properly defining the active spaces in such calculations, and introduce a protocol to determine optimal active spaces based on the use of the Density Matrix Renormalization Group algorithm and concepts of quantum information theory. We apply the protocol to elucidate the electronic structure and bonding mechanism of volatile plutonium oxides (PuO$_3$ and PuO$_2$(OH)$_2$), species associated with nuclear safety issues for which little is known about the electronic structure and energetics. We show how, within a scalar relativistic framework, orbital-pair correlations can be used to guide the definition of optimal active spaces which provide an accurate description of static/non-dynamic electron correlation, as well as to analyse the chemical bonding beyond a simple orbital model. From this bonding analysis we are able to show that the addition of oxo- or hydroxo-groups to the plutonium dioxide species considerably changes the pi-bonding mechanism with respect to the bare triatomics, resulting in bent structures with considerable multi-reference character. ","On the Multi-Reference Nature of Plutonium Oxides: PuO$_2^{2+}$,   PuO$_2$, PuO$_3$ and PuO$_2$(OH)$_2$"
"  Land cover mapping is essential for monitoring global environmental change and managing natural resources. Unfortunately, traditional classification models are plagued by limited training data available in existing land cover products and data heterogeneity over space and time. In this survey, we provide a structured and comprehensive overview of challenges in land cover mapping and machine learning methods used to address these problems. We also discuss the gaps and opportunities that exist for advancing research in this promising direction. ",Land Cover Mapping in Limited Labels Scenario: A Survey
"  A compact and elegant description of the electromagnetic fields in media and in vacuum is attained in the differential forms formalism. This description is explicitly invariant under diffeomorphisms of the spacetime so it is suitable for arbitrary curvilinear coordinates. Moreover, it is independent of the geometry of the underline spacetime. The bulk electric charge and current densities are represented by twisted non-singular differential 3-forms. The charge and current densities with a support on the low dimensional submanifolds (surfaces, strings and points) naturally require singular differential forms. In this paper, we present a covariant metric-free description of the surface, string and point densities. It is shown that a covariant description requires Dirac's delta-forms instead of delta-functions. Covariant metric-free conservation laws for the low-dimensional densities are derived. ",Low-dimensional electric charges. Covariant description
"  We study quasinormal modes and scattering properties via calculation of the $S$-matrix for scalar and electromagnetic fields propagating in the background of spherically and axially symmetric, traversable Lorentzian wormholes of a generic shape. Such wormholes are described by the Morris-Thorne ansatz and its axially symmetric generalization. The properties of quasinormal ringing and scattering are shown to be determined by the behavior of the wormhole's shape function $b(r)$ and shift factor $\Phi(r)$ near the throat. In particular, wormholes with the shape function $b(r)$, such that $b'(r) \approx 1$, have very long-lived quasinormal modes in the spectrum. We have proved that the axially symmetric traversable Lorentzian wormholes, unlike black holes and other compact rotating objects, do not allow for superradiance. As a by product we have shown that the 6th order WKB formula used for scattering problems of black or wormholes provides high accuracy and thus can be used for quite accurate calculations of the Hawking radiation processes around various black holes. ",Passage of radiation through wormholes of arbitrary shape
"  Weak lensing calculations are often made under the assumption of the Born approximation, where the ray path is approximated as a straight radial line. In addition, lens-lens couplings where there are several deflections along the light ray are often neglected. We examine the effect of dropping the Born approximation and taking lens-lens couplings into account, for weak lensing effects up to second order (cosmic flexion), by making a perturbative expansion in the light path. We present a diagrammatic representation of the resulting corrections to the lensing effects. The flexion signal, which measures the derivative of the density field, acquires correction terms proportional to the squared gravitational shear; we also find that by dropping the Born approximation, two further degrees of freedom of the lensing distortion can be excited (the twist components), in addition to the four standard flexion components. We derive angular power spectra of the flexion and twist, with and without the Born-approximation and lens-lens couplings and confirm that the Born approximation is an excellent approximation for weak cosmic flexions, except at very small scales. ",On the validity of the Born approximation for weak cosmic flexions
"  It is known that the eigenvalues of selfadjoint elements a,b,c with a+b+c=0 in the factor R^omega (ultrapower of the hyperfinite II1 factor) are characterized by a system of inequalities analogous to the classical Horn inequalities of linear algebra. We prove that these inequalities are in fact true for elements of an arbitrary finite factor. A matricial (`complete') form of this result is equivalent to an embedding question formulated by Connes. ",Intersections of Schubert varieties and eigenvalue inequalities in an   arbitrary finite factor
"  We present the results of near-infrared imaging and low-resolution near- infrared spectroscopy of low mass objects in the NGC 1333 molecular cloud. A JHK survey of an 11.4' x 11.7' area of the northern cluster was conducted to a sensitivity of K < 16 mag. Using near-infrared magnitudes and colors from this and previously published surveys, twenty-five brown dwarf candidates were selected toward the high extinction cloud core. Spectra in the K band were obtained and comparisons of the depths of water vapor absorption bands in our candidate objects with a grid of dwarf,subgiant, and giant standards were made to derive spectral types. These data were then used to derive effective temperatures and stellar luminosities which, when combined with theoretical tracks and isochrones for pre-main sequence objects, resulted in estimates for their masses and ages. The models suggest a median age for the sample of < 1 Myr with substellar masses for at least 9 of the candidates including the x-ray flare source ASR 24. Surface gravities have been estimated for the brown dwarf candidates and, for a given spectral type,found to resemble more closely dwarfs than giants. Using the near-infrared imaging data and age estimates from the spectroscopic sample, an extinction-limited sample in the northern cluster was defined. Consistent with recent studies of other young clusters, this sample exhibits an accretion disk frequency of 0.75 +-0.20 and a mass spectrum slope across the hydrogen-burning limit of alpha < 1.6 where dN/dM ~ M^-(alpha). ",Low Mass Stars and Substellar Objects in the NGC 1333 Molecular Cloud
"  This article deals with redundant digit expansions with an imaginary quadratic algebraic integer with trace $\pm 1$ as base and a minimal norm representatives digit set. For $w\geq 2$ it is shown that the width-$w$ non-adjacent form is not an optimal expansion, meaning that it does not minimize the (Hamming-)weight among all possible expansions with the same digit set. One main part of the proof uses tools from Diophantine analysis, namely the theory of linear forms in logarithms and the Baker--Davenport reduction method. ",Non-Minimality of the Width-$w$ Non-adjacent Form in Conjunction with   Trace One $\tau$-adic Digit Expansions and Koblitz Curves in Characteristic   Two
"  Dealing with broadcast scenarios has become a relevant topic in the scientific community. Because of interference, resource management presents a challenge, specially when spatial diversity is introduced. Many researches presented theoretical benchmarks, simplifications and low complex schemes, but in fact it is difficult the real implementation.   The major part of current works propose iterative solutions, which are far away of feasible results. Since the problem is not convex, iterative solutions are prohibitive. Moreover, they always require the full knowledge of the channel state information. Hence, the feedback channel is often unaffordable and makes impossible to carry a huge amount of information.   The present work aims to fill this gap presenting a novel scheme, from the theoretical framework to realistic scheme. It introduces the solution of the maximization of the sum rate in the broadcast scenario with multiple antennas at the transmitter. This solution aims to be realistic and to distribute the complexity between the base station and user equipment.   Also, due to its construction, it opens the door to be compatible with LTE standards with no relevant changes. Thus, it allows to combine the resource allocation with scheduling tasks in a LTE environment, fulfilling the feedback requirements and maximizing the sum rate of the system. ",Smart Resource Allocation: Beyond the Optimum
"  In this talk, we present the recent results on charmonium decays from the BES experiment at the BEPC collider. The analyses are based on a 14 million psi(2S) events data sample. We report results on leptonic decays, hadronic decays, and radiative decays of psi(2S), as well as hadronic decays of chi_cJ states and rare or forbidden decays of J/psi. ",Recent BES results on charmonium decays
"  We consider the problem of quantization of the bosonic membrane via the large $N$ limit of its matrix regularizations $H_N$ in Fock space. We prove that there exists a choice of the Fock space frequency such that $ H_N$ can be written as a sum of a non-interacting Hamiltonian $H_{0,N}$ and the original normal ordered quartic potential. Using this decomposition we obtain upper and lower bounds for the ground state energy in the planar limit, we study a perturbative expansion about the spectrum of $H_{0,N}$, and show that the spectral gap remains finite at $N=\infty$ at least up to the second order. We also apply the method to the $U(N)$-invariant anharmonic oscillator, and demonstrate that our bounds agree with the exact result of Brezin et al. ",Optimized Fock space in the large N limit of quartic interactions in   Matrix Models
"  Electron mobility, energy spectra and intrinsic carrier concentrations in the n-type Hg0.32Cd0.68Te / Hg1-xCdxTe / Hg0.32Cd0.68Te quantum well (QW) in semi-metallic state are numerically modeled. Energy spectra and wave functions were calculated in the framework of the 8-band k-p Hamiltonian. In our model, electron scattering on longitudinal optical phonons, charged impurities, and holes has been taken into account, and the mobility has been calculated by an iterative solution of the Boltzmann transport equation. Our results show that the increase of the electron concentration in the well enhances the screening of the 2D electron gas, decreases the hole concentration, and can ultimately lead to a high electron mobility at liquid nitrogen temperatures. The increase of the electron concentration in the QW could be achieved in situ by delta-doping of barriers or by applying the top-gate potential. Our modeling has shown that for low molar composition x the concentration of holes in the well is high in a wide range of electron concentrations; in this case, the purity of samples does not significantly influence the electron mobility. These results are important in the context of establishing optimal parameters for the fabrication of high-mobility Hg1-xCdxTe quantum wells able to operate at liquid nitrogen temperature and thus suitable for applications in terahertz detectors. ",Modeling of electron energy spectra and mobilities in semi-metallic   Hg1-xCdxTe quantum wells
"  [abridged] Building upon a previous study, we define a method to blindly identify galaxies that underwent, and may still be undergoing, a fast downfall of their star-formation activity, that is, a more than 80% drop in star-formation rate (SFR) occurring in less than 500 Myr. Modeling galaxies' SED with a delayed-$\tau$ star formation history (SFH), with and without allowing an instantaneous SFR drop within the last hundreds Myr, we isolate 102 candidates out of a subsample of 6,680 galaxies classified as star-forming from the UVJ criterion in the ZFOURGE catalogues. These galaxies are mostly located in the lower part of the SFR-M$_*$ main sequence (MS) and extend up to a factor 100 below it. They also lie close to the limit between the passive and active regions on the UVJ diagram, indicating that they are in a transition phase. We show that the selected candidates have different physical properties compared to galaxies with similar UVJ colors, namely, lower star-formation rates and different stellar masses. The morphology of the candidates show no preference for a particular type. Among the 102 candidates, only 4 show signs of an AGN activity (from X-ray luminosity or UV-IR SED fitting decomposition). This low fraction of AGNs among the candidates implies that AGN activity may not be the main driver of the recent downfall, although timescale differences and duty cycle must be taken into account. We finally attempt to recover the past position of these galaxies on the SFR-M$_*$ plane, before the downfall of their star-formation and show that some of them were in the starburst region before and are back on the MS. These candidates constitute a promising sample that need more investigation in order to understand the different mechanisms at the origin of the star formation decrease of the Universe since $z$$\sim$2. ",Identification of galaxies that experienced a recent major drop of star   formation
  We consider the simplest parabolic-elliptic model of chemotaxis in the whole space in several dimensions. Criteria for the existence of radial global-in-time solutions in terms of suitable Morrey norms are derived. ,Global radial solutions in classical Keller-Segel model of chemotaxis
"  In this paper, we present an explicit form in terms of end-point data for the classical action $S_{2n}$ evaluated on extremals satisfying the Hamilton-Jacobi equation for each member of a hierarchy of classical non-relativistic oscillators characterized by even power potentials (i.e., attractive potentials $V_{2n}(y_{2n})={\frac{1}{2n}}k_{2n}y_{2n}^{2n}(t)|_{n{\geq}1}$). The nonlinear quartic oscillator corresponds to $n=2$ while the harmonic oscillator corresponds to $n=1$. ",Actions for an Hierarchy of Attractive Nonlinear Oscillators Including   the Quartic Oscillator in 1+1 Dimensions
"  Density matrix embedding theory (DMET) provides a theoretical framework to treat finite fragments in the presence of a surrounding molecular or bulk environment, even when there is significant correlation or entanglement between the two. In this work, we give a practically oriented and explicit description of the numerical and theoretical formulation of DMET. We also describe in detail how to perform self-consistent DMET optimizations. We explore different embedding strategies with and without a self-consistency condition in hydrogen rings, beryllium rings, and a sample S$_{\text{N}}$2 reaction. The source code for the calculations in this work can be obtained from \url{https://github.com/sebwouters/qc-dmet}. ",A practical guide to density matrix embedding theory in quantum   chemistry
"  The cycling operation is a special kind of conjugation that can be applied to elements in Artin's braid groups, in order to reduce their length. It is a key ingredient of the usual solutions to the conjugacy problem in braid groups. In their seminal paper on braid-cryptography, Ko, Lee et al. proposed the {\it cycling problem} as a hard problem in braid groups that could be interesting for cryptography. In this paper we give a polynomial solution to that problem, mainly by showing that cycling is surjective, and using a result by Maffre which shows that pre-images under cycling can be computed fast. This result also holds in every Artin-Tits group of spherical type.   On the other hand, the conjugacy search problem in braid groups is usually solved by computing some finite sets called (left) ultra summit sets (left-USS), using left normal forms of braids. But one can equally use right normal forms and compute right-USS's. Hard instances of the conjugacy search problem correspond to elements having big (left and right) USS's. One may think that even if some element has a big left-USS, it could possibly have a small right-USS. We show that this is not the case in the important particular case of rigid braids. More precisely, we show that the left-USS and the right-USS of a given rigid braid determine isomorphic graphs, with the arrows reversed, the isomorphism being defined using iterated cycling. We conjecture that the same is true for every element, not necessarily rigid, in braid groups and Artin-Tits groups of spherical type. ",On the cycling operation in braid groups
"  The current paper is aimed at the determination of barriers that govern the covalent coupling between two fullerenes C60 (C60 dimer), C60 and single-walled carbon nanotube ([C60-(4,4)] carbon nanobud), and C60 and graphene ([C60-(5,5)] and [C60-(9,8)] graphene nanobuds). Brutto barriers determined as couplings energies are expanded over two contributions that present total energy of deformation of the composites' components and energy of covalent coupling . In view of these energetic parameters and in contrast to expectations, seemingly identical reactions result in different final products. The peculiarity is suggested to be provided by a topochemical character of the covalent coupling between any two members of the sp2 nanocarbons' family. The computations were performed by using the AM1 semiempirical version of unrestricted broken symmetry Hartree-Fock approach. ",Reaction barriers and deformation energies of C60-based composites
"  This reform was a part of a transnational movement as 'the New Math' in the United States or the activity of the Lichnerowicz commission in France. The Russian version of these events involved the whole secondary and high school (4-10 grades). The leaders of the reformation were Alexey Markushevich and Andrey Kolmogorov. Their team consisted of best educationalists and best specialists in supplementary education. The project offered unqualified support of the Academy of Sciences and of the Ministry of education. However, the program of the reform was too optimistic, apparently some strategical ideas were unrealizable (and certainly there were no sufficient preliminary experiments for their verification). Starting September 1972 Soviet school was depressed, enormous efforts of participants of the reformation and simplification of the new school curriculum could not improve the situation. The reform was stopped by Lev Pontryagin in autumn 1980. The counterreformation required quick not-prepared steps and was not well-ordered. In 1981-1985 the heavy crisis was overcome but the mathematical education did not return to the pre-reform level. ","Kolmogorov reform of mathematical education, 1970-1980"
"  We study the electromagnetic form factor of the pion and kaons at low-energies with the use of Chiral Perturbation Theory. The analysis is performed within the three flavour framework and at next-to-next-to-leading order. We explain carefully all the relevant consistency checks on the expressions, present full analytical results for the pion form factor and describe all the assumptions in the analysis. From the phenomenological point of view we make use of our expression and the available data to obtain the charge radius of the pion obtaining $<r^2 >_V^\pi=(0.452+-0.013) fm^2$, as well as the low-energy constant $L_9^r(m_\rho)= (5.93+-0.43)10^{-3}$. We also obtain experimental values for 3 combinations of order $p^6$ constants. ",Pion and Kaon Electromagnetic Form Factors
"  Let $R$ be a polynomial ring over a field $k$ with irrelevant ideal $\frak m$ and dimension $d$. Let $I$ be a homogeneous ideal in $R$. We study the asymptotic behavior of the length of the modules $H^{i}_{\frak m}(R/I^n)$ for $n\gg 0$. We show that for a fixed number $\alpha \in \mathbb Z$, $\limsup_{n\rightarrow \infty}\frac{\lambda(H^{i}_{\frak m}(R/I^n)_{\geq -\alpha n})}{n^d}<\infty.$ Combining this with recent strong vanishing results gives that $\limsup_{n\rightarrow \infty}\frac{\lambda(H^{i}_{\frak m}{R/I^n})}{n^d}<\infty$ in many situations. We also establish that the actual limit exists and is rational for certain classes of monomial ideals $I$ such that the lengths of local cohomology of $I^n$ are eventually finite. Our proofs use Gr\""obner deformation and Presburger arithmetic. Finally, we utilize more traditional commutative algebra techniques to show that $\liminf_{n\rightarrow \infty}\frac{\lambda(H^{i}_{\frak m}(R/I^n))}{n^d}>0$ when $R/I$ has ""nice"" singularities in both zero and positive characteristics. ",Length of local cohomology of powers of ideals
"  In this article we report on a new proposal to treat the infrared problems of thermal QCD by taking into account explicitly the confining influence of the Gribov horizon. In order to make clear the possible value of such an approach, we briefly review the most important arguments why a straightforward perturbative description of finite-temperature QCD is unlikely to be successful. From the infrared problems of thermal perturbation theory one can conclude that confinement effects and bound states probably play an important role also in the high-temperature phase.   To set the stage we recount the supposed role of the Gribov horizon for confinement, before we turn to the application to finite-temperature theory. In the current approach it has been found that the contributions to the free energy from the explicit inclusion of the horizon begin to set in at order $g^6$ -- precisely where the infrared problems of thermal QCD lead to a breakdown of ordinary perturbation theory.   From the study of observables (free energy, anomaly, bulk viscosity) we also note that for thermodynamic observables the leading order term obtained by such an expansion in the coupling strongly deviates from the more complete numerical solution. This can be regarded as yet another sign for general problems of series expansions in thermal QCD. ",Contributions to the QCD Pressure Beyond Perturbation Theory
  We review classical results on holographic entanglement entropy utilizing the Hamilton-Jacobi approach. Possibility of using the entanglement entropy as a probe of confinement is shortly discussed in the context of lattice data. ,Hamilton-Jacobi formulation of holographic Entanglement Entropy
"  We address the question what information, other than the Final State Interaction parameters, one can extract from data on near-threshold meson production. ",Final state interaction in near-threshold meson production
"  Full-text search engines are important tools for information retrieval. In a proximity full-text search, a document is relevant if it contains query terms near each other, especially if the query terms are frequently occurring words. For each word in the text, we use additional indexes to store information about nearby words at distances from the given word of less than or equal to MaxDistance, which is a parameter. A search algorithm for the case when the query consists of high-frequently used words is discussed. In addition, we present results of experiments with different values of MaxDistance to evaluate the search speed dependence on the value of MaxDistance. These results show that the average time of the query execution with our indexes is 94.7-45.9 times (depending on the value of MaxDistance) less than that with standard inverted files when queries that contain high-frequently occurring words are evaluated.   This is a pre-print of a contribution published in Pinelas S., Kim A., Vlasov V. (eds) Mathematical Analysis With Applications. CONCORD-90 2018. Springer Proceedings in Mathematics & Statistics, vol 318, published by Springer, Cham. The final authenticated version is available online at: https://doi.org/10.1007/978-3-030-42176-2_37 ",Proximity full-text searches of frequently occurring words with a   response time guarantee
"  We describe a search method for fast moving ($\beta > 5 \times 10^{-3}$) magnetic monopoles using simultaneously the scintillator, streamer tube and track-etch subdetectors of the MACRO apparatus. The first two subdetectors are used primarily for the identification of candidates while the track-etch one is used as the final tool for their rejection or confirmation. Using this technique, a first sample of more than two years of data has been analyzed without any evidence of a magnetic monopole. We set a 90% CL upper limit to the local monopole flux of $1.5 \times 10^{-15} cm^{-2} s^{-1} sr^{-1}$ in the velocity range $5 \times 10^{-3} \le \beta \le 0.99$ and for nucleon decay catalysis cross section smaller than $\sim 1 mb$. ",A combined analysis technique for the search for fast magnetic monopoles   with the MACRO detector
  We present a simple method to stabilize the optical path length of an optical fiber to an accuracy of about 1/100 of the laser wavelength. We study the dynamic response of the path length to modulation of an electrically conductive heater layer of the fiber. The path length is measured against the laser wavelength by use of the Pound-Drever-Hall method; negative feedback is applied via the heater. We apply the method in the context of a cryogenic resonator frequency standard. ,Optical fibers with interferometric path length stability by controlled   heating for transmission of optical signals and as components in frequency   standards
"  We study forward dijet production in dilute-dense hadronic collisions. By considering the appropriate limits, we show that both the transverse-momentum-dependent (TMD) and the high-energy factorization formulas can be derived from the Color Glass Condensate framework. Respectively, this happens when the transverse momentum imbalance of the dijet system, $k_t$, is of the order of either the saturation scale, or the hard jet momenta, the former being always much smaller than the latter. We propose a new formula for forward dijets that encompasses both situations and is therefore applicable regardless of the magnitude of $k_t$. That involves generalizing the TMD factorization formula for dijet production to the case where the incoming small-$x$ gluon is off-shell. The derivation is performed in two independent ways, using either Feynman diagram techniques, or color-ordered amplitudes. ",Improved TMD factorization for forward dijet production in dilute-dense   hadronic collisions
"  In this paper, we give an example of a chiral 4-polytope in projective 3-space. This example naturally yields a finite chiral 4-polytope in Euclidean 4-space, giving a counterexample to Theorem 11.2 of [2]. ",A finite chiral 4-polytope in $\mathbb{R}^4$
"  We study parallel algorithms for the classical balls-into-bins problem, in which $m$ balls acting in parallel as separate agents are placed into $n$ bins. Algorithms operate in synchronous rounds, in each of which balls and bins exchange messages once. The goal is to minimize the maximal load over all bins using a small number of rounds and few messages.   While the case of $m=n$ balls has been extensively studied, little is known about the heavily loaded case. In this work, we consider parallel algorithms for this somewhat neglected regime of $m\gg n$. The naive solution of allocating each ball to a bin chosen uniformly and independently at random results in maximal load $m/n+\Theta(\sqrt{m/n\cdot \log n})$ (for $m\geq n \log n$) w.h.p. In contrast, for the sequential setting Berenbrink et al (SIAM J. Comput 2006) showed that letting each ball join the least loaded bin of two randomly selected bins reduces the maximal load to $m/n+O(\log\log m)$ w.h.p. To date, no parallel variant of such a result is known.   We present a simple parallel threshold algorithm that obtains a maximal load of $m/n+O(1)$ w.h.p. within $O(\log\log (m/n)+\log^* n)$ rounds. The algorithm is symmetric (balls and bins all ""look the same""), and balls send $O(1)$ messages in expectation per round. The additive term of $O(\log^* n)$ in the complexity is known to be tight for such algorithms (Lenzen and Wattenhofer Distributed Computing 2016). We also prove that our analysis is tight, i.e., algorithms of the type we provide must run for $\Omega(\min\{\log\log (m/n),n\})$ rounds w.h.p.   Finally, we give a simple asymmetric algorithm (i.e., balls are aware of a common labeling of the bins) that achieves a maximal load of $m/n + O(1)$ in a constant number of rounds w.h.p. Again, balls send only a single message per round, and bins receive $(1+o(1))m/n+O(\log n)$ messages w.h.p. ",Parallel Balanced Allocations: The Heavily Loaded Case
"  We study the birational geometry of some moduli spaces of abelian varieties with extra structure: in particular, with a symmetric theta structure and an odd theta characteristic. For a $(d_1,d_2)$-polarized abelian surface, we show how the parities of the $d_i$ influence the relation between canonical level structures and symmetric theta structures. For certain values of $d_1$ and $d_2$, a theta characteristic is needed in order to define Theta-null maps. We use these Theta-null maps and preceding work of other authors on the representations of the Heisenberg group to study the birational geometry and the Kodaira dimension of these moduli spaces. ","Moduli of abelian surfaces, symmetric theta structures and theta   characteristics"
"  In this paper, we start by giving the definitions and basic facts about hyperoctahedral number system. There is a natural correspondence between the integers expressed in the latter and the elements of the hyperoctahedral group when we use the inversion statistic on this group to code the signed permutations. We use this correspondence to define a way with which the signed permutations group can be ordered. With this classification scheme, we can find the r-th signed permutation from a given number r and vice versa without consulting the list in lexicographical order of the elements of the signed permutations group. ","On Hyperoctahedral Enumeration System, Application to Signed   Permutations"
"  We analyze conditions leading to enhancement of thermal entanglement in two-qubit XY models. The effect of including cross-product terms, besides the standard XY exchange interactions, in the presence of an external magnetic field, is investigated. We show that entanglement can be yield at elevated temperatures by tuning the orientation of the external magnetic field. The details of the intrinsic exchange interactions determine the optimal orientation. ",Enhancement of thermal entanglement in two-qubit XY models
"  We present the experimental realization of a compressible blue detuned crossed dipole trap for cold atoms allowing for fast dynamical compression (~ 5 - 10 ms) of 5x10^7 Rubidium atoms up to densities of ~ 10^13 cm^-3. The dipole trap consists of two intersecting tubes of blue-detuned laser light. These tubes are formed using a single, rapidly rotating laser beam which, for sufficiently fast rotation frequencies, can be accurately described by a quasi-static potential. The atomic cloud is compressed by dynamically reducing the trap volume leading to densities close to the Ioffe-Reggel criterion for light localization. ",Fast compression of a cold atomic cloud using a blue detuned crossed   dipole trap
  A zircon is a poset in which every principal order ideal is finite and equipped with a so-called special matching. We prove that the subposet induced by the fixed points of any automorphism of a zircon is itself a zircon. This provides a natural context in which to view recent results on Bruhat orders on twisted involutions in Coxeter groups. ,Fixed points of zircon automorphisms
"  Heat generated by spin currents in spintronics-based devices is typically much less than that generated by charge current flows in conventional electronic devices. However, the conventional approaches for excitation of spin currents based on spin-pumping and spin Hall effect are limited in efficiency which restricts their application for viable spintronic devices. We propose a novel type of photonic-crystal (PC) based structures for efficient and tunable optically-induced spin current generation via the Spin Seebeck and inverse spin Hall effects. It is experimentally demonstrated that optical surface modes localized at the PC surface covered by ferromagnetic layer and materials with giant spin-orbit coupling (SOC) notably increase the efficiency of the optically-induced spin current generation and provides its tunability by modifying light wavelength or angle of incidence. Up to 100% of the incident light power can be transferred to heat within the SOC layer and, therefore, to spin current. Importantly, high efficiency becomes accessible even for ultra-thin SOC layers. Moreover, surface patterning of the PC-based spintronic nanostructure allows local generation of spin currents at the pattern scales rather than diameter of the laser beam. ",Nanophotonic structures with optical surface modes for tunable spin   current generation
"  We analyzed the potential of the LC with $\sqrt{s}=0.5$ TeV, LC$\times$LHC based ep collider with $\sqrt{s}=3.74$ TeV and LHC with $\sqrt{s}=14$ TeV to search for excited electrons through transition magnetic type couplings with gauge bosons. The $e^{\star}\to e\gamma$ signal and corresponding backgrounds are studied in detail. ","Single production of excited electrons at future e^-e^+, ep and pp   colliders"
"  We investigate the breathing of optical spatial solitons in highly nonlocal media. Generalizing the Ehrenfest theorem, we demonstrate that oscillations in beam width obey a fourth-order ordinary differential equation. Moreover, in actual highly nonlocal materials, the original accessible soliton model by Snyder and Mitchell [Science \textbf{276}, 1538 (1997)] cannot accurately describe the dynamics of self-confined beams as the transverse size oscillations have a period which not only depends on power but also on the initial width. Modeling the nonlinear response by a Poisson equation driven by the beam intensity we verify the theoretical results against numerical simulations. ",Breather solitons in highly nonlocal media
"  Modifications of the equations of general relativity at large distances offer one possibility to explain the observed properties of our Universe without invoking a cosmological constant. Numerous proposals for such modified gravity cosmologies exist, but often their consequences for structure formation in the non-linear sector are not yet accurately known. In this work, we employ high-resolution numerical simulations of f(R)-gravity models coupled with a semi-analytic model (SAM) for galaxy formation to obtain detailed predictions for the evolution of galaxy properties. The f(R)-gravity models imply the existence of a `fifth-force', which is however locally suppressed, preserving the successes of general relativity on solar system scales. We show that dark matter haloes in f(R)-gravity models are characterized by a modified virial scaling with respect to the LCDM scenario, reflecting a higher dark matter velocity dispersion at a given mass. This effect is taken into account in the SAM by an appropriate modification of the mass--temperature relation. We find that the statistical properties predicted for galaxies (such as the stellar mass function and the cosmic star formation rate) in f(R)-gravity show generally only very small differences relative to LCDM, smaller than the dispersion between the results of different SAM models, which can be viewed as a measure of their systematic uncertainty. We also demonstrate that galaxy bias is not able to disentangle between f(R)-gravity and the standard cosmological scenario. However, f(R)-gravity imprints modifications in the linear growth rate of cosmic structures at large scale, which can be recovered from the statistical properties of large galaxy samples. ",Semi-analytic galaxy formation in f(R)-gravity cosmologies
"  The question concerning the possibility of a first order surface transition in a semi--infinite Blume--Capel model is addressed by means of low temperature expansions. It is found that such a transition can exist, according to mean field and cluster variation approximations, and contrarily to renormalization group results. ",Low-Temperature Expansion for a First Order Surface Transition
"  The precise knowledge of the temperature of an ultracold lattice gas simulating a strongly correlated system is a question of both, fundamental and technological importance. Here, we address such question by combining tools from quantum metrology together with the study of the quantum correlations embedded in the system at finite temperatures. Within this frame we examine the spin-$1/2$ XY chain, first estimating, by means of the quantum Fisher information, the lowest attainable bound on the temperature precision. We then address the estimation of the temperature of the sample from the analysis of correlations using a quantum non demolishing Faraday spectroscopy method. Finally, we demonstrate that for sufficiently low temperatures the proposed measurements are optimal to estimate accurately the temperature of the sample. ",Thermometry Precision in Strongly Correlated Ultracold Lattice Gases
"  Concerning renormalisation group theory applied to phase transitions, we examine the value of positive numerical and analytical evidence, the divergent short-wavelength behaviour of classical free fields and the absence of UV-divergences in quantum field theories with proper mathematical handling. We conclude as to the inadequacy of the conceptual and mathematical framework of renormalisation theory of critical phenomena. ",Some Aspects regarding Renormalisation Theory of Critical Phenomena
  We present an approach to generate chimera dynamics (localized frequency synchrony) in oscillator networks with two populations of (at least) two elements using a general method based on delayed interactions with linear and quadratic terms. The coupling design yields robust chimeras through a phase-model-based design of the delay and the ratio of linear and quadratic components of the interactions. We demonstrate the method in the Brusselator model and experiments with electrochemical oscillators. The technique opens the way to directly bridge chimera dynamics in phase models and real-world oscillator networks. ,Robust Weak Chimeras in Oscillator Networks with Delayed Linear and   Quadratic Interactions
"  Magnetic pickup loops or B-dot probes are one of the oldest known sensors of time-varying magnetic fields. The operating principle is based on Faraday's law of electromagnetic induction. However, obtaining accurate measurements of time-varying magnetic fields using these kinds of probes is a challenging task. A B-dot probe and its associated circuit are prone to electrical oscillations. As a result, the measured signal may not faithfully represent the magnetic field sampled by the B-dot probe. In this paper, we have studied the transient response of a B-dot probe and its associated circuit to a time-varying magnetic field. Methods of removing the oscillations pertaining to the detector structure are described. After removing the source of the oscillatory signal, we have shown that the time-integrated induced emf measured by the digitiser is linearly proportional to the magnetic field sampled by the B-dot probe, thus verifying the faithfulness of the measured signal. ",Understanding the working of a B-dot probe
"  This paper analyses the construction of the kernel graph of a non-synchronizing transformation semigroup and introduces the inverse synchronization problem. Given a transformation semigroup $S\leq T_n$, we construct the kernel graph $\text{Gr}(S)$ by saying $v$ and $w$ are adjacent, if there is no $f\in S$ with $vf=wf$. The kernel graph is trivial or complete if the semigroup is a synchronizing semigroup or a permutation group, respectively. The connection between graphs and synchronizing (semi-) groups was established by Cameron and Kazanidis, and it has led to many results regarding the classification of synchronizing permutation groups, and the description of singular endomorphims of graphs. This paper, firstly, emphasises the importance of this construction mainly by proving its superior structure, secondly, analyses the construction and discusses minimal generating sets and their combinatorial properties, and thirdly, introduces the inverse synchronization problem. The third part also includes an additional characterization of primitive groups. ",Generating Sets of the Kernel Graph and the Inverse Problem in   Synchronization Theory
"  We study an exact asymptotic behavior of the Witten-Reshetikhin-Turaev invariant for the Brieskorn homology spheres $\Sigma(p_1,p_2,p_3)$ by use of properties of the modular form following a method proposed by Lawrence and Zagier. Key observation is that the invariant coincides with a limiting value of the Eichler integral of the modular form with weight 3/2. We show that the Casson invariant is related to the number of the Eichler integrals which do not vanish in a limit $\tau\to N \in \mathbb{Z}$. Correspondingly there is a one-to-one correspondence between the non-vanishing Eichler integrals and the irreducible representation of the fundamental group, and the Chern-Simons invariant is given from the Eichler integral in this limit. It is also shown that the Ohtsuki invariant follows from a nearly modular property of the Eichler integral, and we give an explicit form in terms of the L-function. ",On the Quantum Invariant for the Brieskorn Homology Spheres
"  We present a detailed solution of the active interface equations in the inviscid limit. The active interface equations were previously introduced as a toy model of membrane-protein systems: they describe a stochastic interface where growth is stimulated by inclusions which themselves move on the interface. In the inviscid limit, the equations reduce to a pair of coupled conservation laws. After discussing how the inviscid limit is obtained, we turn to the corresponding Riemann problem: the solution of the set of conservation laws with discontinuous initial condition. In particular, by considering two physically meaningful initial conditions, a giant trough and a giant peak in the interface, we elucidate the generation of shock waves and rarefaction fans in the system. Then, by combining several Riemann problems, we construct an oscillating solution of the active interface with periodic boundaries conditions. The existence of this oscillating state reflects the reciprocal coupling between the two conserved quantities in our system. ",Inviscid limit of the active interface equations
"  We consider systems with two competing species whose actions are completely symmetric, with same mobility, reproduction and competition rates. Numerical implementations of the model in two and three-dimensional space show that regions of single species are formed by spontaneous symmetry breaking. We propose a theoretical formalism for describing the static profile of the interfaces of empty spaces separating domains with different species. We compute the topological properties of the interfaces and show that these theoretical functions are useful to the understanding of the dynamics of the network. Finally, we compare the theoretical functions with results from the numerical implementation of the mean field equations and verify that our model fits well the properties of interfaces. ",Solitonic description of interface profiles in competition models
"  We discuss the recent paper by Inan and Ugurlu [Inan I.E., Ugurlu Y., Exp-function method for the exact solutions of fifth order KdV equation and modified Burgers equation, Appl. Math. Comp. 217 (2010) 1294 -- 1299]. We demonstrate that all exact solutions of fifth order KdV equation and modified Burgers equation by Inan and Ugurlu are trivial solutions that are reduced to constants. Moreover, we show exact solutions of the fifth -- order equation studied by Inan and Ugurlu cannot be found by the Exp-function method. ","A Note on ""Exp-function method for the exact solutions of fifth order   KdV equation and modified Burgers equation"""
"  We propose a trade-off between the Lipschitz constants of the position and momentum probability distributions for arbitrary quantum states. We refer to the trade-off as a quantum reciprocity relation. The Lipschitz constant of a function may be considered to quantify the extent of fluctuations of that function, and is, in general, independent of its spread. The spreads of the position and momentum distributions are used to obtain the celebrated Heisenberg quantum uncertainty relations. We find that the product of the Lipschitz constants of position and momentum probability distributions is bounded below by a number that is of the order of the inverse square of the Planck's constant. ",Position and momentum cannot both be lazy: Quantum reciprocity relation   with Lipschitz constants
"  We discuss the ""quantum deformed Schwarzschild spacetime"" as originally introduced by Kazakov and Solodukhin in 1993, and investigate the precise sense in which it does and does not satisfy the desiderata for being a ""regular black hole"". We shall carefully distinguish (i) regularity of the metric components, (ii) regularity of the Christoffel components, and (iii) regularity of the curvature. We shall then embed the Kazakov-Solodukhin spacetime in a more general framework where these notions are clearly and cleanly separated. Finally we analyze aspects of the classical physics of these ""quantum deformed Schwarzschild spacetimes"". We shall discuss the surface gravity, the classical energy conditions, null and timelike geodesics, and the appropriate variant of Regge--Wheeler equation. ","General class of ""quantum deformed"" regular black holes"
"  Rigorous pointwise asymptotics are established for semiclassical soliton ensembles (SSEs) of the focusing nonlinear Schroedinger equation using techniques of asymptotic analysis of matrix Riemann-Hilbert problems. The accumulation of poles in the eigenfunction is handled using a new method in which the residues are simultaneously interpolated at the poles by two distinct interpolants. The results justify the WKB approximation for the nonselfadjoint Zakharov-Shabat operator with real-analytic, bell-shaped, even potentials. The new technique introduced in this paper is applicable to other problems as well: (i) it can be used to provide a unified treatment by Riemann-Hilbert methods of the zero-dispersion limit of the Korteweg-de Vries equation with negative (soliton generating) initial data as studied by Lax, Levermore, and Venakides, and (ii) it allows one to compute rigorous strong asymptotics for systems of discrete orthogonal polynomials. ",Asymptotics of semiclassical soliton ensembles: rigorous justification   of the WKB approximation
"  Short coherence times present a primary obstacle in quantum computing and sensing applications. In atomic systems, clock transitions (CTs), formed from avoided crossings in an applied Zeeman field, can substantially increase coherence times. We show how CTs can dampen intrinsic and extrinsic sources of quantum noise in molecules. Conical intersections between two periodic potentials form CTs in electron paramagnetic resonance experiments of the spin-polarized singlet fission photoproduct. We report on a pair of CTs for a two-chromophore molecule in terms of the Zeeman field strength, molecular orientation relative to the field, and molecular geometry. ",Clock Transitions Guard Against Spin Decoherence in Singlet Fission
"  In this paper, we come back on the notion of local simulation allowing to transform a cellular automaton into a closely related one with different local encoding of information. In a previous paper, we applied it to the Firing Squad Synchronization Problem. In this paper, we show that the approach is not tied to this problem by applying it to the class of Real-Time Sequence Generation problems. We improve in particular on the generation of n 3 sequence by using local mappings to obtain millions of 5state solution, one of them using 58 transitions. It is based on the solution of Kamikawa and Umeo that uses 6 states and 74 transitions. Then, we explain in which sense even bigger classes of problems can be considered. ",Millions of 5-State n^3 Sequence Generators via Local Mappings
"  We introduce and study a new functional which was motivated by our paper on the Caffarelli-Kohn-Nirenberg inequality with variable exponent (Bahrouni, R\u{a}dulescu and Repov\v{s}, Nonlinearity 31 (2018), 1518-1534). We also study the eigenvalue problem for equations involving this new functional. ",Low perturbations for a class of nonuniformly elliptic problems
"  In extended models of gravity a nonminimal coupling to matter has been assumed to lead to irreversible particle creation. In this paper we challenge this assumption. We argue that a non-minimal coupling of the matter and gravitational sectors results in a change in particle-momentum on a cosmological timescale, irrespective of particle creation or decay. We further argue that particle creation or decay associated with a non-minimal coupling to gravity could only happen as a result of significant deviations from a homogeneous Friedmann-Robertson-Walker geometry on microscopic scales, and provide a phenomenological description of the impact of particle creation or decay on the cosmological evolution of the density of the matter fields. ",Particle creation and decay in nonminimally coupled models of gravity
"  We study a special sort of 2-dimensional extended Topological Quantum Field Theories (TQFTs) which we call open-closed TQFTs. These are defined on open-closed cobordisms by which we mean smooth compact oriented 2-manifolds with corners that have a particular global structure in order to model the smooth topology of open and closed string worldsheets. We show that the category of open-closed TQFTs is equivalent to the category of knowledgeable Frobenius algebras. A knowledgeable Frobenius algebra (A,C,i,i^*) consists of a symmetric Frobenius algebra A, a commutative Frobenius algebra C, and an algebra homomorphism i:C->A with dual i^*:A->C, subject to some conditions. This result is achieved by providing a generators and relations description of the category of open-closed cobordisms. In order to prove the sufficiency of our relations, we provide a normal form for such cobordisms which is characterized by topological invariants. Starting from an arbitrary such cobordism, we construct a sequence of moves (generalized handle slides and handle cancellations) which transforms the given cobordism into the normal form. Using the generators and relations description of the category of open-closed cobordisms, we show that it is equivalent to the symmetric monoidal category freely generated by a knowledgeable Frobenius algebra. Our formalism is then generalized to the context of open-closed cobordisms with labeled free boundary components, i.e. to open-closed string worldsheets with D-brane labels at their free boundaries. ",Open-closed strings: Two-dimensional extended TQFTs and Frobenius   algebras
"  We study non-reversible Finsler metrics with constant flag curvature 1 on S^2 and show that the geodesic flow of every such metric is conjugate to that of one of Katok's examples, which form a 1-parameter family. In particular, the length of the shortest closed geodesic is a complete invariant of the geodesic flow. We also show, in any dimension, that the geodesic flow of a Finsler metrics with constant positive flag curvature is completely integrable.   Finally, we give an example of a Finsler metric on~$S^2$ with positive flag curvature such that no two closed geodesics intersect and show that this is not possible when the metric is reversible or have constant flag curvature ",Geodesic behavior for Finsler metrics of constant positive flag   curvature on $S^2$
"  We have determined the equilibrium shape of graphene domains grown on Ni(111) via carbon segregation at 925{\deg}C. In situ, spatially-resolved electron diffraction measurements were used to determine the crystallographic orientation of the edges of the graphene domains. In contrast to recent theoretical predictions of a nearly-circular shape, we show that graphene domains, which nucleate with random shapes, all evolve toward a triangular equilibrium shape with 'zig-zag' edges. Only one of the two possible zig-zag edge orientations is observed. ",The Equilibrium Shape of Graphene Domains on Ni(111)
"  In many realistic problems of allocating resources, economy efficiency must be taken into consideration together with social equality, and price rigidities are often made according to some economic and social needs. We study the computational issues of dynamic mechanisms for selling multiple indivisible items under price rigidities. We propose a polynomial algorithm that can be used to find over-demanded sets of items, and then introduce a dynamic mechanism with rationing to discover constrained Walrasian equilibria under price rigidities in polynomial time. We also address the computation of sellers' expected profits and items' expected prices, and discuss strategical issues in the sense of expected profits. ",Allocating Indivisible Resources under Price Rigidities in Polynomial   Time
"  Exposing the rate information of wireless transmission enables highly efficient attacks that can severely degrade the performance of a network at very low cost. In this paper, we introduce an integrated solution to conceal the rate information of wireless transmissions while simultaneously boosting the resiliency against interference. The proposed solution is based on a generalization of Trellis Coded Modulation combined with Cryptographic Interleaving. We develop algorithms for discovering explicit codes for concealing any modulation in {BPSK, QPSK, 8-PSK, 16-QAM, 64-QAM}. We demonstrate that in most cases this modulation hiding scheme has the side effect of boosting resiliency by up to 8.5dB. ",CBM: A Crypto-Coded Modulation Scheme for Rate Information Concealing   and Robustness Boosting
  We give a detailed analysis of the anti-self-adjoint operator contribution to the fluctuation terms in the trace dynamics Ward identity. This clarifies the origin of the apparent inconsistency between two forms of this identity discussed in Chapter 6 of our recent book on emergent quantum theory. ,Structure of Fluctuation Terms in the Trace Dynamics Ward Identity
"  We describe how to construct the dynamics of relativistic particles following, either timelike or null curves, by means of an auxiliary variables method instead of the standard theory of deformations for curves. There are interesting physical particle models governed by actions that involve higher order derivatives of the embedding functions of the worldline. We point out that the mechanical content of such models can be extracted wisely from a lower order action, which can be performed by implementing in the action a finite number of constraints that involve the geometrical relationship structures inherent to a curve and by using a covariant formalism. We emphasize our approach for null curves. For such systems, the natural time parameter is a pseudo-arclength whose properties resemble those of the standard proper time. We illustrate the formalism by applying it to some models for relativistic particles. ",Auxiliary fields in the geometrical relativistic particle dynamics
"  The semi-classical approximation is an explicit formula of mathematical physics for the sum of Feynman diagrams with a single circuit.In this paper, we study the same problem in the setting of modular operads (see dg-ga/9408003); instead of being a number, the interaction at a vertex of valence n is an S_n-module.   As an application, we calculate the S_n-equivariant Hodge polynomials of the moduli spaces \Mbar_{1,n}. ",The semi-classical approximation for modular operads
"  Assuming that AXPs and SGRs accrete matter from a fallback disk, we attempt to explain both the soft and the hard X-ray emission as the result of the accretion process. We also attempt to explain their radio emission or the lack of it. We test the hypothesis that the power-law, hard X-ray spectra are produced in the accretion flow mainly by bulk-motion Comptonization of soft photons emitted at the neutron star surface. Fallback disk models invoke surface dipole magnetic fields of $10^{12} - 10^{13}$ G, which is what we assume here. Unlike normal X-ray pulsars, for which the accretion rate is highly super-Eddington, the accretion rate is approximately Eddington in AXPs and SGRs and thus the bulk-motion Comptonization operates efficiently. As an illustrative example we reproduce both the hard and the soft X-ray spectra of AXP 4U 0142+61 well using the XSPEC package compTB. Our model seems to explain both the hard and the soft X-ray spectra of AXPs and SGRs, as well as their radio emission or the lack of it, in a natural way. It might also explain the short bursts observed in these sources. On the other hand, it cannot explain the giant X-ray outbursts observed in SGRs, which may result from the conversion of magnetic energy in local multipole fields. ",The Energy Spectrum of Anomalous X-ray Pulsars and Soft Gamma-ray   Repeaters
"  I study the class of problems efficiently solvable by a quantum computer, given the ability to ""postselect"" on the outcomes of measurements. I prove that this class coincides with a classical complexity class called PP, or Probabilistic Polynomial-Time. Using this result, I show that several simple changes to the axioms of quantum mechanics would let us solve PP-complete problems efficiently. The result also implies, as an easy corollary, a celebrated theorem of Beigel, Reingold, and Spielman that PP is closed under intersection, as well as a generalization of that theorem due to Fortnow and Reingold. This illustrates that quantum computing can yield new and simpler proofs of major results about classical computation. ","Quantum Computing, Postselection, and Probabilistic Polynomial-Time"
"  We develop model free PAC performance guarantees for multiple concurrent MDPs, extending recent works where a single learner interacts with multiple non-interacting agents in a noise free environment. Our framework allows noisy and resource limited communication between agents, and develops novel PAC guarantees in this extended setting. By allowing communication between the agents themselves, we suggest improved PAC-exploration algorithms that can overcome the communication noise and lead to improved sample complexity bounds. We provide a theoretically motivated algorithm that optimally combines information from the resource limited agents, thereby analyzing the interaction between noise and communication constraints that are ubiquitous in real-world systems. We present empirical results for a simple task that supports our theoretical formulations and improve upon naive information fusion methods. ",PAC Guarantees for Cooperative Multi-Agent Reinforcement Learning with   Restricted Communication
  In our work we considered orientations of bright X-ray halos of the galaxy clusters (mainly Abell clusters). 78 appropriate clusters were selected using data from Xgal sample of extragalactic objects in XMM-Newton observation archive. Position angles and eccentricities of these halos were calculated applying FOCAS method. No privileged orientations were found. ,Determination of the Galaxy Cluster Orientation Using X-ray Images by   FOCAS Method
"  Reverberation lags in AGN were first discovered in the NLS1 galaxy, 1H0707-495. We present a follow-up analysis using 1.3 Ms of data, which allows for the closest ever look at the reverberation signature of this remarkable source. We confirm previous findings of a hard lag of ~100 seconds at frequencies v ~ [0.5 - 4] e-4 Hz, and a soft lag of ~30 seconds at higher frequencies, v ~ [0.6 - 3] e-3 Hz. These two frequency domains clearly show different energy dependences in their lag spectra. We also find evidence for a signature from the broad Fe K line in the high frequency lag spectrum. We use Monte Carlo simulations to show how the lag and coherence measurements respond to the addition of Poisson noise and to dilution by other components. With our better understanding of these effects on the lag, we show that the lag-energy spectra can be modelled with a scenario in which low frequency hard lags are produced by a compact corona responding to accretion rate fluctuations propagating through an optically thick accretion disc, and the high frequency soft lags are produced by short light-travel delay associated with reflection of coronal power-law photons off the disc. ",The Closest Look at 1H0707-495: X-ray Reverberation Lags with 1.3 Ms of   Data
"  We study the connection between the singularities of a finite type $\mathbb{Z}$-scheme X and the asymptotic point count of X over various finite rings. In particular, if the generic fiber $X_{\mathbb{Q}}=X\times_{\mathrm{Spec}\mathbb{Z}}\mathrm{Spec}\mathbb{Q}$ is a local complete intersection, we show that the boundedness of $\frac{\left|X(\mathbb{Z}/p^{n}\mathbb{Z})\right|}{p^{n\mathrm{dim}X_{\mathbb{Q}}}}$ in p and n is in fact equivalent to the condition that $X_{\mathbb{Q}}$ is reduced and has rational singularities. This paper completes a result of Aizenbud and Avni. ",On rational singularities and counting points of schemes over finite   rings
"  We develop an empirical behavioural order-driven (EBOD) model, which consists of an order placement process and an order cancellation process. Price limit rules are introduced in the definition of relative price. The order placement process is determined by several empirical regularities: the long memory in order directions, the long memory in relative prices, the asymmetric distribution of relative prices, and the nonlinear dependence of the average order size and its standard deviation on the relative price. Order cancellation follows a Poisson process with the arrival rate determined from real data and the cancelled order is determined according to the empirical distributions of relative price level and relative position at the same price level. All these ingredients of the model are derived based on the empirical microscopic regularities in the order flows of stocks on the Shenzhen Stock Exchange. The model is able to produce the main stylized facts in real markets. Computational experiments uncover that asymmetric setting of price limits will cause the stock price diverging exponentially when the up price limit is higher than the down price limit and vanishing vice versus. We also find that asymmetric price limits have influences on stylized facts. Our EBOD model provides a suitable computational experiment platform for academics, market participants and policy makers. ",An empirical behavioural order-driven model with price limit rules
"  The computational complexity of the Vertex Coloring problem is known for all hereditary classes of graphs defined by forbidding two connected five-vertex induced subgraphs, except for seven cases. We prove the polynomial-time solvability of four of these problems: for ($P_5$, dart)-free graphs, ($P_5$, banner)-free graphs, ($P_5$, bull)-free graphs, and (fork, bull)-free graphs. ",Polynomial Cases for the Vertex Coloring Problem
"  A key process in the life of any multicellular organism is its development from a single egg into a full grown adult. The first step in this process often consists of forming a tissue layer out of randomly placed cells on the surface of the egg. We present a model for generating such a tissue, and find that the resulting cellular pattern corresponds to the Voronoi tessellation of the nuclei of the cells. Experimentally, we obtain the same result in both fruit flies and flour beetles, with a distribution of cell shapes that matches that of the model, without any adjustable parameters. Finally, we show that this pattern is broken when the cells do not all grow at the same rate. ",Mechanics of epithelial tissue formation
"  We propose a tensor-to-vector regression approach to multi-channel speech enhancement in order to address the issue of input size explosion and hidden-layer size expansion. The key idea is to cast the conventional deep neural network (DNN) based vector-to-vector regression formulation under a tensor-train network (TTN) framework. TTN is a recently emerged solution for compact representation of deep models with fully connected hidden layers. Thus TTN maintains DNN's expressive power yet involves a much smaller amount of trainable parameters. Furthermore, TTN can handle a multi-dimensional tensor input by design, which exactly matches the desired setting in multi-channel speech enhancement. We first provide a theoretical extension from DNN to TTN based regression. Next, we show that TTN can attain speech enhancement quality comparable with that for DNN but with much fewer parameters, e.g., a reduction from 27 million to only 5 million parameters is observed in a single-channel scenario. TTN also improves PESQ over DNN from 2.86 to 2.96 by slightly increasing the number of trainable parameters. Finally, in 8-channel conditions, a PESQ of 3.12 is achieved using 20 million parameters for TTN, whereas a DNN with 68 million parameters can only attain a PESQ of 3.06. Our implementation is available online https://github.com/uwjunqi/Tensor-Train-Neural-Network. ",Tensor-to-Vector Regression for Multi-channel Speech Enhancement based   on Tensor-Train Network
"  A mathematics student's first introduction to the fundamental theorem of finite fields (FTFF) often occurs in an advanced abstract algebra course and invokes the power of Galois theory to prove it. Yet the combinatorial and algebraic coding theory applications of finite fields can show up early on for students in STEM. To make the FTFF more accessible to students lacking exposure to Galois theory, we provide a proof from algebraic ""first principles."" ",The fundamental theorem of finite fields: a proof from first principles
"  The expansion factor, $\alpha^{2}=\langle s_{N}^{2}\rangle/\langle s_{N}^{2}\rangle_{0}$, of branched molecules in the melt state is estimated. The equilibrium expansion factor is determined as the point in which all the inhomogeneity terms of the osmotic potential, $\Delta G_{osmotic}$, go to zero. Numerical analysis shows that $\log\,\alpha=0.082\,\log N+\text{const.}$ for $10^{3}\le N\le 10^{7}$, giving $\alpha\cong \text{const.}\,N^{1/12}$ so that $\langle s_{N}^{2}\rangle^{1/2}\propto N^{1/3}$ which coincides with the value for the critical packing density. ",Excluded Volume Effects of Branched Molecules
"  We propose two sparsity-aware normalized subband adaptive filter (NSAF) algorithms by using the gradient descent method to minimize a combination of the original NSAF cost function and the l1-norm penalty function on the filter coefficients. This l1-norm penalty exploits the sparsity of a system in the coefficients update formulation, thus improving the performance when identifying sparse systems. Compared with prior work, the proposed algorithms have lower computational complexity with comparable performance. We study and devise statistical models for these sparsity-aware NSAF algorithms in the mean square sense involving their transient and steady -state behaviors. This study relies on the vectorization argument and the paraunitary assumption imposed on the analysis filter banks, and thus does not restrict the input signal to being Gaussian or having another distribution. In addition, we propose to adjust adaptively the intensity parameter of the sparsity attraction term. Finally, simulation results in sparse system identification demonstrate the effectiveness of our theoretical results. ",Study of Sparsity-Aware Subband Adaptive Filtering Algorithms with   Adjustable Penalties
"  We present a fully automatic system that takes a 3D scene and generates plausible 3D human bodies that are posed naturally in that 3D scene. Given a 3D scene without people, humans can easily imagine how people could interact with the scene and the objects in it. However, this is a challenging task for a computer as solving it requires that (1) the generated human bodies to be semantically plausible within the 3D environment (e.g. people sitting on the sofa or cooking near the stove), and (2) the generated human-scene interaction to be physically feasible such that the human body and scene do not interpenetrate while, at the same time, body-scene contact supports physical interactions. To that end, we make use of the surface-based 3D human model SMPL-X. We first train a conditional variational autoencoder to predict semantically plausible 3D human poses conditioned on latent scene representations, then we further refine the generated 3D bodies using scene constraints to enforce feasible physical interaction. We show that our approach is able to synthesize realistic and expressive 3D human bodies that naturally interact with 3D environment. We perform extensive experiments demonstrating that our generative framework compares favorably with existing methods, both qualitatively and quantitatively. We believe that our scene-conditioned 3D human generation pipeline will be useful for numerous applications; e.g. to generate training data for human pose estimation, in video games and in VR/AR. Our project page for data and code can be seen at: \url{https://vlg.inf.ethz.ch/projects/PSI/}. ",Generating 3D People in Scenes without People
"  This paper presents an extensive survey of regular distributions in natural and social sciences. The survey includes studies from a wide scope of academic disciplines, in order to create an inventory of the different mathematical functions used to describe the distributions. The goal of the study was to determine, whether a unique function can be used to describe all the distributions (universality) or a particular function is best suited to describe the distributions in each specific field of research (domain universality). We propose a classification of distributions into eighth different categories, based on three representations: the Zipf representation, the cumulative density function (CDF) and the probability density function (PDF). In the 89 cases included in the survey, neither universality nor domain universality was found. In particular, based on the results of the survey, the claim that ""power law provides a good description for majority of distributions"" may be rejected. Only one third of the distributions in our survey are associated with power laws, while another third is well described by lognormal and similar functions (Dagum, Weibull, loglogistic and Gamma functions). We suggest that correct characterization of a distribution relies on two conditions. First, it is important to include the full range of the available data to avoid distortion due to arbitrary cut off values. Second, it is advisable to display the data in all three representations: the Zipf representation, the CDF and the PDF. ",A classification of natural and social distributions Part one: the   descriptions
"  We show that extremal correlators in all Lagrangian ${\cal N}=2$ superconformal field theories with a simple gauge group are governed by the same universal Toda system of equations, which dictates the structure of extremal correlators to all orders in the perturbation series. A key point is the construction of a convenient orthogonal basis for the chiral ring, by arranging towers of operators in order of increasing dimension, which has the property that the associated two-point functions satisfy decoupled Toda chain equations. We explicitly verify this in all known SCFTs based on $\mathrm{SU}(N)$ gauge groups as well as in superconformal QCD based on orthogonal and symplectic groups. As a by-product, we find a surprising non-renormalization property for the ${\cal N}=2$ $\mathrm{SU}(N)$ SCFT with one hypermultiplet in the rank-2 symmetric representation and one hypermultiplet in the rank-2 antisymmetric representation, where the two-loop terms of a large class of supersymmetric observables identically vanish. ",Universality of Toda equation in ${\cal N}=2$ superconformal field   theories
"  Braided differential operators $\del^i$ are obtained by differentiating the addition law on the braided covector spaces introduced previously (such as the braided addition law on the quantum plane). These are affiliated to a Yang-Baxter matrix $R$. The quantum eigenfunctions $\exp_R(\vecx|\vecv)$ of the $\del^i$ (braided-plane waves) are introduced in the free case where the position components $x_i$ are totally non-commuting. We prove a braided $R$-binomial theorem and a braided-Taylors theorem $\exp_R(\veca|\del)f(\vecx)=f(\veca+\vecx)$. These various results precisely generalise to a generic $R$-matrix (and hence to $n$-dimensions) the well-known properties of the usual 1-dimensional $q$-differential and $q$-exponential. As a related application, we show that the q-Heisenberg algebra $px-qxp=1$ is a braided semidirect product $\C[x]\cocross \C[p]$ of the braided line acting on itself (a braided Weyl algebra). Similarly for its generalization to an arbitrary $R$-matrix. ","Free Braided Differential Calculus, Braided Binomial Theorem and the   Braided Exponential Map"
"  In this paper, we will consider cosmological implications of the Maxwell theory coupled to a non-local $U(1)$-symmetric term. It is well-known that the theory in flat space time, reduces to the Proca theory. However, it will be shown that in curved space time the resulting theory will differ from the coupled Einstein-Proca system. The cosmological perturbations on top of the de Sitter space-time is also considered and the dynamics of separate modes will be investigated in details. Anisotropic cosmology of the model is also investigated and we will show that the behavior of the universe at late time satisfies the observational data and the model predicts an isotropic universe. ",Cosmology in non-local Bopp-Podolski electrodynamics
"  We study the cubic ab-family of equations, which includes both the Fokas-Olver-Rosenau-Qiao (FORQ) and the Novikov (NE) equations. For $a\neq0$, it is proved that there exist initial data in the Sobolev space $H^s$, $s<3/2$, with non-unique solutions. Multiple solutions are constructed by studying the collision of 2-peakon solutions. Furthermore, we prove the novel phenomenon that for some members of the family, collision between 2-peakons can occur even if the ""faster"" peakon is in front of the ""slower"" peakon. ",Non-uniqueness for the ab-family of equations
  We generalize some results on semicomputability by Jockusch \cite{jockusch1968semirecursive} to the setting of $\alpha$-Computability Theory. We define an $\alpha$-Kalimullin pair and show that it is definable in the $\alpha$-enumeration degrees $\mathcal{D}_{\alpha e}$ if the projectum of $\alpha$ is $\alpha^*=\omega$ or if $\alpha$ is an infinite regular cardinal. Finally using this work on $\alpha$-semicomputability and $\alpha$-Kalimullin pairs we conclude that every nontrivial total $\alpha$-enumeration degree is a join of a maximal $\alpha$-Kalimullin pair if $\alpha$ is an infinite regular cardinal. ,Kalimullin Pair and Semicomputability in $\alpha$-Computability Theory
  We prove that the higher order Poincare-Pontryagin functions associated to the perturbed polynomial foliation $df -\epsilon (P dx + Q dy) =0$ satisfy a differential equation of Fuchs type. ,Higher order Poincare-Pontryagin functions and iterated path integrals
"  We study the survivability of neutrino mass models with normal as well as inverted hierarchical mass patterns in the presence of both type I and type II seesaw contributions to neutrino mass within the framework of generic left-right symmetric models. At leading order, the Dirac neutrino mass matrix is assumed to be diagonal with either charged lepton (CL) type or up quark (UQ) type structure which gets corrected by non-leading effects giving rise to deviations from tri-bi-maximal (TBM) mixing and hence non-zero value of $\theta_{13}$. Using the standard form of neutrino mass matrix which incorporates such non-leading effects, we parametrize the neutrino mass matrix incorporating both oscillation as well as cosmology data. Also considering extremal values of Majorana CP phases such that the neutrino mass eigenvalues have the structure $(m_1, -m_2, m_3)$ and $(m_1, m_2, m_3)$, we then calculate the predictions for neutrino parameters in the presence of both type I and type II seesaw contributions, taking one of them dominant and the other sub-dominant. We show that these mass models can survive in our framework with certain exceptions. ",Neutrino masses and mixings with non-zero $\theta_{13}$ in Type I+II   Seesaw Models
"  We have investigated electronic and magnetic properties of the pyrite-type CoS_2 using the linearized muffin-tin orbital (LMTO) band method. We have obtained the ferromagnetic ground state with nearly half-metallic nature. The half-metallic stability is studied by using the fixed spin moment method. The non-negligible orbital magnetic moment of Co 3d electrons is obtained as $\mu_L = 0.06 \mu_B$ in the local spin density approximation (LSDA). The calculated ratio of the orbital to spin angular momenta <L_z >/< S_z > = 0.15 is consistent with experiment. The effect of the Coulomb correlation between Co 3d electrons is also explored with the LSDA + U method. The Coulomb correlation at Co sites is not so large, $U \lesssim 1$ eV, and so CoS_2 is possibly categorized as an itinerant ferromagnet. It is found that the observed electronic and magnetic behaviors of CoS_2 can be described better by the LSDA than by the LSDA + U. ",Itinerant ferromagnetism in half-metallic CoS_2
"  This article proposes and evaluates a technique to predict the level of interference in wireless networks. We design a recursive predictor that estimates future interference values by filtering measured interference at a given location. The predictor's parameterization is done offline by translating the autocorrelation of interference into an autoregressive moving average (ARMA) representation. This ARMA model is inserted into a steady-state Kalman filter enabling nodes to predict with low computational effort. Results show a good accuracy of predicted values versus true values for relevant time horizons. Although the predictor is parameterized for Poisson-distributed nodes, Rayleigh fading, and fixed message lengths, a sensitivity analysis shows that it also tends to work well in more general network scenarios. Numerical examples for underlay device-to-device communications, a common wireless sensor technology, and coexistence scenarios of Wi-Fi and LTE illustrate its broad applicability. The predictor can be applied as part of interference management to improve medium access, scheduling, and radio resource allocation. ",Interference Prediction in Wireless Networks: Stochastic Geometry meets   Recursive Filtering
"  In a scenario where there is no vaccine for COVID-19, non-pharmaceutical interventions are necessary to contain the spread of the virus and the collapse of the health system in the affected regions. One of these measures is social distancing, which aims to reduce interactions in the community by closing public and private establishments that involve crowds of people. The lockdown presupposes a drastic reduction in community interactions, representing a more extreme measure of social distancing. Based on geolocation data provided by Google for six categories of physical spaces, this article identifies the variations in the circulation of people in South America for different types of social distancing measures adopted during the COVID-19 pandemic. In this study, population mobility trends for a group of countries between February 15, 2020 and May 16, 2020 were analyzed. To summarize these trends in a single metric, a general circulation index was created, and to identify regional mobility patterns, descriptive analyzes of spatial autocorrelation (global and local Moran index) were used. The first hypothesis of this study is that countries with a lockdown decree can achieve greater success in reducing the mobility of the population, and the second hypothesis is that Argentina, Brazil and Colombia have regional mobility patterns. The first hypothesis was partially confirmed (considering 10 countries in South America), and the results obtained in the spatial analyzes confirmed the second hypothesis. In general, the observed data shows that less rigid lockdown or social distancing measures are necessary, however, they are not sufficient to achieve a significant reduction in the circulation of people during the pandemic. ",Medidas de distanciamento social e mobilidade na Am\'erica do Sul   durante a pandemia por COVID-19: Condi\c{c}\~oes necess\'arias e suficientes?
"  We determine the relationship between the contact structure induced by a fibered knot, K, in the three-sphere and the contact structures induced by its various cables. Understanding this relationship allows us to classify fibered cable knots which bound a properly embedded complex curve in the four-ball satisfying a genus constraint. This generalizes the well-known classification of links of plane curve singularities. ","Some remarks on cabling, contact structures, and complex curves"
"  In this paper, we study the role of both ""spin""(species) and mass imbalance in a mixture of two species of fermionic atoms with attractive interaction in an one-dimensional optical lattice. Using the bosonization approach, quantum phase transitions between a liquid phase and phase separated states are studied under various conditions of interaction, spin imbalance, and mass imbalance. We find that, in the phase-separated region, there exists two kinds of phase separation and a special quantum phase transition might exist between them in the large $U$ limit. On the other hand, the singlet superconducting correlation dominates in the liquid phase. The pairing behavior has been also demonstrated that there is oscillating behavior in real space. We find both the spin and mass imbalance are in favor of the formation of Fulde-Ferrell-Larkin-Ovchinnikov state. ",Spin and mass imbalance in a mixture of two species of fermionic atoms   in a 1D optical lattice
"  A new method to generate and control the amplitude and phase distributions of a optical vortex beam is proposed. By introducing a holographic grating on top of the dielectric waveguide, the free space vortex beam and the in-plane guiding wave can be converted to each other. This microscale holographic grating is very robust against the variation of geometry parameters. The designed vortex beam generator can produce the target beam with a fidelity up to 0.93, and the working bandwidth is about 175 nm with the fidelity larger than 0.80. In addition, a multiple generator composed of two holographic gratings on two parallel waveguides are studied, which can perform an effective and flexible modulation on the vortex beam by controlling the phase of the input light. Our work opens a new avenue towards the integrated OAM devices with multiple degrees of optical freedom, which can be used for optical tweezers, micronano imaging, information processing, and so on. ",On-chip generation and control of the vortex beam
"  A metasurface is a surface that consists of artificial material, called metamaterial, with configurable electromagnetic properties. This paper presents work in progress on the design and formal verification of a programmable metasurface, the Hypersurface, as part of the requirements of the VISORSURF research program (HORIZON 2020 FET-OPEN). The Hypersurface design is concerned with the development of a network of switch controllers that are responsible for configuring the metamaterial. The design of the Hypersurface, however, has demanding requirements that need to be delivered within a context of limited resources. This paper shares the experience of a rigorous design procedure for the Hypersurface network, that involves iterations between designing a network and its protocols and the formal evaluation of each design. Formal evaluation has provided results that, so far, drive the development team in a more robust design and overall aid in reducing the cost of the Hypersurface manufacturing. This paper presents work in progress on the design and formal verification of a programmable Hypersurface as part of the requirements of the VISORSURF research programme (HORIZON 2020 FET-OPEN). ",Formal Verification of a Programmable Hypersurface
"  The idea that black hole spin is instrumental in the generation of powerful jets in active galactic nuclei and X-ray binaries is arguably the most contentious claim in black hole astrophysics. Because jets are thought to originate in the context of electromagnetism, and the modeling of Maxwell fields in curved spacetime around black holes is challenging, various approximations are made in numerical simulations that fall under the guise of 'ideal magnetohydrodynamics'. But the simplifications of this framework may struggle to capture relevant details of real astrophysical environments near black holes. In this work, we highlight tension between analytic and numerical results, specifically between the analytically derived conserved Noether currents for rotating black hole spacetimes and the results of general relativistic numerical simulations (GRMHD). While we cannot definitively attribute the issue to any specific approximation used in the numerical schemes, there seem to be natural candidates, which we explore. GRMHD notwithstanding, if electromagnetic fields around rotating black holes are brought to the hole by accretion, we show from first principles that prograde accreting disks likely experience weaker large-scale black hole-threading fields, implying weaker jets than in retrograde configurations. ",Magnetic Fields Threading Black Holes: restrictions from general   relativity and implications for astrophysical black holes
"  The famous biologist Robert Rosen argued for an intrinsic difference between biological and artificial life, supporting the claim that `living systems are not mechanisms'. This result, understood as the claim that life-like mechanisms are non-computable, can be phrased as the non-existence of an equivalence between a category of `static'/analytic elements and a category of `variable'/synthetic elements.   The property of a system of being synthetic, understood as being the gluing of `variable families' of analytica, must imply that the latter class of objects does not retain sufficient information in order to describe said variability; we contribute to this thesis with an argument rooted in elementary category theory.   Seen as such, Rosen's `proof' that no living system can be a mechanism arises from a tension between two contrapuntal needs: on one side, the necessity to consider (synthetically) variable families of systems; on the other, the necessity to describe a syntheticum via an universally chosen analyticum. ",Rosen's no-go theorem for regular categories
"  We introduce a deep learning method to simulate the motion of particles trapped in a chaotic recirculating flame. The Lagrangian trajectories of particles, captured using a high-speed camera and subsequently reconstructed in 3-dimensional space, were used to train a variational autoencoder (VAE) which comprises multiple layers of convolutional neural networks. We show that the trajectories, which are statistically representative of those determined in experiments, can be generated using the VAE network. The performance of our model is evaluated with respect to the accuracy and generalization of the outputs. ",Variational Autoencoding the Lagrangian Trajectories of Particles in a   Combustion System
"  We measure the topological susceptibility of quenched QCD on the lattice at two high temperatures. For this, we define topology with the help of gradient flow and mitigate the statistical problem of topology at high temperatures using a reweighting technique. This allows us to enhance tunneling events between topological sectors and alleviate topological freezing. We quote continuum extrapolated results for the susceptibility at $2.5$ and $4.1~T_\mathrm c$ that agree well with the existing literature. We conclude that the method is feasible and can be extended to unquenched QCD with no conceptual problems. ",Topological Susceptibility to High Temperatures via Reweighting
"  MAXI/GSC detected a superburst from EXO 1745-248 in the globular cluster Terzan 5 on 2011 October 24. The GSC light curve shows an exponential decay with an e-folding time of 0.3 day. The spectra are consistent with the blackbody radiation, whose temperature is 2.2 keV and 1.2 keV at MJD 55858.56 and 55859.20, respectively. The fluence is $1.4 \times 10^{42}$ erg in 2-20 keV assuming 8.7 kpc distance. The sphere radius of the blackbody and its luminosity are estimated to be 6.2 km and $1.1 \times 10^{38}$ erg s$^{-1}$, respectively, from the spectral fitting at the flux peak. Those e-folding time, temperature, softening, fluence, and radius are typical of superbursts from the low-mass X-ray binaries. The superburst was followed by an outburst 28 hours after the superburst onset. The outburst lasted for 5 days and the fluence was $4.3 \times 10^{42}$ erg. The instability of the accretion disk caused by the superburst would be an explanation for the outburst, whereas the mass accretion of the matter evaporated from surface of the companion star by the superburst would be another possibility. ",Superburst with Outburst from EXO 1745-248 in Terzan 5 with MAXI
"  Write ${\cal F}$ for the set of homomorphisms from $\{0,1\}^d$ to ${\bf Z}$ which send $\underline{0}$ to 0 (think of members of ${\cal F}$ as labellings of $\{0,1\}^d$ in which adjacent strings get labels differing by exactly 1), and ${\cal F}_i$ for those which take on exactly $i$ values. We give asymptotic formulae for $|{\cal F}|$ and $|{\cal F}_i|$.   In particular, we show that the probability that a uniformly chosen member ${\bf f}$ of ${\cal F}$ takes more than five values tends to 0 as $d \rightarrow \infty$. This settles a conjecture of J. Kahn. Previously, Kahn had shown that there is a constant $b$ such that ${\bf f}$ a.s. takes at most $b$ values. This in turn verified a conjecture of I. Benjamini {\em et al.}, that for each $t > 0$, ${\bf f}$ a.s. takes at most $td$ values.   Determining $|{\cal F}|$ is equivalent both to counting the number of rank functions on the Boolean lattice $2^{[d]}$ (functions $f \colon 2^{[d]} \longrightarrow {\bf N}$ satisfying $f(\emptyset)=0$ and $f(A) \leq f(A \cup x) \leq f(A)+1$ for all $A \in 2^{[d]}$ and $x \in [d]$) and to counting the number of proper 3-colourings of the discrete cube (i.e., the number of homomorphisms from $\{0,1\}^d$ to $K_3$, the complete graph on 3 vertices).   Our proof uses the main lemma from Kahn's proof of constant range, together with some combinatorial approximation techniques introduced by A. Sapozhenko. ",On homomorphisms from the Hamming cube to {\bf Z}
"  To explain the decision of any model, we extend the notion of probabilistic Sufficient Explanations (P-SE). For each instance, this approach selects the minimal subset of features that is sufficient to yield the same prediction with high probability, while removing other features. The crux of P-SE is to compute the conditional probability of maintaining the same prediction. Therefore, we introduce an accurate and fast estimator of this probability via random Forests for any data $(\boldsymbol{X}, Y)$ and show its efficiency through a theoretical analysis of its consistency. As a consequence, we extend the P-SE to regression problems. In addition, we deal with non-binary features, without learning the distribution of $X$ nor having the model for making predictions. Finally, we introduce local rule-based explanations for regression/classification based on the P-SE and compare our approaches w.r.t other explainable AI methods. These methods are publicly available as a Python package at \url{www.github.com/salimamoukou/acv00}. ",Consistent Sufficient Explanations and Minimal Local Rules for   explaining regression and classification models
"  Most earthquake ruptures propagate at speeds below the shear wave velocity within the crust, but in some rare cases, ruptures reach supershear speeds. The physics underlying the transition of natural subshear earthquakes to supershear ones is currently not fully understood. Most observational studies of supershear earthquakes have focused on determining which fault segments sustain fully-grown supershear ruptures. Experimentally cross-validated numerical models have identified some of the key ingredients required to trigger a transition to supershear speed. However, the conditions for such a transition in nature are still unclear, including the precise location of this transition. In this work, we provide theoretical and numerical insights to identify the precise location of such a transition in nature. We use fracture mechanics arguments with multiple numerical models to identify the signature of supershear transition in coseismic off-fault damage. We then cross-validate this signature with high-resolution observations of fault zone width and early aftershock distributions. We confirm that the location of the transition from subshear to supershear speed is characterized by a decrease in the width of the coseismic off-fault damage zone. We thus help refine the precise location of such a transition for natural supershear earthquakes. ",Signature of transition to supershear rupture speed in coseismic   off-fault damage zone
"  Raman spectroscopy plays a key role in studies of graphene and related carbon systems. Graphene is perhaps the most promising material of recent times for many novel applications, including electronics. In this paper, the traditional and well established Kramers-Heisenberg-Dirac (KHD) Raman scattering theory (1925-1927) is extended to crystalline graphene for the first time. It demands different phonon production mechanisms and phonon energies than does the popular ""double resonance"" Raman scattering model. The latter has never been compared to KHD. Within KHD, phonons are produced instantly along with electrons and holes, in what we term an electron-hole-phonon triplet, which does not suffer Pauli blocking. A new mechanism for double phonon production we name ""transition sliding"" explains the brightness of the 2D mode and other overtones, as a result of linear (Dirac cone) electron dispersion. Direct evidence for sliding resides in hole doping experiments performed in 2011 \cite{chenCrommie}. Whole ranges of electronic transitions are permitted and may even constructively interfere for the same laser energy and phonon q, explaining the dispersion, bandwidth, and strength of many two phonon Raman bands. Graphene's entire Raman spectrum, including dispersive and fixed bands, missing bands not forbidden by symmetries, weak bands, overtone bands, Stokes anti-Stokes anomalies, individual bandwidths, trends with doping, and D-2D band spacing anomalies emerge naturally and directly in KHD theory. ",Theory of Graphene Raman Spectroscopy
"  Many problems in Computer Science can be framed as the computation of queries over sequences, or ""streams"" of data units called events. The field of Complex Event Processing (CEP) relates to the techniques and tools developed to efficiently process these queries. However, most CEP systems developed so far have concentrated on relatively narrow types of queries, which consist of sliding windows, aggregation functions, and simple sequential patterns computed over events that have a fixed tuple structure. Many of them boast throughput, but in counterpart, they are difficult to setup and cumbersome to extend with user-defined elements.   This paper describes a variety of use cases taken from real-world scenarios that present features seldom considered in classical CEP problems. It also provides a broad review of current solutions, that includes tools and techniques going beyond typical surveys on CEP. From a critical analysis of these solutions, design principles for a new type of event stream processing system are exposed. The paper proposes a simple, generic and extensible framework for the processing of event streams of diverse types; it describes in detail a stream processing engine, called BeepBeep, that implements these principles. BeepBeep's modular architecture, which borrows concepts from many other systems, is complemented with an extensible query language, called eSQL. The end result is an open, versatile, and reasonably efficient query engine that can be used in situations that go beyond the capabilities of existing systems. ",From Complex Event Processing to Simple Event Processing
"  We present a novel method enabling robots to quickly learn to manipulate objects by leveraging a motion planner to generate ""expert"" training trajectories from a small amount of human-labeled data. In contrast to the traditional sense-plan-act cycle, we propose a deep learning architecture and training regimen called PtPNet that can estimate effective end-effector trajectories for manipulation directly from a single RGB-D image of an object. Additionally, we present a data collection and augmentation pipeline that enables the automatic generation of large numbers (millions) of training image and trajectory examples with almost no human labeling effort.   We demonstrate our approach in a non-prehensile tool-based manipulation task, specifically picking up shoes with a hook. In hardware experiments, PtPNet generates motion plans (open-loop trajectories) that reliably (89% success over 189 trials) pick up four very different shoes from a range of positions and orientations, and reliably picks up a shoe it has never seen before. Compared with a traditional sense-plan-act paradigm, our system has the advantages of operating on sparse information (single RGB-D frame), producing high-quality trajectories much faster than the ""expert"" planner (300ms versus several seconds), and generalizing effectively to previously unseen shoes. ",Pixels to Plans: Learning Non-Prehensile Manipulation by Imitating a   Planner
"  The results from hydrodynamical TREESPH simulations of galaxy clusters are used to investigate the dependence of the final cluster X-ray properties upon the numerical resolution and the assumed star formation models for the cooled gas. A comparison between runs with different star formation methods shows that the results of simulations, based on star formation methods in which gas conversion into stars is controlled by an efficiency parameter c_{star}, are sensitive to the simulation numerical resolution. In this respect star formation methods based instead on a local density threshold, are shown to give more stable results. Final X-ray luminosities are found to be numerically stable, with uncertainties of a factor 2. ",Numerical Convergence of Hydrodynamical SPH Simulations of Cooling   Clusters
"  The detection of stochastic background of gravitational waves (GWs), produced by cosmological phase transitions (PTs), is of fundamental importance because allows to probe the physics related to PT energy scales. Motivated by the decisive role of non-zero quark chemical potential towards understanding physics in the core of neutron stars, quark stars and heavy-ion collisions, in this paper we qualitatively explore the stochastic background of GW spectrum generated by a cosmological source such as high-density QCD first order PT during the early Universe. Specifically, we calculate the frequency peak $f_{peak}$ redshifted at today time and the fractional energy density $\Omega_{gw}h^2$ in light of equation-of-state improved by the finite quark (baryon) chemical potential (we consider an effective three flavor chiral quarks model of QCD). Our calculations reveal a striking increase in $f_{peak}$ and $\Omega_{gw}h^2$ due to the quark chemical potential, which means to improve the chances of detection, in possible future observations (in particular SKA/PTA experiments), of the stochastic background of GWs from QCD first order PT. Even if the improvements could be weak, by updating the sensitivity of relevant detectors in the future, we can still remain hopeful. Concerning the phenomenological contribution of QCD equation-of-state, and in particular the possibility to detect a stochastic GW signal, we further show that the role of the quark chemical potential is model-dependent. This feature allows to discriminate among possible QCD effective models depending on their capability to shed light on the dynamic of QCD-PT through future observations of primordial GWs. In this perspective, the results are indeed encouraging to employ the GWs to study the QCD PT in high density strong interaction matter. ",The quark chemical potential of QCD phase transition and the stochastic   background of gravitational waves
"  A search for evidence of particle dark matter (DM) and unparticle production at the LHC has been performed using events containing two charged leptons, consistent with the decay of a Z boson, and large missing transverse momentum. This study is based on data collected with the CMS detector corresponding to an integrated luminosity of 19.7 inverse femtobarns of pp collisions at the LHC at a center-of-mass energy of 8 TeV. No significant excess of events is observed above the number expected from the standard model contributions. The results are interpreted in terms of 90% confidence level limits on the DM-nucleon scattering cross section, as a function of the DM particle mass, for both spin-dependent and spin-independent scenarios. Limits are set on the effective cutoff scale Lambda, and on the annihilation rate for DM particles, assuming that their branching fraction to quarks is 100%. Additionally, the most stringent 95% confidence level limits to date on the unparticle model parameters are obtained. ",Search for dark matter and unparticles produced in association with a Z   boson in proton-proton collisions at sqrt(s) = 8 TeV
"  We address the problem of subsequence search in time series using Chebyshev distance, to which we refer as twin subsequence search. We first show how existing time series indices can be extended to perform twin subsequence search. Then, we introduce TS-Index, a novel index tailored to this problem. Our experimental evaluation compares these approaches against real time series datasets, and demonstrates that TS-Index can retrieve twin subsequences much faster under various query conditions. This paper has been published in the 24th International Conference on Extending Database Technology (EDBT 2021). ",Twin Subsequence Search in Time Series
"  We extend the method of Balister, Bollob\'as and Walters for determining rigorous confidence intervals for the critical threshold of two dimensional lattices to three (and higher) dimensional lattices. We describe a method for determining a full confidence interval and apply it to show that the critical threshold for bond percolation on the simple cubic lattice is between 0.2485 and 0.2490 with 99.9999% confidence, and the critical threshold for site percolation on the same lattice is between 0.3110 and 0.3118 with 99.9999% confidence. ",Rigorous Confidence Intervals on Critical Thresholds in 3 Dimensions
"  The linear viscoelastic behavior of the red blood cell membrane of mammal and human was studied in previous works proposing different experimental methods to determine their viscoelastic parameters. In the present work the nonlinear component of dynamic viscosity of the red blood cell membrane by nonlinear time series analysis is used. For such aim, it obtained time series of test in vitro of samples of humans and rats red blood cells using the Erythrodeformeter in oscillating regime. The signal filtrate suppresses any linear behavior as well as represented by a system of linear ordinary differential equations. The test shown as much in humans as in rats resonance frequencies associated to an attractor of unknown nature independently of excitation in the physiological range. The preliminary studies shown that attractor could be correspond to a complex form bull. These results allow to extend the present knowledge on dynamic of the cellular membrane to similar stimulus which happens in the blood circulation and it will allows to make better models of the same one. ",On study of nonlinear viscoelastic behavior of red blood cell membrane
"  Matrix stiffness expressions are derived for the particle movements in an assembly of rigid granules having compliant contacts. The derivations include stiffness terms that arise from the particle shapes at their contacts. These geometric stiffness terms may become significant during granular failure. The geometric stiffness must be added to the mechanical stiffnesses of the contacts to produce the complete stiffness. With frictional contacts, this stiffness expression is incrementally nonlinear, having multiple loading branches. To aid the study of material behavior, a modified stiffness is derived for isolated granular clusters that are considered detached from the rest of a granular body. Criteria are presented for bifurcation, instability, and softening of such isolated and discrete granular sub-regions. Examples show that instability and softening can result entirely from the geometric terms in the matrix stiffness. ","Stability, bifurcation, and softening in discrete systems: A conceptual   approach for granular materials"
"  The radiative spin-flip transition rates of heavy quarkonium states depend sensitively on the matrix elements of the effective confining interaction through the associated two-quark exchange current operator. The Hamiltonian model based on a scalar linear confining interaction with a single gluon exchange hyperfine term is shown to provide an adequate description of the $J/\psi\to \eta_c\gamma$ and $\psi(2S)\to \eta_c\gamma$ decay widths once the relativistic single quark magnetic moment operator is treated without approximation and the exchange current is taken into account. Predictions are given for the radiative spin-flip decay widths of the 1S,2S and 3S states of the $c\bar c$, $b\bar b$ and $B_c^+$ systems. In the B_c^+ system the gluon exchange current also contributes to the spin-flip transition rates. ",The Confining Interaction and Radiative Decays of Heavy Quarkonia
"  We intend to study a new class of cosmological models in $f(R, T)$ modified theories of gravity, hence define the cosmological constant $\Lambda$ as a function of the trace of the stress energy-momentum-tensor $T$ and the Ricci scalar $R$, and name such a model ""$\Lambda(R, T)$ gravity"" where we have specified a certain form of $\Lambda(R, T)$. $\Lambda(R, T)$ is also defined in the perfect fluid and dust case. Some physical and geometric properties of the model are also discussed. The pressure, density and energy conditions are studied both when $\Lambda$ is a positive constant and when $\Lambda=\Lambda(t)$, i.e a function of cosmological time, t. We study the behaviour of some cosmological quantities such as Hubble and deceleration parameters. The model is innovative in the sense that it has been described in terms of both $R$ and $T$ and display a better understanding of the cosmological observations. ",(2+1) dimensional cosmological models in f(R; T) gravity with   $\Lambda$(R; T)
"  We present the calculation of gamma gamma -> 2e+e- process cross section. The construction are perfomed using both helicity amplitude method and method of precision covariant calculation. The magnitude of cross section is obtained by the Monte-Carlo method of numerical integration. Different energies, polarization states and kinematics cuts are considered. ",Production of two electron-positron couples in electroweak gamma gamma -   interaction
"  Density matrices of graphs are combinatorial laplacians normalized to have trace one (Braunstein \emph{et al.} \emph{Phys. Rev. A,} \textbf{73}:1, 012320 (2006)). If the vertices of a graph are arranged as an array, then its density matrix carries a block structure with respect to which properties such as separability can be considered. We prove that the so-called degree-criterion, which was conjectured to be necessary and sufficient for separability of density matrices of graphs, is equivalent to the PPT-criterion. As such it is not sufficient for testing the separability of density matrices of graphs (we provide an explicit example). Nonetheless, we prove the sufficiency when one of the array dimensions has length two (for an alternative proof see Wu, \emph{Phys. Lett. A}\textbf{351} (2006), no. 1-2, 18--22).   Finally we derive a rational upper bound on the concurrence of density matrices of graphs and show that this bound is exact for graphs on four vertices. ",Combinatorial laplacians and positivity under partial transpose
"  We study the effects of field modulation on the energy spectrum of an electron in a two-dimensional bipartite periodic lattice subject to a magnetic field. Dependence of the energy spectrum on both the period and the strength of field modulation is discussed in detail. Our main finding is that introducing field modulation drastically changes the energy spectrum and the localization properties of the system appearing in the absence of field modulation; the degeneracies induced by a uniform magnetic field are broken and the resultant energy spectrum shows a dispersive band structure, indicating that most of Aharonov-Bohm cages become unbounded. The effects of field modulation on the superconducting transition temperature and the critical current in a wire network with the same geometry are also discussed. ",Effects of field modulation on Aharonov-Bohm cages in a two-dimensional   bipartite periodic lattice
"  Many statistical methods have been proposed for variable selection in the past century, but few balance inference and prediction tasks well. Here we report on a novel variable selection approach called Penalized regression with Second-Generation P-Values (ProSGPV). It captures the true model at the best rate achieved by current standards, is easy to implement in practice, and often yields the smallest parameter estimation error. The idea is to use an l0 penalization scheme with second-generation p-values (SGPV), instead of traditional ones, to determine which variables remain in a model. The approach yields tangible advantages for balancing support recovery, parameter estimation, and prediction tasks. The ProSGPV algorithm can maintain its good performance even when there is strong collinearity among features or when a high dimensional feature space with p > n is considered. We present extensive simulations and a real-world application comparing the ProSGPV approach with smoothly clipped absolute deviation (SCAD), adaptive lasso (AL), and mini-max concave penalty with penalized linear unbiased selection (MC+). While the last three algorithms are among the current standards for variable selection, ProSGPV has superior inference performance and comparable prediction performance in certain scenarios. Supplementary materials are available online. ",Variable Selection with Second-Generation P-Values
"  Border indentations in non-linear conductors, such as superconducting thin films in the creep regime, alter the distribution of currents and magnetic fields near and far from the indentation. One of such disturbances are the discontinuity lines, or \textit{d}-lines, a parabolic-like line originating from the indentation where the current density direction changes abruptly. Hodograph series results are obtained for the currents around a triangular indentation and its corresponding $d$-lines in a conducting stripe of finite width and in an infinite half plane, considering two cases: uniform creep exponent and mixed infinite and ohmic exponents. The mixed creep exponent case presents currents distributions resembling the purely ohmic case, with significant current disturbances only near the indentation. For uniform creep exponent, results similar to a planar indentation are obtained, with far ranged currents features and parabolic-like $d$-lines with shapes depending on the creep exponent. In particular, the same $d$-line asymptotic behaviour is obtained for the triangle indentation as that of the planar defect in the critical state, a result obtained here just on continuity considerations of the hodograph expansions. This equivalence is due to identical contributions to the Fourier series of the current stream-function in the hodograph space, obtained from an images method expansion. ",Calculation of currents around a triangular indentation by the hodograph   method
"  In this work we calculate the tensor power spectrum and the tensor-to-scalar ratio r within the frame of the Starobinsky inflationary model using the improved uniform approximation method and the third-order phase-integral method. We compare our results with those obtained with numerical integration and the slow-roll approximation to second order. We have obtained consistent values of r using the different approximations, and r is inside the interval reported by observations. ",Semiclassical analysis of the tensor power spectrum in the Starobinsky   inflationary model
"  Wavelets are a new and powerful mathematical tool, whose most celebrated applications are data compression and de-noising. In Paper I (Romeo, Horellou & Bergh 2003, astro-ph/0302343), we have shown that wavelets can be used for removing noise efficiently from cosmological, galaxy and plasma N-body simulations. The expected two-orders-of-magnitude higher performance means, in terms of the well-known Moore's law, an advance of more than one decade in the future. In this paper, we describe a wavelet add-on code designed for such an application. Our code can be included in common grid-based N-body codes, is written in Fortran, is portable and available on request from the first author. The code can also be applied for removing noise from standard data, such as signals and images. ",A wavelet add-on code for new-generation N-body simulations and data   de-noising (JOFILUREN)
"  We consider linearly coupled discrete nonlinear Schr\""odinger equations with gain and loss terms and with a cubic-quintic nonlinearity. The system models a parity-time ($\cal{PT}$)-symmetric coupler composed by a chain of dimers. Particularly we study site-centered and bond-centered spatially-localized solutions and present that each solution has a symmetric and antisymmetric configuration between the arms. When a parameter is varied, the resulting bifurcation diagrams for the existence of standing localized solutions have a snaking behaviour. The critical gain/loss coefficient above which the $\cal{PT}-$symmetry is broken corresponds to the condition when bifurcation diagrams of symmetric and antisymmetric states merge. Past the symmetry breaking, the system no longer has time-independent states. Nevertheless, equilibrium solutions can be analytically continued by defining a dual equation that leads to so-called ghost states associated with growth or decay, that are also identified and examined here. We show that ghost localized states also exhibit snaking bifurcation diagrams. We analyse the width of the snaking region and provide asymptotic approximations in the limit of strong and weak coupling where good agreement is obtained. ",Snakes and ghosts in a parity-time-symmetric chain of dimers
"  We examine the evolution of the IGM Ly-alpha optical depth distribution using the transmitted flux probability distribution function (PDF) in a sample of 63 QSOs spanning absorption redshifts 1.7 < z < 5.8. The data are compared to two theoretical optical depth distributions: a model distribution based on the density distribution of Miralda-Escude et al. (2000) (MHR00), and a lognormal distribution. We assume a uniform UV background and an isothermal IGM for the MHR00 model, as has been done in previous works. Under these assumptions, the MHR00 model produces poor fits to the observed flux PDFs at redshifts where the optical depth distribution is well sampled, unless large continuum corrections are applied. However, the lognormal optical depth distribution fits the data at all redshifts with only minor continuum adjustments. We use a simple parametrization for the evolution of the lognormal parameters to calculate the expected mean transmitted flux at z > 5.4. The lognormal optical depth distribution predicts the observed Ly-alpha and Ly-beta effective optical depths at z > 5.7 while simultaneously fitting the mean transmitted flux down to z = 1.6. If the evolution of the lognormal distribution at z < 5 reflects a slowly-evolving density field, temperature, and UV background, then no sudden change in the IGM at z ~ 6 due to late reionization appears necessary. We have used the lognormal optical depth distribution without any assumption about the underlying density field. If the MHR00 density distribution is correct, then a non-uniform UV background and/or IGM temperature may be required to produce the correct flux PDF. We find that an inverse temperature-density relation greatly improves the PDF fits, but with a large scatter in the equation of state index. [Abridged] ",The Evolution of Optical Depth in the Ly-alpha Forest: Evidence Against   Reionization at z~6
"  The modified Dirac equation in the Lorentz-violating Standard-Model Extension (SME) is considered. Within this framework, the construction of a hermitian Hamiltonian to all orders in the Lorentz-breaking parameters is investigated, discrete symmetries and the first-order roots of the dispersion relation are determined, and various properties of the eigenspinors are discussed. ",Dirac theory within the Standard-Model Extension
  The CTIO Prime Focus CCD instrument with an RCA CCD was in operation at the CTIO 4-m telescope for six years between 1982-1988. A large body of literature has been published based on CCD images taken with this instrument. We review the general properties of the now-retired PFCCD system to aid astronomers in the interpretation of the photometric data in the literature. ,The CTIO Prime Focus CCD: System Characteristics from 1982-1988
"  We consider the ten confidently detected gravitational wave signals in the GWTC-1 catalog [1] which are consistent with mergers of binary black hole systems, and re-analyze them with waveform models that contain subdominant spherical harmonic modes. This analysis is based on the current (fourth) generation of the IMRPhenom family of phenomenological waveform models, which consists of the IMRPhenomX frequency-domain models [2-5] and the IMRPhenomT time-domain models [6-8]. We find overall consistent results, with all Jensen-Shannon divergences between the previous results using IMRPhenomPv2 and our default IMRPhenomXPHM posterior results below 0.045 bits. Effects of subdominant harmonics are however visible for several events, and for GW170729 our new time domain IMRPhenomTPHM model provides the best fit and shifts the posterior further toward more unequal masses and a higher primary mass of $57.3^{+12.0}_{-10.9}$ solar masses at the lower end of the PISN mass gap. ",Adding harmonics to the interpretation of the black hole mergers of   GWTC-1
"  This is the second part of a three part series abut delocalization for band matrices. In this paper, we consider a general class of $N\times N$ random band matrices $H=(H_{ij})$ whose entries are centered random variables, independent up to a symmetry constraint. We assume that the variances $\mathbb E |H_{ij}|^2$ form a band matrix with typical band width $1\ll W\ll N$. We consider the generalized resolvent of $H$ defined as $G(Z):=(H - Z)^{-1}$, where $Z$ is a deterministic diagonal matrix such that $Z_{ij}=\left(z 1_{1\leq i \leq W}+\widetilde z 1_{ i > W} \right) \delta_{ij}$, with two distinct spectral parameters $z\in \mathbb C_+:=\{z\in \mathbb C:{\rm Im} z>0\}$ and $\widetilde z\in \mathbb C_+\cup \mathbb R$. In this paper, we prove a sharp bound for the local law of the generalized resolvent $G$ for $W\gg N^{3/4}$. This bound is a key input for the proof of delocalization and bulk universality of random band matrices in \cite{PartI}. Our proof depends on a fluctuations averaging bound on certain averages of polynomials in the resolvent entries, which will be proved in \cite{PartIII}. ","Random band matrices in the delocalized phase, II: Generalized resolvent   estimates"
"  Negative dielectric constant and dominant kinetic resistance make superconductors an intriguing plasmonic media. Here we report on the first study of one of the most important and disputed manifestations of plasmonics, the effect of extraordinary transmission through an array of sub-wavelength holes, using a perforated film of high-temperature superconductor. ",Superconducting plasmonics and extraordinary transmission
"  We present a novel area matching algorithm for merging two different 2D grid maps. There are many approaches to address this problem, nevertheless, most previous work is built on some assumptions, such as rigid transformation, or similar scale and modalities of two maps. In this work we propose a 2D map matching algorithm based on area segmentation. We transfer general 2D occupancy grid maps to an area graph representation, then compute the correct results by voting in that space. In the experiments, we compare with a state-of-the-art method applied to the matching of sensor maps with ground truth layout maps. The experiment shows that our algorithm has a better performance on large-scale maps and a faster computation speed. ",Fast 2D Map Matching Based on Area Graphs
"  We examine the origin of the Newton-Schr\""odinger equations (NSEs) that play an important role in alternative quantum theories (AQT), macroscopic quantum mechanics and gravity-induced decoherence. We show that NSEs for individual particles do not follow from general relativity (GR) plus quantum field theory (QFT). Contrary to what is commonly assumed, the NSEs are not the weak-field (WF), non-relativistic (NR) limit of the semi-classical Einstein equation (SCE) (this nomenclature is preferred over the `M\/oller-Rosenfeld equation') based on GR+QFT. The wave-function in the NSEs makes sense only as that for a mean field describing a system of $N$ particles as $N \rightarrow \infty$, not that of a single or finite many particles. From GR+QFT the gravitational self-interaction leads to mass renormalization, not to a non-linear term in the evolution equations of some AQTs. The WF-NR limit of the gravitational interaction in GR+QFT involves no dynamics. To see the contrast, we give a derivation of the equation (i) governing the many-body wave function from GR+QFT and (ii) for the non-relativistic limit of quantum electrodynamics (QED). They have the same structure, being linear, and very different from NSEs. Adding to this our earlier consideration that for gravitational decoherence the master equations based on GR+QFT lead to decoherence in the energy basis and not in the position basis, despite some AQTs desiring it for the `collapse of the wave function', we conclude that the origins and consequences of NSEs are very different, and should be clearly demarcated from those of the SCE equation, the only legitimate representative of semiclassical gravity, based on GR+QFT. ","Problems with the Newton-Schr\""odinger Equations"
"  We study an effect of the off-shellness of the quark and antiquark inside a heavy quarkonium system on IR renormalons contained in the perturbative computations of the quarkonium energy levels. We demonstrate that, when the off-shellness p_Q^2 -m_Q^2 \sim alpha_S^2 m_Q^2 is larger than m_Q Lambda_QCD, renormalons in the energy levels as calculated in perturbative QCD are suppressed by a factor Lambda_QCD/alpha_S^2 m_Q as compared to those in 2 m_pole + V_QCD(r). In this case the residual O(Lambda_QCD^4) renormalon has the same dimension as that of the leading gluon-condensate contribution. ",Off-shell Suppression of Renormalons in Non-relativistic QCD Boundstates
"  A graph is said to be a bi-Cayley graph over a group H if it admits H as a group of automorphisms acting semiregularly on its vertices with two orbits. A non-abelian group is called an inner-abelian group if all of its proper subgroups are abelian. In this paper, we complete the classification of connected cubic edge-transitive bi-Cayley graphs over inner-abelian p-groups for an odd prime p. ",Cubic edge-transitive bi-Cayley graphs over inner-abelian p-groups
"  Yang-Mills theory with flavor quarks in the dS${}_4$ is studied through the dual supergravity in the AdS${}_5\times S^5$ background with non-trivial dilaton and axion. The flavor quarks are introduced by embedding a probe D7 brane. We find that the dynamical properties of YM theory in the dS${}_4$ are similar to the case of the finite temperature theory given by the 5d AdS-Schwarzschild background. In the case of dS${}_4$, however, contrary to the finite temperature case, the gauge field condensate plays an important role on the dynamical properties of quarks. We also give the quark-antiquark potential and meson spectra to find possible quark-bound states. And we arrive at the conclusion that, while the quarks are not confined in the dS${}_4$, we could find stable meson states at very small cosmological constant as expected in the present universe. But there would be no hadrons at early universe as in the inflation era. ",Gauge theory in de Sitter space-time from a holographic model
"  We present images of the jets in the nearby radio galaxy NGC 315 made with the VLA at five frequencies between 1.365 and 5 GHz with resolutions between 1.5 and 45 arcsec FWHM. Within 15 arcsec of the nucleus, the spectral index of the jets is 0.61. Further from the nucleus, the spectrum is flatter, with significant transverse structure. Between 15 and 70 arcsec from the nucleus, the spectral index varies from 0.55 on-axis to 0.44 at the edge. This spectral structure suggests a change of dominant particle acceleration mechanism with distance from the nucleus and the transverse gradient may be associated with shear in the jet velocity field. Further from the nucleus, the spectral index has a constant value of 0.47. We derive the distribution of Faraday rotation over the inner +/-400 arcsec of the radio source and show that it has three components: a constant term, a linear gradient (both probably due to our Galaxy) and residual fluctuations at the level of 1 - 2 rad/m^2. These residual fluctuations are smaller in the brighter (approaching) jet, consistent with the idea that they are produced by magnetic fields in a halo of hot plasma that surrounds the radio source. We model this halo, deriving a core radius of approximately 225 arcsec and constraining its central density and magnetic-field strength. We also image the apparent magnetic-field structure over the first +/-200 arcsec from the nucleus. ",Multifrequency observations of the jets in the radio galaxy NGC 315
"  We study soliton interaction in the Modified Kadomtsev-Petviashvili-(II) equation (MKP-(II)) using the totally non-negative Grassmannian. One constructs the multi-kink soliton of MKP equation using the $\tau$-function and the Binet-Cauchy formula, and then investigates the interaction between kink solitons and line solitons. Especially, Y-type kink-soliton resonance, O-type kink soliton and P-type kink soliton of X-shape are investigated. Their amplitudes of interaction are computed after choosing appropriate phases. ",Soliton Interaction In the Modified Kadomtsev-Petviashvili-(II) Equation
"  A new microcanonical equilibrium state is introduced for quantum systems with finite-dimensional state spaces. Equilibrium is characterised by a uniform distribution on a level surface of the expectation value of the Hamiltonian. The distinguishing feature of the proposed equilibrium state is that the corresponding density of states is a continuous function of the energy, and hence thermodynamic functions are well defined for finite quantum systems. The density of states, however, is not in general an analytic function. It is demonstrated that generic quantum systems therefore exhibit second-order (continuous) phase transitions at finite temperatures. ",Quantum phase transitions without thermodynamic limits
"  The existence of a unique numerical solution of the semi-Lagrangian method for the simple Monge-Amp\`ere equation is known independently of the convexity of the domain or Dirichlet boundary data -- when the Monge-Amp\`ere equation is posed as Bellman problem. However, the convergence to the viscosity solution has only been proved on strictly convex domains. In this paper we provide numerical evidence that convergence of numerical solutions is observed more generally without convexity assumptions. We illustrate how in the limit multi-valued functions may be approximated to satisfy the Dirichlet conditions on the boundary as well as local convexity in the interior of the domain. ",Numerical Solution of the Simple Monge-Amp\`ere Equation with Non-convex   Dirichlet Data on Non-convex Domains
"  $L-$series attached to two classical families of elliptic curves with complex multiplications are studied over number fields, formulae for their special values at $s=1, $ bound of the values, and criterion of reaching the bound are given. Let $ E_1: y^{2}=x^{3}-D_1 x $ be elliptic curves over the Gaussian field $K=\Q(\sqrt{-1}), $ with $ D_1 =\pi_{1} ... \pi_{n} $ or $ D_1 =\pi_{1} ^{2}... \pi_{r} ^{2} \pi_{r+1} ... \pi_{n}$, where $\pi_{1}, ..., \pi_{n}$ are distinct primes in $K$. A formula for special values of Hecke $L-$series attached to such curves expressed by Weierstrass $\wp-$function are given; a lower bound of 2-adic valuations of these values of Hecke $L-$series as well as a criterion for reaching these bounds are obtained. Furthermore, let $ E_{2}: y^{2}=x^{3}-2^{4}3^{3}D_2^{2} $ be elliptic curves over the quadratic field $ \Q(\sqrt{-3}) $ with $ D_2 =\pi_{1} ... \pi_{n}, $ where $\pi_{1}, ..., \pi_{n}$ are distinct primes of $\Q(\sqrt{-3})$, similar results as above but for $3-adic$ valuation are also obtained. These results are consistent with the predictions of the conjecture of Birch and Swinnerton-Dyer, and develop some results in recent literature for more special case and for $2-adic$ valuation. ",L-series and their 2-adic and 3-adic valuations at s=1 attached to CM   elliptic curves
"  In this paper, we extend a model of host-parasite co-evolution to incorporate the semi-conservative nature of DNA replication for both the host and the parasite. We find that the optimal mutation rate for the semi-conservative and conservative hosts converge for realistic genome lengths, thus maintaining the admirable agreement between theory and experiment found previously for the conservative model and justifying the conservative approximation in some cases. We demonstrate that, while the optimal mutation rate for a conservative and semi-conservative parasite interacting with a given immune system is similar to that of a conservative parasite, the properties away from this optimum differ significantly. We suspect that this difference, coupled with the requirement that a parasite optimize survival in a range of viable hosts, may help explain why semi-conservative viruses are known to have significantly lower mutation rates than their conservative counterparts. ",Host-Parasite Co-evolution and Optimal Mutation Rates for   Semi-conservative Quasispecies
"  We study dynamical properties of blowup solutions to the focusing $L^2$-supercritical nonlinear fractional Schr\""odinger equation \[ i\partial_t u -(-\Delta)^s u = -|u|^\alpha u, \quad u(0) = u_0, \quad \text{on } [0,\infty) \times \mathbb{R}^d, \] where $d \geq 2, \frac{d}{2d-1} \leq s <1$, $\frac{4s}{d}<\alpha<\frac{4s}{d-2s}$ and $u_0 \in \dot{H}^{s_{\text{c}}} \cap \dot{H}^s$ is radial with the critical Sobolev exponent $s_{\text{c}}$. To this end, we establish a compactness lemma related to the equation by means of the profile decomposition for bounded sequences in $\dot{H}^{s_{\text{c}}} \cap \dot{H}^s$. As a result, we obtain the $\dot{H}^{s_{\text{c}}}$-concentration of blowup solutions with bounded $\dot{H}^{s_{\text{c}}}$-norm and the limiting profile of blowup solutions with critical $\dot{H}^{s_{\text{c}}}$-norm. ","On blowup solutions to the focusing $L^2$-supercritical nonlinear   fractional Schr\""odinger equation"
"  Recent interferometric data have been used to constrain the brightness distribution at the surface of nearby stars, in particular the so-called gravity darkening that makes fast rotating stars brighter at their poles than at their equator. However, good models of gravity darkening are missing for stars that posses a convective envelope. In order to better understand how rotation affects the heat transfer in stellar convective envelopes, we focus on the heat flux distribution in latitude at the outer surface of numerical models. We carry out a systematic parameter study of three-dimensional, direct numerical simulations of anelastic convection in rotating spherical shells. Restricting our investigations to hydrodynamical models with a thermal Prandtl number fixed to unity, we consider both thick and thin (solar-like) shells, and vary the stratification over three orders of magnitude. We measure the heat transfer efficiency in terms of the Nusselt number, defined as the output luminosity normalised by the conductive state luminosity. We report diverse Nusselt number profiles in latitude, ranging from brighter (usually at the onset of convection) to darker equator and uniform profiles. We find that the variations of the surface brightness are mainly controlled by the surface value of the local Rossby number: when the Coriolis force dominates the dynamics, the heat flux is weakened in the equatorial region by the zonal wind and enhanced at the poles by convective motions inside the tangent cylinder. In the presence of a strong background density stratification however, as expected in real stars, the increase of the local Rossby number in the outer layers leads to uniformisation of the surface heat flux distribution. ",Gravity darkening in late-type stars. The Coriolis effect
"  We perform simulations of general relativistic rotating stellar core collapse and compute the gravitational waves (GWs) emitted in the core bounce phase of three representative models via multiple techniques. The simplest technique, the quadrupole formula (QF), estimates the GW content in the spacetime from the mass quadrupole tensor. It is strictly valid only in the weak-field and slow-motion approximation. For the first time, we apply GW extraction methods in core collapse that are fully curvature-based and valid for strongly radiating and highly relativistic sources. We employ three extraction methods computing (i) the Newman-Penrose (NP) scalar Psi_4, (ii) Regge-Wheeler-Zerilli-Moncrief (RWZM) master functions, and (iii) Cauchy-Characteristic Extraction (CCE) allowing for the extraction of GWs at future null infinity, where the spacetime is asymptotically flat and the GW content is unambiguously defined. The latter technique is the only one not suffering from residual gauge and finite-radius effects. All curvature-based methods suffer from strong non-linear drifts. We employ the fixed-frequency integration technique as a high-pass waveform filter. Using the CCE results as a benchmark, we find that finite-radius NP extraction yields results that agree nearly perfectly in phase, but differ in amplitude by ~1-7% at core bounce, depending on the model. RWZM waveforms, while in general agreeing in phase, contain spurious high-frequency noise of comparable amplitudes to those of the relatively weak GWs emitted in core collapse. We also find remarkably good agreement of the waveforms obtained from the QF with those obtained from CCE. They agree very well in phase but systematically underpredict peak amplitudes by ~5-11% which is comparable to the NP results and is within the uncertainties associated with core collapse physics. (abridged) ",Gravitational Wave Extraction in Simulations of Rotating Stellar Core   Collapse
"  We consider the following inverse problem for an ordinary differential equation (ODE): given a set of data points $P=\{(t_i,x_i),\; i=1,\dots,N\}$, find an ODE $x^\prime(t) = v (x)$ that admits a solution $x(t)$ such that $x_i \approx x(t_i)$ as closely as possible. The key to the proposed method is to find approximations of the recursive or discrete propagation function $D(x)$ from the given data set. Afterwards, we determine the field $v(x)$, using the conjugate map defined by Schr\""{o}der's equation and the solution of a related Julia's equation. Moreover, our approach also works for the inverse problems where one has to determine an ODE from multiple sets of data points. We also study existence, uniqueness, stability and other properties of the recovered field $v(x)$. Finally, we present several numerical methods for the approximation of the field $v(x)$ and provide some illustrative examples of the application of these methods. ",Solving the inverse problem for an ordinary differential equation using   conjugation
"  One way to interpret trained deep neural networks (DNNs) is by inspecting characteristics that neurons in the model respond to, such as by iteratively optimising the model input (e.g., an image) to maximally activate specific neurons. However, this requires a careful selection of hyper-parameters to generate interpretable examples for each neuron of interest, and current methods rely on a manual, qualitative evaluation of each setting, which is prohibitively slow. We introduce a new metric that uses Fr\'echet Inception Distance (FID) to encourage similarity between model activations for real and generated data. This provides an efficient way to evaluate a set of generated examples for each setting of hyper-parameters. We also propose a novel GAN-based method for generating explanations that enables an efficient search through the input space and imposes a strong prior favouring realistic outputs. We apply our approach to a classification model trained to predict whether a music audio recording contains singing voice. Our results suggest that this proposed metric successfully selects hyper-parameters leading to interpretable examples, avoiding the need for manual evaluation. Moreover, we see that examples synthesised to maximise or minimise the predicted probability of singing voice presence exhibit vocal or non-vocal characteristics, respectively, suggesting that our approach is able to generate suitable explanations for understanding concepts learned by a neural network. ",GAN-based Generation and Automatic Selection of Explanations for Neural   Networks
"  The Levi-Malcev decomposition is applied to bosonic models of quantum mechanics based on unitary Lie algebras u(2), u(2)+u(2), u(3) and u(4) to clearly disentangle semisimple subalgebras. The theory of weighted Dynkin diagrams is then applied to identify conjugacy classes of relevant A_1 subalgebras allowing to introduce a complete classification of new angular momentum non conserving (AMNC) dynamical symmetries. The tensor analysis of the whole algebra based on the new ""angular momentum"" operators reveals unexpected spinors to occur in purely bosonic models. The new chains of subalgebra can be invoked to set up ANMC bases for diagonalization. ",Angular momentum non conserving symmetries in bosonic models
"  The features of electron assisted neutron exchange processes in crystalline solids are survayed. It is stated that, contrary to expectations, the cross section of these processes may reach an observable magnitude even in the very low energy case because of the extremely huge increment caused by the Coulomb factor of the electron assisted processes and by the effect of the crystal-lattice. The features of electron assisted heavy charged particle exchange processes, electron assisted nuclear capure processes and heavy charged particle assisted nuclear processes are also overviewed. Experimental observations, which may be related to our theoretical findings, are dealt with. The anomalous screening phenomenon is related to electron assisted neutron and proton exchange processes in crystalline solids. A possible explanation of observations by Fleischmann and Pons is presented. The possibility of the phenomenon of nuclear transmutation is qualitatively explained with the aid of usual and charged particle assisted reactions. The electron assisted neutron exchange processes in pure $Ni$ and $Li-Ni$ composite systems (in the Rossi-type E-Cat) are analyzed and it is concluded that these reactions may be responsible for recent experimental observations. ",Charged particle assisted nuclear reactions in solid state environment:   renaissance of low energy nuclear physics
"  We report the discovery of a several-Jupiter mass planetary companion to the primary lens star in microlensing event OGLE-2005-BLG-071. Precise (<1%) photometry at the peak of the event yields an extremely high signal-to-noise ratio detection of a deviation from the light curve expected from an isolated lens. The planetary character of this deviation is easily and unambiguously discernible from the gross features of the light curve. Detailed modeling yields a tightly-constrained planet-star mass ratio of q=m_p/M=0.0071+/-0.0003. This is the second robust detection of a planet with microlensing, demonstrating that the technique itself is viable and that planets are not rare in the systems probed by microlensing, which typically lie several kpc toward the Galactic center. ",A Jovian-mass Planet in Microlensing Event OGLE-2005-BLG-071
"  We show that, given a set $E\subset \mathbb R^{n+1}$ with finite $n$-Hausdorff measure $H^n$, if the $n$-dimensional Riesz transform $$R_{H^n|E} f(x) = \int_{E} \frac{x-y}{|x-y|^{n+1}} f(y) dH^n(y)$$ is bounded in $L^2(H^n|E)$, then $E$ is $n$-rectifiable. From this result we deduce that a compact set $E\subset\mathbb R^{n+1}$ with $H^n(E)<\infty$ is removable for Lipschitz harmonic functions if and only if it is purely $n$-unrectifiable, thus proving the analog of Vitushkin's conjecture in higher dimensions. ","The Riesz transform, rectifiability, and removability for Lipschitz   harmonic functions"
"  The properties of low-redshift Type Ia supernovae are investigated using published multi-band optical broadband data from the Calan/Tololo and CfA surveys. The average time evolution of B-V, V-R, R-I, B-I and V-I, the intrinsic dispersion and time correlations are studied. This information is required to deduce the extinction of such explosions from the measured colours. We find that extinction corrections on individual SNe based on their colours up to 40 days past the B-band lightcurve maximum are generaly limited to \sigma_{A_V} \gsim 0.1, due to intrinsic variations, as far as it can be conservatively deduced with the current sample of data. However, we find that the V-R colour, especially at late times, is consistent with a negligible intrinsic spread, and may be the most accurate estimator for extinction. ",The intrinsic colour dispersion in Type Ia supernovae
"  As is well known, in quantum mechanics, the calculation rule of the probability that an eigen-value a_n is observed when the physical quantity A is measured for a state described by the state vector |> is P(a_n)=<|A_n><A_n|> . However, in Ref.[1], based on strict logical reasoning and mathematical calculation, it has been pointed out, replacing <|A_n><A_n|>, one should use a new rule to calculate P(a_n) for particle satisfying the Dirac equation.   In this paper, we first state some results given by Ref.[1]. And then, we present a proof for the new calculation rule of probability according to Dirac sea of negative energy particles, hole theory and the principle ""the vacuum is not observable"". Finally, we discuss simply the case of particle satisfying the Klein-Gordon equation. ",On the calculation rule of probability of relativistic free particle in   quantum mechanics
"  Let X be a subshift satisfy non-uniform structure. In this paper, we give quantitative estimate of the recurrence sets. These results can be applied to a large class of symbolic systems, including beta-shifts, S-gap shifts and their factors. ",Quantitative recurrence properties for systems with non-uniform   structure
"  Graph neural networks (GNNs) achieve remarkable performance for tasks on graph data. However, recent works show they are extremely vulnerable to adversarial structural perturbations, making their outcomes unreliable. In this paper, we propose DefenseVGAE, a novel framework leveraging variational graph autoencoders(VGAEs) to defend GNNs against such attacks. DefenseVGAE is trained to reconstruct graph structure. The reconstructed adjacency matrix can reduce the effects of adversarial perturbations and boost the performance of GCNs when facing adversarial attacks. Our experiments on a number of datasets show the effectiveness of the proposed method under various threat models. Under some settings it outperforms existing defense strategies. Our code has been made publicly available at https://github.com/zhangao520/defense-vgae. ",DefenseVGAE: Defending against Adversarial Attacks on Graph Data via a   Variational Graph Autoencoder
"  The distribution of Helium in the intracluster medium (ICM) permeating galaxy clusters is not well constrained due to the very high plasma temperature. Therefore, the plasma is often assumed to be homogeneous. A non-uniform Helium distribution can however lead to biases when measuring key cluster parameters. This has motivated one-dimensional models that evolve the ICM composition assuming that the effects of magnetic fields can be parameterized or ignored. Such models for non-isothermal clusters show that Helium can sediment in the cluster core leading to a peak in concentration offset from the cluster center. The resulting profiles have recently been shown to be linearly unstable when the weakly-collisional character of the magnetized plasma is considered. In this paper, we present a modified version of the MHD code Athena, which makes it possible to evolve a weakly-collisional plasma subject to a gravitational field and stratified in both temperature and composition. We thoroughly test our implementation and confirm excellent agreement against several analytical results. In order to isolate the effects of composition, in this initial study we focus our attention on isothermal plasmas. We show that plasma instabilities, feeding off gradients in composition, can induce turbulent mixing and saturate by re-arranging magnetic field lines and alleviating the composition gradient. Composition profiles that increase with radius lead to instabilities that saturate by driving the average magnetic field inclination to roughly $45^{\circ}$. We speculate that this effect may alleviate the core insulation observed in homogeneous settings, with potential consequences for the associated cooling flow problem. ",Local Simulations of Instabilities Driven by Composition Gradients in   the ICM
"  A major impediment to the application of deep learning to real-world problems is the scarcity of labeled data. Small training sets are in fact of no use to deep networks as, due to the large number of trainable parameters, they will very likely be subject to overfitting phenomena. On the other hand, the increment of the training set size through further manual or semi-automatic labellings can be costly, if not possible at times. Thus, the standard techniques to address this issue are transfer learning and data augmentation, which consists of applying some sort of ""transformation"" to existing labeled instances to let the training set grow in size. Although this approach works well in applications such as image classification, where it is relatively simple to design suitable transformation operators, it is not obvious how to apply it in more structured scenarios. Motivated by the observation that in virtually all application domains it is easy to obtain unlabeled data, in this paper we take a different perspective and propose a \emph{label augmentation} approach. We start from a small, curated labeled dataset and let the labels propagate through a larger set of unlabeled data using graph transduction techniques. This allows us to naturally use (second-order) similarity information which resides in the data, a source of information which is typically neglected by standard augmentation techniques. In particular, we show that by using known game theoretic transductive processes we can create larger and accurate enough labeled datasets which use results in better trained neural networks. Preliminary experiments are reported which demonstrate a consistent improvement over standard image classification datasets. ",Transductive Label Augmentation for Improved Deep Network Learning
"  The classical embedding theorem of Carleson deals with finite positive Borel measures $\mu$ on the closed unit disk for which there exists a positive constant $c$ such that $|f|_{L^2(\mu)} \leq c |f|_{H^2}$ for all $f \in H^2$, the Hardy space of the unit disk. Lef\'evre et al. examined measures $\mu$ for which there exists a positive constant $c$ such that $\|f\|_{L^2(\mu)} \geq c |f|_{H^2}$ for all $f \in H^2$. The first type of inequality above was explored with $H^2$ replaced by one of the model spaces $(\Theta H^2)^{\perp}$ by Aleksandrov, Baranov, Cohn, Treil, and Volberg. In this paper we discuss the second type of inequality in $(\Theta H^2)^{\perp}$. ",Reverse Carleson Embeddings for Model Spaces
"  Attribute recognition, particularly facial, extracts many labels for each image. While some multi-task vision problems can be decomposed into separate tasks and stages, e.g., training independent models for each task, for a growing set of problems joint optimization across all tasks has been shown to improve performance. We show that for deep convolutional neural network (DCNN) facial attribute extraction, multi-task optimization is better. Unfortunately, it can be difficult to apply joint optimization to DCNNs when training data is imbalanced, and re-balancing multi-label data directly is structurally infeasible, since adding/removing data to balance one label will change the sampling of the other labels. This paper addresses the multi-label imbalance problem by introducing a novel mixed objective optimization network (MOON) with a loss function that mixes multiple task objectives with domain adaptive re-weighting of propagated loss. Experiments demonstrate that not only does MOON advance the state of the art in facial attribute recognition, but it also outperforms independently trained DCNNs using the same data. When using facial attributes for the LFW face recognition task, we show that our balanced (domain adapted) network outperforms the unbalanced trained network. ",MOON: A Mixed Objective Optimization Network for the Recognition of   Facial Attributes
"  In a black hole, hair and quantum information retrieval are interrelated phenomena. The existence of any new form of hair necessarily implies the existence of features in the quantum-mechanically evaporated radiation. Classical supertranslation hair can be only distinguished from global diffeomorphisms if we have access to the interior of the black hole. Indirect information on the interior can only be obtained from the features of the quantum evaporation. Supertranslations $(T^-,T^+) \in BMS_{-}\otimes BMS_{+}$ can be used as bookkepers of the probability distributions of the emitted quanta where the first element describes the classical injection of energy and the second one is associated to quantum-mechanical emission. The connection between $T^-$ and $T^+$ is determined by the interior quantum dynamics of the black hole. We argue that restricting to the diagonal subgroup is only possible for decoupled modes, which do not bring any non-trivial information about the black hole interior and therefore do not constitute physical hair. We show that this is also true for gravitational systems without horizon, for which both injection and emission can be described classically. Moreover, we discuss and clarify the role of infrared physics in purification. ","Black Hole Evaporation, Quantum Hair and Supertranslations"
"  We consider a hybrid scalar field which is non-minimally coupled to the matter and models a chameleon cosmology. By introducing an effective potential, we study the dependence of the effective potential's minimum and hybrid chameleon field's masses to the local matter density. In a dynamical system technique, we analyze the phase space of this two-field chameleon model, find its fixed points and study their stability. We show that the hybrid chameleon domination solution is a stable attractor and the universe in this setup experiences a phantom divide crossing. ",Cosmological dynamics of a hybrid chameleon scenario
"  Collinearity and near-collinearity of predictors cause difficulties when doing regression. In these cases, variable selection becomes untenable because of mathematical issues concerning the existence and numerical stability of the regression coefficients, and interpretation of the coefficients is ambiguous because gradients are not defined. Using a differential geometric interpretation, in which the regression coefficients are interpreted as estimates of the exterior derivative of a function, we develop a new method to do regression in the presence of collinearities. Our regularization scheme can improve estimation error, and it can be easily modified to include lasso-type regularization. These estimators also have simple extensions to the ""large $p$, small $n$"" context. ",Regression on manifolds: Estimation of the exterior derivative
"  Most existing feature learning methods optimize inflexible handcrafted features and the affinity matrix is constructed by shallow linear embedding methods. Different from these conventional methods, we pretrain a generative neural network by stacking convolutional autoencoders to learn the latent data representation and then construct an affinity graph with them as a prior. Based on the pretrained model and the constructed graph, we add a self-expressive layer to complete the generative model and then fine-tune it with a new loss function, including the reconstruction loss and a deliberately defined locality-preserving loss. The locality-preserving loss designed by the constructed affinity graph serves as prior to preserve the local structure during the fine-tuning stage, which in turn improves the quality of feature representation effectively. Furthermore, the self-expressive layer between the encoder and decoder is based on the assumption that each latent feature is a linear combination of other latent features, so the weighted combination coefficients of the self-expressive layer are used to construct a new refined affinity graph for representing the data structure. We conduct experiments on four datasets to demonstrate the superiority of the representation ability of our proposed model over the state-of-the-art methods. ",Generative approach to unsupervised deep local learning
"  Recently, it has been showed that a slow expansion, which is asymptotically a static state in infinite past and may be described as an evolution with \epsilon \ll -1, of early universe may lead to the generation of primordial perturbation responsible for the structure formation of observable universe. However, its feasibility depends on whether the growing mode of Bardeen potential before phase transition can be inherited by the constant mode of curvature perturbation after phase transition. In this note, we phenomenally regard this slow expansion as that driven by multi NEC violating scalar fields. We calculate the curvature perturbation induced by the entropy perturbation before phase transition, and find that the spectrum is naturally scale invariant with a slight red tilt. The result has an interesting similarity to that of slow roll inflation. ",Primordial Perturbations During a Slow Expansion
"  We give a 2-approximation algorithm for Non-Uniform Sparsest Cut that runs in time $n^{O(k)}$, where $k$ is the treewidth of the graph. This improves on the previous $2^{2^k}$-approximation in time $\poly(n) 2^{O(k)}$ due to Chlamt\'a\v{c} et al.   To complement this algorithm, we show the following hardness results: If the Non-Uniform Sparsest Cut problem has a $\rho$-approximation for series-parallel graphs (where $\rho \geq 1$), then the Max Cut problem has an algorithm with approximation factor arbitrarily close to $1/\rho$. Hence, even for such restricted graphs (which have treewidth 2), the Sparsest Cut problem is NP-hard to approximate better than $17/16 - \epsilon$ for $\epsilon > 0$; assuming the Unique Games Conjecture the hardness becomes $1/\alpha_{GW} - \epsilon$. For graphs with large (but constant) treewidth, we show a hardness result of $2 - \epsilon$ assuming the Unique Games Conjecture.   Our algorithm rounds a linear program based on (a subset of) the Sherali-Adams lift of the standard Sparsest Cut LP. We show that even for treewidth-2 graphs, the LP has an integrality gap close to 2 even after polynomially many rounds of Sherali-Adams. Hence our approach cannot be improved even on such restricted graphs without using a stronger relaxation. ",Sparsest Cut on Bounded Treewidth Graphs: Algorithms and Hardness   Results
"  Discrete symmetries, parity, time reversal, antipodal, and charge conjugation transformations for spinor field in de Sitter space, are presented in the ambient space notation, i.e. in a coordinate independent way. The PT and PCT transformations are also discussed in this notation. The five-current density is studied and their transformation under the discrete symmetries is discussed. ",Discrete Symmetries for Spinor Field in de Sitter Space
"  We characterize the sets of norm one vectors $\mathbf{x}_1,\ldots,\mathbf{x}_k$ in a Hilbert space $\mathcal H$ such that there exists a $k$-linear symmetric form attaining its norm at $(\textbf{x}_1,\ldots,\mathbf{x}_k)$. We prove that in the bilinear case, any two vectors satisfy this property. However, for $k\ge 3$ only collinear vectors satisfy this property in the complex case, while in the real case this is equivalent to $\mathbf{x}_1,\ldots,\mathbf{x}_k$ spanning a subspace of dimension at most 2. We use these results to obtain some applications to symmetric multilinear forms, symmetric tensor products and the exposed points of the unit ball of $\mathcal L_s(^k\mathcal{H})$. ",Symmetric multilinear forms on Hilbert spaces: where do they attain   their norm?
"  A calculational framework is proposed for phylogenetics, using nonlocal quantum field theories in hypercubic geometry. Quadratic terms in the Hamiltonian give the underlying Markov dynamics, while higher degree terms represent branching events. The spatial dimension L is the number of leaves of the evolutionary tree under consideration. Momentum conservation modulo ${\mathbb Z}_{2}^{times L}$ in $L \leftarrow 1$ scattering corresponds to tree edge labelling using binary L-vectors. The bilocal quadratic term allows for momentum-dependent rate constants - only the tree(s) compatible with selected nonzero edge rates contribute to the branching probability distribution. Applications to models of evolutionary branching processes are discussed. ",Quantum Field Theory and Phylogenetic Branching
"  We explore brane induced gravity on a 3-brane in six locally flat dimensions. To regulate the short distance singularities in the brane core, we resolve the thin brane by a cylindrical 4-brane, with the geometry of 4D Minkowski $\times$ a circle, which has an axion flux to cancel the vacuum pressure in the compact direction. We discover a large diversity of possible solutions controlled by the axion flux, as governed by its boundary conditions. Hence brane induced gravity models really give rise to a {\it landscape} of vacua, at least semiclassically. For sub-critical tensions, the crossover scale, below which gravity may look 4D, and the effective 4D gravitational coupling are sensitive to vacuum energy. This shows how the vacuum energy problem manifests in brane induced gravity: instead of tuning the 4D curvature, generically one must tune the crossover scale. On the other hand, in the near-critical limit, branes live inside very deep throats which efficiently compactify the angular dimension. In there, 4D gravity first changes to $5D$, and only later to $6D$. The crossover scale saturates at the gravitational see-saw scale, independent of the tension. Using the fields of static loops on a wrapped brane, we check the perturbative description of long range gravity below the crossover scale. In sub-critical cases the scalars are strongly coupled already at the crossover scale even in the vacuum, because the brane bending is turned on by the axion flux. Near the critical limit, linearized perturbation theory remains under control below the crossover scale, and we find that linearized gravity around the vacuum looks like a scalar-tensor theory. ",Charting the Landscape of Modified Gravity
"  By using the reduction technique to impulsive differential equations [1], we rigorously prove the presence of chaos in dynamic equations on time scales (DETS). The results of the present study are based on the Li-Yorke definition of chaos. This is the first time in the literature that chaos is obtained for DETS. An illustrative example is presented by means of a Duffing equation on a time scale. ",Li-Yorke chaos in hybrid systems on a time scale
"  Identifying important scholarly literature at an early stage is vital to the academic research community and other stakeholders such as technology companies and government bodies. Due to the sheer amount of research published and the growth of ever-changing interdisciplinary areas, researchers need an efficient way to identify important scholarly work. The number of citations a given research publication has accrued has been used for this purpose, but these take time to occur and longer to accumulate. In this article, we use altmetrics to predict the short-term and long-term citations that a scholarly publication could receive. We build various classification and regression models and evaluate their performance, finding neural networks and ensemble models to perform best for these tasks. We also find that Mendeley readership is the most important factor in predicting the early citations, followed by other factors such as the academic status of the readers (e.g., student, postdoc, professor), followers on Twitter, online post length, author count, and the number of mentions on Twitter, Wikipedia, and across different countries. ",Early Indicators of Scientific Impact: Predicting Citations with   Altmetrics
"  The anomalous Hall effect (AHE) is a non-linear Hall effect appearing in magnetic conductors, boosted by internal magnetism beyond what is expected from the ordinary Hall effect. With the recent discovery of the quantized version of the AHE, the quantum anomalous Hall effect (QAHE), in Cr- or V-doped topological insulator (TI) (Sb,Bi)$_2$Te$_3$ thin films, the AHE in magnetic TIs has been attracting significant interest. However, one of the puzzles in this system has been that while Cr- or V-doped (Sb,Bi)$_2$Te$_3$ and V-doped Bi$_2$Se$_3$ exhibit AHE, Cr-doped Bi$_2$Se$_3$ has failed to exhibit even ferromagnetic AHE, the expected predecessor to the QAHE, though it is the first material predicted to exhibit the QAHE. Here, we have successfully implemented ferromagnetic AHE in Cr-doped Bi$_2$Se$_3$ thin films by utilizing a surface state engineering scheme. Surprisingly, the observed ferromagnetic AHE in the Cr-doped Bi$_2$Se$_3$ thin films exhibited only positive slope regardless of the carrier type. We show that this sign problem can be explained by the intrinsic Berry curvature of the system as calculated from a tight-binding model combined with a first-principles method. ",Ferromagnetic Anomalous Hall Effect in Cr-doped Bi$_2$Se$_3$ Thin Films   via Surface-State Engineering
"  Lumped-element kinetic inductance detectors (LEKIDs) are an attractive technology for millimeter-wave observations that require large arrays of extremely low-noise detectors. We designed, fabricated and characterized 64-element (128 LEKID) arrays of horn-coupled, dual-polarization LEKIDs optimized for ground-based CMB polarimetry. Our devices are sensitive to two orthogonal polarizations in a single spectral band centered on 150 GHz with $\Delta\nu/\nu=0.2$. The $65\times 65$ mm square arrays are designed to be tiled into the focal plane of an optical system. We demonstrate the viability of these dual-polarization LEKIDs with laboratory measurements. The LEKID modules are tested with an FPGA-based readout system in a sub-kelvin cryostat that uses a two-stage adiabatic demagnetization refrigerator. The devices are characterized using a blackbody and a millimeter-wave source. The polarization properties are measured with a cryogenic stepped half-wave plate. We measure the resonator parameters and the detector sensitivity, noise spectrum, dynamic range, and polarization response. The resonators have internal quality factors approaching $1\times 10^{6}$. The detectors have uniform response between orthogonal polarizations and a large dynamic range. The detectors are photon-noise limited above 1 pW of absorbed power. The noise-equivalent temperatures under a 3.4 K blackbody load are $<100~\mu\mathrm{K\sqrt{s}}$. The polarization fractions of detectors sensitive to orthogonal polarizations are >80%. The entire array is multiplexed on a single readout line, demonstrating a multiplexing factor of 128. The array and readout meet the requirements for 4 arrays to be read out simultaneously for a multiplexing factor of 512. This laboratory study demonstrates the first dual-polarization LEKID array optimized for CMB polarimetry and shows the readiness of the detectors for on-sky observations. ",Design and performance of dual-polarization lumped-element kinetic   inductance detectors for millimeter-wave polarimetry
  The results of many experiments on a search of fractionally charged particles in cosmic rays have been reviewed. The registered by ATIC and PAMELA experiments change of the proton energy spectrum at about 250 GeV can be explained if fractionally charged particles with another energy spectrum slope actually mixed with protons but cannot be separated because of a strong dE/dx fluctuations. The performed simulations show that multilayer detectors can seriously help in such separation. In the Aragats experiment performed using multilayer proportional counter combined with hadron calorimeter a group of 4e/3 like events with unexpectedly high average energy has been registered. It could be explained by their different from regular hadrons energy spectrum. The ATIC experiment ionization spectrum in single charged particle area has been examined. An interesting bump in 2e/3 charge region was observed. The events in the bump have very different from regular protons angular distribution. ,Fractionally charged particles in cosmic rays
  Quantum isometry groups of spectral triples associated with approximately finite-dimensional C*-algebras are shown to arise as inductive limits of quantum symmetry groups of corresponding truncated Bratteli diagrams. This is used to determine explicitly the quantum isometry group of the natural spectral triple on the algebra of continuous functions on the middlethird Cantor set. It is also shown that the quantum symmetry groups of finite graphs or metric spaces coincide with the quantum isometry groups of the corresponding classical objects equipped with natural Laplacians. ,Quantum Isometry Groups of 0- Dimensional Manifolds
"  We explore the benefits of using a passively evolving population of galaxies to measure the evolution of the rate of structure growth between z=0.25 and z=0.65 by combining data from the SDSS-I/II and SDSS-III surveys. The large-scale linear bias of a population of dynamically passive galaxies, which we select from both surveys, is easily modeled. Knowing the bias evolution breaks degeneracies inherent to other methodologies, and decreases the uncertainty in measurements of the rate of structure growth and the normalization of the galaxy power-spectrum by up to a factor of two. If we translate our measurements into a constraint on sigma_8(z=0) assuming a concordance cosmological model and General Relativity (GR), we find that using a bias model improves our uncertainty by a factor of nearly 1.5. Our results are consistent with a flat Lambda Cold Dark Matter model and with GR. ",The clustering of galaxies in the SDSS-III Baryon Oscillation   Spectroscopic Survey: measuring structure growth using passive galaxies
  We prove that Thompson's group F is not minimally almost convex with respect to any generating set which is a subset of the standard infinite generating set for F and which contains x_1. We use this to show that F is not almost convex with respect to any generating set which is a subset of the standard infinite generating set. ,Convexity properties of Thompson's group F
"  We present a simple, semi-analytical model to compute the mass functions of dark matter subhaloes. The masses of subhaloes at their time of accretion are obtained from a standard merger tree. During the subsequent evolution, the subhaloes experience mass loss due to the combined effect of dynamical friction, tidal stripping, and tidal heating. Rather than integrating these effects along individual subhalo orbits, we consider the average mass loss rate, where the average is taken over all possible orbital configurations. This allows us to write the average mass loss rate as a simple function that depends only on redshift and on the instantaneous mass ratio of subhalo and parent halo. After calibrating the model by matching the subhalo mass function (SHMF) of cluster-sized dark matter haloes obtained from numerical simulations, we investigate the predicted mass and redshift dependence of the SHMF.We find that, contrary to previous claims, the subhalo mass function is not universal. Instead, both the slope and the normalization depend on the ratio of the parent halo mass, M, and the characteristic non-linear mass M*. This simply reflects a halo formation time dependence; more massive parent haloes form later, thus allowing less time for mass loss to operate. We analyze the halo-to-halo scatter, and show that the subhalo mass fraction of individual haloes depends most strongly on their accretion history in the last Gyr. Finally we provide a simple fitting function for the average SHMF of a parent halo of any mass at any redshift and for any cosmology, and briefly discuss several implications of our findings. ",The Mass Function and Average Mass Loss Rate of Dark Matter Subhaloes
"  We show that stationary characters on irreducible lattices $\Gamma < G$ of higher-rank connected semisimple Lie groups are conjugation invariant, that is, they are genuine characters. This result has several applications in representation theory, operator algebras, ergodic theory and topological dynamics. In particular, we show that for any such irreducible lattice $\Gamma < G$, the left regular representation $\lambda_\Gamma$ is weakly contained in any weakly mixing representation $\pi$. We prove that for any such irreducible lattice $\Gamma < G$, any uniformly recurrent subgroup (URS) of $\Gamma$ is finite, answering a question of Glasner-Weiss. We also obtain a new proof of Peterson's character rigidity result for irreducible lattices $\Gamma < G$. The main novelty of our paper is a structure theorem for stationary actions of lattices on von Neumann algebras. ",Stationary characters on lattices of semisimple Lie groups
"  In the first part of the paper we study the reflexivity of Sobolev spaces on non-compact and not necessarily reversible Finsler manifolds. Then, by using direct methods in the calculus of variations, we establish uniqueness, location and rigidity results for singular Poisson equations involving the Finsler-Laplace operator on Finsler-Hadamard manifolds having finite reversibility constant. ",Singular Poisson equations on Finsler-Hadamard manifolds
"  This work considers the distributed computation of the one-to-one vertex correspondences between two undirected and connected graphs, which is called \textit{graph matching}, over multi-agent networks. Given two \textit{isomorphic} and \textit{asymmetric} graphs, there is a unique permutation matrix that maps the vertices in one graph to the vertices in the other. Based on a convex relaxation of graph matching in Aflalo et al. (2015), we propose a distributed computation of graph matching as a distributed convex optimization problem subject to equality constraints and a global set constraint, using a network of multiple agents whose interaction graph is connected. Each agent in the network only knows one column of each of the adjacency matrices of the two graphs, and all agents collaboratively learn the graph matching by exchanging information with their neighbors. The proposed algorithm employs a projected primal-dual gradient method to handle equality constraints and a set constraint. Under the proposed algorithm, the agents' estimates of the permutation matrix converge to the optimal permutation globally and exponentially fast. Finally, simulation results are given to illustrate the effectiveness of the method. ",Distributed Computation of Graph Matching in Multi-Agent Networks
"  We develop a novel framework to study smooth and strongly convex optimization algorithms, both deterministic and stochastic. Focusing on quadratic functions we are able to examine optimization algorithms as a recursive application of linear operators. This, in turn, reveals a powerful connection between a class of optimization algorithms and the analytic theory of polynomials whereby new lower and upper bounds are derived. Whereas existing lower bounds for this setting are only valid when the dimensionality scales with the number of iterations, our lower bound holds in the natural regime where the dimensionality is fixed. Lastly, expressing it as an optimal solution for the corresponding optimization problem over polynomials, as formulated by our framework, we present a novel systematic derivation of Nesterov's well-known Accelerated Gradient Descent method. This rather natural interpretation of AGD contrasts with earlier ones which lacked a simple, yet solid, motivation. ",On Lower and Upper Bounds for Smooth and Strongly Convex Optimization   Problems
"  The development of quantum information theory has renewed interest in the idea that the state vector does not represent the state of a quantum system, but rather the knowledge or information that we may have on the system. I argue that this epistemic view of states appears to solve foundational problems of quantum mechanics only at the price of being essentially incomplete. ",Why Should we Interpret Quantum Mechanics?
"  We present a comparison of a recently proposed model, which describes the Deeply Virtual Compton Scattering amplitude, to the HERA data. ",Deeply virtual Compton scattering and generalized parton distributions
"  It is well known that, whenever $k$ divides $n$, the complete $k$-uniform hypergraph on $n$ vertices can be partitioned into disjoint perfect matchings. Equivalently, the set of $k$-subsets of an $n$-set can be partitioned into parallel classes so that each parallel class is a partition of the $n$-set. This result is known as Baranyai's theorem, which guarantees the existence of \emph{Baranyai partitions}. Unfortunately, the proof of Baranyai's theorem uses network flow arguments, making this result non-explicit. In particular, there is no known method to produce Baranyai partitions in time and space that scale linearly with the number of hyperedges in the hypergraph. It is desirable for certain applications to have an explicit construction that generates Baranyai partitions in linear time. Such an efficient construction is known for $k=2$ and $k=3$. In this paper, we present an explicit recursive quadrupling construction for $k=4$ and $n=4t$, where $t \equiv 0,3,4,6,8,9 ~(\text{mod}~12)$. In a follow-up paper (Part II), the other values of~$t$, namely $t \equiv 1,2,5,7,10,11 ~(\text{mod}~12)$, will be considered. ","Explicit Baranyai Partitions for Quadruples, Part I: Quadrupling   Constructions"
"  A proof for the lower bound is provided for the smallest eigenvalue of finite element equations with arbitrary conforming simplicial meshes. The bound has a similar form as the one by Graham and McLean [SIAM J. Numer. Anal., 44 (2006), pp. 1487--1513] but doesn't require any mesh regularity assumptions, neither global nor local. In particular, it is valid for highly adaptive, anisotropic, or non-regular meshes without any restrictions. In three and more dimensions, the bound depends only on the number of degrees of freedom $N$ and the H\""older mean $M_{1-d/2} (\lvert \tilde{\omega} \rvert / \lvert \omega_i \lvert)$ taken to the power $1-2/d$, $\lvert \tilde{\omega} \rvert$ and $\lvert \omega_i \rvert$ denoting the average mesh patch volume and the volume of the patch corresponding to the $i^{\text{th}}$ mesh node, respectively. In two dimensions, the bound depends on the number of degrees of freedom $N$ and the logarithmic term $(1 + \lvert \ln (N \lvert \omega_{\min} \rvert) \rvert)$, $\lvert \omega_{\min} \rvert$ denoting the volume of the smallest patch. Provided numerical examples demonstrate that the bound is more accurate and less dependent on the mesh non-uniformity than the previously available bounds. ",Sharp bounds on the smallest eigenvalue of finite element equations with   arbitrary meshes without regularity assumptions
"  We study noise sensitivity of the consensus opinion of the voter model on finite graphs, with respect to noise affecting the initial opinions and noise affecting the dynamics.   We prove that the final opinion is stable with respect to small perturbations of the initial configuration, and is sensitive to perturbations of the dynamics governing the evolution of the process.   Our proofs rely on the duality relationship between the voter model and coalescing random walks, and on a precise description of this evolution when we have coupled dynamics. ",Dynamical noise sensitivity for the voter model
"  Federated learning allows us to distributively train a machine learning model where multiple parties share local model parameters without sharing private data. However, parameter exchange may still leak information. Several approaches have been proposed to overcome this, based on multi-party computation, fully homomorphic encryption, etc.; many of these protocols are slow and impractical for real-world use as they involve a large number of cryptographic operations. In this paper, we propose the use of Trusted Execution Environments (TEE), which provide a platform for isolated execution of code and handling of data, for this purpose. We describe Flatee, an efficient privacy-preserving federated learning framework across TEEs, which considerably reduces training and communication time. Our framework can handle malicious parties (we do not natively solve adversarial data poisoning, though we describe a preliminary approach to handle this). ",Flatee: Federated Learning Across Trusted Execution Environments
"  In the Israel-Stewart's theory of second order hydrodynamics, we have simulated $\sqrt{s}$=2.76 TeV Pb+Pb collisions. ALICE data for the centrality dependence of charged particles multiplicity, $p_T$ spectra in 0-5% collisions, centrality dependence of integrated and differential elliptic flow are analysed. Analysis indicate that while ALICE data on charged particles multiplicity or $p_T$ spectra do not demand any viscosity, viscosity is demanded by the elliptic flow data. From a simulataneous fit to all the data sets, viscosity to entropy ratio in $\sqrt{s}_{NN}$=2.76 TeV Pb+Pb collisions is extracted as, $\eta/s=0.06\pm 0.02$. ",Charged particle's elliptic flow in 2+1D viscous hydrodynamics at LHC   ($\sqrt{s}$= 2.76 TeV) energy in Pb+Pb collision
"  We analyze Assessment Voting, a new two-round voting procedure that can be applied to binary decisions in democratic societies. In the first round, a randomly-selected number of citizens cast their vote on one of the two alternatives at hand, thereby irrevocably exercising their right to vote. In the second round, after the results of the first round have been published, the remaining citizens decide whether to vote for one alternative or to ab- stain. The votes from both rounds are aggregated, and the final outcome is obtained by applying the majority rule, with ties being broken by fair randomization. Within a costly voting framework, we show that large elec- torates will choose the preferred alternative of the majority with high prob- ability, and that average costs will be low. This result is in contrast with the literature on one-round voting, which predicts either higher voting costs (when voting is compulsory) or decisions that often do not represent the preferences of the majority (when voting is voluntary). ",Assessment Voting in Large Electorates
"  Most of the sources detected in the extreme ultraviolet (EUV; 100 Ang to 600 Ang) by the Rosat WFC and EUVE all-sky surveys have been identified with active late-type stars and hot white dwarfs that are near enough to escape absorption by interstellar gas. However, about 15% of EUV sources are as of yet unidentified with any optical counterparts. We examine whether the unidentified EUV sources may consist of the same population of late-type stars and white dwarfs. We present B and R photometry of stars in the fields of seven of the unidentified EUV sources. We detect in the optical the entire main-sequence and white-dwarf population out to the greatest distances where they could still avoid absorption. We use colour-magnitude diagrams to demonstrate that, in most of the fields, none of the observed stars have the colours and magnitudes of late-type dwarfs at distances less than 100 pc. Similarly, none are white dwarfs within 500 pc that are hot enough to be EUV-emitters. The unidentified EUV sources we study are not detected in X-rays, while cataclysmic variables, X-ray binaries, and active galactic nuclei generally are. We conclude that some of the EUV sources may be a new class of nearby objects, that are either very faint at optical bands or which mimic the colours and magnitudes of distant late-type stars or cool white dwarfs. One candidate for optically faint objects is isolated old neutron stars, slowly accreting interstellar matter. Such neutron stars are expected to be abundant in the Galaxy, and have not been unambiguously detected. ",Evidence for a New Class of Extreme UV Sources
"  We present a brief overview of some recent observations of colliding galaxies and relevant numerical simulations. These are compared, and details of the locations and history of collision induced star formation are explored, with possible application to star formation at earlier epochs. ",Galaxy Collisions and Star Formation
"  Solar wind electron velocity distributions at 1 au consist of a thermal ""core"" population and two suprathermal populations: ""halo"" and ""strahl"". The core and halo are quasi-isotropic, whereas the strahl typically travels radially outwards along the parallel and/or anti-parallel direction with respect to the interplanetary magnetic field. With Cluster-PEACE data, we analyse energy and pitch angle distributions and use machine learning techniques to provide robust classifications of these solar wind populations. Initially, we use unsupervised algorithms to classify halo and strahl differential energy flux distributions to allow us to calculate relative number densities, which are of the same order as previous results. Subsequently, we apply unsupervised algorithms to phase space density distributions over ten years to study the variation of halo and strahl breakpoint energies with solar wind parameters. In our statistical study, we find both halo and strahl suprathermal breakpoint energies display a significant increase with core temperature, with the halo exhibiting a more positive correlation than the strahl. We conclude low energy strahl electrons are scattering into the core at perpendicular pitch angles. This increases the number of Coulomb collisions and extends the perpendicular core population to higher energies, resulting in a larger difference between halo and strahl breakpoint energies at higher core temperatures. Statistically, the locations of both suprathermal breakpoint energies decrease with increasing solar wind speed. In the case of halo breakpoint energy, we observe two distinct profiles above and below 500 km/s. We relate this to the difference in origin of fast and slow solar wind. ",Statistics of Solar Wind Electron Breakpoint Energies Using Machine   Learning Techniques
"  High resolution geospatial data are challenging because standard geostatistical models based on Gaussian processes are known to not scale to large data sizes. While progress has been made towards methods that can be computed more efficiently, considerably less attention has been devoted to big data methods that allow the description of complex relationships between several outcomes recorded at high resolutions by different sensors. Our Bayesian multivariate regression models based on spatial multivariate trees (SpamTrees) achieve scalability via conditional independence assumptions on latent random effects following a treed directed acyclic graph. Information-theoretic arguments and considerations on computational efficiency guide the construction of the tree and the related efficient sampling algorithms in imbalanced multivariate settings. In addition to simulated data examples, we illustrate SpamTrees using a large climate data set which combines satellite data with land-based station data. Source code is available at https://github.com/mkln/spamtree ",Spatial Multivariate Trees for Big Data Bayesian Regression
"  In the theory of dilute magnetic impurities in superconductors, the effect of all impurity spin-components is expressed via a single magnetic scattering rate $\Gamma_\mathrm{m}$. In a more realistic setting, magnetic impurities are anisotropic. In this case, the spatial randomness of three spin-components of impurities gives rise to generally different scattering rates $\Gamma_i$ ($i=1,2,3$). We explore the effects of anisotropic magnetic impurities on the in-plane critical field in 2D superconductors. We discuss singlet, triplet and parity-mixed order parameters allowed in systems without the inversion center. Also, the addition of a small amount of magnetic impurities may cause singlet to triplet crossovers. In all cases, different components of impurity spin affect the magnetic field -- temperature phase diagram differently. We show that anisotropy of the magnetic impurities can serve as a probe of unconventional triplet or parity-mixed superconductivity. ",Magnetic impurities in thin films and 2D Ising superconductors
"  Fast rotation is responsible for important changes in the structure and evolution of stars. Optical long baseline interferometry now permits the study of its effects on the stellar surface, mainly gravity darkening and flattening. We aim to determine the fundamental parameters of the fast-rotating star Altair, in particular its evolutionary stage, mass, and differential rotation, using state-of-the-art stellar interior and atmosphere models together with interferometric, spectroscopic, and asteroseismic observations. We use ESTER 2D stellar models to produce the relevant surface parameters needed to create intensity maps from atmosphere models. Interferometric and spectroscopic observables are computed from these intensity maps and several stellar parameters are then adjusted using the MCMC algorithm Emcee. We determined Altair's equatorial radius to be 2.008 +/- 0.006 Rsun, the position angle 301.1 +/- 0.3 degrees, the inclination 50.7 +/- 1.2 degrees, and the equatorial angular velocity 0.74 +/- 0.01 times the Keplerian angular velocity. This angular velocity leads to a flattening of 0.220 +/- 0.003. We also deduce from the spectroscopically derived vsini ~ 243 km/s, a true equatorial velocity of ~314 km/s corresponding to a rotation period of 7h46m (~3 c/d). The data also impose a strong correlation between mass, metallicity, hydrogen abundance, and core evolution. Thanks to asteroseismic data, we constrain the mass of Altair to 1.86 +/- 0.03 Msun and further deduce its metallicity Z = 0.019 and its core hydrogen mass fraction Xc = 0.71, assuming an initial solar hydrogen mass fraction X = 0.739. These values suggest that Altair is ~100 Myrs old. Finally, the 2D ESTER model also gives the internal differential rotation of Altair, showing that its core rotates approximately 50% faster than the envelope, while the surface differential rotation does not exceed 6%. ",A realistic two-dimensional model of Altair
"  In this work we propose a novel campaign for constraining relativistically compact MACHO dark matter, such as primordial black holes (PBHs), using the moon as a detector. PBHs of about $10^{19} \textrm{ g}$ to $10^{22} \textrm{ g}$ may be sufficiently abundant to have collided with the moon in the history of the solar system. We show that the crater profiles of a PBH collision differ from traditional impactors and may be detectable in high resolution lunar surface scans now available. Any candidates may serve as sites for in situ measurements to identify high pressure phases of matter which may have formed near the PBH during the encounter. While we primarily consider PBH dark matter, the discussion generalises to the entire family of MACHO candidates with relativistic compactness. Moreover, we focus on the Moon since it has been studied well, but the same principles can be applied to other rocky bodies in our solar system without an atmosphere. ",Crater Morphology of Primordial Black Hole Impacts
  The non-chiral edge excitations of quantum spin Hall systems and topological insulators are described by means of their partition function. The stability of topological phases protected by time-reversal symmetry is rediscussed in this context and put in relation with the existence of discrete anomalies and the lack of modular invariance of the partition function. The $\Z_2$ characterization of stable topological insulators is extended to systems with interacting and non-Abelian edge excitations. ,Partition Functions and Stability Criteria of Topological Insulators
"  Motivated by the response pattern for property specifications and applications within flexible workflow management systems, we report upon an initial study of modal and mixed transition systems in which the must transitions are interpreted as must eventually, and in which implementations can contain may behaviors that are resolved at run-time. We propose Transition Systems with Responses (TSRs) as a suitable model for this study. We prove that TSRs correspond to a restricted class of mixed transition systems, which we refer to as the action-deterministic mixed transition systems. We show that TSRs allow for a natural definition of deadlocked and accepting states. We then transfer the standard definition of refinement for mixed transition systems to TSRs and prove that refinement does not preserve deadlock freedom. This leads to the proposal of safe refinements, which are those that preserve deadlock freedom. We exemplify the use of TSRs and (safe) refinements on a small medication workflow. ",Refinement for Transition Systems with Responses
"  We present ARC2 (Astrophysically Robust Correction 2), an open-source Python-based systematics-correction pipeline to correct for the Kepler prime mission long cadence light curves. The ARC2 pipeline identifies and corrects any isolated discontinuities in the light curves, then removes trends common to many light curves. These trends are modelled using the publicly available co-trending basis vectors, within an (approximate) Bayesian framework with `shrinkage' priors to minimise the risk of over-fitting and the injection of any additional noise into the corrected light curves, while keeping any astrophysical signals intact. We show that the ARC2 pipeline's performance matches that of the standard Kepler PDC-MAP data products using standard noise metrics, and demonstrate its ability to preserve astrophysical signals using injection tests with simulated stellar rotation and planetary transit signals. Although it is not identical, the ARC2 pipeline can thus be used as an open source alternative to PDC-MAP, whenever the ability to model the impact of the systematics removal process on other kinds of signal is important. ","Robust, open-source removal of systematics in Kepler data"
  We report a continuous variable key distribution system that achieves a final secure key rate of 3.45 kb/sec over a distance of 24.2 km of optical fiber. The protocol uses discrete signaling and post-selection to improve reconciliation speed and quantifies security by means of quantum state tomography. Polarization multiplexing and a frequency translation scheme permit transmission of a continuous wave local oscillator and suppression of noise from guided acoustic wave Brillouin scattering by more than 27 dB. ,A 24 km fiber-based discretely signaled continuous variable quantum key   distribution system
"  Femto-second techniques addressing phase transitions induced by optical pumps have allowed recently to put an ambitious goal to attend hidden states which are inaccessible and even unknown under equilibrium conditions. Recently (*), the group from Slovenia led by D. Mihailovic achieved a bistable switching to a hidden electronic state in TaS2. The state is stable until an erase procedure reverts it to the thermodynamic ground state. A notoriously intricate nature of this material requires to consider simultaneous evolution of electrons and holes as mobile charge carriers, and crystallized electrons modifiable by intrinsic defects (voids and interstitials); all that on the CDW background. Our model considers mutual transformations among the three reservoirs of electrons, together with the heat production, which are dictated by imbalances of three partial chemical potentials. The phenomenological approach sheds a light on a very complicated and not yet resolved physics of this material which includes interplaying effects like CDW, Wigner crystal, commensurability, polarons, and Mott state.   *) L. Stojchevska, I. Vaskivskyi, T. Mertelj, P. Kusar, D. Svetin, S. Brazovskii, and D. Mihailovic, Science, 344, 177 (2014); arXiv:1401.6786v3 ",Modeling of evolution of a complex electronic system to an ordered   hidden state: application to optical quench in TaS2
"  We discuss the decomposition of the zeta-determinant of the square of the Dirac operator into contributions coming from the different parts of the manifold. The easy case was worked in the previous paper of authors. Due to the assumptions made on the operators in the previous paper, we were able to avoid the presence of the small eigenvalues which provide the large time contibution to the determinant. In the present work we analyze the general case. We offer a detailed analysis of the contribution made by the small eigenvalues. ",Adiabatic decomposition of the zeta-determinant and Scattering theory
"  For long-pulse tokamaks, one of the main challenges in control strategy is to simultaneously reach multiple control objectives and to robustly handle in real-time (RT) unexpected events (off-normal-events -- ONEs) with a limited set of actuators. We have developed in our previous work a generic architecture of the plasma control system (PCS) including a supervisor and an actuator manager to deal with these issues. We present in this paper recent developments of real-time decision-making by the supervisor to switch between different control scenarios (normal, backup, shutdown, disruption mitigation, etc.) during the discharge, based on off-normal-event states. We first standardize the evaluation of ONEs and thereby simplify significantly the supervisor decision logic, as well as facilitate the modifications and extensions of ONE states in the future. The whole PCS has been implemented on the TCV tokamak, applied to disruption avoidance with density limit experiments, demonstrating the excellent capabilities of the new RT integrated strategy. ",Integrated real-time supervisory management for off-normal-event   handling and feedback control of tokamak plasmas
"  The spectral lineshape of spontaneous Rayleigh-Brillouin scattering in CO2 is studied in a range of pressures. The spectrum is influenced by the bulk viscosity, which is a relaxation phenomenon involving the internal degrees of freedom of the molecule. The associated relaxation rates can be compared to the frequency shift of the scattered light, which demands precise measurements of the spectral lineshape. We find the value of the bulk viscosity around 5.7 X 10^{-6} kg/(ms) for the range of pressures p= 2-4 bar and for conditions of room temperature. ",Rayleigh-Brillouin scattering of carbon dioxide
"  We describe arrangements of ions capable of producing short-range attractive interactions between pairs of charged colloidal spheres in the low temperature strongly correlated limit. For particles of radius $R$ with bare charge $Z$ and comparable absorbed charge $-N$ ($N \sim Z$), the correlations contribution to the spheres self-energy scales as $N^{3/2}/R$, and as $N/R$ for the interaction energy between two touching spheres. We show that the re-arrangement of charges due to polarization plays an insignificant role in the nature and magnitude of the interaction. ",Attractions between charged colloidal spheres mediated by correlated   absorbed ions
"  Thanks to high-resolution and non-dispersive spectrometers onboard future X-ray missions such as XRISM and Athena, we are finally poised to answer important questions about the formation and evolution of galaxies and large-scale structure. However, we currently lack an adequate understanding of many atomic processes behind the spectral features we will soon observe. Large error bars on parameters as critical as transition energies and atomic cross sections can lead to unacceptable uncertainties in the calculations of e.g., elemental abundance, velocity, and temperature. Unless we address these issues, we risk limiting the full scientific potential of these missions. Laboratory astrophysics, which comprises theoretical and experimental studies of the underlying physics behind observable astrophysical processes, is therefore central to the success of these missions. ",Unlocking the Capabilities of Future High-Resolution X-ray Spectroscopy   Missions Through Laboratory Astrophysics
"  Inspired by the fact that different modalities in videos carry complementary information, we propose a Multimodal Semantic Attention Network(MSAN), which is a new encoder-decoder framework incorporating multimodal semantic attributes for video captioning. In the encoding phase, we detect and generate multimodal semantic attributes by formulating it as a multi-label classification problem. Moreover, we add auxiliary classification loss to our model that can obtain more effective visual features and high-level multimodal semantic attribute distributions for sufficient video encoding. In the decoding phase, we extend each weight matrix of the conventional LSTM to an ensemble of attribute-dependent weight matrices, and employ attention mechanism to pay attention to different attributes at each time of the captioning process. We evaluate algorithm on two popular public benchmarks: MSVD and MSR-VTT, achieving competitive results with current state-of-the-art across six evaluation metrics. ",Multimodal Semantic Attention Network for Video Captioning
"  A vortex line, shaped by a zigzag of pinning centers, is described here through a three-dimensional unit cell containing two pinning centers positioned symmetrically with respect to its center. The unit cell is a cube of side $L=12\xi$, the pinning centers are insulating spheres of radius $R$, taken within the range $0.2\xi$ to $3.0\xi$, $\xi$ being the coherence length. We calculate the free energy density of these systems in the framework of the Ginzburg-Landau theory. ",Energy dependence of a vortex line length near a zigzag of pinning   centers
"  In this paper we report the evaluation of an optical lattice clock based on neutral mercury down to a relative uncertainty of $1.7\times 10^{-16}$. Comparing this characterized frequency standard to a Cs atomic fountain we determine the absolute frequency of the $^1S_0 \rightarrow \phantom{}^3P_0$ transition of $^{199}$Hg as $\nu_{\mathrm{Hg}} = 1 128\,575\,290\,808\,154.62\,$Hz $\pm\,0.19\,$Hz (statistical) $\pm\,0.38\,$Hz (systematic), limited solely by the realization of the SI second. Furthermore, by comparing the mercury optical lattice clock to a Rb atomic fountain, we determine for the first time to our knowledge the ratio between the $^{199}$Hg clock transition and the $^{87}$Rb ground state hyperfine transition. Finally we present a direct optical to optical measurement of the $^{199}$Hg/$^{87}$Sr frequency ratio. The obtained value of $\nu_{\mathrm{Hg}}/\nu_{\mathrm{Sr}}=2.629\,314\,209\,898\,909\,15$ with a fractional uncertainty of $1.8\times10^{-16}$ is in excellent agreement with the same measurement obtained by Yamanaka et al. (arXiv:1503.07941). This makes this frequency ratio one of the few physical quantities agreed upon by different laboratories to this level of uncertainty. Frequency ratio measurements of the kind of those reported in this paper have a strong impact for frequency metrology but also for fundamental physics as they can be used to monitor putative variations of fundamental constants. ",Comparing a mercury optical lattice clock with microwave and optical   frequency standards
"  Denial of Service (DoS) is a security threat which compromises the confidentiality of information stored in Local Area Networks (LANs) due to unauthorized access by spoofed IP addresses. SYN Flooding is a type of DoS which is harmful to network as the flooding of packets may delay other users from accessing the server and in severe cases, the server may need to be shut down, wasting valuable resources, especially in critical real-time services such as in e-commerce and the medical field. The objective of this paper is to review the state-of-the art of detection mechanisms for SYN flooding. The detection schemes for SYN Flooding attacks have been classified broadly into three categories - detection schemes based on the router data structure, detection schemes based on statistical analysis of the packet flow and detection schemes based on artificial intelligence. The advantages and disadvantages for various detection schemes under each category have been critically examined. The performance measures of the categories have also been compared. ",Review of syn-flooding attack detection mechanism
"  We show that a four-parameter generating solution for a general class of four-dimensional, spherically-symmetric, static, dyonic BPS saturated solutions of leading-order effective equations of toroidally compactified heterotic or type II superstring theory are exact string solutions. The corresponding ten-dimensional background defines a conformal sigma-model which is a particular case of a `chiral null model' with curved `transverse' part. The exact conformal invariance is a consequence of the chiral null structure of the `electric' part of the model and the N=4 world-sheet supersymmetry of its transverse `magnetic' part. The sigma-model action has a remarkable covariance under both target space and the electromagnetic $S$-duality transformations, and it illustrates the relation between string-string duality in six dimensions and $S$-duality in four dimensions. In general, there exists a large class of exact six-dimensional superstring solutions described by chiral null models with four-dimensional transverse parts represented by N=4 supersymmetric sigma-models with metrics conformal to hyper-Kahler ones. ",General class of BPS saturated dyonic black holes as exact superstring   solutions
"  We present a panoramic view of the utility of coarse-grained (CG) models to study folding and functions of proteins and RNA. Drawing largely on the methods developed in our group over the last twenty years, we describe a number of key applications ranging from folding of proteins with disulfide bonds to functions of molecular machines. After presenting the theoretical basis that justifies the use of CG models, we explore the biophysical basis for the emergence of a finite number of folds from lattice models. The lattice model simulations of approach to the folded state show that non-native interactions are relevant only early in the folding process - a finding that rationalizes the success of structure-based models that emphasize native interactions. Applications of off-lattice $C_{\alpha}$ and models that explicitly consider side chains ($C_{\alpha}$-SCM) to folding of $\beta$-hairpin and effects of macromolecular crowding are briefly discussed. Successful application of a new class of off-lattice model, referred to as the Self-Organized Polymer (SOP), is shown by describing the response of Green Fluorescent Protein (GFP) to mechanical force. The utility of the SOP model is further illustrated by applications that clarify the functions of the chaperonin GroEL and motion of the molecular motor kinesin. We also present two distinct models for RNA, namely, the Three Site Interaction (TIS) model and the SOP model, that probe forced unfolding and force quench refolding of a simple hairpin and {\it Azoarcus} ribozyme. The predictions based on the SOP model show that force-induced unfolding pathways of the ribozyme can be dramatically changed by varying the loading rate. We conclude with a discussion of future prospects for the use of coarse-grained models in addressing problems of outstanding interest in biology. ",Minimal models for proteins and RNA: From folding to function
"  We study a system of self-propelled disks that perform run-and-tumble motion, where particles can adopt more than one internal state. One of those internal states can be transmitted to another particle if the particle carrying this state maintains physical contact with another particle for a finite period of time. We refer to this process as a reaction process and to the different internal states as particle species making an analogy to chemical reactions. The studied system may fall into an absorbing phase, where due to the disappearance of one of the particle species no further reaction can occur or remain in an active phase where particles constantly react. Combining individual-based simulations and mean-field arguments, we study the dependence of the equilibrium densities of particle species with motility parameters, specifically the active speed $v_0$ and tumbling frequency $\lambda$. We find that the equilibrium densities of particle species exhibit two very distinct, non-trivial scaling regimes with $v_0$ and $\lambda$ depending on whether the system is in the so-called ballistic or diffusive regime. Our mean-field estimates lead to an effective renormalization of reaction rates that allow building the phase-diagram $v_0$--$\lambda$ that separates the absorbing and active phase. We find an excellent agreement between numerical simulations and estimates. This study is a necessary step to an understanding of phase transitions into an absorbing state in active systems and sheds light on the spreading of information/signaling among moving elements. ",Reaction processes among self-propelled particles
"  On August 17, 2017, the first gravitational wave signal from a binary neutron star inspiral (GW170817) was detected by Advanced LIGO and Advanced VIRGO. Here we present radioactive $\beta$-decay rates of three independent sources $^{44}$Ti, $^{60}$Co and $^{137}$Cs, monitored during the same period by a precision experiment designed to investigate the decay of long-lived radioactive sources. We do not find any significant correlations between decay rates in a 5\,h time interval following the GW170817 observation. This contradicts a previous claim published in this journal of an observed 2.5$\sigma$ Pearson Correlation between fluctuations in the number of observed decays from two $\beta$-decaying isotopes ($^{32}$Si and $^{36}$Cl) in the same time interval. By correcting for the choice of an arbitrary time interval, we find no evidence of a correlation above 1.5$\sigma$ confidence. In addition, we argue that such analyses on correlations in arbitrary time intervals should always correct for the so-called Look-Elsewhere effect by quoting the global significance. ",Testing claims of the GW170817 binary neutron star inspiral affecting   $\beta$-decay rates
"  Simulations of magnetization dynamics in a multiscale environment enable rapid evaluation of the Landau-Lifshitz-Gilbert equation in a mesoscopic sample with nanoscopic accuracy in areas where such accuracy is required. We have developed a multiscale magnetization dynamics simulation approach that can be applied to large systems with spin structures that vary locally on small length scales. To implement this, the conventional micromagnetic simulation framework has been expanded to include a multiscale solving routine. The software selectively simulates different regions of a ferromagnetic sample according to the spin structures located within in order to employ a suitable discretization and use either a micromagnetic or an atomistic model. To demonstrate the validity of the multiscale approach, we simulate the spin wave transmission across the regions simulated with the two different models and different discretizations. We find that the interface between the regions is fully transparent for spin waves with frequency lower than a certain threshold set by the coarse scale micromagnetic model with no noticeable attenuation due to the interface between the models. As a comparison to exact analytical theory, we show that in a system with Dzyaloshinskii-Moriya interaction leading to spin spiral, the simulated multiscale result is in good quantitative agreement with the analytical calculation. ",Multiscale Model Approach for Magnetization Dynamics Simulations
"  Within the standard accretion disk theory for active galactic nuclei (AGN), the observed X-rays are often modeled by Compton up-scattering of ultraviolet (UV) disk photons inside a hot disk corona. Here, we point out that for many AGN, radiation pressure due to the very same UV disk photons can drive a flow from the disk into the corona and couple the processes producing X-rays and UV photons. This coupling could lead to quenching of the disk corona because the regions above the UV disk will be too dense, too opaque, and consequently too cold. We discuss various consequences of this new type of the X-ray/UV coupling on the dynamical and radiative properties of AGN. ",On how much X-ray and UV radiation processes are coupled in accretion   disks: AGN case
"  Invisible plasma content in blazar jets such as protons and/or thermal electron-positron ($e^{\pm}$) pairs is explored through combined arguments of dynamical and radiative processes. By comparing physical quantities required by the internal shock model with those obtained through the observed broadband spectra for Mrk 421, we obtain that the ratio of the Lorentz factors of a pair of cold shells resides in about $2\sim 20$, which implies that the shocks are at most mildly relativistic. Using the obtained Lorentz factors, the total mass density $\rho$ in the shocked shells is investigated. The upper limit of $\rho$ is obtained from the condition that thermal bremsstrahlung emission should not exceed the observed $\gamma$-ray luminosity, whilst the lower limit is constrained from the condition that the energy density of non-thermal electrons is smaller than that of the total plasma. Then we find $\rho$ is $10^2$-$10^3$ times heavier than that of non-thermal electrons for pure $e^{\pm}$ pairs, while $10^2$-$10^6$ times heavier for pure electron-proton ($e/p$) content, implying the existence of a large amount of invisible plasma. The origin of the continuous blazar sequence is shortly discussed and we speculate that the total mass density and/or the blending ratio of $e^{\pm}$ pairs and $e/p$ plasma could be new key quantities for the origin of the sequence. ",On invisible plasma content in radio-loud AGNs: The case of TeV blazar   Markarian 421
"  The density matrix renormalization group (DMRG) approach is arguably the most successful method to numerically find ground states of quantum spin chains. It amounts to iteratively locally optimizing matrix-product states, aiming at better and better approximating the true ground state. To date, both a proof of convergence to the globally best approximation and an assessment of its complexity are lacking. Here we establish a result on the computational complexity of an approximation with matrix-product states: The surprising result is that when one globally optimizes over several sites of local Hamiltonians, avoiding local optima, one encounters in the worst case a computationally difficult NP-hard problem (hard even in approximation). The proof exploits a novel way of relating it to binary quadratic programming. We discuss intriguing ramifications on the difficulty of describing quantum many-body systems. ",Computational Difficulty of Global Variations in the Density Matrix   Renormalization Group
"  Let $p>5$ be a prime. Motivated by the known formulae $\sum_{k=1}^\infty(-1)^k/(k^3\binom{2k}{k})=-2\zeta(3)/5$ and $\sum_{k=0}^\infty \binom{2k}{k}^2/((2k+1)16^k)=4G/\pi$$ (where $G=\sum_{k=0}^\infty(-1)^k/(2k+1)^2$ is the Catalan constant), we show that $$\sum_{k=1}^{(p-1)/2}\frac{(-1)^k}{k^3\binom{2k}{k}}\equiv-2B_{p-3}\pmod{p},$$ $$\sum_{k=(p+1)/2}^{p-1}\frac{\binom{2k}{k}^2}{(2k+1)16^k}\equiv-\frac 7{4}p^2B_{p-3}\pmod{p^3}$$, and $$\sum_{k=0}^{(p-3)/2}\frac{\binom{2k}{k}^2}{(2k+1)16^k} \equiv-2q_p(2)-pq_p(2)^2+\frac{5}{12}p^2B_{p-3}\pmod{p^3},$$ where $B_0,B_1,\ldots$ are Bernoulli numbers and $q_p(2)$ is the Fermat quotient $(2^{p-1}-1)/p$. ",p-adic congruences motivated by series
  We present an exact solution that describes collision of electromagnetic shock waves coupled with axion plane waves. The axion has a rather special coupling to the cross polarization term of the metric. The initial data on the null surfaces is well-defined and collision results in a singularity free interaction region. Our solution is a generalization of the Bell-Szekeres solution in the presence of an axion field. ,Collision of Electromagnetic Shock Waves Coupled with Axion Waves: An   Example
  A probabilistic cellular automaton for cargo transport is presented that generalizes the totally asymmetric exclusion process with a defect from continuous time to parallel dynamics. It appears as an underlying principle in cellular automata for traffic flow with non-local jumps for the kinetic constraint to drive as fast as possible. The exactly solvable model shows a discontinuous phase transition between two regions with different cargo velocities. ,Phase transitions in cellular automata for cargo transport and   kinetically constrained traffic
  A modified perturbation theory in the strength of the nonlinear term is used to solve the Nonlinear Schroedinger Equation with a random potential. It is demonstrated that in some cases it is more efficient than other methods. Moreover we obtain error estimates. This approach can be useful for the solution of other nonlinear differential equations of physical relevance. ,A numerical and symbolical approximation of the Nonlinear Anderson Model
  Some phenomenological properties of the unidentified EGRET detections suggest that there are two distinct groups of galactic gamma-ray sources that might be associated with compact objects endowed with relativistic jets. We discuss different models for gamma-ray production in both microquasars with low- and high-mass stellar companions. We conclude that the parent population of low-latitude and halo variable sources might be formed by yet undetected microquasars and microblazars. ,Unidentified Gamma-Ray Sources and Microquasars
"  Adversarial attacks are valuable for providing insights into the blind-spots of deep learning models and help improve their robustness. Existing work on adversarial attacks have mainly focused on static scenes; however, it remains unclear whether such attacks are effective against embodied agents, which could navigate and interact with a dynamic environment. In this work, we take the first step to study adversarial attacks for embodied agents. In particular, we generate spatiotemporal perturbations to form 3D adversarial examples, which exploit the interaction history in both the temporal and spatial dimensions. Regarding the temporal dimension, since agents make predictions based on historical observations, we develop a trajectory attention module to explore scene view contributions, which further help localize 3D objects appeared with the highest stimuli. By conciliating with clues from the temporal dimension, along the spatial dimension, we adversarially perturb the physical properties (e.g., texture and 3D shape) of the contextual objects that appeared in the most important scene views. Extensive experiments on the EQA-v1 dataset for several embodied tasks in both the white-box and black-box settings have been conducted, which demonstrate that our perturbations have strong attack and generalization abilities. ",Spatiotemporal Attacks for Embodied Agents
"  In this paper we present an approach to quadratic structures in derived algebraic geometry. We define derived n-shifted quadratic complexes, over derived affine stacks and over general derived stacks, and give several examples of those. We define the associated notion of derived Clifford algebra, in all these contexts, and compare it with its classical version, when they both apply. Finally, we prove three main existence results for derived shifted quadratic forms over derived stacks, define a derived version of the Grothendieck-Witt group of a derived stack, and compare it to the classical one. ",Quadratic forms and Clifford algebras on derived stacks
"  The electronic properties of graphene have been intensively investigated over the last decade, and signatures of the remarkable features of its linear Dirac spectrum have been displayed using transport and spectroscopy experiments.   In contrast, the orbital magnetism of graphene, which is one of the most fundamental signature of the characteristic Berry phase of graphene's electronic wave functions, has not yet been measured in a single flake. In particular, the striking prediction of a divergent diamagnetic response at zero doping calls for an experimental test.   Using a highly sensitive Giant Magnetoresistance sensor (GMR) we have measured the gate voltage-dependent magnetization of a single graphene monolayer encapsulated between boron nitride crystals. The signal exhibits a diamagnetic peak at the Dirac point whose magnetic field and temperature dependences agree with theoretical predictions starting from the work of Mc Clure \cite{McClure1956}. Our measurements open a new field of investigation of orbital currents in graphene and 2D topological materials, offering a new means to monitor Berry phase singularities and explore correlated states generated by combined effects of Coulomb interactions, strain or moir\'e potentials. ",Detection of graphene's divergent orbital diamagnetism at the Dirac   point
"  We consider the quadratic optimization problem $\max_{x \in C}\ x^T Q x + q^T x$, where $C\subseteq\mathbb{R}^n$ is a box and $r := \mathrm{rank}(Q)$ is assumed to be $\mathcal{O}(1)$ (i.e., fixed). We show that this case can be solved in polynomial time for an arbitrary $Q$ and $q$. The idea is based on a reduction of the problem to enumeration of faces of a certain zonotope in dimension $O(r)$. This paper generalizes previous results where $Q$ had been assumed to be positive semidefinite and no linear term was allowed in the objective function. Positive definiteness was a strong restriction and it is now relaxed. Generally, the problem is NP-hard; this paper describes a new polynomially solvable class of instances, larger than those known previously. ",A new polynomially solvable class of quadratic optimization problems   with box constraints
"  In this paper we study well-posedness of a second order SPDE with multiplicative noise on the torus $\T =[0,2\pi]$. The equation is considered in $L^p(\O\times(0,T);L^q(\T))$ for $p,q\in (1, \infty)$. It is well-known that if the noise is of gradient type, one needs a stochastic parabolicity condition on the coefficients for well-posedness with $p=q=2$. In this paper we investigate whether the well-posedness depends on $p$ and $q$. It turns out that this condition does depend on $p$, but not on $q$. Moreover, we show that if $1<p<2$ the classical stochastic parabolicity condition can be weakened. ",Is the stochastic parabolicity condition dependent on $p$ and $q$?
"  Liquid capillary-bridge formation between solid particles has a critical influence on the rheological properties of granular materials and, in particular, on the efficiency of fluidized bed reactors. The available analytical and semi-analytical methods have inherent limitations, and often do not cover important aspects, like the presence of non-axisymmetric bridges. Here, we conduct numerical simulations of the capillary bridge formation between equally and unequally-sized solid particles using the lattice Boltzmann method, and provide an assessment of the accuracy of different families of analytical models. We find that some of the models taken into account are shown to perform better than others. However, all of them fail to predict the capillary force for contact angles larger than $\pi/2$, where a repulsive capillary force attempts to push the solid particle outwards to minimize the surface energy, especially at a small separation distance. ",Capillary-bridge Forces Between Solid Particles: Insights from Lattice   Boltzmann Simulations
"  We study the one-loop effective potentials of the four-dimensional Lifshitz scalar field theory with the particular anisotropic scaling $z=2$, and show that the renormalization is possible without resort to the renormalization of the coupling constant due to the improvement of UV divergence. Moreover, the IR divergence can be also solved for the massless case of $m^2 =0$, because of the absence of the logarithmic divergence. For a massive case, we obtain a condition for the symmetry breaking. Finally, we investigate whether the critical temperature can exist or not in this approximation. The physical consequences of the other logarithmic divergence free model is discussed. ",Effective potentials in the Lifshitz scalar field theory
"  A feature of human creativity is the ability to take a subset of existing items (e.g. objects, ideas, or techniques) and combine them in various ways to give rise to new items, which, in turn, fuel further growth. Occasionally, some of these items may also disappear (extinction). We model this process by a simple stochastic birth--death model, with non-linear combinatorial terms in the growth coefficients to capture the propensity of subsets of items to give rise to new items. In its simplest form, this model involves just two parameters $(P, \alpha)$. This process exhibits a characteristic 'hockey-stick' behaviour: a long period of relatively little growth followed by a relatively sudden 'explosive' increase. We provide exact expressions for the mean and variance of this time to explosion and compare the results with simulations. We then generalise our results to allow for more general parameter assignments, and consider possible applications to data involving human productivity and creativity. ",Dynamics of a birth-death process based on combinatorial innovation
"  When two independent analog signals, X and Y are added together giving Z=X+Y, the entropy of Z, H(Z), is not a simple function of the entropies H(X) and H(Y), but rather depends on the details of X and Y's distributions. Nevertheless, the entropy power inequality (EPI), which states that exp [2H(Z)] \geq exp[2H(X)] + exp[2H(Y)], gives a very tight restriction on the entropy of Z. This inequality has found many applications in information theory and statistics. The quantum analogue of adding two random variables is the combination of two independent bosonic modes at a beam splitter. The purpose of this work is to give a detailed outline of the proof of two separate generalizations of the entropy power inequality to the quantum regime. Our proofs are similar in spirit to standard classical proofs of the EPI, but some new quantities and ideas are needed in the quantum setting. Specifically, we find a new quantum de Bruijin identity relating entropy production under diffusion to a divergence-based quantum Fisher information. Furthermore, this Fisher information exhibits certain convexity properties in the context of beam splitters. ",The entropy power inequality for quantum systems
"  Given two continuous functions $f,g:I\to\mathbb{R}$ such that $g$ is positive and $f/g$ is strictly monotone, a measurable space $(T,A)$, a measurable family of $d$-variable means $m: I^d\times T\to I$, and a probability measure $\mu$ on the measurable sets $A$, the $d$-variable mean $M_{f,g,m;\mu}:I^d\to I$ is defined by $$   M_{f,g,m;\mu}(\pmb{x})   :=\left(\frac{f}{g}\right)^{-1}\left(   \frac{\int_T f\big(m(x_1,\dots,x_d,t)\big) d\mu(t)}   {\int_T g\big(m(x_1,\dots,x_d,t)\big) d\mu(t)}\right)   \qquad(\pmb{x}=(x_1,\dots,x_d)\in I^d). $$ The aim of this paper is to study the local and global comparison problem of these means, i.e., to find conditions for the generating functions $(f,g)$ and $(h,k)$, for the families of means $m$ and $n$, and for the measures $\mu,\nu$ such that the comparison inequality $$   M_{f,g,m;\mu}(\pmb{x})\leq M_{h,k,n;\nu}(\pmb{x}) \qquad(\pmb{x}\in I^d) $$ be satisfied. ",On the local and global comparison of generalized Bajraktarevi\'c means
"  This paper presents a novel method to deal with the challenging task of generating photographic images conditioned on semantic image descriptions. Our method introduces accompanying hierarchical-nested adversarial objectives inside the network hierarchies, which regularize mid-level representations and assist generator training to capture the complex image statistics. We present an extensile single-stream generator architecture to better adapt the jointed discriminators and push generated images up to high resolutions. We adopt a multi-purpose adversarial loss to encourage more effective image and text information usage in order to improve the semantic consistency and image fidelity simultaneously. Furthermore, we introduce a new visual-semantic similarity measure to evaluate the semantic consistency of generated images. With extensive experimental validation on three public datasets, our method significantly improves previous state of the arts on all datasets over different evaluation metrics. ",Photographic Text-to-Image Synthesis with a Hierarchically-nested   Adversarial Network
"  We study the dynamics of Fermi-Pasta-Ulam chains with both harmonic and anharmonic power-law long-range interactions. We show that the dynamics is described in the continuum limit by a generalized fractional Boussinesq differential equation, whose derivation is performed in full detail. We also discuss a version of the model where couplings are alternating in sign. ",Fermi-Pasta-Ulam chains with harmonic and anharmonic long-range   interactions
"  Starting from a generalization of the quantum trajectory theory (based on the stochastic Schr\""odinger equation - SSE), non-Markovian models of quantum dynamics are derived. In order to describe non-Markovian effects, the approach used in this article is based on the introduction of random coefficients in the usual linear SSE. A major interest is that this allows to develop a consistent theory of quantum measurement in continuous time for these non-Markovian quantum trajectory models. In this context, the notions of instrument, a priori and a posteriori states are rigorously described. The key point is that by starting from a stochastic equation on the Hilbert space of the system, we are able to respect the complete positivity of the mean dynamics for the statistical operator and the requirements of the axioms of quantum measurement theory. The flexibility of the theory is next illustrated by a concrete physical model of a noisy oscillator where non Markovian effects come from random environment, coloured noises, randomness in the stimulating light, delay effects. The statistics of the emitted photons and the heterodyne and homodyne spectra are studied and we show how these quantities are sensible to the non-Markovian features of the system dynamics, so that, in principle, the observation and analysis of the fluorescence light could reveal the presence of non-Markovian effects and allow for a measure of the spectra of the noises affecting the system dynamics. ",Quantum trajectories: memory and continuous observation
  A short Technical Report of Multi-year Crop Mapping of Southeastern Anatolia Region of Turkey and its potential impacts on water use estimation. ,"Change of Cropping Patterns of Southeastern Anatolia, Turkey in 2019 and   2020"
"  The most important stages in designing a computer network in a wider geographical area include: definition of requirements, topological description, identification and calculation of relevant parameters (i.e. traffic matrix), determining the shortest path between nodes, quantification of the effect of various levels of technical and technological development of urban areas involved, the cost of technology, and the cost of services. These parameters differ for WAN networks in different regions - their calculation depends directly on the data ""in the field"": number of inhabitants, distance between populated areas, network traffic density, as well as available bandwidth. The main reason for identification and evaluation of these parameters is to develop a model that could meet the constraints imposed by potential beneficiaries. In this paper, we develop a methodology for planning and cost-modeling of a wide area network and validate it in a case study, under the supposition that behavioral interactions of individuals and groups play a significant role and have to be taken into consideration by employing either simple or composite indicators of socioeconomic status. ",On the Development of Methodology for Planning and Cost-Modeling of a   Wide Area Network
  Charge asymmetries in diffractive electroproduction of two mesons are proportional to the interference of Pomeron and Odderon exchange amplitudes. We calculate in the framework of QCD and in the Born approximation a forward-backward charge asymmetry which turns out to be sizable in a kinematical domain accessible to HERA experiments. We predict a distinctive dependence of this asymmetry on the invariant mass of the two pions. Testing this prediction is a crucial step in the discovery of the QCD-Odderon. ,Hunting the QCD-Odderon in hard diffractive electroproduction of two   pions
"  A general class of Markov processes with a local interaction is introduced, which includes exclusion and Kawasaki processes as a very particular case. Bernoulli invariant measures are found for this class of processes. ",Processes with a Local Deterministic Interaction: Invariant Bernoulli   Measures
"  Is it possible to generally construct a dynamical system to simulate a black system without recovering the equations of motion of the latter? Here we show that this goal can be approached by a learning machine. Trained by a set of input-output responses or a segment of time series of a black system, a learning machine can be served as a copy system to mimic the dynamics of various black systems. It can not only behave as the black system at the parameter set that the training data are made, but also recur the evolution history of the black system. As a result, the learning machine provides an effective way for prediction, and enables one to probe the global dynamics of a black system. These findings have significance for practical systems whose equations of motion cannot be approached accurately. Examples of copying the dynamics of an artificial neural network, the Lorenz system, and a variable star are given. Our idea paves a possible way towards copy a living brain. ",Copy the dynamics using a learning machine
"  The article comprises structural, microstructural, and physical properties analysis of Bi2Se3-xTex (x= 0, 1, 2 and 3) mixed topological insulator (MTI) single crystals. All the crystals were grown through a well-optimized solid-state reaction route via the self-flux method. These MTI are well characterized through XRD (X-ray Diffraction), SEM (Scanning Electron Microscopy), EDAX (Energy Dispersive spectroscopy), and thereby, the physical properties are analyzed through the RT (Resistance vs temperature) down to 10K as well as the magneto-resistance (MR) measurements (at 5K) in a magnetic field of up to 10 Tesla. The MR drastically varies from x=0 to x=3 in MTI, from a huge 400 percent, it goes down to 20 percent and 5 percent and eventually back to 315 percent. This fascinated behaviour of MR is explained in this article through HLN (Hikami-Larkin-Nagaoka) equation and an additional term. This article not only proposed the mesmerizing behavior of MR in MTI but also explains the reason through competing WAL (Weak Anti-Localization) and WL (Weak Localization) conduction processes. ","High Field Magneto-Transport of Mixed Topological Insulators Bi2Se3-xTex   (x = 0, 1, 2 & 3)"
"  In this note we find new relations in the mapping class group of a genus two surface with n boundary components for n=1,..., 8 which induce a genus two Lefschetz fibration $CP^2#13CP^2bar \to S^2$ with n disjoint sections. As a consequence, we observe any holomorphic genus 2 Lefschetz fibration without separating singular fibers admits a section. ",On sections of genus two Lefschetz fibrations
"  The goal of this paper is to take a single 2D image of a scene and recover the 3D structure in terms of a small set of factors: a layout representing the enclosing surfaces as well as a set of objects represented in terms of shape and pose. We propose a convolutional neural network-based approach to predict this representation and benchmark it on a large dataset of indoor scenes. Our experiments evaluate a number of practical design questions, demonstrate that we can infer this representation, and quantitatively and qualitatively demonstrate its merits compared to alternate representations. ","Factoring Shape, Pose, and Layout from the 2D Image of a 3D Scene"
"  In this paper, we study the existence of random periodic solutions for semilinear stochastic partial differential equations with multiplicative linear noise on a bounded open domain ${\cal O}\subset {\mathbb R}^d$ with smooth boundary. We identify them with the solutions of coupled forward-backward infinite horizon stochastic integral equations in $L^2({\cal O})$. We then use generalized Schauder's fixed point theorem, the relative compactness of Wiener-Sobolev spaces in $C^0([0, T], L^2(\Omega\times{\cal O}))$ and a localization argument to prove the existence of solutions of the infinite horizon integral equations, which immediately implies the existence of the random periodic solution to the corresponding SPDEs. As an example, we apply our result to the stochastic Allen-Cahn equation with a periodic potential and prove the existence of a random periodic solution using a localisation argument. ",Anticipating Random Periodic Solutions--II. SPDEs with Multiplicative   Linear Noise
"  We analyzed extensively the dynamics of polymer chains in solutions simulated with dissipative particle dynamics (DPD), with a special focus on the potential influence of a low Schmidt number of a typical DPD fluid on the simulated polymer dynamics. It has been argued that a low Schmidt number in a DPD fluid can lead to underdevelopment of the hydrodynamic interaction in polymer solutions. Our analyses reveal that equilibrium polymer dynamics in dilute solution, under a typical DPD simulation conditions, obey the Zimm model very well. With a further reduction in the Schmidt number, a deviation from the Zimm model to the Rouse model is observed. This implies that the hydrodynamic interaction between monomers is reasonably developed under typical conditions of a DPD simulation. Only when the Schmidt number is further reduced, the hydrodynamic interaction within the chains becomes underdeveloped. The screening of the hydrodynamic interaction and the excluded volume interaction as the polymer volume fraction is increased are well reproduced by the DPD simulations. The use of soft interaction between polymer beads and a low Schmidt number do not produce noticeable problems for the simulated dynamics at high concentrations, except that the entanglement effect which is not captured in the simulations. ",The Hydrodynamic Interaction in Polymer Solutions Simulated with   Dissipative Particle Dynamics
"  The paper is to classify irreducible integrable modules for the twisted full toroidal Lie algebra with some technical conditions. The twisted full toroidal Lie algebra are extensions of multiloop algebra twisted by sevaral finite order automorphisms. The result genaralizes a result by Fu Jiayuan and Cuipo Jiang, where they consider only one automorphism. ",On Integrable modules for the twisted full toroidal Lie algebra
"  We present parsec-scale kinematics of eleven nearby galactic nuclei, derived from adaptive-optics assisted integral-field spectroscopy at (near-infrared) CO band-head wavelengths. We focus our analysis on the balance between ordered rotation and random motions, which can provide insights into the dominant formation mechanism of nuclear star clusters (NSCs). We divide our target sample into late- and early-type galaxies, and discuss the nuclear kinematics of the two sub-samples, aiming at probing any link between NSC formation and host galaxy evolution. The results suggest that the dominant formation mechanism of NSCs is indeed affected by the different evolutionary paths of their hosts across the Hubble sequence. More specifically, nuclear regions in late-type galaxies are on average more rotation dominated, and the formation of nuclear stellar structures is potentially linked to the presence of gas funnelled to the center. Early-type galaxies, in contrast, tend to display slower-rotating NSCs with lower ellipticity. However, some exceptions suggest that in specific cases, early-type hosts can form NSCs in a way similar to spirals. ",Resolved nuclear kinematics link the formation and growth of nuclear   star clusters with the evolution of their early and late-type hosts
"  We present the results of the first high angular resolution observations of SiO maser emission towards the star forming region W51-IRS2 made with the Very Large Array (VLA) and Very Long Baseline Array (VLBA). Our images of the water maser emission in W51-IRS2 reveal two maser complexes bracketing the SiO maser source. One of these water maser complexes appears to trace a bow shock whose opening angle is consistent with the opening angle observed in the distribution of SiO maser emission. A comparison of our water maser image with an image constructed from data acquired 19 years earlier clearly shows the persistence and motion of this bow shock. The proper motions correspond to an outflow velocity of 80 km/s, which is consistent with the data of 19 years ago (that spanned 2 years). We have discovered a two-armed linear structure in the SiO maser emission on scales of ~25 AU, and we find a velocity gradient on the order of 0.1 km/s/AU along the arms. We propose that the SiO maser source traces the limbs of an accelerating bipolar outflow close to an obscured protostar. We estimate that the outflow makes an angle of <20 degrees with respect to the plane of the sky. Our measurement of the acceleration is consistent with a reported drift in the line-of-sight velocity of the W51 SiO maser source. ",Outflow 20--2000 AU from a High-Mass Protostar in W51-IRS2
"  In an influential critique of empirical practice, Freedman (2008) showed that the linear regression estimator was biased for the analysis of randomized controlled trials under the randomization model. Under Freedman's assumptions, we derive exact closed-form bias corrections for the linear regression estimator with and without treatment-by-covariate interactions. We show that the limiting distribution of the bias corrected estimator is identical to the uncorrected estimator, implying that the asymptotic gains from adjustment can be attained without introducing any risk of bias. Taken together with results from Lin (2013), our results show that Freedman's theoretical arguments against the use of regression adjustment can be completely resolved with minor modifications to practice. ",Exact Bias Correction for Linear Adjustment of Randomized Controlled   Trials
  We find a strong coupling expansion around the non-trivial extremum of the Yang-Mills action. It is shown that the developed formalism is the Gribov ambiguity free since each order of the developed perturbation theory is transparently gauge invariant. The success is a consequence of the restriction: calculations are not going beyond the norm of the $S$-matrix element. ,On elimination of the Gribov ambiguity
"  In terms of the complex angular momentum method, we compute the absorption cross section by analyzing a massless scalar field around conformally related black holes. At first, we investigate circular null geodesics and thereby prove a precondition for calculating the absorption cross section in the context of conformally related black holes. Then we use the WKB approximation method to derive the analytic expression of Regge frequency and the oscillation part of absorption cross section. We find that this oscillation part depends on the scale factor of conformal transformations. By taking the conformally related Schwarzschild-Tangherlini black hole as an example, we show that this regular black hole has substantially distinctive absorption behavior compared with singular black holes. Our result provides a new approach to distinguish a regular black hole from a singular one. ",Absorption cross section of regular black holes in scalar-tensor   conformal gravity
"  We demonstrate rotational excitation spectroscopy with the scanning tunneling microscope for physisorbed hydrogen and its isotopes hydrogen-deuterid and deuterium. The observed excitation energies are very close to the gas phase values and show the expected scaling with moment of inertia. Since these energies are characteristic for the molecular nuclear spin states we are able to identify the para and ortho species of hydrogen and deuterium, respectively. We thereby demonstrate nuclear spin sensitivity with unprecedented spatial resolution. ",Distinction of Nuclear Spin States with the Scanning Tunneling   Microscope
"  Element abundances of three roAp stars, HD 166473, HD 203932, and HD 217522, were determined using Kurucz model atmospheres with metal abundances scaled to solar ones and the results were compared with data from the literature concerning three further roAp stars, normal B and A stars and two lambda Bootis stars. Up to 38 elements could be identified and therefore, this work represents the most complete chemical investigation hitherto published, which can be summarized as follows:   - all investigated roAp stars have a similar abundance pattern,   - the overabundances of rare earth and other heavy elements are comparable to cool non-pulsating Ap-stars,   - iron belongs to the most deficient and cobalt to the most enhanced elements in the group of the iron peak elements, and   - the light elements carbon, nitrogen, and oxygen are less abundant than in atmospheres with abundances scaled to the Sun.   Beside an unexpected possible relation between effective temperature and metallicity of roAp stars, no outstanding differences from non-pulsating Ap stars could be detected. This statement, however, suffers from the lack of comparably detailed investigations of the latter. ",Chemical composition and fundamental parameters of roAp stars
"  We present the first edition of a catalog of variable stars from OGLE-II Galactic Bulge data covering 3 years: 1997-1999. Typically 200-300 I band data points are available in 49 fields between -11 and 11 degrees in galactic longitude, totaling roughly 11 square degrees in sky coverage. Photometry was obtained using the Difference Image Analysis (DIA) software and tied to the OGLE data base with the DoPhot package. The present version of the catalog comprises 221,801 light curves. In this preliminary work the level of contamination by spurious detections is still about 10%. Parts of the catalog have only crude calibration, insufficient for distance determinations. The next, fully calibrated, edition will include the data collected in year 2000. The data is accessible via FTP. Due to the data volume, we also distribute DAT tapes upon request. ","Difference Image Analysis of the OGLE-II Bulge Data. III. Catalog of   200,000 Candidate Variable Stars"
"  Using a Hamiltonian approach to gauged WZW models, we present a general method for computing the conformally exact metric and dilaton, to all orders in the $1/k$ expansion, for any bosonic, heterotic, or type-II superstring model based on a coset $G/H$. We prove the following relations: (i) For type-II superstrings the conformally exact metric and dilaton are identical to those of the non-supersymmetric {\it semi-classical} bosonic model except for an overall renormalization of the metric obtained by $k\to k- g$. (ii) The exact expressions for the heterotic superstring are derived from their exact bosonic string counterparts by shifting the central extension $k\to 2k-h$ (but an overall factor $(k-g)$ remains unshifted). (iii) The combination $e^\Phi\sqrt{-G}$ is independent of $k$ and therefore can be computed in lowest order perturbation theory as required by the correct formulation of a conformally invariant path integral measure. The general formalism is applied to the coset models $SO(d-1,2)_{-k}/SO(d-1,1)_{-k}$ that are relevant for string theory on curved spacetime. Explicit expressions for the conformally exact metric and dilaton for the cases $d=2,3,4$ are given. In the semiclassical limit $(k\to \infty)$ our results agree with those obtained with the Lagrangian method up to 1-loop in perturbation theory. ",Conformally Exact Metric and Dilaton in String Theory on Curved   Spacetime
"  For a cyclic group $G$ acting on a smooth variety $X$ with only one character occurring in the $G$-equivariant decomposition of the normal bundle of the fixed point locus, we study the derived categories of the orbifold $[X/G]$ and the blow-up resolution $\widetilde Y \to X/G$.   Some results generalise known facts about $X = A^n$ with diagonal $G$-action, while other results are new also in this basic case. In particular, if the codimension of the fixed point locus equals $|G|$, we study the induced tensor products under the equivalence $D^b(\widetilde Y) \cong D^b([X/G])$ and give a 'flop-flop=twist' type formula. We also introduce candidates for general constructions of categorical crepant resolutions inside the derived category of a given geometric resolution of singularities and test these candidates on cyclic quotient singularities. ",Derived categories of resolutions of cyclic quotient singularities
"  We cast the non--isentropic Einstein--Euler system into a symmetric hyperbolic form. Such systems are very suited to treat initial value problems of hyperbolic type. We obtain this form by using the pressure $p$ and not the density $\rho$ as a variable. However, the system becomes degenerate when the pressure $p$ approaches zero, and in these cases we regularise the system by replacing the pressure with an appropriate new matter variable, the Makino variable. ",The non-isentropic Einstein-Euler system written in a symmetric   hyperbolic form
"  The formation scenario of a gapped disk, i.e., transitional disk, and its asymmetry is still under debate. Proposed scenarios such as disk-planet interaction, photoevaporation, grain growth, anticyclonic vortex, eccentricity, and their combinations would result in different radial distributions of the gas and the small (sub-$\mu$m size) and large (millimeter size) dust grains as well as asymmetric structures in a disk. Optical/near-infrared (NIR) imaging observations and (sub-)millimeter interferometry can trace small and large dust grains, respectively; therefore multi-wavelength observations could help elucidate the origin of complicated structures of a disk. Here we report SMA observations of the dust continuum at 1.3~mm and $^{12}$CO~$J=2\rightarrow1$ line emission of the pre-transitional protoplanetary disk around the solar-mass star PDS~70. PDS~70, a weak-lined T Tauri star, exhibits a gap in the scattered light from its disk with a radius of $\sim$65~AU at NIR wavelengths. However, we found a larger gap in the disk with a radius of $\sim$80~AU at 1.3~mm. Emission from all three disk components (the gas and the small and large dust grains) in images exhibits a deficit in brightness in the central region of the disk, in particular, the dust-disk in small and large dust grains has asymmetric brightness. The contrast ratio of the flux density in the dust continuum between the peak position to the opposite side of the disk reaches 1.4. We suggest the asymmetries and different gap-radii of the disk around PDS~70 are potentially formed by several (unseen) accreting planets inducing dust filtration. ","The Structure of Pre-transitional Protoplanetary Disks. II. Azimuthal   Asymmetries, Different Radial Distributions of Large and Small Dust Grains in   PDS~70"
"  Nanoscale engineering and novel materials have created interesting effects in thermal transport. Thermal conductivity can now be different due to physical and heating sizes. Also, highly anisotropic thermal conductivity can result from unique material composition and geometries. Various experimental methods have been developed to measure these thermal conductivity variations. All of them require varying the physical size of the sample, the heating size or relative positions between heating and detection. Here, we numerically propose a time-domain optical method that uses spatial temporal temperature data to resolve anisotropic and size-dependent thermal conductivity. Our method is hassle-free as it does not vary any experimental parameters and is easily compatible with various methods of measuring temperature in the time domain. This technique can high throughput screening of thermal properties for nanoengineered and novel materials in thermal transport. Also, this technique can be used to identify novel effects in thermal transport within a single experiment. ",Hassle-free Approach to Thermal Transport Measurements Using   Spatial-Temporal Temperature Data
"  Despite its unusual payout structure, the Canadian 6/49 Lotto is one of the few government sponsored lotteries that has the potential for a favorable strategy we call ""buying the pot."" By buying the pot we mean that a syndicate buys each ticket in the lottery, ensuring that it holds a jackpot winner. We assume that the other bettors independently buy small numbers of tickets. This paper presents (1) a formula for the syndicate's expected return, (2) conditions under which buying the pot produces a significant positive expected return, and (3) the implications of these findings for lottery design. ",Does it Pay to Buy the Pot in the Canadian 6/49 Lotto? Implications for   Lottery Design
"  Kepler's orbits with corrections due to Special Relativity are explored using the Lagrangian formalism. A very simple model includes only relativistic kinetic energy by defining a Lagrangian that is consistent with both the relativistic momentum of Special Relativity and Newtonian gravity. The corresponding equations of motion are solved in a Keplerian limit, resulting in an approximate relativistic orbit equation that has the same form as that derived from General Relativity in the same limit and clearly describes three characteristics of relativistic Keplerian orbits: precession of perihelion; reduced radius of circular orbit; and increased eccentricity. The prediction for the rate of precession of perihelion is in agreement with established calculations using only Special Relativity. All three characteristics are qualitatively correct, though suppressed when compared to more accurate general-relativistic calculations. This model is improved upon by including relativistic gravitational potential energy. The resulting approximate relativistic orbit equation has the same form and symmetry as that derived using the very simple model, and more accurately describes characteristics of relativistic orbits. For example, the prediction for the rate of precession of perihelion of Mercury is one-third that derived from General Relativity. These Lagrangian formulations of the special-relativistic Kepler problem are equivalent to the familiar vector calculus formulations. In this Keplerian limit, these models are supposed to be physical based on the likeness of the equations of motion to those derived using General Relativity. The derivation of this orbit equation is approachable by undergraduate physics majors and nonspecialists whom have not had a course dedicated to relativity. ",Kepler's Orbits and Special Relativity in Introductory Classical   Mechanics
"  The DC electrical conductivity of an ultrarelativistic QED plasma is studied in real time by implementing the dynamical renormalization group. The conductivity is obtained from the realtime dependence of a dissipative kernel related to the retarded photon polarization. Pinch singularities in the imaginary part of the polarization are manifest as growing secular terms that in the perturbative expansion of this kernel. The leading secular terms are studied explicitly and it is shown that they are insensitive to the anomalous damping of hard fermions as a result of a cancellation between self-energy and vertex corrections. The resummation of the secular terms via the dynamical renormalization group leads directly to a renormalization group equation in real time, which is the Boltzmann equation for the (gauge invariant) fermion distribution function. A direct correspondence between the perturbative expansion and the linearized Boltzmann equation is established, allowing a direct identification of the self energy and vertex contributions to the collision term.We obtain a Fokker-Planck equation in momentum space that describes the dynamics of the departure from equilibrium to leading logarithmic order in the coupling.This determines that the transport time scale is given by t_{tr}=(24 pi)/[e^4 T \ln(1/e)}]. The solution of the Fokker-Planck equation approaches asymptotically the steady- state solution as sim e^{-t/(4.038 t_{tr})}.The steady-state solution leads to the conductivity sigma = 15.698 T/[e^2 ln(1/e)] to leading logarithmic order. We discuss the contributions beyond leading logarithms as well as beyond the Boltzmann equation. The dynamical renormalization group provides a link between linear response in quantum field theory and kinetic theory. ",Dynamical renormalization group approach to transport in   ultrarelativistic plasmas: the electrical conductivity in high temperature   QED
"  It is a well known fact that Dirac phenomenology of nuclear forces predicts the existence of large scalar and vector mean fields in matter. To analyse the relativistic self-energy in a model independent way, modern high precision nucleon-nucleon ($NN$) potentials are mapped on a relativistic operator basis using projection techniques. This allows to compare the various potentials at the level of covariant amplitudes were a remarkable agreement is found. It allows further to calculate the relativistic self-energy in nuclear matter in Hartree-Fock approximation. Independent of the choice of the nucleon-nucleon interaction large scalar and vector mean fields of several hundred MeV magnitude are generated at tree level. In the framework of chiral EFT these fields are dominantly generated by contact terms which occur at next-to-leading order in the chiral expansion. Consistent with Dirac phenomenology the corresponding low energy constants which generate the large fields are closely connected to the spin-orbit interaction in $NN$ scattering. The connection to QCD sum rules is discussed as well. ",The relativistic self-energy in nuclear dynamics
"  The first measurements of the scattering parameters of $\Lambda$K pairs in all three charge combinations ($\Lambda$K$^{+}$, $\Lambda$K$^{-}$, and $\Lambda\mathrm{K^{0}_{S}}$) are presented. The results are achieved through a femtoscopic analysis of $\Lambda$K correlations in Pb-Pb collisions at $\sqrt{s_{\mathrm{NN}}}$ = 2.76 TeV recorded by ALICE at the LHC. The femtoscopic correlations result from strong final-state interactions, and are fit with a parametrization allowing for both the characterization of the pair emission source and the measurement of the scattering parameters for the particle pairs. Extensive studies with the THERMINATOR 2 event generator provide a good description of the non-femtoscopic background, which results mainly from collective effects, with unprecedented precision. Furthermore, together with HIJING simulations, this model is used to account for contributions from residual correlations induced by feed-down from particle decays. The extracted scattering parameters indicate that the strong force is repulsive in the $\Lambda\rm{K}^{+}$ interaction and attractive in the $\Lambda\rm{K}^{-}$ interaction. The data hint that the and $\Lambda\rm{K}^{0}_{S}$ interaction is attractive, however the uncertainty of the result does not permit such a decisive conclusion. The results suggest an effect arising either from different quark-antiquark interactions between the pairs ($\rm s\overline{s}$ in $\Lambda$K$^{+}$ and $\rm u\overline{u}$ in $\Lambda$K$^{-}$) or from different net strangeness for each system (S = 0 for $\Lambda$K$^{+}$, and S = $-2$ for $\Lambda$K$^{-}$). Finally, the $\Lambda$K systems exhibit source radii larger than expected from extrapolation from identical particle femtoscopic studies. This effect is interpreted as resulting from the separation in space-time of the single-particle $\Lambda$ and K source distributions. ",$\Lambda\rm{K}$ femtoscopy in Pb-Pb collisions at $\sqrt{s_{\rm{NN}}}$ =   2.76 TeV
"  I discuss a new approach to constructing lattices for gauge theories with extended supersymmetry. The lattice theories themselves respect certain supersymmetries, which in many cases allows the target theory to be obtained in the continuum limit without fine-tuning. ",Recent Developments in Lattice Supersymmetry
"  We show that computing an equilibrium in atomic splittable congestion games with player-specific affine cost functions $l_{e,i}(x) = a_{e,i} x + b_{e,i}$ is $\mathsf{PPAD}$-complete. To prove that the problem is contained in $\mathsf{PPAD}$, we develop a homotopy method that traces an equilibrium for varying flow demands of the players. A key technique for this method is to describe the evolution of the equilibrium locally by a novel block Laplacian matrix. Using the properties of this matrix give rise to a path following formulation for computing an equilibrium where states correspond to supports that are feasible for some demands. A closer investigation of the block Laplacian system further allows to orient the states giving rise to unique predecessor and successor states thus putting the problem into $\mathsf{PPAD}$. For the $\mathsf{PPAD}$-hardness, we reduce from computing an approximate equilibrium of a bimatrix win-lose game. As a byproduct of our reduction we further show that computing a multi-class Wardrop equilibrium with class dependent affine cost functions is $\mathsf{PPAD}$-complete as well.   As another byproduct of our $\mathsf{PPAD}$-completeness proof, we obtain an algorithm that computes a continuum of equilibria parametrized by the players' flow demand. For player-specific costs, the algorithm runs in polynomial space. For games with player-independent costs, we obtain an algorithm computing all equilibria as a function of the flow demand that runs in time polynomial in the output. ",Complexity and Parametric Computation of Equilibria in Atomic Splittable   Congestion Games via Weighted Block Laplacians
"  In this paper, we detailedly describe our solution for the IEEE BigData Cup 2021: RL-based RecSys (Track 1: Item Combination Prediction). We first conduct an exploratory data analysis on the dataset and then utilize the findings to design our framework. Specifically, we use a two-headed transformer-based network to predict user feedback and unlocked sessions, along with the proposed session-aware reweighted loss, multi-tasking with click behavior prediction, and randomness-in-session augmentation. In the final private leaderboard on Kaggle, our method ranked 2nd with a categorization accuracy of 0.39224. ",Session-aware Item-combination Recommendation with Transformer Network
"  This paper develops a recent line of economic theory seeking to understand public goods economies using methods of topological analysis. Our first main result is a very clean characterization of the economy's core (the standard solution concept in public goods). Specifically, we prove that a point is in the core iff it is Pareto efficient, individually rational, and the set of points it dominates is path connected.   While this structural theorem has a few interesting implications in economic theory, the main focus of the second part of this paper is on a particular algorithmic application that demonstrates its utility. Since the 1960s, economists have looked for an efficient computational process that decides whether or not a given point is in the core. All known algorithms so far run in exponential time (except in some artificially restricted settings). By heavily exploiting our new structure, we propose a new algorithm for testing core membership whose computational bottleneck is the solution of $O(n)$ convex optimization problems on the utility function governing the economy. It is fairly natural to assume that convex optimization should be feasible, as it is needed even for very basic economic computational tasks such as testing Pareto efficiency. Nevertheless, even without this assumption, our work implies for the first time that core membership can be efficiently tested on (e.g.) utility functions that admit ""nice"" analytic expressions, or that appropriately defined $\varepsilon$-approximate versions of the problem are tractable (by using modern black-box $\varepsilon$-approximate convex optimization algorithms). ",Testing Core Membership in Public Goods Economies
